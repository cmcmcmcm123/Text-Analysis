Privacy-Preserving Two-Party Distributed Association Rules Mining on Horizontally

Abstract?In many applications, data mining has to be done in distributed data scenarios. In such situations, data owners may be concerned with the misuse of data; hence, they do not want their data to be mined, especially when these contain sensitive information. Privacy-preserving Data Mining (PPDM) aims to protect data privacy in the course of data mining. Privacy- preserving distributed association rules mining protocols have been developed for horizontally partitioned data scenarios with more than two participating parties. However, they depend on a secure multi-party summary and union computation, which cannot guarantee security while the number of participating parties is two. We use commutative encryption and design a secure division computation protocol as the core techniques to implement the protocols for the privacy-preserving two-party distributed mining of association rule mining. The protocols? security and performance are analyzed.



I. INTRODUCTION  Data mining has gradually become the core technology in decision-making tasks in recent years. While widely used, however, it is faced with many challenges [1]. Privacy preser- vation is one of these key challenges [2]. In many applications, data owners are concerned with the misuse of their data, and they do not want sensitive information to be mined. With such concerns in mind, they are not willing to provide their data for any data mining-related activities.

Significant privacy concerns in data mining also prevent the legitimate use of data. For example, the Data-Mining Moratorium Act of 2003, enacted by the Senate and House of Representatives of the United States of America, forbids the carrying out of data mini ng activities within the U.S.

Department of Defense unless it is for the purpose of searching public information or owing to particularized suspicion of an individual [3]. Data mining, however, may provide more insights from data, thus bringing huge economic and social interests. PPDM makes tradeoffs between data mining con- tributions and data privacy. It aims to carry out data mining precisely and efficiently while ensuring data privacy.

A. Related Work  PPDM research was initiated by two independent research papers [4], [5]. [4] addresses the PPDM task in the centralized  data storage scenario. It builds a decision-tree classifier from the training data in the values of individual records that have been perturbed. The main idea is to employ a novel recon- struction procedure to accurately estimate the distribution of original data values. By using these reconstructed distributions, it is possible to build a classifier whose accuracy is comparable to the accuracy of classifiers built with original data. Mean- while, [5] addresses the PPDM task in the distributed data storage scenario. It focuses on the issue of ID3 decision tree learning by building efficient cryptographic protocols based on secure multi-party computation. These two studies represent two different research directions in PPDM: One is based on the Randomized Perturbation Technique (RPT), and the other is based on the Cryptography-Based Technique. The former is mostly applied to centralized data storage scenarios, while the latter is generally used in distributed data storage scenarios.

PPDM has developed to be a major research direction in the field of data mining research in recent years. It has achieved significant results in many data mining areas, such as association rules [6], decision trees [5], clustering [7], outlier detection [8], bayesian networks [9], recommender systems [10], stream mining [11] and social network [12].

Besides, there is another PPDM technique called k- anonymity [23], which belongs to the privacy-preserving data publishing techniques. Its purpose is to prevent indirect identi- fication of records from public databases because combinations of record attributes can be used to exactly identify individual records. But k-anonymity is believed to be vulnerable. When there is little diversity in those sensitive attributes or attackers have additional background knowledge about the victim, k- anonymity encounters severe privacy problems [24]. ?-diversity [24] and t-closeness [25] are two subsequent techniques closely relative to k-anonymity and to relieve the problems.

However, all of them haven?t yet resolved the privacy chal- lenges. Many research results have indicated that the three closed relative privacy models are vulnerable to various privacy attacks and pride insufficient privacy protection [26], [27].

In recent years, differential privacy [28], [29], [30] has received considerable attention for PPDM. Differential privacy is a model aiming to provide privacy to statistical queries and pattern mining. It aims to provide means to maximize   DOI 10.1109/CLOUDCOM-ASIA.2013.87    DOI 10.1109/CLOUDCOM-ASIA.2013.87    DOI 10.1109/CLOUDCOM-ASIA.2013.87     the accuracy of queries or data mining while minimizing the chances of identifying its records. Laplace mechanism [29] and exponential mechanism [30] are two methods to implementing differential privacy under the scenarios of numeric outputs and discrete outputs. There have been considerable studies on applying differential privacy to PPDM so far [33], [34], [35], [36].

Our study has little relevance to these above papers, except that it is closely related to [13]. It can be seen as a subsequent work of [13]. In comparison with [36], it addresses a different problem with a different techniques, which is a encrypted one but not a differential privacy.

B. Motivations  [13] presented a method to perform privacy-preserving dis- tributed association rules mining protocols with the assumption of three or more parties at a horizontally partitioned data scenario. However, the method depends on a secure multi-party summary and union computation, which cannot guarantee security while the number of participating parties is two.

In [13], all final globally frequent itemsets (rules) are disclosed to all participating parties. In a two-party case, it may be argued that knowing an (a) itemset (rule) is supported globally but is not supported at one?s site reveals that the other site supports that itemset (rule). This leakage cannot be avoided.

However, we noticed in many cases that knowing whether or not a locally frequent itemset (rule) at one site is globally supported but not revealing this knowledge to the other site is worthy of investigation. For example, Walmart may want to know if the rule beer ? diaper is strong when putting it under consideration for a transaction union of Walmart and Target, but is not willing to reveal to Target that whether the rule beer ? diaper is a strong rule of itself or not; an owner may want to know if the frequent gene patterns in its gene database are still frequent under the combined database with another one, but is not willing to reveal to the other gene database its private data, such as the size of the gene database, and the frequent gene patterns themselves; such motivation does exist in a hospital where its president wants to know whether a nosogenesis generalized from large of patients still works on the combined two patients databases but with some privacy concerns.

Some researches are devoted to two-party security com- putation, such as [20] and [21]. [20] initiates the secure two- party computation and [21] gives its security proof. But they are all about the protocols for the general secure two-party computations, which are limited by their time complexity and are not applicable to concrete applications, such as data mining tasks [22]. Our study can be seen as a complement to [13], as well as a concrete application of the general secure two-party computation protocol in [20].

C. Contributions  To our knowledge, no studies have been conducted to address this gap in knowledge so far. In this study, therefore, we propose a secure division computation protocol based on commutative encryption. The proposed protocol works as the  core technique to build up protocols that perform privacy- preserving two-party distributed mining of association rule mining for the first time so far as we know, which constitute the major contributions of this paper. Since in the two-party case, knowing an itemset is supported globally but is not supported at one?s own site reveals that the other site supports the itemset, this work only needs to examine the problem by way of disclosing the global itemsets to the site at which they are frequent locally but hiding them from the other site.

D. Structure  The rest of the paper is organized as follows. Section II presents the problem definitions, basic preliminaries, and security infrastructures. Section III discusses secure multi- party association rule mining protocols and our proposed two-party protocol. The analysis of the proposed protocols? soundness and security is presented in Sections IV and V.

In Section VI, the performance analysis is shown. Finally, in Section VII, we conclude our paper and identify future work.



II. DEFINITIONS  In this section, we will give some basic definitions of As- sociation Rules Mining, Distributed Association Rules Mining, and Secure Distributed Association Rules Mining; and the security infrastructures, Commutative Encryption System on the mining problems.

A. Association Rules Mining  Let I = {i1, i2, ? ? ? , im} be a set of items. Let DB be a database of transactions, where each transaction T consists of a set of items such that T ? I .

The association rules mining problem can be defined as follows [14]: Let I = {i1, i2, ? ? ? , im} be a set of items. Let DB be a set of transactions, where each transaction T is an itemset such that T ? I . Given an itemset X ? I , a transaction T contains X if and only if X ? T . An association rule is an implication of the form X ? Y , where X ? I , Y ? I and X ? Y = ?. The rule X ? Y has support s in the transaction database DB if the probability of a transaction in DB containing both X and Y is s. The association rule holds in the transaction database DB with confidence c if the probability of a transaction in DB containing X and thus Y is c. An itemset X with k items is called a k-itemset.

The problem of mining association rules is that one must necessarily mind all rules whose support is greater than a minimum support threshold and whose confidence is above a minimum confidence threshold.

For an itemset X , its support is the percentage of trans- actions in a DB which contains X , and its support count, denoted by X.sup, is the number of transactions in DB containing X . An itemset X is frequent (or more precisely, frequently occurring) if its support is no less than the minimum support threshold. It has been shown that the problem of mining association rules can be reduced to two subproblems [14]: (1) Find all frequent itemsets for a given minimum support threshold, and (2) generate the association rules from the frequent itemsets found. Since (1) dominates the overall cost of the mining association rule, association rules mining research has focused on the development of efficient methods to solve the first subproblem.

TABLE I: Notation Table [15]  D Number of transaction in DB S Support threshold minsup  L(k) Globally frequent k-itemset CA(k) Candidate sets generated from L(k)

X.sup Global support count of X  Di Number of transactions in DBi GLi(k) globally frequent k-itemsets at Si CGi(k) Candidate sets generated from GLi(k?1) LLi(k) Locally frequent k-itemsets in CGi(k)

X.supi Local support count of X at Si  B. Distributed Association Rules Mining  This paper investigates the mining of association rules in a distributed environment. Let DB be a database with D transactions. Assume that there are n sites, S1, S2, ? ? ? , Sn, in a distributed system, and the database DB is partitioned over the n sites into {DB1, DB2, ? ? ? , DBn}, respectively.

Let the size of the partitions DBi be Di, for i = 1, ? ? ? , n.

Let X.sup be the global support count, and X.supi be the local support count of X at site Si. For a given minimum support threshold s, X is globally frequent if X.sup ? s?D; corre- spondingly, X is locally frequent at site Si, if X.supi ? s?Di.

In the following, L denotes the globally frequent itemsets in DB, and L(k) the globally frequent k-itemsets in L. The essential task of a distributed association rule mining algorithm is to find the globally frequent itemsets L.

A fast algorithm for distributed association rule mining is given in [15]. The procedure for the fast distributed mining of association rules (FDM) can be summarized below:  1. Candidate Sets Generation: Generate candidate sets CGi(k) based on GLi(k?1), itemsets that are supported by Si at the (k ? 1)th iteration, using the classic Apriori candidate generation algorithm. Each site generates candidates based on the intersection of globally frequent (k ? 1)-itemsets and locally frequent (k ? 1)-itemsets.

2. Local Pruning: For each X ? CGi(k), scan the database DBi at Si to compute X.supi. If X is not locally frequent at site Si, it is excluded from candidate sets LLi(k). (This pruning only removes X from the candidate set at site Si. X could still be a candidate set at some other site.)  3. Support Count Exchange: Broadcast the candidate set in LLi(k) to other sites in order to collect support count. Compute their global support counts and find all globally frequent k- itemsets in site Si.

4. Broadcast Mining Results: Broadcast the computed globally frequent k-itemsets to all the other sites. Some basic notations on distributed association rules mining are listed in Table 1.

C. Secure Distributed Association Rules Mining  Let n > 2 be the number of sites. Each site i has a private transaction database DBi. We are given support threshold s and confidence c as the percentages. The goal is to discover all itemsets (association rules) satisfying the thresholds, as defined in Section 2.2. We further desire that disclosure be limited: No site should learn the contents of a transaction at any other site,  what itemsets (rules) are supported by any other site, or the specific value of support/confidence for any itemset (rule) at any other site unless that information is revealed by knowledge of one?s own data and the final result.

The above is the definition in [13]. However, in the case of i = 2, we have stated in section 1 that knowing an (a) itemset (rule) is supported globally but is not supported at one?s site reveals that the other site supports that itemset (rule). This leakage cannot be avoided. So the definition for the two-party case is a little different; the purpose of our study is to design secure two-party association rules mining protocols to preserve the following data privacy:  1. the support and database size of each site are preserved not to be disclosed to the other site,  2. each site knows whether or not a locally frequent itemset (rule) at the own site is globally supported but not revealing this knowledge to the other site.

D. Commutative Encryption System  To implement the security of multi-party computation, a commutative encryption system is necessary. We define a commutative encryption system as follows [16]:  Definition 1 - Commutative Encryption System. An en- cryption system F = (M,K, f, g) (where M is the domain of plain and encrypted messages, K = (E,D), E, D are sets of encryption keys and decryption keys, respectively) is commutative if both the encryption function f : E?M ?M and the decryption function g : D?M ?M are computable functions in polynomial time, defined on finite computable domains, that satisfy all properties listed below. We denote fe(x) ? f(e, x), gd(x) ? g(d, x), and use ?r to signify is chosen uniformly at random from.

1. For all e1,e2,,en ? E, d1, d2, ? ? ? , dn ? D, each m ?M , we have  fei1 (fei2 (? ? ? (fein (m)) ? ? ? )) = fej1 (fej2 (? ? ? (fejn (m)) ? ? ? )) ? T and  gds1 (gds2 (? ? ? (gdsn (T )) ? ? ? )) = gdt1 (gdt2 (? ? ? (gdtn (T )) ? ? ? )), where (i1, i2, ? ? ? , in),(j1, j2, ? ? ? , jn),(s1, s2, ? ? ? , sn) and (t1, t2, ? ? ? , tn) are four permutations of (1, 2, ? ? ? , n).

2. For all e1,e2,? ? ? ,en ? E, all m1,m2 ? M such that m1 = m2 and big enough k, we have  pr(fe1(fe2(? ? ? (fen(m1)) ? ? ? )) = fe1(fe2(? ? ? (fen(m2)) ? ? ? ))) <  2k .

3. For x, y, z ?r M , e ?r E, the distribution of < x, fe(x), y, fe(y) > is indistinguishable from the distribution of < x, fe(x), y, z >.

Informally, Property 1 denotes that the ciphertext of com- positely commutative encryption is identical regardless of the encryption order. Property 2 signifies that two different plain messages will never have the same encrypted messages. Prop- erty 3 guarantees that the encryption is secure. Specifically, it states that given a plain message x and its randomly chosen encryption way fe(x), for a new plain message y, an adversary     cannot distinguish in polynomial time between fe(y) and a randomly chosen value z from the domain of encrypted messages. The adversary cannot identify in polynomial time which of the two plain messages has been encrypted as well.

Thus, the adversary can neither encrypt y nor decrypt fe(y) in polynomial time.

Some encryption systems satisfy these properties, such as DDH [17]. Interested readers can refer to [16] for more detailed applications.

E. Security in Semi-honest Model  In the following we give the definition of Secure Two-party Computation [22].

Definition 2 - (Privacy with respect to semi-honest be- havior): Let f : {0, 1}? ? {0, 1}? ? {0, 1}? ? {0, 1}? be a functionality, and f1(x, y) (resp., f2(x, y)) denotes the first (resp., second) element of f(x, y). Let  ? be a two-  party protocol for computing f . The view of the first (resp., second) party during and execution of  ? on (x, y), denoted  V IEW ?  1 (x, y) (resp. V IEW ?  2 (x, y)), is (x, r,m1, ? ? ? ,mt) (resp., (y, r,m1, ? ? ? ,mt)), where r represents the outcome of the first (resp., second) party?s internal coin tosses, and mi represents the i-th message it has received. The output of the first (resp., second) party after and execution of  ? on  (x, y), denoted OUTPUT ?  1 (x, y) (resp. OUTPUT ?  2 (x, y)), is implicit in the party?s own view of the execution, and  OUTPUT ?  (x, y) = (OUTPUT ?  1 (x, y), OUTPUT ?  2 (x, y)) .

We say that ?  privately computes f if there exist proba- bilistic polynomial-time algorithms, denoted S1 and S2, such that  {(S1(x, f1(x, y)), f2(x, y))}x,y?{0,1}? C? {(V IEW  ?  1 (x, y), OUTPUT ?  2 (x, y))}x,y?{0,1}?  {(S2(x, f2(x, y)), f1(x, y))}x,y?{0,1}? C? {(V IEW  ?  2 (x, y), OUTPUT ?  1 (x, y))}x,y?{0,1}? .

where C? denotes computational indistinguishability.

Definition 2 says that under semi-honest model, a protocol is said to securely (privately) compute f if the information obtained by every participated party after carrying out the pro- tocol, can be polynomially simulated through the participated party?s input and output.

This method is based on an assumption that the involved parties are semi-honest, i.e. they follow the rules of the protocol using its correct input, but is free to later use what it sees during execution of the protocol to deduce private information. In such model, a proof is secure if the view of each party during the execution of the protocol can be effectively simulated by the input and the output of the party, which is called simulation paradigm (mechanism) of security proof.

In our later proofs, we use a key theorem in the secure multiparty computation, the composition theorem. We state it here for the semi-honest model. A detailed discussion of this theorem, as well as the proof, can be found in [22].

Fig. 1: Determining global candidate itemsets [13]  Theorem 1 (Composition theorem for the semi-honest model) Suppose that g is privately reducible to f and that there exists a protocol for privately computing f . Then there exists a protocol for privately computing g.

In the theorem, ?g is privately reducible to f?implies that we can come up with a private protocol for evaluating function g given a black box access to function f . This allows us to use existing secure protocols as components, worrying only that their results do not reveal anything and ignoring the communications carried on by those components.



III. SECURE ASSOCIATION RULE MINING PROTOCOLS  In section 3.1, we will illustrate the major idea used in [13] and its weaknesses. In section 3.2, we will introduce our idea on how to securely conduct frequent itemsets mining in two-party case.

A. Existing Protocols  [13] follows the general approach of the FDM algorithm [15], with special protocols replacing the broadcasts of LLi(k) and the support count of items in LLk. It first gives a method for finding the union of locally supported itemsets without revealing the originator of the particular itemset. It then provides a method for securely testing if the support count exceeds the threshold.

The idea in [13] follows the two-phase approach, but combining locally generated rules and support counts is done by passing the encrypted values between sites. The two phases discover candidate itemsets (those that are frequent on one or more sites) and determine which of these meets the global support confidence thresholds.

The first phase (Fig. 1) uses commutative encryption. Each party encrypts its own frequent itemsets (for example, site 1 encrypts itemset C). The encrypted itemsets are then passed to other parties until all parties have encrypted all itemsets.

These are passed to a common party to eliminate duplicates and to begin decryption. (In the figure, the full set of itemsets is shown to the left of site 1, after site 1 decrypts.) This set is then passed to each party, and each party decrypts each itemset. The final result is comprised of the distinct itemsets (C and D in the figure).

In the second phase (Fig. 2), each of the locally supported itemsets is tested to see if it is supported globally. Fig. 2 shows     Fig. 2: Determining if itemset support exceeds the 5 percent threshold [13]  that the itemset ABC is known to be supported at one or more sites, and each computes its local support. The first site chooses a random value R and adds to R the amount by which its support for ABC exceeds the minimum support threshold.

This value is passed to site 2, which adds the amount by which its support exceeds the threshold (note that this may be negative, as shown in the figure.) This is passed to Site 3, which again adds its excess support. The resulting value (18) is tested using a secure comparison to see if it exceeds the random value (17). If so, itemset ABC is supported globally.

This gives a brief, oversimplified illustration of how the idea in [13] works. However, as the authors stated in their paper, the methods were not secure while the number of participating parties is exactly two. It is apparent in a two- party case that (1) when one party knows the final itemset union, it will also know that the itemsets in the union definitely belong to the other site, and (2) when one party knows the final summary of the supports, it will also know the support of the other site. One party can easily deduce the other party?s data from the global results and its own input.

B. The Two-Party Case  In this section, we will illustrate how to find globally fre- quent k-itemsets as the foundation to preserve the participating parties? data privacy.

We will need to adjust our expectations since the following leakage cannot be avoided: One party can easily deduce the other party?s data from the global results and its own input.

We lower our expectations of knowing whether or not a locally frequent itemset (rule) at the own site is globally supported but not revealing this knowledge to the other site.

The following is a concrete application of this expectation. For example, Walmart may want to know if the rule beer ? diaper is strong when putting it under consideration for a transaction union of Walmart and Target, but is not willing to reveal to Target that the rule beer ? diaper is a strong rule of itself.

This process is completed in two steps.

The first step is to encrypt CGi(k) through both sites, which is conducted by Protocol 1. At step 2 in the protocol, each site encrypts CGi(k) with its Commutative Encryption System, then via step 3 sends the ciphertexts to the other party, which again encrypts the ciphertexts received by its  own Commutative Encryption System (step 6) and sends the results back (step 7). The purpose is to conduct secure equality comparison in Protocol 2, making use of the fact that the encryption results of Commutative Encryption System have nothing to do with the encryption order.

The second step is to find GLi(k), which is conducted by Protocol 2. In the protocol, one site sends its two-time- encryption ciphertexts one-by-one to the other site (step 2 and 3), thus locating its support count at the other sites (step 6, 7 and 8). Step 11, 14 and 15 generate random numbers for the purpose of conducting secure scalar product computation.

At step 17-27, the two sites conduct a secure scalar product sub-protocol to securely compute the global support of the ciphertext (its corresponding plaintext, the itemset); if the support is not less than the threshold, the itemset is a globally frequent k-itemset and will be added to GLi(k).

Protocol 1: Encrypt the candidate sets CGi(k) through both sites.

input : N(= 2) sites. Each site i (i is 1, 2) owns the gl-frequent itemsets GLi(k?1).

output: Each site i obtains the set of triples < xi(k), xi(k).supi, fe(imod 2)+1fei(xi(k)) >, xi(k) ? CGi(k).

1 foreach site i do 2 Generate CGi(k) based on the gl-frequent  itemsets GLi(k?1) ; 3 Send fei(CGi(k)) to site (imod 2) + 1,  reordered lexicographically; 4 end 5 foreach site i do 6 Encrypt each  y ? fe(imod 2)+1(CG((imod 2)+1)(k)) with ei, resulting in pairs:  7 < y, fei(y) >=< fe(imod 2)+1(x((imod 2)+1)(k)), 8 fe1fe(imod 2)+1(x((imod 2)+1)(k)) > ; 9 Send the pair:  10 < y, fei(y) >=< fe(imod 2)+1(x((imod 2)+1)(k)), 11 fe1fe(imod 2)+1(x((imod 2)+1)(k)) > back to site  (imod 2) + 1, reordered lexicographically ; 12 end 13 foreach site i do 14 Create the triples  < xi(k), xi(k).supi, fe(imod 2)+1fei(xi(k)) > based on pairs < fei(xi(k)), fe(imod 2)+1fei(xi(k)) > by replacing each fei(xi(k)) with the corresponding locally frequent k-itemset xi(k) and adding its support count xi(k).supi ;  15 Reorder triples < xi(k), xi(k).supi, fe(imod 2)+1fei(xi(k)) > by xi(k) lexicographically.

16 end  There is a place that can be optimized in Protocol 2: the data each site sends to the other site can originate from LLi(2) instead of the triple set, that is, CGi(2) . Since we assume that if an itemset is globally frequent, it must be an element of LL1(2) or LL2(2), the optimization will avoid wasting time in     judging whether or not the itemsets which belong to neither LL1(2) nor LL2(2) are globally frequent.



IV. SOUNDNESS ANALYSIS  Protocol 1 is simple: Each site encrypts CGi(k) and sends it to another site to be encrypted. From this, a two-time encryption result is obtained, which is an obviously correct process.

The purpose of Protocol 2 is to determine GLi(k). It first matches the equal ciphertexts between the two sites from steps 1 to 9 (The element of CGi(k) is the corresponding plaintext, which is also equal). Then from steps 10 to 27, the protocol computes the global support of the ciphertexts (the plaintexts, or the itemsets) with a secure two-party division sub-protocol.

Assume site 1 has the support count x1(k).sup1 , and the size of the transaction database is D1. site 2 has the support count sup2 , and the size of the transaction database is D2.

The global support is x1(k)+sup2D1+D2 . It is obvious that  z? = r1 ? z = r1 ? r2 ? z1 z2  = r1 ? r2 ? r11 ? r21 ? (x1(k).sup1 + sup2)  r21 ? r22 ? (D1 +D2) =  r21 r11 ? r   r12 ? r  1 ? r21 ? (x1(k).sup1 + sup2)  r21 ? r22 ? (D1 +D2) =  x1(k).sup1 + sup2  D1 +D2 .

Protocol 2: Generate GL1(k), GL2(k) (1) input : N(= 2) sites number 1, 2; Minimum  support, s output: GLi(k) at each i  1 At site 1 begin 2 Locate the first  < x1(k), x1(k).sup1, fe2fe1(x1(k)) > in its ordered triples;  3 Send fe2fe1(x1(k)) to site 2; 4 end 5 At site 2 begin 6 Search the fe1fe2(x2(k)) that equals  fe2fe1(x1(k)); 7 if Found then Set sup2 = x2(k).sup2; 8 else Set sup2 = 0; 9 end  10 At site 1 begin 11 Generate two new non-zero random numbers  r11 , r 1 and set r1 =  r21 r11  ; 12 end 13 At site 2 begin 14 Generate two new non-zero random numbers  r12 , r 2;  15 Send r2 = r22 r12  to site 1.

16 end  Protocol 2 (Continuing...): Generate GL1(k), GL2(k) input : N(= 2) sites number 1, 2; Minimum support, s output: GLi(k) at each i  17 Site 1 and Site 2 begin 18 Collaborate to securely compute the Scalar Product  on (r11 ? x1(k).sup1, r11) and (r12, r12 ? sup2); Only Site 1 obtains: z1 = r  1 ? r12 ? x1(k).sup1 + r11 ? r12 ? sup2 =  r11 ? r12 ? (x1(k).sup1 + sup2); 19 end 20 Site 1 and Site 2 begin 21 Collaborate to securely compute the Scalar Product  on (r21 ?D1, r21) and (r22, r22 ?D2); Only Site 1 obtains: z2 = r  1?r22?D1+r21?r22?D2 = r21?r22?(D1+D2)  ; 22 end 23 At site 1 begin 24 Calculate z? = r2 ? r1 ? z1z2 =  r2 ? r1 ? r 1?r12?(x1(k).sup1+sup2)  r21?r22?(D1+D2) = x1(k).sup1+sup2  D1+D2 ;  25 if z? ? s then Insert x1(k) into GL1(k); 26 Delete the triple  < x1(k), x1(k).sup1, fe2fe1(x1(k)) >; 27 end 28 Repeat step begin 29 Site 2 selects the first  < x2(k), x2(k).sup2, fe1fe2(x2(k)) > in its ordered triples and duplicates the procedure from step 1 to step 27 in a similar way; Next, Site 1 will go through a similar process with the next triple ;  30 The above processes will repeat until all the triples at Site 1 and at Site 2 have been tackled. At the completion of the protocol, Site 1 and Site 2 will obtain GL1(k) and GL2(k) respectively.

31 end

V. SECURITY ANALYSIS  A. Protocol 1  We use the simulation paradigm illustrated in Definition 2 to prove the security of Protocol 1.

The only communication takes place at step 3 and 7.

The security measures at both steps are the Commutative Encryption (Section 2.4). Specifically, after the execution of step 3, what each site sees is the ciphertexts generated by Commutative Encryption. Based on Definition 1 in Section 2.4, the simulation views can be simply generated by uniformly choosing numbers from the domain of the ciphertexts in random form. Since the chosen numbers and the ciphertexts are uniformly bounded in the same domain, they are indistin- guishable.

The security of step 7 is similar, whose proof is ignored due to the space restriction.

B. Protocol 2  In Protocol 2, the only data transfer occurs at step 3, 15, 18, and 21.

TABLE II: CComp and CCost of Protocol 1  Step CComp CCost 1, 4, 5, 8, 9, 12 N/A N/A  2 O(|GLi(k?1)|2) N/A 3 O(|CGi(k)| ? Tc) O(|CGi(k)| ? B) 6 O(|CGi(k)| ? Tc) N/A 7 N/A O(|CGi(k)| ? B) 10 Ignored N/A 11 Ignored N/A  TABLE III: CComp and CCost of Protocol of Protocol 2  Step CComp CCost 1, 4, 5, 9, 10, 12, 13, 16, 17, N/A N/A 19, 20, 22, 23, 27, 29, 31 2, 6, 7, 8, 11, 14, 25, 26 Ignored N/A  3 N/A O(|CGi(k)| ? B) 15 N/A Ignored  18, 21 O(Sc) O(St) 24 Const N/A  At step 3, since the ciphertext fe2fe1(x1(k)) was received from site 2 (step 6 and 7, Protocol 1), so it is not a private data.

At step 15, the randomly generated number r1 is not a private data.

Steps 16 and 21 collaborate to conduct the secure scalar product (dot product). Their security is based on the security of the scalar product protocol. Many secure scalar product protocols have been developed. Interested readers may refer to [37] and [18] for further details.

Based on the above analysis, the security of Protocol 2 can be concluded from the Composition Theorem.



VI. PERFORMANCE ANALYSIS  A. Communication and Computation Costs  Suppose that the commutative encryption/decryption cost is Tc; transferring plaintexts/ciphertexts needs B bites. We ignore simple linear computation and simple linear communication since they entail small costs compared with encryption costs and ciphertext transferring costs.

The Computation Complexity (CComp) and Communica- tion Costs (CCost) of Protocol 1 are shown in Table 2.

Suppose the computation cost of the Scalar Product Proto- col is Sc, and the communication cost of the protocol is St.

The computation complexity (CComp) and communication costs (CCost) of steps 1 to 31 in Protocol 2 are shown in Table 3. The work at step 29 repeats the work of steps 1 to 27, and its CComp and CCost can be similarly estimated.

B. Discusses on Performance  In [13], the authors state that security comparison sub- protocol can attribute to the distributed association rules min- ing of two-party case. And in our protocols, secure scalar product is in fact dominates the complexity in computation and communications. In this section, we will discuss how the two kinds of solutions perform.

The initial generic circuit evaluation solution to secure comparison problem (Yao?s millionaire problem) is introduced in [20], which is a milestone paper in secure two-party computation. Such solution is exponential in the number of bits of the involved numbers in time and space. Since then, there have been some techniques to improve the performance in time and communication complexity on such problem. For example, based on ElGamal encryption, [38] designs a protocol with time complexity of 5nlogp+4n? 6 and communication complexity of 6nlogp where n is the length of the private inputs and p is the modulus in ElGamal encryption. And based on Paillier encryption, [39] designs a protocol with time complexity of 16nlogN+28n and communication complexity of 4nlogN where n is the length of the private inputs and N is the modulus in Paillier?s homomorphic encryption scheme.

Considering both logp and logN are not small size number compared with the private number n, so we agree with the conclusion in [13] where it says ?there is no significantly faster way for arbitrary a and b than using the generic circuit evaluation solution ?.

Contrastingly, there are many efficient protocols to conduct secure scalar product, such as [37] where the complexities in time and communication are both O(n). Although some extra data, such as r12 , r  2 , r  1 , and r  1 , are added to assist the secure  computation, considering they can be relatively much smaller size of data, the protocol still runs more efficiently.

Therefore, it could be concluded that in time and commu- nications, the secure scalar product protocols outperform the secure comparison protocols.



VII. CONCLUSIONS  Aiming to tackle the privacy issues of the distributed mining of association rules on horizontally partitioned data in a two-party case, this paper proposed a protocol with deliberately designed techniques. The protocol can tell the site whether or not its itemsets are globally frequent under the union transactions of other sites and itself while guaranteeing the related data privacy.

We believe that the two-party protocol is significant as such application scenarios exist in reality, where one party wants to know whether or not its itemsets (rules) are globally frequent but does not want to reveal its supports and other private data to the other party.

The work in this paper is conducted in the semi-honest model as [16] does. The semi-honest model assumes that participating parties follow the prescribed protocol but try to infer private information using the messages they receive during the communication. Although the semi-honest model is realistic in many settings, there are cases where it may be better to use the malicious model that tries to prevent any malicious behavior by using more expensive and complicated techniques. Clearly, protocols that are secure in the malicious model provide more security compared with those in the semi- honest model. At the same time, there is an obvious trade-off: The malicious model provides higher security guarantees with higher computational cost, whereas the semi-honest model is generally more efficient with less security guarantees [19].

Designing privacy-preserving association rules mining pro- tocols, as well as other multi-party data mining protocols under     malicious models, is a major challenge in SMC applications.

This issue, along with how to design a protocol that can further reduce the time and communication cost, will be dealt with further in our subsequent work.

