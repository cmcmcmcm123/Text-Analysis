Effective Mining of Fuzzy Quantitative Weighted  Association Rules

Abstract-This paper presents a new method of mining weighted  association rules ,which can hold the ?weighted downward closed  property? by using an improved model of weighted support  measurements in the weighted setting.Compared to some  generalized weighted association rules mining, it proves that the  method can quickly and efficiently mine important association  rules.

Keyword-weighted association rules; weighted support;  quantitative itemsets

I.  INTRODUCTION  Data mining and knowledge discovery in databases is an interesting research area only developed in the last sixteen years. Association rules mining(ARM) aims to explore large transaction databases for association rules(AR), which may reveal the implicit relationships among the data attributes. It can be divided into boolean AR and quantitative AR. Agrawal first proposed boolean AR in 1993, and then proposed the classic Apriori and Apriori TID algorithm[1].ARM[2] is a popular data mining technique because of its wide application in marketing and retail communities as well as other more diverse fields[3 11].

The classical model of ARM employs the support measure, which treats every transaction equally. In contrast, different transactions have different weights in real-life data sets. For example, in the market basket data, each transaction is recorded with some profit. Much effort has been dedicated to ARM with preassigned weights.

The paper is organized as follows.In section II we presents background and related work;Section III gives problem definition for improved weighted ARM with fuzzy data and details weighted downward closure property;and section IV ,the detail of the IFWARM algorithms;section V reviews  experimental evaluation with a real customer data and section VI concludes the paper.

?. BACKGROUND AND RELATED WORK  In literature on ARM,weights of items are mostly treated as equally important.Recently some approaches give items weights to reflect their significance to the user, The weights may be attributed to occasional promotions of such items or their profitability.[4] proposes a weighted boolean attributes of the concept of AR, and gives two weighted ARM algorithms: MINWAL (O) and MINWAL (W) .

Fuzzy ARM is especially useful to consider the quantities involved in the user?s request. Such merit presents more detail and a more reliable exploration of the association rules than a generic association rule. [6] introduces the problem of mining weighted quantitative AR based on fuzzy approach.[7] develops a systematic approach to the assessment of fuzzy AR.[8] proposes a novel algorithm to avoid the loss of semantic information due to the partition of quantitative values. [9] addresses the issue of invalidation of DCP in weighted ARM.[10] deals with the fuzziness based upon fuzzy taxonomies that reflect partial belongings among itemsets.[11] proposes and implements an intelligent information system using fuzzy ARM.

These fuzzy algorithms are composed of three steps:In the first step,it converts a generic transaction into fuzzy transaction[5],we can use a membership function to finish this conversion.In the second step,it calculates support value using a formula with the fuzzy transaction to discover the frequently occurring item.it is much important to find a good method for calculating items? support value.In the last step,it calculates a confidence value with the all subsets of discovered frequently itemset according to a formula.

In this paper we present an approach to mine weighted quantitative data by fuzzy means to address the issue of invalidation of WDCP. We then show that rules can be generated efficiently by using the proposed technique.

DOI 10.1109/ICEE.2010.360     ?. PROBLEM DEFINITION  In this section formal definitions are presented to define quantitative attributes and The IFWARM concept.

A. Improved Fuzzy Weighted Association Rule Mining  A fuzzy dataset D consists of fuzzy transactions T= },...,,{ 21 nttt  with fuzzy sets associated with each item in I= },...,,{ ||21 Iiii ,which is identified by a set of linguistic labels L= },...,,{ ||21 Llll ,for example L={Small,Medium,Large},We  assign a weight w to each l in L.

Associated with i.Each attribute ][ ji it  is associated with  several fuzzy sets The degree of of association is given by a membership degree in the range[0,1],which indicates the correspondence between the value of a given ][ ji it  and the  set of fuzzy linguistic labels. The ? thk ? weighted fuzzy set for the ? thj ? item in the ? thi ? fuzzy transaction is given by  ]]][[[ wlit kji .Thus each label kl  for item ji  would have  associated with it a weight, i.e. a pair ( wli ]],[[ ) is called a weighted item where Lli ?]][[  is a label associated with i and  Ww? is weight associated with label l.

We illustrate the fuzzy weighted ARM concept and definitions using tables I and II, Table I contains transactions for 2 quanitiative items discretised into two overlapped intervals with fuzzy vales. Table II has corresponding weights associated to each fuzzy item ][li  in T.

TABLE I. FUZZY TRANSACTIONAL DATABASE TID X Y  Small Large Small Large T1 T2  T3  T4  0.9 0.2  1.0  0.6  0.1 0.8  0.0  0.4  0.4 0.5  0.3  0.2  0.6 0.5  0.7  0.8  TABLE II. FUZZY ITEMS WITH WEIGHTS  Fuzzy Items i[l] (X,Small) (X,Large) (Y,Small) (Y,Large)  Weights(IW) 0.8 0.5 0.6 0.3  Fuzzy Item Weight (FIW)  is a value attached with each fuzzy set.It is a non-negative real number value range [0,1] to list some degree of importance.weight of a fuzzy set for an item ji  is denoted as ]][[ wli kj .

Fuzzy Itemset Transaction Weight (FITW)  is the aggregated weights of all the fuzzy sets associated to items in  the itemset present in a single transaction. Fuzzy Itemset transaction weight for an itemset(X,A) is calculated as:Vote  for it  satisfying  X= ]]][[[)max( )min( ||  )]]][[[( wlitX  X kji  L  k Xwli?  = ??     (1)  Let?s take an example of itemset <(X, Large), (Y, Small)> denoted  by  (X, Large)  as A  and  (Y, Small)  as  B.

FITW of itemset (A, B) in transaction 1 is calculated as:  FITW(A,B)= 6.0 5.0  ?  (0.1 ? 0.5) ? (0.4 ? 0.6)=0.01  Fuzzy Weighted Support (FWS)  is the aggregated sum of FITW of all the transactions itemset is present,divided by the total number of transactions.It is denoted as :  FWS(X)= n  wlit X Xn  i kji  L  k Xwli? ?  = = ??   ||  )]]][[[( ]]][[[)max(  )min(  (2)  For  itemset(A, B) ,FWS(A,B)= 138.0 =0.034  Fuzzy Weighted Confidence (FWC)  is the ratio of sum of votes satisfying both X ? Y to the sum of votes satisfying X with Z=X ? Y.It is formulated as: FWC(X ? Y)=  )( )(  XFWS ZFWS =  ? ?  ? ?  = = ??  = = ??  n  i kji  L  k Xwli  n  i kji  L  k Zwli  wlit X X  wlit Z Z   ||  )]]][[[(   ||  )]]][[[(  ]]][[[ )max( )min(  ]]][[[ )max( )min(  (3)  For itemset(A,B), FWC(A,B)= 65.0  138.0 =0.212  B. Weighted Downward Closure Property(WDCP)  In a classical Apriori algorithm , DCP helps algorithm to generate large itemsets of increasing size by adding items to itemsets that are already large.but in the weighted ARM case[4 6] where each item is assigned a weight,the WDCP does not hold. Now we argue that the WDCP with quantitative data can be validated using the proposed approach.

We also brefly prove that the WDCP is always valid in the proposed method.The following lemma applies to both Boolean and quantative data and is stated as:  Lemma If an itemset is not frequent then its superset can not be frequent and FS(subset) ? FS(superset) is true     Proof For any itemset Y,X ? Y i.e superset of  X,  Lli ?]][[ ,vote for t i satisfying X= ]][[)]][[( litiXli? ??  ,Similarly ,  vote for t i satisfying  Y= ]][[)]][[( litiYli? ?? .

Since X ? Y and ]][[ liti  is between 0 and 1.we have  ]][[]][[ )]][[()]][[(  litlit ii YliXli ?? ???? ? . Therefore  FS(X) = n  lit n  i iXli??  = ??  )]][[( ]][[  ? FS(Y)= n  lit n  i iYli??  = ??  )]][[( ]][[  .

According to the definition of FWS, formula (2).

Since min(Y)=min(min(X),min(Y-X)),max(Y)=  max(max(X),max(Y-X)),We can get  min(X) ?  min(Y),  max(X) ? max(Y),then )max( )min(  )max( )min(  Y Y  X X ? ,and the  denominator stays the same, then we have FWS(X) ? FWS(Y)  If FWS(X)<minfws,we get FWS(Y)<minfws.This then proves that Y is not frequent if its subset is not frequent.

?. THE IFWARM ALGORITHM  The IFWARM algorithm is given in Table III.In the Table:C k  is the set of candidate itemsets of cardinality k,w is  the set of weights associated to items I.and L is the set of frequent item sets.R is the final set of generated fuzzy weighted ARs.

Transform(T):This step generates a new transformed fuzzy database D from the original database by user specified fuzzy sets and weights for each fuzzy set.

Initialize(D):The subroutine initializes itemset weights, weighted support and confidence, encodes attributes values and generates 1-frequent itemsets from the database D.

Join( 1?kL ):This Join step generates kC from 1?kC .before  we can prune it using WDCP and check that whether two label are in the same composite items.if two items in a candidate itemsets have the same prefix,we should drop it .

Getsupw(D,c):In this subroutine we calculate weighted support of each candidates items using the formula (2).

Rules(L,wconf):The last step calculates weighted  confidence of each frequent items using the formula (3).

TABLE III. IFWARM ALGORITHM  Input:  T=data set,  wsup=weighted support,  w=itemset weights,wconf=weighted confidence  Output: R=Set of weighted ARs  Main Algorithm:  D=Transform(T)  1L =Initialize(D)  For(k=2; ???1kL ;k++)  { kC  =Join( 1?kL )  For each candidates kCc ?  c.supw=Getsupw(D,c)  kL = sup}sup.|{ wwcCc k ??  L= kk L? }  R=Rules(L, wconf);  ?. EXPERIMENTAL COMPARISON  In this section,we give a experimental analysis between classical fuzzy ARM(FARM)[7], MINWAL(W)[4], normalized weighted ARM(NWARM)[6],fuzzy weighted ARM(FWARM) [9] and IFWARM algorithm. To demonstrate the effectiveness of the approach,we performed several experiments using a real customer data set[12],The data is a composite transaction database containing 5900 records and 20 attributes.we select 6 main attributes from the data itemsets, country includes three values,and education includes five values.we distribute age to three fuzzy regions{Young, Middle,Old},and year_income to three fuzzy regions {Low,  Middle,High}, marital_status and gender are boolean items.We conduct the experiment using Matlab on the computercomposed of  1GB memory and Intel PE CPU.

In the weighted process,the weight to set the value is of flexibility,primarily on the basis of expert experience ,taking full account of the user?s point of view. Table IV shows the attribute value distribution of the weight,and figure 1 give membership fuction of  year-come.

We performe two types of experiments based on quality and performance measures.For quality measures,we compared the number of the interesting rules generated using five algorithms described above.In the second experiment,we     showed the scalability of this algorithms by comparing the execution time with varying user specified support thresholds.

TABLE IV. THE WEIGHT OF ATTRIBUTES  country 0.4 education 0.7  Marital_status 0.5 age 0.8  gender 0.6 year_income 0.8   0.2  0.4  0.6  0.8   1.2  10 40 60 120 140 180 year-income(thousand)  M e m b e rs h ip V a lu e  Low Middle High    Figure 1. The membership function of year-income        2 3 4 5 6 7 8 9 10 weighted support(%)  N u m b e r o f R u le s  FARM MINVAL(W) NWARM FWARM IFWARM    Figure 2. No. of Interesting Rules using support(wconf=0.2)           2 3 4 5 6 7 8 9 10 weighted support(%)  Ex cu  tio n  Ti m  e( se  c)  FARM MINVAL(W) NWARM FWARM IFWARM   Figure 3. Comparation of execution time(wconf=0.2)  In figure 2,the results show quite similar behavior of the weighted algorithms to classical FARM.As expected the number of rules increases as the minimum support decreases in all cases.Results of IFWARM and FWARM approach are better than MINWAL(W) and NWARM approach,because the formers hold the WDCP and all the protential itemsets are considered from the beginning for pruning using WDCP.the IFWARM is more stable and effective than FWARM,and the  smaller the support value,the more obvious performance.

In figure 3,we compares the execution time of this algorithms. due to the way it generates frequent sets i.e it considers items weights ,The weighted algorithms hava less excution time than classical FARM.

The experiments show that the proposed algorithms produces better results and has less excution time as it uses all the possible itemsets and generates rules effectively using valid WDCP.

?. CONCLUSION In this paper,We have presented a generalized approach  for mining weighted association rules from databases with quantitative attributes. And we have demonstrated the valid WDCP with detailed proof.The IFWARM algorithm can extract efficient and valid ARs for holding WDCP. To demonstrate the effectiveness of the approach,we performed several experiments using a real customer data set.Compared to some generalized weighted association rules mining, It is notable that the proposed approach can quickly and efficiently mine important association rules.

