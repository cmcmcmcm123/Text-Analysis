Utilizing Community Centers to Answer Reachability Queries for Large Graphs

Abstract?As a fundamental problem, reachability query has been always the research emphasis in many applications in the near 20 years. Especially with the coming of the big data era, its efficiency plays a critical role. Although there are many research results for this issue, they all reach a scalability bottleneck. In this paper, we propose an index structure utilizing community center, i.e. to select a group of vertices from the original graph and construct a subgraph. With this subgraph, we can answer reach- ability queries rapidly. The experimental result shows that our approach is superior to the-state-of-the-art algorithms including construction time, index size and query time.

Keywords?Reachability query, Community center, Reachability trunk;

I. INTRODUCTION  In recent year, we can commonly find that data is modeled as graphs in many applications, e.g., social networks, semantic web, bioinformatics and so on. For instance, in social net- works, we can use vertices to denote every user and use the edges to denote the relationship between the users. Among all the algorithms involved with graphs, reachability query, which test if one vertex can reach another vertex via a path, is one of the most fundamental issues. Although it is a quite simple problem and has been researched for 20 years, the efficiency is still a bottleneck. Especially with the coming of big data era, many new challenges are posed to this question.

A lot of approaches have been proposed to improve the query efficiency for graphs. These methods mainly try to construct compact indexes of original graphs to achieve a balance between query time, index size and constructing time.

However, with the aggrandizement scale of graph data, they all have problems in scalability. For example, the active user number of Facebook has reached 1 billion in August 2012.

Faced with this tsunami of data, the cost of index size and construction time of current methods is excessive expense. The query time of online BFS (Breadth First Search)/DFS(Depth First Search) is liner related to graph size, which is unaccept- able for large graphs.

To sum up, scalability has become the main obstacle for reachability query. The big question now is whether we can construct indices efficiently when the graph data scale reach tens or even hundreds of millions of vertices. In this paper, we propose a new community-center-based index structure. To achieve reasonable index size and answer query efficiently,  we first divide the original graph into several independent communities. Each community has a unique center and we use these centers instead of all the vertices to construct index.

Because the number of these vertices is much smaller than the total vertex number of the original graphs, the index size can be significantly reduced. Our approach can not only handle medium-sized graphs, but also scales extremely well for large or very large graphs.

A. Overview of Index Structure  At present, most index algorithm need to preserve the whole vertices information. It is the main reason why they have problems in scalability. A sensible solution is to select a few vertices from the original graph to construct index. Then the bottleneck of previous approaches would be broken and large- scale even super-large-scale graphs can be handled efficiently.

Ruoming Jin et. al proposed SCARAB [4], a backbone-based method, to construct reachability index. They exact a small number of vertices to cover the original graph. Every vertex can reach at least one backbone vertex in ? steps. In this way, the storage cost can be reduced greatly. However, this method need to test repeatedly every vertex of the original graph while constructing the backbone. This leads to high cost of time, especially for those dense graphs. In order to meet these challenges, we draw lessons from SCARAB and put forward an index construction method which utilizes community center to cover the graph. Its basic idea can be summarized as follows:  1) Community, Community Center and Reachability Trunk: Social network is a long-standing issue in sociology and many interesting phenomena are found, such as small world phenomenon, power-law distribution and so on. We can find that in the vast majority of social networks or other similar networks, all the vertices have close connection with a small amount of vertices and are weakly associated with other vertices. For instance, in Facebook, all users are in different group organized by affection, politics or hobbies. This kind of group can be called a community. In each community, there often exist several vertices, called community centers, which closely link to other vertices in a direct or indirect way.

Therefore, we can link these community centers by virtual edges to form a reachability trunk. It can be considered as a query subgraph of the original graph and the total index storage cost can be reduced greatly.

2013 10th Web Information System and Application Conference  DOI 10.1109/WISA.2013.47   2013 10th Web Information System and Application Conference  DOI 10.1109/WISA.2013.47   2013 10th Web Information System and Application Conference  DOI 10.1109/WISA.2013.47   2013 10th Web Information System and Application Conference  DOI 10.1109/WISA.2013.47   2013 10th Web Information System and Application Conference  DOI 10.1109/WISA.2013.47     2) Local Accessing and Employing Recursively: Due to us- ing a small proportion of the original graph to construct index, other vertices need to do local search to quickly find their nearest centers. However, because the distance between every vertex and their center is very short, the cost of this operation is almost negligible. Our method is similar to SCARAB, which can also be used recursively to further reduce the index size.

Organization. Section 2 defines the problem and the basic notations. Section 3 gives a heuristic algorithm to find the reachability trunk. Section 4 includes the query processing algorithm and the complexity analysis. Section 5 reports the experimental results. Section 6 and 7 give the related work and the conclusion.



II. DEFINITION  We first give the notations used throughout the paper.

Intuitively, the reachability trunk should have the features as follows:  ? Its size must be much smaller than that of the original graph.

? It must reserve the topological structure of the original graph.

? Each vertices in the original graph must reach one of its vertex quickly and easily in a few steps.

In order to meet them, we explicitly separate internal vertex pairs from external vertex pairs, and focus on utilizing the trunk for recovering the reachability for external reachable pairs. To distinguish the two vertex pairs, we define a threshold ?. For any pair of vertices u and v, if two vertices can reach the same trunk vertex in ? steps, then (u,v) can be called the internal-pair, else they can be called the external-pair.

Therefore, the reachability trunk can be defined as follows:  Definition 1: Given a directed acyclic graph (DAG) and a threshold ?, its reachability is G? = (V ?, E?), where V ? ? V and E? may contain edges not in E, then it has the following features:  ? Any two vertices in V ? must not be in the same community.

? All the vertices which is in the same community can reach its center in ? steps.

? For any internal-pair (u,v), if u can reach v, then the max distance between them is 2?.

? For any external-pair (u,v), if u can reach v, then there must exist u? ? V ? and v? ? V ?, such that (u, u?) and (v, v?) are both internal-pair and u? can reach v?.

Example 1. Figure 1(b) shows a reachability trunk of graph G (figure 1(a)) with ? = 3. As an example, for external-pair (1,14), there is a trunk vertex 0 where vertex 1 can reach in 1 hop, there is another trunk vertex 7 where vertex 7 can reach 14 in 3 hops, and vertex 0 can reach 7 in the reachability trunk. Actually, for any external-pair, we can always find their corresponding community center and test their reacnability by these trunk vertices.

?  ?  ?  ?  ?  ?  ?       ?  ??  ????  ??  ??  ??  (a) Original Graph G  ?  ?? ?    (b) G?s Reachability Trunk  Fig. 1: Running Example  Apparently, the vertex number of the trunk depends on the threshold ?. As is shown in the experimental result Section 5, for any real and synthetic graph data, a reachability trunk with ? ? 3 can dramatically reduce the size of the original graph.

And in many instances, we can get an ideal result with ? = 2.

The main purpose of the reachability trunk is to cover the original graph with as few vertices as possible. Here we give the definition of the minimum reachability trunk discovery.

Definition 2: Minimum Reachability Trunk (MRT) Dis- covery. Given a DAG G=(V,E) and a threshold ?, there must be a vertex set V ? ? V which can cover G in ? hops, and in all the possible candidate sets, its size is the smallest.

However, computing the MRT is NP-hard because its corre- sponding decision problem is an NP-complete problem.

Theorem 1: NP-hardness of MRT discovery problem.

Given a DAG G=(V,E) and a threshold ?, the MRT discovery problem is an NP-hard optimization problem.

Proof: The MRT discovery problem can be to the classic vertex set cover (VSC) problem, a well-known NP-complete problem. Given a DAG G=(V,E), theorem 1 can be proofed as follows:  (1) Suppose there is a solution S? ? V that meets the VSC problem, then for all v ? S?, they must be covered by one and only one u ? V ?.

(2) Suppose there is a solution V ? ? V that meets the MRT problem, then for any two vertex u ? V ?, v ? V ?, they can not cover the same w ? S?.

In summary, the MRT problem can be reduced to the VSC problem, an NP-hard problem.



III. REACHABILITY TRUNK DISCOVERY  Known from the theorem 1, the reachability trunk cannot be computed in polynomial time. Therefore, we propose a maximum-degree-vertex covering first heuristic algorithm. Its basic idea is based on the following discoveries:  ? A community center usually connects closely with other vertices which shows that has a much larger degree than other normal vertices.

? The graph partition problem is NP-hard too. Obvi- ously, it is more efficient if community centers are determined first and then covering other neighbouring vertices.

? Practice shows that those vertices which have a larger degree are often more stable in actual graphs. This means good index structure stability.

Algorithm 1: Computing the vertex set for G?  input : G, a directed data graph; ?, a threshold; output: V ?, a reachability trunk;  1 V ? ? ?; 2 N ? { Order all the vertices of G by degree }; 3 Queue Q; 4 for each u in N do 5 if !visited[u] then 6 V ? ? {u}; 7 Q.enqueue(u); 8 l = 0; 9 while !Q.empty() do  10 v = Q.dequeue(); 11 visited[v] = true; 12 l? v?s level with respect to u; 13 if l < ? then 14 Bout ? {v?s successors }; 15 Bin ? {v?s predecessors}; 16 Q? Bout; 17 Q? Bin;  18 return V ?;  Algorithm 1 gives a brief review of the fast heuristic approach. We first order the vertices by degree (including indegree and outdegree). At first, the vertex set of G?, V ?, is set to be empty. Then for each unvisited u based on the order, we check whether it can cover other unvisited adjacent vertices in ? steps bidirectionally until all the vertices are visited.

Fig. 1(b) is the reachability trunk of the original graph G.

As can be seen from the result, we can use only 4 vertices to cover G?s 16 vertices. The index size is significantly reduced.

The next step is to connect these trunk vertices to construct the reachability trunk G?. We first give a property of the reachability trunk as follows:  Property 1. The max distance between any two trunk vertices is 2?. Based on definition 1, this property is obvious.

Therefore, we omit the proof.

As shown in Algorithm 2, we do BFS from every trunk vertex. If it can reach another trunk vertex in 2? steps, then we add an edge between them. After traversing all the trunk vertices, we build a sub-graph of graph G.

The output of Algorithm 1 and 2 is a sparse subgraph of G because most of the edges have been filtered while computing the reachability trunk. This can be verified by the follow-up experiments. In many cases, the number of trunk edges is even less than that of trunk vertices. Such sparse graph is very suitable for other existing index approaches.

Computational Complexity: In Algorithm 1, the compu- tational cost mainly focuses on sorting and local traversing.

For the sorting problem, we can do it in O(nlog(n)). For local traversing, let N?(u) denote the number of vertices and edges of u?s forward neighbors that can be reached in ? steps. Let N ??(u) denote the number of vertices and edges  Algorithm 2: Computing the edge set for G?  input : G, a directed data graph; V ?, the vertex set of G?; ?, a threshold;  output: E?, the edge set of G?; 1 E? ? ?; 2 for each u in V ? do 3 if !visited[u] then 4 visited[u] = true; 5 Do BFS from u in 2? steps; 6 E? ? (u,v);{u can reach v in 2? steps and  v? V ?} 7 return E?;  of u?s backward neighbors that can reach u in ? steps. Then this process costs O(  ? u?V ? (N?(u) +N  ? ?(u))). Due to the  diversity of actual graph data, we cannot give exact value of |V ?|. As for index size, the storage cost for the reachability trunk is O(V ?+E?). If we adopt other index algorithms on the trunk, the index size is related to their efficiency. In the worst cases, if we construct a transitive closure for the reachability trunk, it would cost O(k2), where k = |V ?| and k << |V |.



IV. QUERY PROCESSING  Before we introduce how to answer reachability queries by the reachability trunk, we give the following property.

Property 2. Let p denote the distance between u and its community center u?. if v? is the neighboring community center and u? can reach v?, then u can reach v? in 2? ? p steps.

This property can be proved by definition 1 too, and based on it we give a theorem as follows:  Theorem 2: Given a DAG G=(V,E) and its reachability trunk T, we can answer whether u can reach v by their community centers and adjacent community centers.

Proof: When vertex u can reach its community center u?, u covers all the u??s reachability information. However, when u? can reach u, we obviously cannot come to this conclusion.

Therefore, besides searching u?s community center, we also need to search u?s adjacent community centers to make sure to cover all u?s reachability information.

Thus, we give the query processing algorithm on the basis of property 2 and theorem 2. As shown in Algorithm 3, we do bidirectional BFS from the source vertex u and the target vertex v, if u can reach v in ? steps or they can reach the same community center, that is, u and v are in the same community, then they are reachable. If u and v are not in the same community, suppose x and y are two different community centers and u can reach v, then they are reachable too. Otherwise, u can not reach v.

Complexity. The query cost mainly lies in the bidirectional local BFS. And the query efficiency of reachability trunk depends on other index methods. Now, there are many ap- proaches that can answer reachability queries in constant time.

Because the threshold ? is often very small, the computation cost of local BFS can be negligible compared with global BFS.

In short, we can answer reachability queries in approximate constant time.

Algorithm 3: Query(u,v) input : G, a directed data graph; G?, the reachability  trunk of G; ?, a threshold;  output: The reachability between u and v; 1 Do forward BFS from u; 2 Do backward BFS from v; 3 if u and v can reach the same community center or u  reaches v in ? steps then 4 return true; 5 p ? the distance between u and its community center; 6 X ? {all u?s forward reachable community centers in 2?? p steps };  7 Y ? { all v?s backward reachable community centers in 2?? p steps};  8 for each x in X do 9 for each y in Y do  10 if x can reach y then 11 return true;  12 return false;

V. EXPERIMENTAL STUDY  In this section, we empirically analyze the performance of our method. We mainly are interested in the following questions:  ? Can our algorithm work efficiently on large scale graphs with millions of vertices, including construc- tion time, index size and query time?

? Whether our method is a great improvement over the- state-of-the-art existing high performance approaches, such as SCARAB?

? Whether our method can improve the efficiency of early proposed algorithms?

To answer the above questions, we first studied SCARAB, an efficient index framework proposed by Ruoming Jin, which close to our idea, and compare it with our algorithm. In addition, we also studied following state-of-the-art reachability approaches.

? PathTree [3], an improved version of Agrawal?s tree- interval method proposed by Ruoming Jin too;  ? 2HOP [5], a famous labeling approach put forward by Cohen et al.

For each of them, we developed their Trunk and SCARAB methods, referred to as PT-T,2HOP-T, PT-S and 2HOP-S, where T refers to the reachability trunk and S refers to the reachability backbone.

In experiments, we focus mainly on testing 3 important indicator, that is query time, index size and construction time. For query time, we utilize 1,000,000 completely random queries. Our construction time consist of two parts: trunk discovery time and index time. Correspondingly, the index size of a Reachability Trunk consists of two parts, the size of the trunk, and the index size on the trunk. All algorithms mentioned in this work are implemented in C++ based on the Standard Template Library (STL).

TABLE I: Real Datasets  Dataset Nodes Edges Diameter p2p-Gnutella25 22,687 31876 11  p2p-Gnutella30 36,682 49605 10  p2p-Gnutella31 62,586 84168 11  Wiki-Vote 8,297 12,374 7  CiteSeer 723,131 1,085,615 10  CiteSeer 723,131 790,552 10  soc-Pokec 1,632,803 2,964,439 11  cit-Patents 3,774,768 6,622,789 11  TABLE II: Construction Time on Real Datasets(in ms)  Datasets Trunk SCARAB 2HOP-T 2HOP-S PT-T PT-S  P2PG25 37 256 257 4,270 39 164  P2PG30 70 462 512 9,973 69 365  P2PG31 170 1,070 2,980 52,501 266 1,106  Wiki-Vote 967 80,637 11 13 7 5  CiteSeer 46,625 518,292 1.3 ? 106 5.5 ? 106 122,121 18,407 Soc-Pokec 712,182 3.3 ? 106 1.5 ? 107 4.1 ? 107 1.4 ? 106 3.7 ? 106 Cit-Patents 4.2 ? 106 9.4 ? 106 5.1 ? 107 9.5 ? 107 4.7 ? 106 8.3 ? 106  All experiments are performed on a Windows 7 machine with Intel I5-2400 3.10GHZ and 8G RAM.

A. Real Data  To validate our approaches, we first purposefully collected 7 real datasets, listed in Table I with some important charac- teristics, where diameter is the longest path between any pair vertices. All these graphs are directed, unweighted, and acyclic.

For those non-DAG graphs, we transform it into a DAG by coalescing strongly connected components (SCC) into virtual vertices [7]. This can be done simply by depth first search (DFS).

The graph size ranges from a few thousand to almost four million vertices. CiteSeer is from The Koblenz Network Collection (KONECT), which is about the digital library for scientific and academic papers, primarily in the fields of computer and information science. Other datasets are provided by Stanford Large Network Dataset Collection (SNAP). P2p- Gnutella25-31 are a sequence of snapshots of the Gnutella peer-to-peer file sharing network from August 25 to 31 in 2002.

Wiki-Vote is a free encyclopedia written collaboratively by volunteers around the world. Soc-Pokec is the anonymized data of the Pokec which is the most popular online social network in Slovakia. Cit-Patents is the U.S. patent dataset maintained by the National Bureau of Economic Research.

Due to space limitation, we present results only for Trunk, SCARAB, 2HOP-T, 2HOP-S, PT-T and PT-S and set the threshold ? to 3. Table II shows the index construction times for different approaches. According to results obtained, we can find that our algorithm runs much faster and more efficiently than SCARAB. Especially for those large data graphs, our algorithm can handle them within acceptable time limits.

Table III shows the subgraph size obtained by Trunk and SCARAB. Columns |V ?| and |E?| record the number of vertices and edges of the reachability trunk or backbone of SCARAB. Figure 2 reports the index size of different reachability methods, including 2HOP-T,2HOP-S, PT-T and PT-S. We make the following observations on index size:     TABLE III: Index Size of Real Datasets  Datasets Trunk SCARAB  |V ?| |E?| |V ?| |E?| P2PG25 4,416 2,230 2,149 6,032  P2PG30 7,301 3,247 3,363 9,435  P2PG31 12,541 6,428 5,832 15,715  Wiki-Vote 1,285 1,393 78 1,772  CiteSeer 121,533 110,100 26,087 109,039  Soc-Pokec 330,804 464,912 320,432 1,940,010  Cit-Patents 832,530 853,782 412,892 1,165,257  ? Both Trunk and SCARAB can establish subgraphs from the original graph and the subgraph size is much smaller than the original graph.

? Although the two approaches provide almost the same index size, the result of Trunk is quite sparse which is very beneficial to the original methods. It is validated in Table II.

? On the basis of the data in Figure 2, the index size of our method is significantly smaller than SCARAB.

?  ??  ???  ????  ?????  ??????  ???????  ????????  ?????  ?????   ?	?  ?	?   Fig. 2: Index Size on Real Graphs Figure 3 reports the query time for different query answer-  ing approaches. In our results, we can see that the threshold ? being equal, there is little difference between Trunk and SCARAB in response times.

?  ??  ???  ?????  ??????  ???????  ?????????   ???  ???  Fig. 3: Query Time on Real Graphs Through different types of real data graphs, we can draw  a conclusion that our method can really improve the index construction time and reduce the index size. Meanwhile, our method do not decrease the query efficiency.

B. Synthetic Data  We ran seven sets of experiments using synthetic random directed graphs. Here, we focus on testing the effects of graphs? density on the efficiency of different approaches. We set the density |V |/|E| from 1.5 to 3 and vary |V | from 5K to 2,000K. In each experiment, we use the same algorithms as previous.

Table IV to IX shows the construction time and index size of six approaches. When the density |E|/|V | = 1.5, the  TABLE IV: Construction Time on Synthetic Datasets |E|/|V | = 1.5(in ms)  Datasets Trunk SCARAB 2HOP-T 2HOP-S PT-T PT-S  5K 8 32 2 6 10 9  10K 17 88 17 30 28 27  50K 146 833 540 1,618 443 482  100K 733 2,653 263 10,539 1,924 1,818  500K 9,410 53,983 67,319 1.2 ? 106 53,983 49,137 1,000K 165,753 133,730 592,351 9.3 ? 106 211,340 194,791 2,000K 665,077 1.6 ? 106 4.9 ? 106 7.7 ? 107 863,289 799,615  TABLE V: Construction Time on Synthetic Datasets |E|/|V | = 2(in ms)  Datasets Trunk SCARAB 2HOP-T 2HOP-S PT-T PT-S  5K 6 57 2 32 9 15  10K 11 120 4 83 17 37  50K 125 1,110 325 5,874 338 754  100K 422 3,125 2,475 37,578 1,355 2,907  500K 8,975 49,931 259,025 4.3 ? 106 40,214 78,600 1,000K 141,479 162,744 2.4 ? 106 3.0 ? 107 148,267 314,534 2,000K 557,614 1.0 ? 106 1.6 ? 107 1.8 ? 108 576,957 1.3 ? 106  TABLE VI: Construction Time on Synthetic Datasets |E|/|V | = 3(in ms)  Datasets Trunk SCARAB 2HOP-T 2HOP-S PT-T PT-S  5K 7 252 9 124 10 19  10K 15 684 26 342 17 49  50K 140 5,715 1,166 31,252 246 1,116  100K 420 14,386 7,414 153,345 1,025 3,903  500K 7,403 120,680 611,920 1.9 ? 107 24,528 104,168 1,000K 103,981 324,468 6.4 ? 106 1.4 ? 108 100,043 423,538 2,000K 920,765 2.2 ? 106 5.0 ? 107 9.7 ? 108 398,477 1.8 ? 106  TABLE VII: Index Size on Synthetic Datasets |E|/|V | = 1.5  Datasets Trunk SCARAB  2HOP-T 2HOP-S PT-T PT-S|V ?| |E?| |V ?| |E?| 5K 1,314 556 446 469 556 436 378 246  10K 2,617 640 942 1,277 641 1,134 493 550  50K 13,064 3,354 4,461 5,295 3,362 4,764 2,621 2,583  100K 26,312 6,444 8,688 9,783 6,436 8,855 5,113 4,930  500K 132,274 35,427 44,272 50,381 35,383 45,597 27,941 25,364  1000K 264,508 70,574 87,802 98,408 70,389 89,182 55,976 50,054  2000K 529,154 141,986 175,980 199,443 141,618 179,457 112,393 100,805  TABLE VIII: Index Size on Synthetic Datasets |E|/|V | = 2.0  Datasets Trunk SCARAB  2HOP-T 2HOP-S PT-T PT-S|V ?| |E?| |V ?| |E?| 5K 1,202 438 536 1,066 438 1,021 248 369  10K 2,309 761 1,021 1,824 775 1,592 456 682  50K 11,550 4,124 5,086 9,081 4,139 8,063 2,385 3,528  100K 23,359 7,971 10,061 18,085 7,993 15,972 4,917 6,866  500K 115,026 42,458 51,212 93,957 42,419 82,533 24,979 35,545  1000K 230,710 88,734 102,660 186,669 88,537 164,184 51,464 70,922  2000K 460,498 176,609 205,810 376,931 175,929 326,244 102,199 141,597  performance of Trunk and SCARAB is similar. However, with the increase of graph density, our method is much better than SCARAB, which is of significance for practical application.

TABLE IX: Index Size on Synthetic Datasets |E|/|V | = 3.0  Datasets Trunk SCARAB  2HOP-T 2HOP-S PT-T PT-S|V ?| |E?| |V ?| |E?| 5K 872 925 558 2146 895 1948 326 471  10K 1,670 1,534 1,072 3,652 1,553 3,229 485 871  50K 8,466 6,987 5,495 23,044 7,046 20,721 2,274 4,746  100K 17,000 15,961 10,621 41,808 16,155 39,118 4,982 9,003  500K 84,869 74,850 54,383 218,000 75,474 197,107 23,503 46,111  1000K 169,151 156,231 108,746 445,631 157,571 403,579 47,935 92,276  2000K 338,874 309,518 218,049 888,661 299,384 85,215 95,080 184,993  Figure 4 reports the query time of two algorithms. Similar to the results of real data graphs, the query performance of them don?t differ significantly from each other.

?  ???????  ???????  ???????  ???????  ???????  ???????  ???????  ???????  ?? ??? ??? ???? ???? ????? ?????   ???  ???  (a) |E|/|V | = 1.5  ?  ???????  ???????  ???????  ???????  ???????  ???????  ???????  ???????  ?? ??? ??? ???? ???? ????? ?????   ???  ???  (b) |E|/|V | = 2  ?  ???????  ???????  ???????  ???????  ???????  ???????  ???????  ???????  ???????  ?? ??? ??? ???? ???? ????? ?????   ???  ???  (c) |E|/|V | = 3 Fig. 4: Query Time of Synthetic Datasets (in ms)

VI. RELATED WORK  In recent years, as a hot topic in graph data management, numerous reachability computation methods [5], [9], [6], [1], [2], [12], [8], [10], [13], [3], [14], [4], [11], [15] have been proposed.

BFS and DFS [7] are two most straight methods. They can compute reachability queries in O(n+m) time, which is very inefficient for those large data graphs.

Many approaches [5], [3], [14], [11], [8], [12], [15] have been used to reduce the index size. But they can only deal with small or medium-sized graphs.

Schaik et al. [13] mainly study how to compress the whole transitive closure and did not involve optimization problems.

Ruoming Jin et al. propose SCARAB [4] to handle large scale graphs. However, when dealing with dense graphs, per- formance drops off precipitously.

James et al. [10] give a new way to compress index. But this method can only answer certain queries and cannot apply to regular reachability queries.



VII. CONCLUSION  In this paper, we introduce a simple and practical frame- work to reduce the index size of large graphs. It can also help improve existing query algorithms greatly. In our work, we propose a new opinion that utilize community to construct index. The experimental results shows, that our method is much faster than SCARAB, the state-of-the-art high perfor- mance index approach. In the future work, we will continue investigate to apply TRUNK to other reachability problems, such as regular expression-based query or dynamic graphs.

Finally, we plan to study how to further improve the efficiency of community and community center discovery.

