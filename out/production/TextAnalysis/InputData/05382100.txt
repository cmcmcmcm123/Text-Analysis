Grounding Symbols:  Labelling and Resolving Pronoun Resolution with fLIF Neurons

Abstract   If a system can represent knowledge symbolically, and ground those symbols in an environment, then it has access to a vast range of data from that environment.  The system described in this paper acts in a simple virtual world.  It is implemented solely in fatiguing Leaky Integrate and Fire neurons; views the environment; processes natural language commands; plans; and acts.

Visual representations are labeled, using a Hebbian learning rule, thus gaining associations with symbols. The labelling is done using simultaneous presentation of the label and a corresponding visual item. These grounded symbols can be useful in reference resolution. Both experiments perform perfectly on all tests.

1. Introduction   A major hurdle in the development of an artificial intelligent agent is the symbol grounding problem (SGP) [6], [16]. A symbol can be defined as an association with an object due to a social convention and usually has an arbitrary shape with no resemblance to its referent.  Each symbol is a part of a wider and more complex system [16], [18].  Any symbol is meaningless to its user unless, somehow, it is given some meaning. Once a symbol gets its meaning, it is grounded. How an artificial agent can develop the meanings of symbols autonomously is the SGP [3], [4], [7], [8].

The SGP is one of the most important open questions in the philosophy of information [20].

Manipulating meaningless symbols into other meaningless symbols is not intelligence [15]. Most artificial agents do not understand the meanings of the symbols they are processing and are just processing information according to predesigned algorithms [19]. Instead of defining symbols in the form of other ungrounded symbols, a  system can derive the meaning from sensory-motor interaction with the environment [1], [2], [17].

2. Theoretical Background & Previous Work   The SGP has been in existence for hundreds of years. As knowledge about human cognition has advanced, more candidate symbol grounding solutions have been proposed. Since the development of connectionist systems, there have been more ideas and solutions to address the SGP. While progress has been made, the SGP remains open.  This paper presents simulations that begin to address the SGP.  The simulations are based on fatiguing Leaky Integrate and Fire (fLIF) neurons [13].

They make use of the cell assembly (CA) concept [9].  A brief description of CAs and fLIF neurons is given below.

fLIF neurons are a relatively simple model of biological neurons [12][13]. The model used in this paper makes use of discrete cycles.  Each neuron has some activation, which it receives from other neurons. If a neuron has enough activation at the end of a cycle, it will fire, spread activation to connected neurons, and lose all its energy. Neurons are connected to other neurons with unidirectional, weighted connections.  A firing neuron passes the activation of the weight of the connection.  If a neuron?s activation is less than the threshold, it will not fire but will lose some of its activation as it leaks away.

fLIF neurons also fatigue just like biological neurons [13].

If a neuron fires regularly it becomes harder to fire.

As neurons fatigue, they become more difficult to fire again. This is modelled by increasing the threshold of a neuron as describe in equation 1.

T(t) = T(t-1) + Fc. (Equation 1) Where T is the threshold at time t and Fc is fatigue constant. If a neuron does not fire the threshold associated with that neuron decreases using the fatigue recovery constant Fr as shown in equation 2. The threshold never goes below the base activation threshold.

T(t) = T(t-1) + Fr. (Equation 2)   DOI 10.1109/ICMLA.2009.97     If a neuron does not fire at a given time, some of its energy leaks away but it still integrates energy from the surrounding active neurons. This is modelled by calculating the activation as describe in equation 3.

A(t) = A(t-1)/D + C. (Equation 3) Where A(t) is the activation at  time t and is sum of activation A at t-1 time, reduced by a decay constant D, and C, the sum of incoming activation of all active neurons that are connected to a given neuron and fired at time t-1. The value of C is determined by multiplying the incoming activation on all connected links with the associated weights of those links.

CAs were proposed by Hebb sixty years ago [9] and  explain how the human brain learns, stores and accesses concepts. A single neuron does not represent a memory but a large number of neurons represent each concept. The learning of a CA is done by Hebbian learning, the connection strength between two neurons is related to how frequently they fire simultaneously.

The repeated presentation of input increases the strength of the connection between simultaneously active neurons while decreasing the connection strength between other neurons. The set of neurons with increased synaptic strength forms a CA. CAs are reverberating circuits.

Initial firing of some neurons in the CA can lead to further firing of other neurons in the CA due to high connection strength.  This then can lead to a cascade of firing called CA ignition [11], [13], [ 21].

The Cell Assembly roBot version 1 (CABot1) [13] was an agent in simulated neurons that took natural language as input and interacted with the environment. By interacting with the environment, it is hoped that it can learn the semantics of the environment sufficiently well to improve language processing.  A total of 21 sub-networks are used to subdivide the tasks of vision, natural language parsing, planning, action and system control.

The important subnets for the purposes of this paper are the vision nets and the word nets.  There are three vision subnets, a simulated retina, a primary visual cortex and a secondary visual cortex (V2).  These systems were hard coded, so there was no learning. Visual input was in the form of a bitmap representation of a view of the game from the agent?s perspective.  In particular, the secondary visual cortex subnet was set to recognize pyramids and stalactites.  If one of these was present in the game, a CA in V2 ignited. Similarly, the parsing component had CAs for words.  In the game, the user issues natural language commands to the agent.  The noun subnet is used during parsing and the instance subnet stores semantic roles during parsing.  Both noun and instance subnets had CAs for both pyramid and stalactite.

3. Proposed Work  The names of different objects (labels) are naturally correlated with the visual appearance of the corresponding objects obtained from the visual field. Once this labeling is done, machines can demonstrate many human like behaviors [5].  Labelling is a simple but necessary form of symbol grounding [22].  There is an existing system, CABot1, that contains semantics CAs and label CAs.  An association between the semantic and label CAs is learned.   These labels provide a form of reference resolution in a relatively simple task, a proof of concept.

One theory states that a concept is represented by a semantic pole and a phonological pole [14]. A CA for the category represents the semantic pole, and a different CA for the label the phonological pole (word). If a system has a semantic CA, and a label CA, it can attach them to each other, which means the symbol is now grounded. The system has attached a name to a category.

Symbol grounding can be used to address the reference resolution problem. Reference resolution is a common problem in natural language. For example in the sentence we saw a doll with a black jacket on and it was quite big. The pronoun it can refer to either doll or to the jacket. If the system can decide which, it is resolving the pronoun.  In resolving the pronoun, the system could ignite both the semantic CA and the label CA associated with the item to which the pronoun is resolved.

4. Simulations The simulations described below are an extension of CABot1 [13].  CABot1 does no real learning.  The first simulation shows how learning allows the attachment of labels.  The second shows how the now labelled semantic CAs can be used for reference resolution.

4.1 Labelling Experiment  The labelling simulation associates label CAs with semantic CAs. Initially pictures and labels are presented at the same time so the weights between the semantic and label categories can be adjusted. Pictures of different instances of pyramid and stalactite were used. These pictures were taken from a virtual 3D environment. The connections between visual CAs and label CAs are learned using Hebbian learning. According to Hebbian learning, the weights of the connections are increased when both the pre and the post synaptic neurons fire, and when the pre but not the post synaptic neuron fires, the weights are decreased. The learning is bi-directional with     weights from V2 to the label net and weights from the label net to V2 being learned at the same time.

Each shape is represented by a CA of 2500 neurons in the V2 net, and each label is by a CA of 150 neurons. Every 10th neuron of a visual shape in V2 has 10 random connections with stalactite and pyramid CAs in the instance net. Each neuron of a label instance has 10 random connections with stalactite and pyramid shape CAs in V2. The initial weights between labels and visual input are low. The other parameters were selected by a trial and error method. For V2 decay rate of 1.1, fatigue of 1.0, fatigue recovery of 3.0, learning of 0.1 and activation threshold of 5 is used and for the instance net, decay rate of 1.5, fatigue rate of 0.4, fatigue recovery rate of 1.2, learning rate of 0.1 and activation threshold of 4 is used.

The correlatory rule was used for learning connections [11]. The complete code for the experiments can be found at www.cs.mdx.ac.uk/research/PhDArea/fawad1/labelling.

During testing, different pictures are presented while the label input to the instance net is switched off to test the connection efficiency between V2 and the instance net. At the end, V2 is turned off and different labels are presented to see the connection efficiency between the Instance net and V2. Figure 1 and figure 2 show an instance of pyramid and an instance of stalactite respectively as visual input to CABot1.

Figure 1    Figure 2   The result is calculated using the number of neurons fired at the 49th step of presenting every picture or label. Thirty eight percent of the images were used for training and the remainder for testing. Each picture was given 50 CABot steps for training and testing purpose.

Individual results for an instance of pyramid and stalactite are produced after the 49th cycle.

The test runs for 2000 steps. In the first 600 steps, 6 different pictures of pyramid and stalactite are presented. Then for the next 1000 steps, 10 different pictures of pyramid and stalactite are presented while the instance net receives no external input.  For the next 398 steps, there is no visual input to the V2 net and input to the instance net is turned on, rotating between pyramid and stalactite labels after every 50 steps.

Different instances of visual pyramid and stalactite were used. On all 28 tests, the correct association between shapes and their labels was learned.

4.2 Pronoun Resolution  For the pronoun resolution experiment, the connection weights are set within CAs of the instance net (from the it CA to all other CAs in the instance net) and from the V2 net to the instance net, the later reflecting those weights learned in the labelling experiment. The connections from the pronoun it in the noun net to the it CA in the instance net are also set. Input from both the V2 net and the instance it CA in the instance net is needed to ignite the stalactite or pyramid instance CAs in the instance net.

Each shape in V2, label in the instance net and words in the noun net are represented by a CA of 500 neurons. Every 11th neuron of a shape CA in the V2net and of the instance it CA has 3 random connections with stalactite and pyramid CAs in the instance net with the weight of 0.7 and 0.6 respectively. Every 5th neuron of the it CA in the noun net has 3 random connections to the it CA in the instance net with the weight of 1.2. The other parameters were selected by a trial and error method. The instance net had a decay rate of 1.4, fatigue of 0.5, fatigue recovery of 1.4 and activation threshold of 3.8.

In a pronoun resolution experiment, a sentence containing pronoun ambiguity [10] and a shape to which the pronoun is referring to was presented to the system.

The activation of the CAs of instance it or CAs of shapes from V2 can not ignite stalactite and pyramid CAs instances on its own. A combined activation from the visual field and the noun field is able to ignite the symbol label. The pronoun it gets linked to the presented shape dynamically each time a different shape is presented.

Figure 5.

Figure 5 shows a run of the pronoun ambiguity resolution experiment. Each square represents a neuron. A filled square represents a fired neuron. In this run, a pyramid is presented to the system as shown in the Visual Input net causing the ignition of the pyramid CA in V2. When a sentence is presented to the system, it gets parsing causes words in the noun net ignite. In this run, a sentence containing it is presented to the system igniting the it CA in the instance net. The label pyramid instance CA is ignited by the combination of V2 and the it instance CA.

For 1000 cycles, the system is tested by presenting different shapes as input to the system and presenting the system with a sentence containing an ambiguous it pronoun. While the system is presented with the pronoun it, if the matching shape CA turns on in the instance net, then the system has associated the pronoun it dynamically with the presented shape and hence has resolved the pronoun ambiguity.

The CAs of the word instances both receive connections from the it instance and the corresponding visual CAs; the word instance is only ignited when it gets activation from both of the nets. The experiment was run 20 times and each time the ambiguous pronoun was successfully dynamically associated with the visual item presented to the system at that time.

5. Conclusions and Future Work  The results of the above experiments are promising. The labelling experiment learns the correct association between shapes and their corresponding labels on all 28 experiments. The label experiment is a small but important step towards the solution of the SGP. Labelling is an essential aspect of symbol grounding because it attaches symbols to sub symbolic representations (semantic CAs).  As compared to other models [19], [22], this model is simpler and more generic in nature.

The pronoun resolution experiment creates a dynamic association between ambiguous pronouns and shape categories. Pronoun resolution is not required to ground symbols, but the experiment shows one of the many benefits of symbol grounding. The promising results of these experiments show that Hebbian learning can be used effectively to ground semantic symbols and indicates that the model and the technique used can be used effectively in solving other aspects of symbol grounding.

Other aspects of the SGP need to be addressed in order to fully ground symbols. These include symbolic theft and functional symbol grounding. Symbolic theft is to makes new categories by modifying old categories from symbolic instruction. For example, by combining stripes with horse, a new category, zebra, can be created.

Functional symbol grounding depends on the context in which the symbols are used. The use of the symbols is domain and situation specific [20]. By improving symbol grounding,  the accuracy of the system can be enhanced.

6. References [1] C. Breazeal,"Sociable Machines: Expressive Social  Exchange between Humans and Robots". Dissertation, Department of EECS, MIT (2000).

[2] A. Cangelosi, ?Evolution of Communication and Language Using Signals, Symbols and Words?, IEEE Transaction in Evolution Computation, 5, pp. 93-101, (2001).

[3] A. Cangelosi, A. Greco S. Harnad, ?From Robotic Toil to Symbolic Theft: Grounding Transfer from Entry-Level to Higher-Level Categories?, Connection Science, 12, pp. 143- 162, (2000).

[4] A. Cangelosi, A. Greco  S. Harnad, ?Symbol Grounding and the Symbolic Theft Hypothesis?, in Simulating the Evolution of Language, A. Cangelosi and D. Parisi, Eds., London, Springer,  pp.191-210, (2002).

[5] P. Davidsson, ?Toward a General Solution to the SGP: Combining Machine Learning and Computer Vision?, in AAAI Fall Symposium Series, Machine Learning in Computer Vision: What, Why and How? pp. 157-161 (1993).

[6] S. Harnad, ?The SGP?, Physica D, pp. 335-346, (1990).

[7] S. Harnad, ?Symbol Grounding in an Empirical Problem:  Neural Nets are just a Candidate Component?, in Proceedings of the Fifteenth Annual Meeting of the Cognitive Science Society, (1993).

[8] S. Harnad, Grounding Symbols in the Analog World with Neural Nets, a Hybrid Model, Psychology,  pp12-78, (2001).

[9] D. Hebb. The Organization of Behavior. John Wiley and Sons, New York (1949).

[10] D. Hindle, Mats Rooth. ?Structural Ambiguity And Lexical Relations?  Meet. Assoc. Computational Linguistics (1993).

[11] C. Huyck. ?Overlapping CA from correlators?.

Neurocomputing 56:435?9 (2004).

[12] C. Huyck. ?Creating hierarchical categories using CA?.

Connection Science (2007).

[13] C.Huyck, ? CABot1: a Videogame Agent Implemented in fLIF Neurons? IEEE Systems, man and Cybernetics Society, London. pp 115-120 (2008).

[14] R. Langacker.  Foundations of Cognitive Grammar. Vol. 1.

Stanford, CA. Stanford University Press (1987).

[15] J. Searle, ?Minds, Brains, and Programs?, Behavioral and Brain Sciences, 3, pp. 417-458, (1980).

[16] L.Steels ?The Symbol Grounding Problem has been solved.

So what?s next?? Symbols, Embodiment and Meaning, Oxford University Press,  (2007).

[17] M. Mayo, ?Symbol Grounding and its Implication for Artificial Intelligence?, in Twenty-Sixth Australian Computer Science Conference , pp. 55-60 (2003).

[18] R. Sun, ?Symbol Grounding: A New Look at an Old Idea?, Philosophical Psychology, 13, pp. 149-172, (2000).

[19] D. Roy. Grounded Spoken Language Acquisition: Multimedia, 5(2): 197-209, (2003).

[20] M. Taddeo  and L. Floridi Solving the Symbol Grounding  Problem: a Critical Review of  15 Years of Research (2003).

[21] T. Wennekers and G. Palm "Cell Assemblies, Associative  Memory and Temporal Structure in Brain Signals", in Time and the Brain, pp 251-274, (2000).

[22] C. Yu and D.  H. Ballard, "A Multimodal Learning Interface for Grounding Spoken Language in Sensory Perceptions", ACM Transactions on Applied Perception, 1, 57-80, (2004).

