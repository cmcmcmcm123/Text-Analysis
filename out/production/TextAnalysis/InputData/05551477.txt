Rule Induction for Identifying Multi Layer Tool  Commonalities

Abstract ? A methodology based on association rule concepts is given for detecting fab tool commonality of affected lots.  The performance of the methodology is then compared to several traditional methods such as ANOVA and contingency tables using eight actual production cases.  In each case, the offending tool is affecting lots at multiple process layers.



I. INTRODUCTION  Many fab tools are used at more than one process step, which poses a challenge for identifying tool commonality of yield problems.  For example, a specific wet bench might be used for a dozen layers (operation numbers), which makes it difficult to find a yield problem caused by the bench if one looks only a layer at a time.  Also, it would be desirable to be able to identify not only which tool is at fault, but also which layers on the tool are at fault and on what dates.  There are several existing methods in common use to search for tool commonality across multiple layers.  Some are model based and rank commonalities using statistical tests, such as ANOVA and contingency tables.  Others are simple ranking criterions that typically have as their goal to rank the tool which processed the most affected lots in the shortest period of time at the top of the rank list.  Generally these methods do not include time or layer in the model or search criterion.  We present a rule induction methodology that efficiently searches through tools, layers, and time combinations finding and ranking those that are likely responsible for the yield problems. We compare   performance of the proposed methodology with ANOVA, contingency tables, and most- lots-in-least-time ranking.

A multi layer tool commonality is loosely defined as a commonality which is best found by looking across all layers a fab tool is running, rather than looking a layer at a time.  For example, consider Fig. 1.  A single fab tool is running 4 layers.  Lots with a ?1? on the y axis have been categorized as ?Bad? and lots with a ?0? have been categorized as ?Good?.

By looking at all layers at once, it is clear that the problem started after Dec. 15th and ended before Dec. 21st.   Contrast Fig. 1 with Fig. 2, which shows the same time trend split into a separate graph for each layer.  The trend is no longer apparent when looking a layer at a time.

Lo t C  at eg  or y  D  ec   D  ec   D  ec   D  ec   D  ec   D  ec   D  ec   D  ec   Date  A B C D  Layer   Fig. 1.  Time trend for single fab tool showing good and bad lots by layer.

Lo t  C at  eg or  y  D  ec   D ec   D  ec   D ec   D  ec   D ec   D  ec   D ec   D  ec   D ec   Date  Scatterplot Matrix Layer=D    Lo t  C at  eg or  y  D  ec   D  ec   D  ec   D  ec   D  ec   D  ec   Date  Scatterplot Matrix Layer=C   Lo  t C  at eg  or y  D  ec   D  ec   D  ec   D  ec   D  ec   D  ec  Date  Scatterplot Matrix Layer=B    Lo t  C at  eg or  y  D  ec   D ec   D  ec   D ec   D  ec   D ec   D  ec   D ec   D  ec   D ec   Date  Scatterplot Matrix Layer=A   Fig. 2.  Time trend from Fig.1 separated by layer.



II.  METHODOLOGY  A.  Basic Concept of Association Rules  A common application of association rules is searching a large database of customer purchases at a retail business. It is often referred as ?market basket analysis? where rules generally have the form of {A,B}=>{C}, meaning that if A and B are bought, customers also buy C. Rules are usually measured by their support and confidence.  Support measures what percent of rows in the database are covered by the rule conditions. Confidence measures how often the rule is correct.

For example, if a rule {A,B}=>{C} has 0.65 support and 0.41 confidence, this indicates that 65% of the transactions in the database contain both A and B and 41% of the {A,B} combination results in {C}.   A tool commonality rule would look like {fab tool, date range, layers}=.{yield issue}.  Here we are more interested in the conditional support, which is the number of known bad lots that were processed on a specific tool, subset of the corresponding layers, during the date range identified by the rule.  Confidence can be thought of as a ?hit rate?, that is, if a number of lots were sent through the specific tool, during the rule date range, and at one of the identified layers, how many do we expect would be hit with the yield problem.  For more on association rules, interested readers are referred to [1].

Using the association rule concepts, we could count the number of bad lots that occur on tool, layer, and date combinations and the number of times that combination results in a bad lot.  Our goal is to put the tool at fault at the top of a rank list.  However, calculating every possible rule is not usually possible since fabs typically have hundreds of tools and operation numbers and analysts usually are looking at tens of bad lots across 30 day time periods, so the count of possible combinations explodes to an impractical number. In [2], we successfully adopted the primary association rule induction algorithm, Apriori, for single layer commonality analysis targeting spatial patterns in sort wafer maps.   Here we look to expand the methodology for multi layer commonality.

B.  Applying the Concept to Ranking Tool Commonality  The main limitation of the association rules approach, which creates an exhaustive set of rules, is the requirement of discrete attributes. It means that time through the tool has to be pre-discretized and layers are pre-grouped before the Apriori algorithm can be used. That poses a significant challenge when a correct rule could have multiple constraints on the tool, subset of layers, and the time interval. We address these limitations by using a direct search optimization technique to solve a 2-target (conditional support and confidence) maximization problem. The 2-target problem is transformed to a single fitness function optimization task that combines a weighted combination of conditional support and confidence of the resulting rule. Conditional support and  confidence are intuitive measures that allow us to rank rules by a combination of how many bad lots they contain and their hit rate. Rules are sorted by the fitness function, and accompanied by insightful, novel visualization.  The algorithm is given formally in Algorithm 1.

ALGORITHM 1  1. For  t = 1,...,T 2.    Calculate c* = c(min(Xi3),max(Xi3)) and cs* = cs(min(Xi3),max(Xi3)) 3.    For k = 1,?,K 4.       for k>1 if(cs(LBk-1,UBk-1) < csmin then go to step 14 end for 5.       for k = 1 set IUBk = I and UBk = max(Xi3) end for 6.       For l = 1,?,IUBk set LBl = xl3 calculate f(LBl,UBk) End For l 7.       select LBk =  f(LBl,UBk)  8.       set ILBk to row number in XT of LBk 9.       For u = I,?,ILBk set UBu = xu3 calculate f(LBk,UBu) End For u 10.     select UBk  =  f(LBk,UBu)  11.     set IUBk to row number in XT of UBk 12.     for k > 1 if f(LBk,UBk)  f(LBk-1,UBk-1) then go to step 14 end for 13.    End For K 14.      set LB = LBk and UB = UBk 15.    End For T   l maxarg  u maxarg  TABLE I NOTATION FOR ALGORITHM 1    T  Number of fab tools I  Number of occurrences of lots on tool t K  Number of user specified iterations LB Lower date bound for rule UB Upper date bound for rule C  Confidence calculated on distinct lots CS Conditional support calculated on distinct lots CSmin User specified minimum conditional support f(LB,UB) Fitness function, (c(LB,UB) ? c*) + (cs(LB,UB) ? cs*) User specified trade off between C and CS  XT [xi,j]i=1,?,I,j=1,?,3 where Xi1=Lot ID, Xi2=Affected ID (0 or 1), Xi3=Date   323 ASMC 2010    C. Competing Methods  Algorithm 1 will be compared to the methods described below.  The goal of each is to rank the tool at fault at the top of a rank list, but how this is attempted is much different between the methods.  For more background on traditional commonality methods, see [3] and [4].

i.  ANOVA:   Very common method for detecting yield differences between tools.  The mean of the failing sort bin(s) that make up the spatial pattern are calculated by tool, by operation.  The means of all tools at an operation are then compared using a statistical test.  Tools are then ranked by the statistical significance of the difference between the tools at a layer.  This is a layer-at-a-time method since means for the tools are calculated by layer.

This method is commonly automated by fab yield analysts where a set number of days back (say 30 days) of end of line sort data is extracted daily and ANOVA is automatically performed.

ii.  Contingency Tables:  Another common statistical model based method for finding tool commonality of bad lots.  Here, a table is constructed for each fab tool, where all lots in the data set are categorized by the user as ?Good? or ?Bad? and also ?Yes? or  ?No? as to whether they ran on a specific tool.  A 2X2 table is then constructed where the columns indicate whether lots were affected or not, e.g.

(?Good?,?Bad?), and the rows indicate whether lots ran on the tool or not, e.g.   (?Yes?,?No?).  A statistical test is then performed to see if the proportion of bad lots for a fab tool exceeds that of other tools of its kind.  Tools are then ranked by the statistical significance of the test.  This is a multi layer approach since the 2X2 tables are constructed by tool, NOT by tool, by layer.

iii.  Most-lots-in-least-time:  An intuitive approach which ranks fab tools by the percent of the user classified ?Bad? lots they ran and the shortest length of time required to span all ?Bad? lots ran on the tool.

For example, if Tool A and Tool B each ran 9 of 10 ?Bad? lots, but the minimum time span needed to cover the 9 lots was 2 days for Tool A and 3 days for Tool B, then Tool A would be ranked above Tool B.

Is a multi layer approach since the count and time span are done by tool, NOT by tool and layer.

iv.  Single Layer Rule:  An association rule based method which uses conditional support and confidence to rank rules.  Rules are ranked based upon their distance from the pareto bound on the conditional support-confidence plane.  The pareto bound is defined by points for which there is no other point with greater conditional support and  confidence.  Method is described in detail in [2].

Similar in concept to Algorithm 1, except this is a single layer method since rules are built by tool, by layer.



III.  APPLICATION  A.  Data Sets  The performance of Algorithm 1 was compared to the traditional methods for finding tool commonality, namely, ANOVA, contingency tables, and most-lots-in-least-time ranking.  The 8 data sets used are production data where the tool causing the yield problem is affecting lots at multiple operation numbers (layers).  These data sets were selected as they are typical of the yield problems seen at a modern semiconductor fab with high yields.  Because of the high yields, the number of die affected per wafer tends to be small, which hurts the ability of mean die per wafer based methods like ANOVA of finding the correct tool commonality.  All 8 yield issues have a spatial pattern.  A summary of the 8 data sets is given in Table II.  Note that hit rate is the percent of bad lots that ran through the tool during the affected time period.

TABLE II DATA SET SUMMARY      Space constraints prevent providing more detail on each of these cases, however, the Deposition Tool 2 case will be highlighted to provide a good idea of the challenges the commonality methods face in identifying the fab tool which is at fault.  Fig. 3 shows some of the sort wafer maps for wafers affected by the deposition tool.  Note that the spatial pattern is a small, approximately square region which rotates around the edge of the wafer.

324 ASMC 2010      Fig. 3.  Sort wafer maps of a sample of the affected wafers   There are several challenges presented by this data set to any commonality method.  Specifically, only 7 lots are affected, the problem is intermittent (hit rate is only 16%), only a small number of die per wafer are affected, there are 30 days of end of line data in the data set, there are approximately 500 fab tools which could be at fault and many of these tools are used at multiple operations.  Some or all of these challenges are present in each data set.

B.  Results  Table III provides the summary results of applying each method to the data sets.  The value given in the table is the rank which was given to the correct tool.  For example, a ?1? indicates the tool which was at fault was ranked at the top of the rank list, a ?17? indicates the tool which was at fault was ranked 17th in the rank list.  A ?NR? means that the method did not provide a rank for the correct tool since no difference between the tool and its peers was detected.  The median and range of the ranks for each method are also provided.  The order of the methods in the table are from best to worst at consistently finding the correct tool as determined by the median and range of the ranks.

TABLE III  RESULTS SUMMARY    Algorithm 1 (Layer=Multiple, Method=Rule) in Table III, ranks the correct tool at the top of the list for all but one of the data sets, where it ranks the correct tool as 2nd.

Fig.?s 4-6 show supporting graphics generated for the rules found by Algorithm 1 for the Deposition Tool 2 data set.  Fig. 4 shows the rules list and x y scatter plot of conditional support and confidence which allows easy browsing of all competing rules in the rank list.

Fig. 5 is the time trend plot of all lots that ran on the tool identified at the top of the rule list.  Multi layer time plots are complicated by a lot being able to enter the tool many times, as opposed to a single layer time plot where a lot can only enter once.  To reduce clutter, only the first and last times a lot enters a tool are charted and a line is drawn between these two points to indicate that the lot may have entered the tool additional times within that range.  Since we are plotting a bi response (?Good?,?Bad?), it is necessary to add jitter to the y axis so that many points are not drawn on top of each other and become unidentifiable.  The ?Bad? lots are shown in red and are at the top of the graph, the ?Good? lots are shown in the bottom of the graph.  Th symbols on the graph correspond to which operation number the lot entered the tool.  Fig. 6 shows other graphs generated which allow the user to compare the identifie      nary  e  d tool to others of its kind, compare operation numbers, and look at the hit rate versus number of times lots passed through a bad tool.

Fig. 4.  Sorted rule list and x y scatter plot of confidence and conditional support for the Deposition Tool 2 case, multilayer analysis    Fig. 5.  Time trend for the tool at fault  in the Dep. Tool 2 data set  325 ASMC 2010        Fig. 6.  Other supporting graphics for the rule identified in Fig. 4.

violated, but that is less critical than say, looking only a layer at  C.  Discussion of Results for Competing Methods  In general, these methods fail to consistently rank the correct tool at the top of the list for at least one of the primary reasons in the list below.  There are secondary reasons as well, such as some of the assumptions of the statistical tests are  a time for a multi layer yield signal.

i.  Method searches a layer at a time.  The ANOVA and single layer rule methods look at the data split into a layer at a time.  As demonstrated in the simple example in Fig. 1    and 2, this can hide an otherwise obvious signal.

ii.  Method searches for a difference in the mean number of bad die (or specific sort fail bins).  This is why ANOVA tends to fail on these data sets.  At high yielding factories, many of the yield issues affect only a small number of lots  and only a small number of die per wafer on affected lots.

Too few lots and die per wafer affected results in a small, if any difference, between the correct tools and other tools of its kind.

iii.  Method does not effectively restrict the data set to approximately the affected time period only.  ANOVA calculates the means for each tool on all data provided.

This means it mixes unaffected and affected time periods, diluting the signal.  Contingency tables also tabulate all the data provided, again mixing affected and unaffected time    periods and also diluting the signal.

iv.  Method uses a statistic for ranking which is sensitive to widely differing run rates and number of layers processed between tool types.  This is the case with the most-lots-in least-time method.  Both Algorithm 1 and most-lots-in- least time use conditional support as part of the ranking criterion.  However, Algorithm 1 also uses hit rate, which normalizes for differences in run rates and layers proc by dividing by the number of lots during the time period.

Most-lots-in-least time does not normalize for these differences, rather it simply searches for the smallest time window that includes the largest number of affected lot This leaves it vulnerable to ranking tools like wet benches consistently near the top of all the data sets  since wet benches typically have high run rates and are used at many layers.  A tool with a high run rate that is in use for many layers is more likely to  -  essed  s.

have a small time window for the affected lots simply because it can run more lots in less time more often.

in    e time  d, rather than on constructing a sample.  Also, it enables greater efficiency in that more signals can be found in less time.



IV.  CONCLUSIONS  In [2], we demonstrated how methods based on modern statistical learning algorithms can greatly reduce the time required to do the typical analysis done by yield analysts fabs.  Here, we have focused specifically on how a modern method generally referred to as association rules can be adapted to out perform traditional methods for doing multi layer tool commonality.  While any of the traditional methods could perform better with more human intervention, such as preparing well groomed data sets with carefully constructed ?Good? lot lists or time periods to compare against, thes consuming efforts are made unnecessary by Algorithm 1.   We have coded the algorithm to run in seconds on a laptop computer against data sets of 500 lots and no time consuming sample selection is required from the user in order for the method to find the correct tool commonality, just run the past n days of data through the algorithm.  The benefit for the analyst is that more time can be spent following up on the top few commonalities identifie     326 ASMC 2010      , IEEE/SEMI International , vol., no.,  pp.85-89, 21-23 May 1990

V.  REFERENCES  [1] T. Hastie,  R Tibshirani, and J. Friedman,  The Elements of Statistical  Learning,  New York:  Springer-Verlag, 2001.

[2] St. Pierre, E.R.; Tuv, E.; Borisov, A., "Spatial Patterns in Sort Wafer  Maps and Identifying Fab Tool Commonalities," Advanced  Semiconductor Manufacturing Conference, 2008. ASMC 2008.

IEEE/SEMI , vol., no., pp.268-272, 5-7 May 2008  [3] Kong, G., "Tool commonality analysis for yield enhancement,"  Advanced Semiconductor Manufacturing 2002 IEEE/SEMI Conference  and Workshop , vol., no., pp. 202-205, 2002  [4] Garling, L.K.; Woods, G.P., "Determining equipment performance using  analysis of variance," Semiconductor Manufacturing Science  Symposium, 1990. ISMSS 1990.

