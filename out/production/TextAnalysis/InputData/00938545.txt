Using Association Rules to Add or Eliminate Query Constraints Automatically

Abstract  Much interesting work has been done on the use of se- mantic associations for optimizing query execution. Our objective is to study the use of association rules to add or eliminate constraints in the where clause of a s e l e c t query. In particular; we take advantage of the following heuristics presented by Siegel et al. [6]: i )  i f  a selection on attribute A is implied by another selection condition on at- tribute B and A is not an index attribute, then the selection on A can be removed from the query; ii) i f a  relation R in the query has a restricted attribute A and an unrestricted cluster index attribute B, then look for a rule where the re- striction on A implies a restriction on B. The contribution of our work is twofold. First, we present detailed algorithms that apply these heuristics. Hence, our ideas are easy to implement. Second, we discuss conditions under which it is worth applying these optimization techniques, and we show the extent to which they speed up query execution.

1. Introduction  Rules that correlate values of data attributes in large databases have been investigated for two main purposes.

The first is to aid management and decision-making in large companies with great amounts of data. The second relates to query optimization, by exploiting the semantic knowl- edge expressed in rules [2 ,  3, 6, 9, 101. Siegel et al. [6] have proposed several heuristics to guide rule generation and so help to transform queries to more efficient forms.

In this paper we investigate algorithms for applying two of these heuristics to optimize range queries. We express queries using OQL (Object Query Language); however, our algorithms and optimization techniques are also applicable in any relational or object-relational database system. The form of queries under consideration is:  s e l e c t  e(.) from ExtentX as x where pl(x) and . . . and p,(x)  The first heuristic (Hl) aims to eliminate as many pred- icates (or constraints) pi(.) as possible, when they are im- plied by other existing predicates. The second heuristic (H2) finds implications from one or more existing predi- cates to a new predicate on a cluster index attribute. If the latter is added to the where clause of the query and is tested first, then the existing predicates will be tested on a smaller number of objects. In order to take advantage of either of these heuristics, we use association rules that are relevant to ExtentX.

In our context, association rules express semantic correlations between the values of the attributes of all objects belonging to a certain extent. They consist of two parts, the antecedent, which has one or more constraints, and the consequent, which has just one constraint: cons t r l  A . .  . A constr ,  3 constro.

The constraints constr ,  are of the form c l a s sname .a t t r ibu te ,  comp-op, valuei,  where for all O <= i <= n, comp-opl E {<, >, <=, >=, =, #}.

Association rules are typically ranked by two measures of interest: confidence and support. Confidence expresses the fraction of all objects satisfying the antecedent that also satisfy the consequent. Support expresses the percentage of objects of the extent satisfying both the antecedent and the consequent; hence it indicates how often the rule occurs in the extent of a certain class. A number of algorithms have been proposed for mining association rules over categorical or quantitative data [ l ,  7,4, 5, 81. In the remainder of the paper, we assume that the process of mining rules has been completed and that we already have a warehouse with a set of rules for each extent in the database. Further, in this warehouse we store the exceptions to each rule, i.e. those objects that satisfy its antecedent but not its consequent.

We also assume that the rules and their exceptions are correctly maintained when the database is updated.

Automatic use of these rules by the OQL optimizer raises many issues. The first concerns mapping the predicates in the where clause of a s e l e c t  query to constraints that could potentially be found in the antecedent (or the conse- quent) of association rules. This is a step towards identi-  0-7695-1218-6/01 $10.00 0 2001 IEEE    fying the templates of association rules that could help in our optimizations; this task is slightly different for heuris- tics H1 and H2, as discussed in section 2. In section 3, we present a common graph algorithm that goes through all existing association rules and discovers the ones that fit the templates along with their exceptions. In section 4, another graph algorithm combines these rules to discover the possi- ble optimizations, i.e. the sets of constraints that could be omitted from (Hl) or added to (H2) the query. In section 5 we present the actual transformations of OQL queries for each of the two optimization techniques. Finally, in sec- tion 6 we investigate the conditions under which it is worth applying the optimizations and show the extent to which they are expected to speed up query execution.

2. Converting query predicates to rule con- straints  The first step towards applying either of the heuristics is to map the predicates found in the where clause of a s e l e c t  query to constraints found in the existing associ- ation rules. Consider the following OQL query: selectxfromhployees asx where x.salary > 35,000 and x.salary < 55,000 and x.position = ?associate? and x.year-of-birth <= 1975 and x.year-of-birth >= 1955 and x.year_of-employment <= 1990 and x.year-of -employment > 1970  (1) We first: need: to gather a edioares that refer; t o  the same attcibuteinto one.pl;edicatt, and:fbml constraints of the. focmc a,t.tribute:namei i n  rangs: The resulting: constraints. in[ owexample are given!belbw:,  s-a.1 aryi 5n. 4 (35 7 .  000;: 5!5$7. 0 pos i t i on  i n  {?associate?} C B year-of-bir th  i n  { [1955: 19751)  c*t  cc CD year-of -employment i n  { (1970; 19901)  Based on these query constraints, the next step is to search for similar constraints in the association rules. Sup- pose that the warehouse contains the association rules illus- trated in figure 1, which are relevant to the class Employee.

The constraints in the antecedent and the consequent of the rules are labeled with short names, e.g. C ~ , R * ,  is a constraint limiting the values of attribute k to the range R k j .  Here a range is a specified set of values of some attribute. The set of ranges associated with a particular attribute is partially ordered under inclusion in the usual way.

To distinguish constraints that are derived from the where clause of our query from those in the antecedent or consequent of the association rules, we refer to the former as query constraints, and to the latter as rule constraints.

For each heuristic we look for rule constraints correspond- ing to the query constraints.

2.1. Heuristic HI  We first discuss rule constraints relevant to the con- straint elimination heuristic. For each constraint C on a t t r i bu tename  with range R, identify the following rule constraints:  Category 1 - relaxed constraints First, identify the con- straints whose ranges are the next more general than (or the same as) the range of the original constraint C.

If there exists such a constraint CO with a range Ro, then for all other constraints Ci i # 0 on a t t r i bu tename with ranges R i ,  if R Ro). That is, R0 is one of the least supersets of R among all ranges of constraints referring to the same attribute.

Ri then not@  Category 2 - relaxed combinations of constraints Second, identify minimal combinations of constraints which have the property that the union of their ranges is a superset of the range of the original constraint C.

The constraints in any combination must satisfy the following conditions: firstly, none of the constraints can be the same as (or with a wider range than the range of) any constraint identified previously in category 1 ; secondly, no combination must include all the constraints of a smaller combination; thirdly, if either of two constraints on the same attribute may take part in a combination, and the range of the one is a subset of the range of the other, then the one with tlie:smaller range is. selected.

Category, 3: - tightened constraints Third, identitfy the constraints; whose ranges are the. next more specific than- (or the same. asJ the range of ttie. original con- seaint.. Ifithere exists.sucti a constraint CO with a range R0, i t  means that for all other constraints C i  i # 0 on a t t r i bu tename  with ranges Ri, if R 2 Ri then not(Ri 2 Ro). That is, Ro is one of the greatest sub- sets of R among all ranges of constraints referring to the same attribute.

Category 4 - tightened combinations of constraints Fourth, identify maximal combinations of constraints which have the property that the intersection of their ranges is a subset of the range of the original constraint C. The constraints in any combination must satisfy the following conditions: firstly, none of the constraints can be the same as (or with a range contained in the range of) any constraint identified previously in category 3: secondly, no combination must include all the constraints of a smaller combination: thirdly, if either of two constraints on the same attribute may take part in a combination, and the range of the one is a superset of the range of the other, then the one with the wider range is selected.

year-of - b i r t h  i n  { [1955, 1975]}(C1.R11) + s a l a r y  i n  { [35, 000, 50, 000]}(C~,RZl) p o s i t i o n  i n  { L L a ~ ~ ~ ~ i a t e ? } ( C 4 . R 4 1 )  3 s a l a r y  i n  {[30, O O O , ~ ~ ,  000]}(CZ,Rz2)  year-of - b i r t h  i n  {[1950: 197o]}(C1.Rl,) 3 p o s i t i o n  i n  { ?associate?}(C4.R41) year-of-employment i n  {[1975, 1990]}(C5.Rs3) + p o s i t i o n  i n  { ?associate?}(C4,R41) year-of-employment i n  { [1965, 1985]} (C5 ,~~~)  + e f f i c i e n c y  i n  {[3: 6 ] } ( ~ ~ , ~ ~ , )  p o s i t i o n  i n  { ? m a r ~ a g e r ? } ( C ~ . ~ , )  + year-of - b i r t h  i n  {[1955, 1980]}(C1.~~~)  CA  CS  CC  CD  in {[30: Oo0: 65; 0001}(C2.~23)  + year-of-employment i n  { [1970, 1985]}(C5.~~,) p o s i t i o n  i n  { ?manager?}(C4,R42) I  Relaxed Constraints salary i n  { [30,OOO, 60, 000]}(~2.R~~) posit ion i n  { ?associate?}(C4.R4, ) year-of-birth i n  {[1955, 1975]}(Cl.R,,) Relaxed Combinations of Constraints {year-of-employment i n  {[1970,~985]}(~s.~,,) year-of-employment i n  {[1975, 1990]}(C5.Rs3)}  3 y e a r - o f - b i r t h  i n  {[1955: 1975]}(C1.Rl,) s a l a r y  i n  {[30, 000, 60, 000]}(CZ.R22) e f f i c i e n c y  in{[3: 6]}(c3.~,,)  CC  I 3 p o s i t i o n  i n  {?associate?}(C4,R4,) s a l a r y  i n  {[30: OOO,60: 000]}(C~.R22) e f f i c i e n c y  in{[3, 6]}(c3.~,,)  Tightened Combinations of Constraints {year-of-birth i n  {[1955, i98O]}(ci.~,,) year-of-birth i n  {[1950, 197o]}(C1.Rl,)}  j e f f i c i e n c y  in{ [3, 61) (c,.~,,) year-of - b i r t h  i n  {[1955, i98O]}(c1.~,,) salary i n  {[35, 000, 50, 000]}(C2.Rz1)  Figure 1. Association rules relevant to the class Employee  In the example of query 1, the query constraints CA, Cg, Cc and CD correspond to the following rule constraints:  For each tightened combination of constraints we generate a new constraint whose range is the intersection of the ranges of the constraints in the combination. We add this new constraint to the category of tightened constraints and create a new temporary rule with the initial constraints in the antecedent and the new tightened constraint in the consequent. For instance, based on the tightened combination {year-of - b i r t h  i n  {[1955, ~ 9 8 o ] ) ( c 1 . ~ , , ) , year-of - b i r t h  i n  { [1950, i970]}(C1.R13)}, we create the constraint {year-of - b i r t h  i n  {[1955, ~970]}(c1.Rl,23).

Repeating this procedure for all tightened combinations of constraints, we generate a new set of tightened constraints.

The rationale behind finding the constraints in categories 1 to 3 is the following. By definition, the query constraints imply their corresponding relaxed constraints. Likewise, the tightened constraints imply the initial query constraints.

Hence if we can find association rules that relate constraints in the first two categories to those in the third, i t  is equiv- alent to finding rules that correlate the initial query con- straints with each other.

2.2. Heuristic H2  For the purposes of applying the constraint introduction heuristic, we identify the following rule constraints:  Category 1 - relaxed constraints These are identical to the relaxed constraints described in section 2.1.

Category 2 - relaxed combination of constraints This category is the same as its counterpart in section 2.1.

Category 3 - index constraints If the extent has a clus- ter index on attribute a t t r i ,  then this category in- cludes all the constraints on this attribute that oc- cur as consequents in the existing rules. Assume that the cluster index of the extent Employees is the attribute e f f i c i e n c y .  Based on the rules of fig- ure 1 ,  the only index constraints is the constraint e f f i c i e n c y  in{ [3, SI}.

Rule constraints imply relaxed (combinations of) con- straints, by definition. If we succeed in finding paths from relaxed (combinations of) constraints to an index constraint, then we can add the latter to the where clause of the query.

Figure 2. Graph of Constraints  This allows us to reduce the disc access overhead without altering the results of the query.

2.3. Discussion  Constraints in categories 1 and 2 play an identical role for heuristics H1 and H2. However, the other categories play a different role in the two cases. Tightened constraints are similar to existing query constraints that can potentially be eliminated. Index constraints are new constraints that can potentially be added to the where clause of the query.

In the next section we present a graph algorithm that finds associations from the relaxed constraints to the tightened (Hl)  or the index (H2) constraints respectively. Since the algorithm is common to both heuristics, tightened and index constraints are hereafter referred to as target constraints.

3. Identifying associations between constraints  In this section, we present an algorithm that goes through the association rules in the warehouse and identifies direct or indirect correlations between the relaxed and the target constraints discussed in the previous section. Before pre- senting this algorithm, we discuss an alternative graphical representation of the association rules. Consider for exam- ple the association rules in figure 1 .  They can be represented using a directed graph of constraints, see figure 2.

A rule having a single constraint in its antecedent (e.g.

C ~ . R : ~  + C~.R?: )  is represented by two vertices, labeled with  the constraints (C1.Rll and C ~ . R ? ~ )  and linked together by an edge from the antecedent constraint ( C 1 . ~ l , )  to the conse- quent constraint (CZ.R21). A rule with more than one con- straint in its antecedent uses an additional vertex to denote the conjunction. The link y.) denotes the fact that a con- straint in the antecedent of a rule implies the consequent only in combination with the other conjuncts forming the antecedent. The dashed edges link pairs of nodes that rep- resent constraints on the same attribute, with the source con- straint implying the destination constraint.

The notion of path in our context requires one extension to the standard notion for a directed graph. A path from a constraint Csource to a constraint Cdest is any sequence of vertices linked by directed edges, provided that no vertex represents a composite constraint. If a path contains a com- posite constraint, say C = C1 A . . . A C,, then there must be n paths from CsouTce, one to each of the conjuncts Ci.  These subpaths merge at the node representing the composite con- straint, and from there the path continues towards Cdest.

We consider also paths from a set of constraints {Cl: .  . . C,} to a single constraint. Such a path consists of subpaths starting from the source constraints {Cl:. . . C,} which merge at various composite constraints before reach- ing the destination constraint.

We can now develop an algorithm that navigates over a graph of constraints, finds paths linking relaxed (combi- nations of) constraints to target constraints and combines them to derive association rules useful for the purposes of optimization. It consists of three basic steps as shown in figure 3. The algorithm is discussed in detail in section 3.1.

paths to target constraints  j , Select or combine these rules to identify useful rules for the optimization, along with their exceptions  I I  Figure 3. An abstract view of the algorithm  Combine path annotations to derive indirect rules from relaxed constraints to target ones  At the end of each step we give an example to show how it can be applied for heuristic H1. It is equally applicable to heuristic H2.

Relaxed constraints and constraints in relaxed combina- tions often play the same role in the following algorithm, and we use the term source constraint in such contexts.

L - - - - - - - - - - - - - - - - - - - - - - - J  3.1. Algorithm  For each constraint Ck.Rkj in the target constraints take the following steps:  Step 1  Navigate backwards from Ck.Rk, in the graph of con- straints, i.e. navigate against the direction of the edges and annotate any source constraints encountered with information about the reverse path traversed so far. On encountering a composite constraint navigate backwards from all of its conjuncts. If a particular constraint is encountered more than once, or if there is no incoming link, then backtracking from the current constraint terminates.

Step 1 may be implemented as a recursive method backtrack on a class C o n s t r a i n t .  We demonstrate its functionality by an example. Consider the target constraint C4,& in the constraint graph (figure 2) .  We recursively apply backtrack to all the constraints leading to it, i.e.

C1.Rlar C ~ . R $ ~  and Ccomp2. The argument for the method is the path traversed so far, i.e. {c4&}. C1.Rl3 is not a source constraint, so no path annotation is assigned to it. No con- straint leads to it  (there is no incoming link), so there is no further recursive call from it. However, C5,RS3 is a constraint in a relaxed combination, so it is annotated with the path {C4.R41}. No recursive call occurs from it either. Ccomp2 is a composite constraint, so we recursively call backtrack on each of the conjuncts C ~ . R ~ ~  and C ~ . R ~ ~ ,  passing as argument  the updated path traversed {Ccomp2 -+ C4.b1} .  Recursive calls of backtrack continue until the constraint on which a call is made has no incoming link or the constraint appears in the argument path annotation. In figure 4, we present the path annotations assigned to source constraints by the time Step 1 is completed for the target constraint C4.b1.

Discussion of step 2  The objective of step 2 is to combine the annotations of source constraints to identify complete paths from sets of these constraints to a target constraint Ck.Rk,. The first step of the algorithm annotated the source constraints with com- plete or incomplete paths from them to a particular target constraint. For instance, C1.R1l ,  which is a relaxed con- straint, is annotated with four paths, as shown in figure 4.

Paths that include * links are called incomplete; they are useful only in combination with other incomplete paths that include the related conjuncts. One of the objectives of step 2 is to combine incomplete paths in order to identify (com- plete) paths from a source constraint like C1.kI1 to a target constraint like C4.R41. In fact, we can combine paths from more than one source constraint to a destination constraint.

Each edge + stands for an association rule which possi- bly has a list of exceptions E. A series of consecutive edges -+ corresponds to an indirect association from the source constraint to the destination one. The exceptions to this rule are evaluated from the exceptions of the association rules involved. In particular, if constraint A leads to constraint B based on a rule with exceptions E A ~ B ,  and B leads to C based on a rule with exceptions EBjC, then the exception set of the indirect path A + C (or the indirect rule A + C) is:  E = {exclexc t E A ~ B ,  no t  C ( e x c ) } U{exclexc t EB-c; A ( e x c ) }  ( 2 )  Note that E A ~ B  n E B ~ C  = {}, since all exceptions of E A ~ B     1 Path Annotations Constraints  Figure 4. Paths from relaxed constraints to the target constraint C4.R41  e in  F F T T F F F F  E(A + B)  F T F  F F  Figure 5. Truth table which shows the correct- ness of formula 2  satisfy A,  but do not satisfy B. Therefore they are not exceptions of EBqC. The correctness of formula 2 is proved by the truth table in figure 5.

Step 2  Path annotations derived from step 1 are combined to form complete paths by repeating steps 2.1 and 2.2:  Step 2.1 For all path annotations we omit all the initial con- straints, until the first constraint which is followed by a edge (this constraint is maintained). To omit these initial constraints, we must first evaluate the excep- tions involved in the rules until the -++ link (equation 2).

The resulting paths are either empty or start with sub- constraints leading to composite constraints.

When this step is executed for the first time the resulting  paths in our example are the following:  CZ.R22  p l :  (CZ.P.22 ut Csompz c4.R41}  E i  = {} C2.Rz2 p2: {C2.R23 -& ccomp3 --f C5.P.51 --f C5.P.52 + C3.R31  Csomp2 --t C ~ . R ~ ~ } EZ = E ( C Z . R ~ ~  * C Z . R ~ ~ )  = { } E3 = {ele t E(CI.R,, * C ~ . R , , ) ,  ! C Z . R , , ( ~ ) )  Cl.RIj p3: {C2.R22 -& ccompi --f C4.P.41)  C l . R I 1  P4: {CZ.R23 .sr) Ccomps + C5.P.51 --f C5.P.52 c3.831 --+ Ccomp2 + C ~ . R ~ ~ }  E4 = {ele t E(Ci.Rll C Z . R ~ ~ ) ,  !C2 R~~ (e), !CZ.R?~ (e)} = {el. +- E(C1.Rl1 * C2.R21), !C2.R23 (e)}  C1.RI1 P5: { C Z . R ~ ~  -+ Ccompl + C3.~31 --+ Ccomp2 + C 4 . ~ 4 1 } E5 = E(Ci.nI1 * C Z . R ~ ~ ) E6 = {}  Cl.R11 PS: (Cl.RI2 .r) Ccompl + C3.R31 -& Csomp2 3 C4.P.41)  c 5 . R ~ ~  P7: (C3.P.31 II^) Ccomp2 + c4.R41} E7 = {} U {ele t E(C5.nS2 C ~ . R ~ ~  ),C5.nsl (e)}  C5.P.53 PE: {} Ea = E(CmS3 =+ C4.nql)  If a path annotation is empty, it means that there is a com- plete path from the source constraint (e.g. C5.R5,) to the des- tination one (C4,bl). A new rule is created from the for- mer to the latter (C5,Rs3 + C4.b1)  and the exceptions eval- uated so far for this path annotation (E8) are assigned to the new association rule. The path annotation and its ex- ceptions are deleted. If an empty annotation corresponds to more than one source constraint then the rule that is gen- erated has a composite antecedent, i.e. it is of the form:  When using equation 2 to determine exceptions during step 2.1 we must take note of the exception sets arising from earlier iterations of steps 2.1 and 2.2.

Step 2.2 For each composite constraint Ccomp at the second position of some path annotation, we try to find a set of  C1 A . .  . A C, + Co.

path annotations having at their first positions the com- ponent constraints of Ccomp. These path annotations are combined into new path annotations as follows: i) the subconstraints at their first positions are omitted; ii) the resulting exceptions of the remaining paths are the union of the exceptions evaluated so far for each combined path that satisfy the source constraints of the other combined paths.

E(C& A CB =$ C) =  {ele t E(CI * C),C,(e)}U {ele +- E(CB 3 c),Ca(e)} ( 3 )  When step 2.2 is executed for the first time in our exam- ple, the following path annotations are generated:  C Z . R ~ ~ ,  ~ 5 . n ~ ~  Cl .Rl1 ,  C5.R.51 PlO: {ccompp? C4.R41}  P g :  {Ccompp? + C4.R41} E 9  = {.[e t E 7 ,  C2.R2, (e)}  Em = {ele t E 3 ,  C S . R s , ( e ) ) U{ele + E 7 ,  Ci .R11(e)}  EH = {ele +- E 5 ,  C 1 . R l l ( e ) }  If two path annotations which are combined do not have the same paths after the composite constraint (after the sec- ond position), then two combinations of paths should be generated, one for each annotation.

We retain path annotations P1 to P8 in order to combine them with new annotations at a later execution of step 2.2.

Substeps 2.1 and 2.2 are repeated until neither of them has any effect on the path annotations. This happens when all paths that have not been converted to rules in step 2.1 cannot be further combined in step 2.2.

C i . R i i  pll:  {ccompi --f C3.R31 Ccampi + C4.R41)  = E ( C ~ . R ~ ,  * C ~ . R ~ , )  Step 3  Not all the rules derived in step 2.1 are useful for op- timization purposes. The aim of this step is to filter and combine the rules derived from the previous step, referred to as RA, in order to generate rules relating query constraints with each other (HI), or query constraints to new index con- straints (H2). The resulting set of rules is referred to as Rg. We first give a detailed account of step 3 in the context of heuristic H1. We then point out a detail that should be changed so that the step is also applicable for H2.

We look for (sets of) rules in RA of the following kinds: 0 A rule from a relaxed constraint to the target constraint  C i ,  i.e. of the form C + Co. Such a rule is used to gen- erate a new rule C? 3 Cb, such that C?, Cb are the query constraints that refer to the same attributes as C and CO respectively, C is one of the relaxed constraints of C? and CO is one of the target constraints of Cb. Indeed,  c 3 CO (existing rule) c? =+ c  CO =2 c;  If the rule C 3 CO has exceptions E, the exceptions of the new rule C? + Cb are E? = {ele t E: C?(e)}.

0 A set of rules of the form Ci  j CO: i = 1, . . . n, such that Ci are all constraints in the same relaxed combina- tion of size n. This set of rules is used to generate the new rule C? + Cb, in which C?, Cb are the query con- straints that refer to the same attribute as the C, and CO respectively. If the corresponding exception lists of the rules C i  + CO: i = 1: . . . , n are Ei, the exceptions of the new rule are E = {ele t El U . .  . U E,, C?(e)}.

0 A rule from a set of relaxed constraints on differ- ent attributes to a target one, i.e. C I  A . . . A C, 3 CO.

This rule is converted to the corresponding rule C\ A . . . A Ch + Cb, such that Cb: . . . Ch are the query constraints on the same attributes as C O ,  . . . ~ C, re- spectively. The exceptions of the new rule are those of the initial rule that satisfy C; A . . . A Ch, i.e.

E? = {ele t E: C i ( e ) :  . . . : CL(.)>.

0 A set of rules whose antecedents contain both relaxed constraints and constraints in relaxed combinations is useful if i t  consists of all rules of the form:  Relaxed constraints - ,  Constraints  in relaxed combinat ions C ( k + i ) . ~ l  ? ? ? c(k+m).~m  A .

c 1  . . . CI,  where 1 5 ji 5 ni for all 1 5 i 5 m.

Constraints C(k+i ) . l : .  . . ~ C(k+i),,l form the relaxed combination i. The set contains N = n l  x . . . x n, rules, such that each constraint in a relaxed combi- nation occurs in all possible combinations with con- straints from the other relaxed combinations. In some of the rules some (or all) of the relaxed constraints C1 . . . Ca may not be present.

If such a set of rules occurs in RA we may derive the new rule C\ . .  . Ck Ck+l . . . Ck+,,, + Cb , such that Cl,:. . . CL+,,,: Cb are the query constraints that refer to the same attributes as C1: . . . ~ C(k+m). jmt  CO respectively. If the original rules have exception lists El, . . . , EN, then the resulting rule has exceptions E = {ele t E1 U . .  . U  EN: C),(e): . . . ,  Ck+m(e)}.

Evaluating exceptions appears very expensive in this case. However, in the common situation that m = 1, the cost of finding exceptions to the new rule is similar to the cost in the second case of step 3 .

Note that in the context of heuristic H2, C O  is a constraint on the cluster index attribute; i t  does not correspond to any of the existing query constraints. Hence, step 3 is applicable to H2, provided that in all four cases above, C b  = Co.

E15 c9 .R~ I  Figure 6. Correlations of query constraints  4. Identifying optimization solutions  In the previous section, we gave an algorithm that nav- igates over a constraint graph and extracts a set of useful association rules along with their exceptions. This section combines these rules to identify all possible solutions to the constraint elimination or constraint introduction problem.

Consider an OQL select  query with say 15 predi- cates. We combine all predicates referring to the same attribute into a single constraint a t t r i  i n  rangei (Ci.R,).

Assume that we derive the following set of constraints: C1.RI, . . . , C 1 2 . ~ ~ ~ ,  say. Since there is just one range for each ahribute, ranges are presented as R i  instead of Rij .  We first identify the rule constraints of possible interest for H1 or H2, then apply the graph algorithm presented in section 3.

The next step is discussed separately for each heuristic.

4.1. Heuristic H1  Say that the graph algorithm (section 3) results in the as- sociations illustrated in figure 6. Not all query constraints need be related; in our example only the first nine are. Note that the association graph (figure 6) is transitive; if there is a direct link from constraint A to constraint B, and another one from B to C, then A and C are also directly connected. This is a property of the graph algorithm in section 3. We now de- fine an algorithm that produces a set of constraint elimina- tion solutions { ( M i :  Ei)}, where Mi ,  Ei stand for Maintained Constraints and Exceptions respectively. Each pair (Mi, E i ) implies a solution of the following form:  We may eliminate all but the constraints M i from the where clause of the query, given that we take into account the exceptions Ei.

Algorithm Step 1 Identify all constraints that do not have any incom-  ing links. These constraints should be maintained (not eliminated), since no other constraint implies them. In figure 6, these constraints are C1.Rl, C6.Rs, C ~ . R ~ .

Step 2 Identify all cyclic paths that have no incoming link from any external constraint. If two cyclic paths have at least one common constraint, they are con- sidered as a single cyclic path. This case does not occur in our example. Form combinations of con- straints by choosing one constraint from every cyclic path identified. In our example there is just one such path containing the constraints C5.Rs, c g . ~ ~ :  C9.Rs; therefore the combinations consist of just one ele- ment: {c5&}, { c g , ~ ~ } ,  {Cg&}. Extend each of these combinations with the constraints without incoming links, identified in step 1. The resulting combinations  and {Cg.Rs: C1.R1: C6.R6: CT.~?} .  Each combination is a minimal set of constraints that implies all the remain- ing constraints in the graph (figure 6).

are {C5.RsrCI.Rl,C6.Rs:C7.R7}r {CE.RB,C~.R~:C~.R~:C~.R~}  Step 3 For each combination evaluate the exceptions that are involved in removing the implied constraints. If a constraint is implied by more than one constraint in a combination, then consider the exceptions of the strongest implication (the implication with the fewest exceptions). For example, the exceptions correspond- ing to the combination {C5.Rs: C1 .R1 .  C6.R6: C7.R7} are evaluated by forming the union of the exception lists: El for the elimination of C2; min-set {E2: E5} for the elimination of C1; m i n - s e t ( E 3 ,  E6: E7} for the elimi- nation of Cq;  E8 for the elimination of Cg;  E l 2  for the elimination of Cg.

Step 4 Form the final solutions to the elimination prob- lem by adding to each combination the remaining query constraints that are not related to each other (CIO.Rlo, C1l.Rll C12.R12). The exceptions corresponding to each solution are filtered so that they satisfy all the maintained constraints, i.e. all the constraints in the combination.

Note that all the solutions identified in the algorithm have the same number of constraints. We assume that the car- dinality of the extent against which the query is run is far greater than any of the exception lists annotating the op- timization solutions. Therefore, there is no advantage in eliminating only a subset of the constraints in a solution in order to decrease the number of exceptions involved.

4.2. Heuristic H2  Assume that in the context of H2 the graph algorithm (section 3) results in the associations illustrated in fig- ure 7. The constraints of the form Ci.Ri are existing query constraints, while the constraints C O . R ~ ~  , j 1: . . . , 3 are new constraints on the cluster index attribute. The additional subscript j is needed because the constraints on  =     Figure 7. Correlations between query con- straints and new indexed constraint  the index attribute may have different ranges. We iden- tify all possible constraint introduction solutions as follows:  Algorithm  For each constraint on the index attribute CO.Roj  Step 1 find the least expensive association from a query constraint to i.e. find the incoming link C ~ . R ~  + CO.Roj with the fewest exceptions. For exam- ple if the cardinalities of E l  ~ . . . E5 are nl, . . . n5 and n4 5 nz <_ n3, then the least expensive association for C O . R ~ ~  is c6.b + CO.R~,(E = E4).

Step 2 filter out all the exceptions that do not satisfy at least one of the query constraints C1.Rl ~ . . . C 1 2 . ~ ~ ~ .  We do not need to test the exceptions for the antecedent of the corresponding rule, since they satisfy it by definition.

The constraint introduction solutions identified in our example are the following:  ~~~  Introduced Constraints Exceptions  {ele t E l ,  C z . n , ( e ) ,  . . . , C 1 2 . n l 2 ( e ) ) {el. +- E 4 ,  C 1 . h  (e) ,  . . . , C5.nS (e) ,  C ~ . R ,  (e), . . . , C12.nll (e)} {ele + E 5 ,  C1.nl (e) ,  . . . , C5.nS (e) ,  C ~ . R ,  (e) ,  . . . , C12.n12 (e))  C O . R o l  CO.RO2  CO.RO3  5. Optimizing OQL queries  In the previous sections, a series of algorithms were given to find a collection of constraint elimination or con- straint introduction solutions. In this section, we show how the original query is transformed to its optimized form using the optimal solution. Consider the OQL query:  s e l e c t  x f romExtentX as x where C ~ . R ~  and . . . and Cn.~ .

5.1. Heuristic H1  Let < { C i l : .  . . Ci,},Ei > be the maintained con- straints and the exceptions of a solution i. Only the main-  tained constraints of the optimization solution should be tested on the objects of the whole extent; however, all the constraints should be tested on the exception cases and the objects that satisfy the maintained constraints but not the ones omitted should be removed from the result. Hence, the original query should be converted to the following one:  ( s e l e c t  x from E x t e n t 2  as x where C i l  and . . . and Ci,)  except E i  If we assume that tests on the query constraints take roughly the same time, the optimal solution is the one with fewest exceptions Ei.

5.2. Heuristic H2  Let < Co.Roi Ei > be the index constraint and the corre- sponding exceptions of a constraint introduction solution.

Instead of testing the query constraints C 1 . ~ l ,  . . . , C,.R, on the entire extent Extent X, we apply them only on the re- sults of the subquery  s e l e c t  x from E x t e n t 2  as x (40) where C O . R ~ ~  Since Co.Roi is a constraint on a cluster index attribute, the select operation is expected to be quite fast. The original query is transformed to its more efficient form:  ( s e l e c t  x from 9 0  as x where Cl.+ and . . . and C,.,)  union E i  The exceptions Ei  are merged to the result because they satisfy the query constraints, but not the new index con- straint Co.Roi. Since the union operation is relatively cheap, the optimal solution is the one that introduces the index con- straint with the highest selectivity.

6. Discussion  We now look at two different scenarios, and estimate the extent to which heuristics H1 and H2 speed up query exe- cution.

The Jirst scenario concerns frequently executed queries.

Assume that the association rules which are used by algo- rithm 3 are not modified. We may optimize a query once at compilation time, then execute its optimized form. It is worth optimizing provided that the execution time of the optimized query is less than the execution time of the orig- inal query. For heuristic H1 this happens only if the time     saved by omitting some constraints is greater than the time needed to remove the exceptions from the result (except operation). The more the eliminated constraints and the fewer the exceptions, the better the optimization. As one of the referees pointed out, the time saved by the elimina- tion of constraints is CPU-related. Since query execution is dominated by data access time, this optimization is not expected to alter performance significantly. It would help only in contexts rich in associations with few exceptions, in which users express many constraints in their queries.

Heuristic H2 is expected to bring more significant ben- efits. Firstly, this optimization involves a union  operation, which is much cheaper than the except operation used in H1. Secondly, instead of retrieving all the objects of an extent from the database, we need only look at the subset retrieved through an indexed constraint. Hence, we save a considerable amount of data access time, spending a negli- gible amount of CPU time in evaluating the additional con- straint.

The second scenario concerns queries which are exe- cuted only once. In this case, the time required for opti- mization is significant. This time depends on the algorithm that finds associations between relaxed constraints and tight constraints (see section 3), since this is the most expensive step in the optimization process. This algorithm finds paths in a directed graph, and combines the exceptions associated with each edge of the path to derive the total exceptions for the path. Therefore its complexity is a function of i )  the av- erage number of exceptions in the existing association rules and ii) the number of different constraints found in the an- tecedents and the consequents of the rules.

We have already implemented the algorithms for apply- ing H1; the next step is to implement the corresponding al- gorithms for H2. This should not be difficult, since the main algorithm - finding associations between rule constraints - is common to the two heuristics. We intend to set up an experimental model in order to evaluate H1 and H2 in the scenarios discussed above.

7. Conclusion  The use of association rules for query optimization is rel- evant to both relational and object-oriented database sys- tems. There has been a lot of research on generating asso- ciation rules and maintaining them in the presence of up- dates. Research has also focused on finding heuristics that take advantage of rules in order to optimize a query. Most of this work ([2, 31) has considered integrity rules, rather than association rules with exceptions. Semantic optimiza- tion heuristics were also applied without considering indi- rect associations. In this paper, we implement algorithms that apply two optimization heuristics presented by Siegel et al., taking account of both exceptions and indirect asso-  ciations. We show how to use these heuristics to optimize an OQL query. The complexity of the optimization process is closely related to the complexity of the constraint graph, which represents the set of association rules in the data. It also depends on the number of exceptions associated with each rule. We have designed an experimental framework to evaluate the two optimization techniques, both in the con- text of queries repeated frequently over a period of time, and in the context of ad-hoc queries executed once only. The re- sults of this experimental work will be presented in a later paper.

8. Acknowledgements  We are grateful to the anonymous referees, who read the paper carefully and critically and made many helpful suggestions. Agathoniki Trigoni is supported by a scholar- ship from the Greek Scholarships Foundation, and is deeply obliged to the National Bank of Greece.

