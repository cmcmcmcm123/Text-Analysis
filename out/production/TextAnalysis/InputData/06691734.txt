A Novel Integrated Method for Human Multiplex  Protein Subcellular Localization Prediction

Abstract?Protein subcellular localization prediction based on machine learning is a research focus in bioinformatics. The fast growth of protein sequences in databases leads to be hard to label enough protein samples only by experts for training a learner to get satisfying prediction result. This paper proposes a novel integrated method for human multiplex protein subcellular localization prediction. In this method, to avoid artificially evaluating and labeling the big data of unseen proteins, an active sample selection algorithm is presented to pick out protein samples with non-experimental labels as supplementary training data to help train an ensemble predictor, which includes a protein identifying module, a single-label classifier and a multi- label classifier. The numerical experiments show the effectiveness of the proposed approach.

Keywords?protein subcellular localizaiton; big data multiplex protein;  active learning;  transductive learning

I.  INTRODUCTION Knowledge of protein subcellular location is very  significant for deducing protein function, revealing disease pathogenesis, identifying drag target and so on. Comparing with traditional biology experiments, prediction methods based on intelligent computation for protein subcellular localization are superior for significantly saving time and cost [1]. There have been many computational methods to predict protein subcellular locations [2-9], and this kind of technique is more and more significant for this field. However, rapid growth of new protein sequences brings many new challenges. Especially, the discovery of multiplex proteins which can be localized at more than one location is a sign that the study on protein subcellular localization has stepped into a new stage.

On challenge is big data. According to the record of UniprotKB (release 2013_08), there are 41991850 protein entries in this database, where the number of data with reviewed subcellular location comment is 322023 and the other 41669827 protein data are unlabeled. It is impossible to label such huge number of proteins merely via experiments or manual work, therefore, computational approaches are the best choices. Nevertheless, computational methods always need a large number of reliable labeled data for training feasible classifiers, but the number of available labeled protein sequences in many tasks are not enough to learn a good classifier for prediction [10]. For example, the virus benchmark  dataset in [11] only consists 207 data. This problem is mainly caused by two reasons, one reason is existing methods only use the proteins labeled by experiment, which is a small part of entire reviewed data; the other reason is most of collected data are abandoned for redundant or homologous reason. It needs more labeled protein samples to supply enough information for prediction, but if people evaluate all unseen samples in such a big dataset to select some data to label, it also costs too much.

Another challenge is, when a predicting algorithm learns sample information, singplex proteins and multiplex proteins interfere with each other and it leads to be hard to get high- accuracy results for both two types of proteins. Conventional predicting methods always try to use the approaches based on multi-label learning to uniformly predict singplex and multiplex proteins. But the localizing mechanisms of the two types of proteins are very different, therefore, a single multi- label classifier is hard to get satisfying results on both of them.

Human proteins have the most complicated localization mechanism, and above mentioned two challenges also exist in human multiplex protein subcellular localization prediction.

Hum-mPLoc 2.0 [12] and iLoc-Hum [13] are two of the best predictors for human proteins, but they also suffer from the two problems. In this paper, a novel integrated method is proposed for human multiplex protein subcellular localization prediction to deal with two above challenges. Instead of traditional proteins labeled by experiments, we focus on another type of reviewed proteins which are labeled by non-experimental prove [14]. Be different from unseen data without labels,  this kind of proteins have non-experimental labels which have high confidence level but a part of them may still have some inaccuracy. Therefore, we first propose an active sample selection algorithm to evaluate and select non-experimental proteins in a sample pool. The selected proteins are most valuable and added into original small training dataset to be new training data. They do not need to be labeled manually and their non-experimental labels are deemed to be real labels to be directly used for training. Based on the updated training dataset, we then present an ensemble predictor composed of a protein identifying module, a single-label classifier and a multi-label classifier. When the predictor works, a query protein is first identified whether it is a multiplex protein. If the answer is yes, the protein will be dealt with by the multi-label classifier, otherwise, it is dealt with by the single-label classifier.



II. THE PROPOSED METHOD The proposed method includes an active sample selection  algorithm for updating training set and an ensemble predictor for multiplex protein subcellular localization prediction. The ensemble predictor actually is a frame which is based on the preliminary identification for query protein and the identifying module is the key of this predictor,  and the types of single- label and multi-label classifier are not fix but adjustable according to practical problems. The work process of the integrated method is illustrated in Fig. 1.

A. Active Sample Selection  Let 1 2x , x , , x ll nD represent the original training set consisting of ln  protein samples classified in m  different subcellular locations. Each protein xk lD  can be represented  by a feature vector of d  dimension as T1 2, , ,k k kdx x x , and  the label set T1 2y , , ,k k k kmy y y  denotes the protein subcellular locations of xk . For each protein xk , if it inhabits the thi subcellular location, label 1kiy , otherwise 1kiy .

The basic classifier : 2d mf  is trained by lD . Let  x , y 1u s s uD s n  denote the supplementary training  sample pool containing un  non-experimental proteins, where  each protein T1 2x , , ,s s s sdx x x has the set of subcellular  locations T1 2y , , ,s s s smy y y . For each protein x s , if its thj subcellular location is a experimental/non-experimental  label, mark 1 / 1sj e sj ney y  otherwise 1siy . Both 1sj ey  and 1sj ney  mean 1sjy , and the subscripts are just  for marking the label?s origin.

For a sample x , ys s  in uD , an evaluation function , , x , yl s sE f D  for measuring the sample?s ?value?  based on  structure risk is defined as follows:   y 1 1 1    1, ,x , y max min x  x , , x  l  m s  n m  l s s ki i k f k i  m  s sj sj sj j s j  E f D f y f  w y y y f  H  (1)  where, T1 2y , , , 1 m  s s s smy y y represents the unknown actual label set for x s , where for each label sjy , 1sj ey means 1sjy , 1sjy means 1sjy , but if  1sj ney then sjy may be 1 or -1.

2 T 1f f K f  is the  regularization item, where fK K I , fK  is the kernel matrix of size 1 1l ln n , I is an m m identity matrix, and is the Kronecker product. Item x , ,s sj sjw y y is the confidence parameter for the event that sjy just equals sjy when x s has a non-experimental label sjy .

Fig. 1. The work process of the  proposed integrated method.

From the derivation, it is straightforward to show: T  y 1  1, ,x , y max 2msl s s  E f D Y LY                        (2)  where, T T1 2y , y , , y , y , yln s l sY Y , 11 1L K ,  and  I  I W  (3)  1 1  2 2  x , , x , ,  x , ,  s s s  s s s  s sm sm  w y y w y y  W  w y y  (4)  Let ll ls sl ss  L L L  L L , then  T T T T Ty y y yl ll l s ss s s sl l l ls sY LY Y L Y L L Y Y L           (5)  Except ys , all other parts in (5) is able to be worked out, and the min-max optimization problem described as (1) can be solved through plugging in all feasible values of ys to find the  optimal x , ys s with the smallest value of , , x , yl s sE f D .

Similarly, we can pick out other non-experimental samples one by one.

Rank all the samples within uD  in ascending order according to their evaluation to compose a new ordered set rD in ascending order. Next, denote the evaluation value of a sample x , yi i  in rD by 1i uE i n . Then the change rate  The most valuable samples  Multiplex proteins  Singleplex proteins  Single-label classifier  Identification module  Multi-label classifier  Active sample selection  Query proteins Non-experimental protein sample pool  Ensemble predictor  Original training protein data  Prediction result     of its evaluation value iR  can be written as:  1 , 1 1  0 ,  i i u  ii  u  E E i n  ER i n  (6)  For a given step of proportion and the corresponding number of intervals 1/T , the algorithm needs to decide which proportion is preferred for helping to retrain the basic classifier. Let 1tNum t T be the number of the samples in the t th  interval, and the preferred proportion  can be calculated as:  1,2, , 1 1  1argmin G t  i t T i G tt  R Num  (7)  where,   , 0 ( )  0 , 0  t  j j  Num t G t  t (8)  B. Protein Identification Algorithm This part we present the identification algorithm based on  transductive learning [15] to distinguish singleplex protein and multiplex protein. Let tD  be the testing set including tn  query protein samples. Denote 1 2x , x , , xl t nD D D is the union of lD  and tD , where the first ln ln n proteins are labeled and the remaining proteins are unlabeled query proteins.

For convenience, suppose 1, 2, , lL n is the index set for the labeled protein samples and 1, 2, ,l lU n n n for the unlabeled query samples, therefore we have ,L UD D D .

Let iQ denote the number of subcellular locations for a protein x i in D . The values of iQ  on LD  can be directly fixed,  i.e. 1, y y ,i ij ij ij i iQ y y y i L , and the iQ values  on UD will be estimated for identifying the query proteins, which is our goal.

We build a weighted neighborhood graph , ,G V E C  to characterize the relation between similar proteins, which consists of a set of vertices V on D , a subset edges E of V V , and a nonnegative weight function : 0,1W E . If a sample x i  is among the k nearest neighbors of another sample x j , we will have , 0C i j  and say that there is an edge between x i  and x j . We define an n n  weight matrix C to describe the similarity degrees among the whole protein samples:  , , if  x x  ,,  0                   ,    otherwise k i  j i  X N X  S i j N  S i kC i j             (9)  where, (x )iN  is the k nearest neighbor set of x i , and  , 1n  j C i j for each sample x i . ,S i j  is the similarity  between x i  and x j , which is defined as:    x x , exp  i jS i j                           (10)  Here,  is empirically learned by the average distance between protein samples.

Based on the smoothness assumption, we propose an optimization framework to deduce the optimal estimations of the location number for query proteins:    , , x x min  0  1, , . .

y  n j i  i ij jQ Q i U N  i  i i  Q C Q  Q i n s t  Q i L  (11)  where, is a slack variable. 0  is fixed when y 1i , and  is a non-negative integer when y 1i .

In order to simplify the optimization problem, we have   x xj i i ij j U  i U N  Q C Q H Q CQ                  (12)  where, 0 0 0U U n n  H I  , and T T1 2, , ,  n L UQ Q Q Q Q Q .

Thus, the optimization problem (11) can be rewritten as:    , , min  0  1, , . .

y  n UQ Q  i  L L  H I C Q  Q i n s t  Q  (13)  It is a quadratic programming and a global solution exists because the objective function and the constraints are all convex.

For convenience, let LL LU UL UU  A A A I C  A A and ignore  the constraint 0iQ . Thus, the Lagrange function for (13) is:  2 T1, y 2 U L L  F Q H AQ Q                (14)  where, 0 . The optimal condition for Q  can be derived  T T  T T 00 LUL UL UL UU  UUU UL UU UU  QA A A AF QQ A A A A  (15)  Thus, we have     T 0UU UL L UU UA A Q A Q                        (16)  Here, UUA can be guaranteed to be invertible for a connected  graph. Considering the constraint yL LQ , we can get the optimal solutions of (13) by solving following linear equation:  1 yU UU UL LQ A A                        (17)  And then we can obtain the optimal solution iQ  of each query protein sample x i  , and its number of the subcellular location is predicted as the closest integer to iQ . If the value of  iQ equals to 1, the query sample x i  will be identified as a singleplex protein to be dealt with by a single-label classifier; otherwise, it will be identified as a multiplex protein to be dealt with by a multi-label classifier. Our method does not fix the types of the two classifiers, which are adjustable and will be determined according to practical problems. The choosing and combining pattern of single-label and multi-label classifiers will not be discussed in this paper.



III. EXPERIMENTS In this section, the performance of proposed method is  evaluated on the human proteins data by independent test. The human benchmark dataset established by [12] is adopted as the original training dataset, which includes 3106 human protein sequences and 14 different subcellular location classifications.

1213 human non-experimental proteins are collected from UniProtKB/Swiss-Prot database by us to constitute the supplementary training sample pool. 321 new proteins labeled by experiments construct a testing dataset. In order to reduce the redundancy and avoid homology bias, none of the proteins in the entire three datasets has 25% sequence similarity to any other. Table I show the general information of each dataset.

TABLE I. GENERAL INFORMATION OF EACH DATASET  Datasets Number  Singleplex Protein  Multiplex Protein Total  Orignial training set 2580 526 3106 Non-experimental protein data pool 921 292 1213  Testing dataset 192 129 321  The concerned 14 subcellular locations are as follows: centriole, cytoplasm, cytoskeleton, endoplasmic reticulum, endosome, extracell, golgi apparatus, lysosome, microsome, mitochondrion, nucleus, peroxisome, plasma membrane, and synapse  In the numerical experiments, the amphiphilic pseudo amino acid composition [16] is adopted as the feature extraction technique to represent protein sequences. The protein sequences can be formulated with a valid mathematical expression by this method through a public online server named PseAAC at: http://www.csbio.sjtu.edu.cn/bioinf/PseAA/.

In our experiments, amino acid characters are empirically chosen to be hydrophobicity, hydrophilicity and mass; weight factor is 0.4 and lambda parameter is 5. We employ the popular  ML-RBF [17] neural network  as the multi-label classifier and combine it with a classic KNN single-label classifier for each prediction task, where the ML-RBF classifier is trained on the whole training set and the KNN classifier is trained by all the singleplex protein samples. The parameters of ML-RBF are assigned the same values as the original paper the value, and the number of nearest neighbor is 10k . The slack variable in our method is 2 for multiplex proteins, and all the parameters in the experiments are fixed.

Learned by the same training sets, we compare our algorithm with Hum-mPLoc 2.0 [12] and iLoc-Hum [13], which are two popular web-server predictors for the subcellular localization prediction of human multiplex proteins. Besides, since the ML-RBF classifier is incorporated into our integrated method for the prediction task, we observe the prediction result of using this algorithm alone for comparison too. We also test the performance of our ensemble predictor without the active sample selection, which includes two cases using no non- experimental proteins and directly using all the non- experimental proteins in the supplementary training sample pool. 3 global indices: accuracy, MCC, F1-sore, and 4 popular multi-label indices: average precision, ranking loss, coverage and one-error are employed as evaluation metrics.

The comparison result is as shown in Table II, and the preferred proportion of non-experimental samples selected is  40% . It can be seen our method achieves the best results in all the 7 evaluation metrics. The superior performance to ML-RBF classifier means the proposed method can sufficiently utilizes the individual strengths and abilities of single-label and multi-label classifiers and indeed gets the improvement for an individual multi-label algorithm of multiplex protein subcellular localization prediction. Here, we just select and integrate two common classifiers, and the proposed ensemble predictor has achieved better prediction result than existing two best human predictors. If more suitable classifiers replace the two classifiers  used in the experiment, our method will become more powerful. Moreover, the better performance of our method than the same ensemble predictor with no non- experimental proteins indicates this kind of proteins indeed can help to retrain and improve basic classifier, and the better prediction result than the ensemble predictor directly using all non-experimental proteins means not all the non-experimental proteins are proper to update classifier and we should use this kind of proteins selectively. Therefore, the active sample selection is indeed useful and necessary for human multiplex proteins subcellular localization prediction.

