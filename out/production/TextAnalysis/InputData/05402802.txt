A New Association Rules Mining Algorithm Based on Vector

Abstract?As a classical algorithm of association rules mining, Apriori algorithm has two bottlenecks: the large number of candidate itemsets and the poor efficiency of counting support.

A new association rules mining algorithm based on vector is proposed, which can reduce the number of candidate frequent itemsets, improve efficiency of pruning operation and count support quickly using vector inner product operation and vector addition operation between transaction vector and itemset vector. According to the results of the experiments, the proposed algorithm can quickly discover frequent itemsets and is more efficient than Apriori algorithm.

Keywords-data mining; association rules; vector

I.  INTRODUCTION Association rules mining is an active research topic in the  data mining field, which is the key step in the knowledge discovery process [1]. Association rules mining may discover interesting associations or dependency relations between item sets among mass data, helping people make better decisions.

Mining association rules have two problems: frequent itemsets discovery and association rules generation. Since the overall performance of mining is greatly determined by the first problem, this paper focuses on the process of discovering frequent itemsets.

Apriori algorithm [1], as a classical algorithm of association rules mining, adopts an iterative method to discover frequent itemsets. It consists of two steps: the join step and the prune step. In the join step, a candidate k- itemsets is generated by joining two frequent (k-1)-itemsets.

Then in the prune step, all itemsets whose (k-1)-subset is not a frequent k-itemsets are removed from the candidate k- itemsets. Then, the database is scanned to compute the support of the candidate k-itemsets. This process is repeated until no new candidate k-itemsets is generated. A huge calculation and a complicated transaction process are required during the algorithm. Therefore, the mining efficiency of Apriori algorithm will be poor if the transaction database is large.

Recently, many methods have been proposed to improve Apriori algorithm?s efficiency. AprioriTid [2] reduces the overhead of I/O by scanning the database only once in the first iteration. DHP [3], a hash-based algorithm, is especially effective for the generation of frequent 2-itemsets. Some algorithms avoid generating candidate itemsets, such as DLG  [4] and EDM [5]. Max-Miner algorithm [10] efficiently identifies long frequent itemsets, which, in turn, can be used to generate other frequent itemsets.

In order to avoid the deficiency of Apriori algorithm, a new algorithm is proposed in this paper. The transaction database is scanned only once and every transaction is transformed into vector at the same time. Each itemset is expressed as a vector. Lastly, with vector inner product operation and vector addition operation between the transaction vectors and the itemset vectors, the new algorithm reduces the number of candidate frequent itemsets, improves the efficiency of counting support and generates frequent itemsets quickly.



II. BASIC CONCEPTION AND PROPERTIES Let I = {i1,i2,?,im} be a universal set of items. Let  D={T1,T2,?,Tn} be a set of transactions. Each transaction T is a subset of I, viz. T ? I. All items in transaction and itemset are arranged in dictionary order.

Definition 1: Transaction Vector (TV).

A transaction is expressed as a m-dimensional vector.

Transaction vector of transaction T is expressed as TV= (x1,x2,?,xm), xk?[0,1], (k=1,2,?,m). If ik?T, and then xk=1, otherwise xk=0, and the dimension of TV is equal to the number of items in I.

Example 1: Let I = {A,B,C,D,E} be a universal set. If a transaction is expressed as Ti={A,B,E}, then TVi=(1,1,0,0,1).

Definition 2: k-Itemset Vector (IVk).

A k-itemset is expressed as a n-dimensional vector, k-  itemset vector of k-itemset c is expressed as IVk = (y1,y2,?,ym), yk?[0,1], (k=1,2,?,m). If ik?c, and then yk=1, otherwise yk=0. The dimension of IVk is equal to the number of items in I. The value of k is equal to the number of digital ?1? in IVk.

Example 2: Let I={A,B,C,D,E} be a universal set.  If a 2- itemset is expressed as c={A,B}, then IV2=(1,1,0,0,0).

Definition 3: Cumulative k-Itemset Vector ( kCIV ).

C is a set of k-itemsets. In C, the total number of all the k-  itemsets having a equal last item as ij is rj. The k-itemset vectors of these k-itemsets are expressed as s  k ii jxIV )( ,... ,  1 ? s ? rj. And the cumulative k-itemset vector of all k- itemsets ended with item ij in C is expressed as:   DOI 10.1109/WGEC.2009.64     ? =  = j  jxj  r  s s  k ii  k i IVCIV  ,... )( .                          (1)  Example 3: Let I={A,B,C,D,E} be a set of items. If a frequent 3-itemsets is expressed as L3 = { {A,B,C}, {A,B,E}, {B,C,E} }, then 3CCIV  = (1,1,1,0,0),  ECIV  = (1,2,1,0,2).

Property 1: All nonempty subsets of a frequent itemset must also be frequent [1].

Property 2: Let X be a k-itemset. If X has a (k-1)-subset which is not a frequent (k-1)-itemset, then X is not a frequent k-itemset [1].

Inference 1: Let Lk-1 be a frequent k-itemsets, let l = {ip1,ip2,?,ip(k-1)} be a frequent (k-1)-itemset, and l?Lk-1, let iq be a item contained in Lk-1, and q > p(k-1). A k-itemset X, which is generated by joining l with iq, is expressed as X={ip1,ip2,?,ip(k-1),iq}. A vector S is expressed as:  11 ?? += ki k  l qCIVIVS .                             (2)  Suppose there exists a number r such that for each r?(p1,p2,?,p(k-1),q) we have S[r]<k-1, then X is not a frequent k-itemset. S[r] presents the value of the rth element in S.

Proof: Suppose X is a frequent k-itemset, then all (k-1)- subsets of X are contained in Lk-1. According to definition 2, each value of the p1th, p2th, ? , p(k-1)th element in 1?klIV  is equal to 1.

There may be some itemsets ended with item iq in Lk-1, which is not (k-1)-subset of X. Then according to definition 3, the value of the p1th, p2th, ? , p(k-1)th element in 1?kiqCIV is at least equal to k-2, and the value of the qth element is at least equal to k-1. Therefore for each number r ? (p1,p2,?,p(k-1),q), there is  S[r] ? k-1, which contradicts with the conditions. So X is not a frequent k-itemset.



III. A NEW ALGORITHM BASED ON VECTOR The proposed algorithm is similar to Apriori algorithm,  which can be divided into two steps. First, the algorithm finds out all frequent itemsets. Then it generates all association rules from frequent itemsets. Obviously, the second step is easier than first step, so we only describe the algorithm of discovering frequent itemsets.

At first, we generate all transaction vector which only entries either 0 or 1 by scanning the database once. Every transaction T is expressed as transaction vector TVr, 1 ? r ? n.

At the same time, we count the support number of every item ij in T, which is expressed as sup({ij}). If the support number of {ij} is beyond the user specified threshold MinSupNumber, viz. sup({ij}) ? MinSupNumber, then {ij}? L1.

Secondly, the set of candidate 2-itemsets C2 is generated by joining L1 with itself. Each 2-itemset in C2 has the form {ip,iq}, p<q. Then each {ip,iq} in C2 is expressed as a 2-  itemset vector 2, qp iiIV , and the support number of the set {ip,iq} is  )]( 1[int}),sup({ 2,  qp iir  n  r qp IVTVii ?=?  =  ,            (3)  where ?? ? is the inner product operator, int[ ] is the round function that transforms a real number to an integer by truncating the fractional part. For example, int[1.2] = 1, and int[0.7] = 0. If sup({ip,iq}) ?  MinSupNumber,  then {ip,iq}? L2.

After the frequent 2-itemsets L2 is obtained, the frequent k-itemsets Lk-1 can be iteratively used to generate candidate k-itemests Ck. According to the sort rule, a k-itemset {ip,?,iq,ij} can be generated by joining a arbitrary (k-1)- itemset {ip,?,iq} in Lk-1 with a item ij in Lk-1 which is bigger than iq.

Then, we generate cumulative (k-1)-itemset vectors of (k- 1)-itemests in Lk-1, which is 1?ki jCIV , k ? j ? m. Then with  plusing every 1?ki jCIV  (j=q+1,q+2,?,m) with the  ,, ?k  ii qpIV  of every frequent (k-1)-intemset {ip,?,iq} in Lk-1, we can get S= 11,,  ?? + ki k  ii jqp SVIV . Based on vector S and Inference 1, it  can be determined {ip,?,iq,ij}?Ck or {ip,?,iq,ij}?Ck.

At last, we compute the support number of each  candidate k-itemset {ip1,ip2,?,ipk} in Ck according to the following formula:  ? =  ?= n  r  k iiirpkpp pkppIVTVk  iii  ,,,21 )]( 1int[})...,sup({  .    (4)  If the support number is beyond the user specified threshold MinSupNumber, then {ip1,ip2,?,ipk}?Lk.

Repeat the above process with successively increasing number k until either Ck or Lk is empty. At the end of procedure, we can get the all frequent itemsets.

A detailed description of the proposed algorithm is given in Figure 1.



IV. EXPERIMENTAL RESULTS To assess the performance of the new algorithm, we  performed several simulation experiments. We compare the performance of the new algorithm with the Apriori algorithm. The new algorithm and the Apriori algorithm is programmed in Matlab, all experiments are performed on a PC with 2.5GHz Intel Dual-Core E5200, 2GB memory. We use synthetic data to evaluate two algorithms, which is generated by the QUEST data generator of IBM Almaden Lab. The way of generating synthetic data is similar to that of [2]. The parameters used in our experiments are defined as: N is the number of items; |D| is the number of transactions; |T| is the average size of transactions; |I| is the average size of the maximal frequent itemsets. We generated     four datasets as: T10I2, T10I4, T20I2, T20I4, by setting N=500 and |D|=1000.

Input: a transaction database D, the minimum threshold of support minSupNum Output: the set of frequent itemsets L 1)  for all transaction t?D do 2)      generate TV; 3)  L1 = (frequent 1-itemsets); 4)  C2 = L1 ? L1; 5)  L2 = {c?C2 | sup(c) ? MinSupNum};  // sup(c) is the result of the formula (4) 6)  for ( k=3; Lk-1? ?; k++ ) do begin 7)      for( j=k; j ? m; j++ ) do 8)          generate 1?ki jCIV ; Ck = candidate_gen(Lk-1); 9)          Lk = {c?Ck | sup(c) ? MinSupNum}; 10) end 11) Return L = ?Lk; candidate_gen( frequent itemsets Lk-1 ) 1)  for all (k-1)-itemset l?Lk-1 do 2)      for all ij?Lk-1 do 3)          // S is the result of the formula (2)  if for every r(1 ? r ? k) such that S[r] ? k-1 then 4)              add l?{ij} to Ck;  Figure 1. The proposed algorithm.

The following four figures show the comparison of the execution time of the Apriori algorithm and the proposed algorithm, along with the minimum support increasing.

The results illustrate that the execution time of two algorithms decrease along with the minimum support increases, but the performance of the new algorithm is much better than that of the Apriori. Moreover, the smaller the minimum support is, the more efficient the performance of the new algorithm is. This is because that as minimum support reduces, Apriori produces more candidate itemsets and spends more time making pruning operation and counting support operation. However, by inner product operation and addition operation, the new algorithm can reduce candidate itemsets and simplify pruning operation and counting support operation.

Figure 2. The execution time in T10I2D1K.

Figure 3. The execution time in T10I4D1K.

Figure 4. The execution time in T20I2D1K.

Figure 5. The execution time in T20I4D1K.



V. CONCLUSION In this paper, a new association rules mining algorithm  based on vector has been presented in order to easily generate candidate frequent itemsets and quickly compute support of itemsets. The new algorithm only scans the database once, stores all transaction data into transaction vectors. And, for a more convenient calculation, express     itemsets as the form of vector. In the joint step, candidate frequent k-itemsets can be generated by enlarging the last item of frequent (k-1)-itemstes only. This step can significantly reduce the times of comparison among items. In the prune step, the k times comparison of numerical value is much more efficient than the circular comparison in the Apriori algorithm. Then, inner product operations between transaction vector and itemset vector are performed to count the support of items. Therefore, frequent itemsets is generated quickly. The experiment results indicate that the proposed algorithm is much more efficient than Apriori algorithm for mining association rules.

