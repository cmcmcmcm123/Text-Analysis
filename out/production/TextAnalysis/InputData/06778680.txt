An Incremental Closed Frequent Itemsets Mining Algorithm Based on Shadow  Prefix Tree

Abstract?This paper introduces an incremental closed frequent itemsets mining algorithm, which is based on a shadow prefix tree to get closed frequent itemsets. By the use of shadow technology this algorithm can avoid the cost of generating and testing of candidate subsets. Shadow prefix tree can find nodes by virtual node without generating all nodes.

The experiment results show that this algorithm can deal with big data more efficiently than others.

Keywords?Data mining; closed frequent itemsets;  prefix tree; incrementally update

I. INTRODUCTION As an important branch of frequent patterns mining,  closed frequent itemsets mining can take place of frequent itemsets mining in a compressive way without information lost[3][4][5][6].Closed frequent itemsets mining algorithms can be classified into two types :the first is based on Apriori algorithm[1][7] which adopt the strategy of candidate generating and testing; the other one is based on FP algorithm[8]which adopt the strategy of divide-and-conquer strategy, such as: CLOSET[9],CLOSET+[10], FPClose[11], DFCIM[14].

NewMoment[12] is an incremental closed frequent itemsets mining algorithm, this algorithm uses bit vector to represent transaction database. A data structure like prefix tree is used to store critical data. But every item has a bit vector with fixed length in NewCet, when the dataset is scattered much space will be waste.   CFPL generates FPL structure from the preprocessing dataset[13][14] and gets the closed frequent itemsets by comparing these signature vertex.

FPL is an algorithm dealing with vertical data structure, the waste of space will become obvious when the dataset is large.

AFOPT algorithm[15] generates a data structure  derived from prefix-tree(PT) to mining closed itemsets. This structure is a kind of ascending prefix tree, but    it will generate much duplicate nodes, and the space has exponent relation to the number of items.

This page raises an incremental mining algorithm SPTCI(Shadow Prefix Tree Closed frequent itemsets Incremental mining algorithm) based on Shadow Prefix Tree(SPT) which is  generated by using the merging technology and shadowing technology on PT.

. RELATED CONCEPTS  A. Closed Frequent Itemsets Suppose that items set I={item1,item2,?,itemn} and  transactions database D={t1,t2,?,tm},if X is a subset of I,the support count of X (supcount(X)) is the number of transactions in D which include X,and the support of X (sup(X)) is the percentage of supcount(X) with the number of transactions in D. The task of frequent itemsets mining is to find all these itemsets whose support  are no less than a mini support (minsup) assigned by the users.

Suppose that ,DT ? Ii? ,then f(T)={ tiTtIi ???? ,| };suppose , ,then g(X)={  DT ? IX ? Dt? | tiXi ??? , }.

Definition 1:Suppose that X is an itemsets, if c(X)=f(g(X))= =X, then X is called a closed itemsets, the function c is the Galois operator  )(Xgf ? [2].

Definition 2:If two itemsets are supported by the same transactions, then the two itemsets belong to an equivalence class. Suppose ,if and only if (g(X))=f(g(Y))then X  IYIX ?? , ? Y,?  is an equivalence relation.

From definition 1 and 2 it is obviously that the c function divides the frequent itemsets into several equivalence classes and a closed frequent itemsets is the longest itemsets in a equivalence class, so the task of closed frequent itemsets mining is to find all the longest itemsets of each equivalence classes.

B. Prefix Tree The nodes of Prefix tree(PT) consist of four parts: node  label, node count, links of sub nodes, point to parent node.

The value of node label is an element of I, it is used to distinguish the nodes; the value of node count is a number ,it represents the times the node appearances, written as PT(i).count; the links of sub nodes is a set of points which point to each children of this node; the parent point points to the parent node, all the prefix nodes can be find through this point easily[15].A path is a set of nodes in PT from root to leaf, and brother in PT represent nodes with the same parent node.

PT has a root node, all the nodes in PT are sorted ascending in alphabet order. The node label of parent node are litter then all these node label of children, so the node label of root node is the smallest, written as PT(0);for a node  2013 10th Web Information System and Application Conference  DOI 10.1109/WISA.2013.89   2013 10th Web Information System and Application Conference  DOI 10.1109/WISA.2013.89   2013 10th Web Information System and Application Conference  DOI 10.1109/WISA.2013.89   2013 10th Web Information System and Application Conference  DOI 10.1109/WISA.2013.89   2013 10th Web Information System and Application Conference  DOI 10.1109/WISA.2013.89     PT(i),all the node label of the nodes in the left of it is smaller that i, the node label of the nodes in the right of it is bigger then i. For example, TABLE.I is a sample transaction database denoted as TD and fig.1 is a PT of TD.

TABLE I. SAMPLE TTRASACTION DATABASE  . STRUCTURE AND GENERATE OF SHADOW PREFIX TREE SPT is derived form PT. The shadow technology of  virtual nodes makes SPT avoiding the repeated nodes and uniting with an other SPT generated from a different dataset.

By the uniting of SPT,SPT can update incrementally.

C. The Structure and Features of Shadow Prefix Tree The structure of node in SPT is similar to PT, but the  type of nodes in SPT can be classified into three classes: Real Node(written as RN(i)),Virtual Node(written as VN(i)) and Null Node(written as NN(i)).The structure of RN is same as the node of PT, RN(i) represent a node in SPT with the node label of i, the node count of RN(i) written as RN(i).

count. SPT contains many sub SPT, these sub SPT take a RN as root node, written as SPT(RN(i)),this means that SPT(RN(i)) has a root node RN(i).A sub node of SPT(RN(i)) is a node appearing in a path of SPT(RN(i)).In SPT(RN(i)),if  1 1 then a node RN(iI1j) is the last node  with node label j in the path of iI1j,SPT(iI1j) is the sub SPT with the root node of RN(iI1j).

I, , i k jI k I? ? ? ? ?  Fig. 1. The  prefix tree of  sample transaction database  Definition 3:Suppose that node(i) is a node in SPT, its node label is i, if node(i) is made up of node label, parent point and node link(the point to a real node with the same node label),then this node is called Virtual Node, written as VN(i).If node(i) is made up of only node label then it is a Null Node written as NN(i).

Virtual node is a node point to another RN with the same node label but has different prefix items. Null node would not be seen in the final SPT ,it was used to represent some node in the process of creating SPT.

Definition 4:Suppose node(i) is a node in SPT, the set of node labels  of nodes from node(i) to root node(not include node(i) and root node) is the prefix set of node(i),written as PS(node(i)).

Definition 5:If RN(i) is a real node in SPT, then take RN(i) as a root node, all these sub nodes and RN(i) is a sub SPT, written as SPT(RN(i)).For SPT(RN(i)), jiIj ?,? .By the strategy of wide first, the first sub nodes RN(j) of SPT(RN(i)) finding in the order of right to left is called the right j node of SPT(RN(i)) written as R(SPT(RN(i))j);the sub tree with the root node of RN(j) is called right j sub tree of SPT(RN(i)),written as RT(SPT(RN(i))j).

SPT has two important attributes, and the algorithm proposed by this page is based on the two attributes.

Attribute 1:If RN(i) is not the root node then RN(i).count=|g(PS(RN(i)) )|. ?||? is the number of elements in the set.

{i}?  Attribute 2:SPT(RN(i)) is a sub SPT with the root node of RN(i), ,j i? if there is a node with node label j in SPT(RN(i)) and RN(j)=R(SPT(RN(i))j),then RN(j).count=|g(PS(RN(i)) {i,j})|.?  The purpose of creating SPT is to make SPT has these two features and avoid generating duplicative nodes. There two important operation with SPT: Create SPT, unite SPT.

D. Build Shadow Prefix Tree It is obviously that PT has the attribute 1 of SPT but not attribute2. The key step in the process of building SPT is the sub tree uniting which gives the attribute 2. Sub tree uniting takes the strategy of depth-first. Algorithm 1 is the process of building SPT. Create_SPT function operates on every brother from left to right, when the last brother finishes this operation then the unite operation in algorithm 1 will unite these nodes. Unite(SPT(RN(i))) operation will unite  each children with brother in the left.

Algorithm 1: Create_SPT Input:RN(i) Output:shadow prefix tree SPT(RN(i)) Begin: { For cn=each children of RN(i) {If cn is the last children of RN(i) Unite(SPT(cn.node label)): {For j=each node label of node in RN(i) {If j not in the children of RN(i) Create NN(j) If(TESTNN(NN(j))) Delete NN(j) Else change NN(j) to a real node RN(j)} Conjunction SPT(RN(j)) with each right tree ;Return;}}Create_SPT(RN(cn));}  ID SETS ID SETS T1 A,B,C,E,F T6 D,E T2 A,C,E T7 A,B,D T3 B,D,E,F T8 C,F T4 B,E,F T9 B,D,F T5 C,E,F T10 B,F     Theorem1: kjiXiIX ??,, ??? , then  .

|}){(||}),{(| kXgkjXg ?? ?  }){(}),{( kXCkjXC ?? ? Proof: Suppose there is  T1 ? D, 1 1{ } , { , }X k T X j k T? ?? ? ,T1 ? }),{(}){( kjXgkXg 	? ,  and  is inconsistent, so T 1|}),{(||}){(| kjXgkXg ??  |}){(||}),{(| kXgkjXg ?? ? 1 is not existing, so .According to definition 2,  belong to the same equivalence class, so .

}){(}),{( kXgkjXg ?? ? { , }, { }X j k X k? ?  }){(}),{( kXCkjXC ?? ? Lemma 1:Suppose the set of sub nodes of SPT(RN(i)) is  SI, ,Iji ?, ji ? , { | (RN( )), RN( ) ( )( ), }I PS j j R j SI? ? ? ? ? ? ? ??  N( )) { })C PS i j C PS i j? ?? ? ?  )  ,if  then  .

0||, ????? ??  ? ( (RN( )) { }) ( (R  Proof: Because exists in the path of right tree of SPT(RN(i)),so .According to theorem 1, .Lemma 1 explains when a null node can be delete and when change a null node to a real node. In fig.1,Create_SPT function will firstly operate on RN(ABCEF) on strategy of depth-firstly.

RN(ABCEF) has no children, so operate on its parent RN(ABCE).Because RN(ABCE) has only one child so there is no new node generating after the unite function, so is its parent RN(ABC).RN(ABC) has a brother RN(ABD) in its left side, so when RN(ABC) finishes the Create_SPT operation, RN(ABD) will begin the Create_SPT  operation.

RN(ABD) is the last child of STP(AB),so when the create_SPT operation finishes, the unite process will begin.

E,F are node labels of sub nodes of SPT(RN(AB)),but not the node labels of any children of SPT(RN(AB)),so it is necessary to generate two null nodes NN(E) and NN(F) temporarily as children of SPT(RN(AB)) and then test them.

Delete NN(E) and NN(F),because there is only one right E or F sub tree of SPT(RN(ABC)) and SPT(ABD).When SPT(RN(AB)) and SPT(RN(AC)) finish the Create_SPT operation, then  RN(A) will begin the unite operation. D,E,F are node labels of sub nodes of SPT(RN(A)),but not the node labels of any children of SPT(RN(A)),so it is necessary to generate three null nodes NN(D), NN(E) and NN(F) temporarily as children of SPT(RN(A)) and then test them.

Delete NN(D) and NN(F),because there is only one right D or F sub tree of SPT(RN(AB)) and SPT(RN(AC)).NN(E) will be deleted too,because although there are two right E sub tree of SPT(RN(AB)) and SPT(RN(AC)),node with node label C appear in sub nodes of both the two right C sub trees.

? |g(PS(RN(i)) {j})| |g(PS(RN(i)) {j})| ? ?? ? ?  ( (RN( )) { }) ( (RN( )) { }C PS i j C PS i j? ?? ? ?  Conjunction function in unite process has two parameters SPT1  and SPT2.The action of conjunction function is to add the node count of sub nodes in SPT1 to node count of sub nodes in SPT2 and generate virtual at the right time. If a sub node N1 in SPT1  has a corresponding node N2 in SPT2 then add the node count of N1 to the node count of N2.If a sub node N1 in SPT1  has a corresponding  node in SPT2 then generate a virtual node at the corresponding place in SPT2 The node label of the virtual node is the node label of N1 and the node point links to N1.

Algorithm2: Conjunction Input: shadow prefix tree1:SPT1, shadow prefix tree2:SPT2  Begin {SPT2.count=SPT2.count+SPT1.count; For cSPT1=each children in SPT1 {If(SPT2 have a child cSPT2 {and cSPT2.itemid=cSPT1.itemid) Conjunction(cSPT1,cSPT2)} Else { vn=new Virtual Node; vn.link=SPT1;}} SPT2.children.add Virtual Node(vn);}  Continue to the previous sample,SPT(RN(AC)) will conjunction with right C sub tree of SPT(RN(AB)).The right C sub tree of SPT(RN(AB)) is SPT(RN(ABC)).The node count of RN(AC) will firstly add the node count of RN(ABC) and then the node count of RN(ACE) will add the node count of RN(ABCE). SPT(RN(ACE)) will add a virtual node VN(F) point to RN(ABCEF) because SPT(RN(ACE)) has no child with the node label F. When PT finishes all the operation, a SPT will be built. The SPT of table 1 is shown in Fig.2.

Fig. 2. The shadow prefix tree of  sample database  It is clear that the SPT has the two important attributes after the building process. All the closed frequent itemsets could be found easily by scanning the SPT. By the way, SPT has the basal attributes of PT, so SPT can be stored in the disk after serializing[16].It is convenient to read the SPT from the serialized SPT the next time to mining the same data set avoiding building process.

E. Update Incrementally SPTCI is an closed frequent itemsets mining algorithm  which can be updated incrementally .SPTCI realizes updating incrementally by uniting two SPT generated from two different data sets.

Theorem 2: If X is a closed itemsets in transaction data base D1, when D1 add another transaction data base D2 then X still be a closed itemsets in the new transaction data base.

Proof :Let c(X)=X in D1.Suppose in the transaction data base consisted of D1 and D2 ,X is no longer a closed itemsets, then there is a itemset Y,  and c(X)=Y, so the support count of Y is equal to the support count of X. Let count_X and count_Y represent the support count of X and Y. The support count of X in D  YXIY ?? ,  1 is bigger than the support count of Y in D1, because X is a closed itemset in D1 .Let count_X1,count_X2 represent the support count of X in D1 and D2 respectively and count_Y1,count_Y2 represent the support count of Y in  D1 and D2 respectively. In D2 the support count of X is no little than the support of Y. So count_X=count_X1+count_X2,count_Y=count_Y1+count_Y2 and count_X>count_Y, it is inconsistent with count_X=count_Y. So X is still a closed itemsets in the new transaction data base.

Theorem 2 indicates that if an itemsets is closed itemsets it will be still closed itemsets when add new transactions. In order to find all the closed itemsets from data set consisted of two sub data sets, it is necessary to conjunction each real nodes of two SPT generated from the two sub data sets. Algorithm 3 shows how to unite two SPT of different data sets. The unite_SPT operation is similarly to the union operation in algorithm 1.The unite_SPT has two parameters: SPTA and SPTB. In this operation each real node in SPTA and SPTB will be united to the new SPT. At the last of unite_SPT operation , all the point of virtual node should be redirected to the corresponding node in the new SPT because the input SPT will be delete when the new SPT is generated.

Algorithm3: unite_SPT Input: shadow prefix tree1: SPT_A, shadow prefix tree2: SPT_B Output: SPT_C BEGIN: { For ch=each children of SPT_B If ch in SPT_A Conjunction(SPT_A.ch,SPT_B.ch) Else SPT_B.addchildren(SPT_A.ch) For each  VN point to node of SPT_A REDIRECT TO nodes of SPT_B Delete SPT_A Return SPT_B}  . CFI MINING ALGORITHM SPTCI algorithm scans the SPT according to the mini  support count denoted as minsup. Algorithm 4 shows the process of SPTCI.

Theorem 3: In the SPT generated from data set D, there is a path corresponding to each closed itemsets of D.

Proof: Suppose ,I is the  set of items appears in the transaction of D, if X is a closed itemset, then C(X)=X. If  ,it is obvious that X has a corresponding path  in SPT, because T has a corresponding path in PT and the process of building SPT does not reducing the node of PT. If  IX ?  XTDT ??? ,  XTDT ??? , ,then suppose g(X)=D1, ,let i be the first element in X sorted by alphabet order. If i is not a root node of a sub SPT, suppose the right i tree of SPT(0) is SPT(RN(i)) and right i node of SPT(0) is RN(i),then |g({i}|=RN(i).count according attribute 2 and  TXDT ??? ,  |g(PS(RN(i)) { }) | ( ).i RN i count??  according to attribute 1,so )))(((}){))((( iRNPSciiRNPSc ??  because theorem 1.It is conflicting with the definition of closed itemset. So SPT(0) has a child with nod label i. If i and j are two adjacent elements in X and  ji ? ,then SPT(RN(i))(with the root node of RN(i)) has a child with node label j. Let RN(j)=R(SPT(RN(i))j),by the two attributes of SPT , |g(PS(RN(j)) { }) | ( ). | ( (RN( )) |j RN j count g PS j? ?? ,if RN(j) is not a child of SPT(RN(i)),then ????? }|{ jliIl ?? ,  ( (RN( )) { }) ( (RN( )) { })C PS i j C PS i j? ?? ? ? ,it is conflicting with that i and j are adjacent in X. So elements in X are corresponding to nodes in a path of SPT.

Algorithm 4: SPTCI Input: shadow prefix tree: SPT, Mini support count: minsup Output:closed frequent itemsets :  CFIS  Begin: {Close Frequent itemsets CFIS; CFIS=null; For ( ep=each path of SPT) {For (en=each node of ep) {If (en.count<minsup) break; If (en have no children OR en.children.count <en.count OR en has two or more children) CFIS.add(PS(en)+i)}} Return CFIS}  Theorem 4:If node(i) is a real node in SPT and the node count of node(i) is bigger than the node count of its children, then P is a closed itemset. S(node(i)) {i}?  Proof: Suppose is not a closed itemset, then exist and  PS(node(i)) {i}? ik ?  |}){))(((||}),{))(((| iinodePSgkiinodePSg ?? ? .There is a path corresponding to by theorem3.Let ,  (node( )) { } { }PS i k i? ? 1 2PS(RN(i)) {i} I I {i}?? ? ?  1 2PS(RN(i)) { } {i} I { } I {i}k k?? ? ? ? ? , 1,1,,2 IkInlkIl ?? ???? ,j is the first element in I2,then  RN( ) has a brother RN(j),and there is a path to i in SPT(RN(j))(with the root node of RN(j)).  Because node( ) is a real node, so the node count of RN( ) is bigger than the node count of RN( ).It is conflicting with  }{1 kI ?  1 2I I {i? ? }  1 2I I {i}? ? (node( )) { } { }PS i k i? ?     | ( (RN( )) { } { }) | | ( (RN( )) { }) |g PS i i k g PS i i?? ? ? ,so is a closed itemset. PS(node(i)) {i}?  Theorem 3 and 4 declares that all the frequent closed itemsets can be found by a scanning of SPT .SPT stores all the closed itemsets, SPTCI finds all frequent itemsets from SPT by mini support count.

. EXPERIMENT In order to evaluate the performance of SPTCI, the  experiment compares with FPL and AFOPT  on the data set generated by IBM data generator .  TABLE.II describes the information of the test datasets. Both of the two test datasets are very large, and the experiment is finished on a cluster in  [13] [15]  [17]  Yangzhou University. The cluster is consist of fourteen blades of IBM. Each blade has two Intel Xeon processors and 24GB RAM. These algorithms are realized by C++ on Ubuntu. Fig.3 and 4 are the results of the experiment.

TABLE II. THE INFORMATION OF TEST DATASET  Both dataset 1 and 2 are dense datasets with long patterns.

The time consumed by SPTCI is little than the time consumed by FPL and AFOPT because there is no sub set testing process in SPTCI.SPTCI avoids the scanning of sub tree whose root node has a node count little than mini support count, so the mini support count would not effect SPTCI as much as FPL and AFOPT.

Fig. 3. Result of dataset 1  Fig. 4. Result of dataset 2  CONCLUSIONS SPTCI algorithm gets closed frequent itemsets directly  by scanning the SPT once, improves the performance by reducing the searching space and avoiding the testing of sub sets. SPT is an important data structure used by SPTCI. The two attributes of SPT let it store all the closed itemsets, and the virtual nodes makes SPT avoiding to generate duplicate nodes and reducing the space.

