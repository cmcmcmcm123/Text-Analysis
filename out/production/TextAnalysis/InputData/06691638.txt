HIG ? An In-memory Database Platform

Abstract?Costs and time required for sequencing of DNA and RNA declined through use of next generation sequencing technology, e.g. up to 30-times coverage reads are generated in less than two days.

However, its interpretation and analysis is still a time-consuming process potentially taking weeks. In this work, we present a completely new architecture for processing and analyzing genome data. It builds on the in-memory database technology to eliminate time-consuming file-based data operations and to enable real-time data analysis. We found out that the use of in-memory technology as an integral com- ponent for genome data processing and its analysis significantly reduces time and costs to obtain relevant results, e.g. in the course of personalized medicine.

Keywords-Real-Time Data Analysis; In-Memory Database Technology; Genome Data; Personalized Medicine; Next-Generation Sequencing

I. Introduction  The Human Genome (HG) project officially launched in 1990 involved thousands of worldwide research in- stitutes and required more than a decade to sequence and decode the full HG [1]. Nowadays, Next-Generation Sequencing (NGS) devices process whole genomes within hours at reduced costs [2]. They are used in research and clinical environments to support treatment of specific diseases, such as cancer. Personalized medicine aims at treating patients specifically based on individual dispo- sitions, e.g. genetic or environmental factors [3]. This requires tool support to identify relevant data out of the huge amount of acquired diagnostic data [4].

The In-Memory Database (IMDB) technology has demonstrated major advantages in analyzing big en- terprise data [5], [6]. In the given work, we present our findings of applying IMDB technology to enable real-time analysis of genome data in course of our High-performance In-memory Genome (HIG) research project. We developed a specific platform that com- bines processing and analyzing of genomic data as a holistic process based on the feedback of researchers and clinicians. Our HIG architecture is designed to run on commodity hardware instead of highly specialized  H IG  W eb Serv ice (R uby on R ails)  Specific  C loud A pp lications  W orker N ode  R  W orker (Python)  In-M em ory D atabase Instance  R eads and R eference G enom es  R  H IG  W eb S erv ice (R uby on  R ails)  In te  rn et  In tra  ne t  L  functions, S Q L scrip t p rocedures  M aster N ode  Prim ary In-M em ory D atabase Instance  R  C lin ic ian  w ith M obile  D evice  Specific  C loud A pplication  R  R esearcher w ith W eb Brow ser  R  W ork L is t, W orker S ta tus,  G lobal S tate  S chedu le r and C oord inator Task Scheduler  (Python)  Data Layer Platform   Layer  Application Layer  R  R  W orker (P ython)  R  3rd  P arty Too l  3rd Party Too l  R  S pecific  C loud A pp lications  S pecific  M obile Applica tion  R  R  Figure 1: The HIG system architecture consist of appli- cation, platform, and data layer. Data analysis is directly performed within the IMDB eliminating time-intensive data transfers from the file system.

hardware to be a) cost-efficient and to b) make use of existing hardware infrastructures. Fig. 1 depicts the sys- tem architecture of our system modeled as block diagram using the Fundamental Modeling Concepts (FMC) [7].

The rest of the paper is structured as follows: In Sect. II our work is set in context of related work and we introduce selected components of our HIG system in Sect. III. We share our benchmarks results in Sect. IV and discuss our findings in Sect. V. Our work concludes with an outlook in Sect. VI.



II. Related Work  Time consumed by sequencing and related costs dropped disruptively with the introduction of latest NGS technologies around 2007. Meanwhile, algorithms used data processing of NGS data date back to early 1970s.

Related work in the field of genome data processing has increased in the recent years, but work focusing on implementing end-to-end processes is still rare.

Wandelt et al. have discussed recent data manage- ment challenges for processing NGS data. They observed trends towards more and more cloud-based solutions, but they identified the efficient mapping of workflow tasks onto heterogeneous distributed compute nodes and the adjustment of a given workflow to a dynamic environment as still open issues [8, Sect. 4.3]. Our work contributes by defining a system architecture that combines processing and analyzing of genome data. We contribute by sharing details about our worker frame- work developed in Python in Sect. III, which enables integration of compute resources across platform and Operating System (OS) borders. Furthermore, we share details about our scheduler in Sect. III, which enables prioritized processing of multiple tasks in parallel, e.g.

simultaneous users or multiple departments.

Pabinger et al. published a survey on variant anal- ysis tools and evaluated their functionality [9]. They selected 32 of them for evaluation and found out that the majority is command-line based, e.g. ANNOVAR, AnnTools or snpEff [10], [11], [12]. For web-based tools they see a drawback in data preparation before analysis can start since "[. . . ] files need to be packed, sorted and indexed before they can be used [9]". With our incor- porated IMDB technology we address time-consuming data transformation steps and replace them by native database operations as discussed in Sect. V.

Furthermore, Pabinger et al. evaluated workflow sys- tems and analysis pipeline tools. They realized that these tools either miss flexibility or need to have additional know-how to install specific tools. Our work contributes by introducing a flexible way to execute individual pipeline configurations without the need of adapting command line scripts. We enable graphical modeling of individual pipeline configurations and its execution within a single system as presented in Sect. III.



III. Architecture  Our platform consists of the following layers: appli- cation, platform, and data as depicted in Fig. 1. In the following, all layers are described in detail.

A. Application Layer  The application layer consists of special purpose ap- plications to answer specific medical and research ques- tions. Although these applications can only be used  for limited use-cases, they are highly optimized. For example, Fig. 2 depicts our genome browser application, which combines patient-specific data and data from various annotations databases in a single view.

All applications in the application layer communicate with the web service interface as depicted in Fig. 1.

We provide a Application Programming Interface (API) that can be consumed by various kinds of applications, such as web browser applications or iPad and Android devices as mobile applications, via asynchronous Ajax calls and JavaScript Object Notation (JSON) [13], [14].

As a result, performing specific analyses is no longer limited to a specific location, e.g. the desktop computer of a clinician. Instead, all applications can be accessed via any internet-connected device, e.g. web browser or mobile tablet computer, which enhances the user?s pro- ductivity by having access to relevant data at any time.

B. Platform Layer  The platform layer holds the complete process logic and consists of the IMDB system for enabling real- time analysis of genomic data. We developed specific extensions for the IMDB system to support genome data processing and its analysis. In the following, selected extensions and their integration in the IMDB system are described in more detail.

1) Scheduling of Data Processing: We extended the IMDB by a worker framework, which executes tasks asynchronously, e.g. alignment of chunks of genome data.

It consists of a task scheduler instance and a number of workers controlling dedicated compute resources, e.g. in- dividual compute nodes. Workers retrieve tasks and pa- rameters by the scheduler instance and perform specific tasks, such as workbench preparation, task execution, and maintenance of status information. Thus, all workers are connected to the IMDB to store status information about currently executed tasks.

The scheduler is responsible for managing the parallel execution of jobs on distributed compute resources. It performs non-preemptive resp. cooperative scheduling operations comparable to a process scheduler known from multitasking OS, i.e. assigning tasks to available resources without interrupting their operation at defined times [15]. We implemented different scheduling poli- cies, which can be extended by adding new policies to the policies.d folder. The default policy is random select, i.e. any free worker select any available job at random and starts its execution. In addition, we use a first-come first-serve policy, i.e. the job with the oldest creation timestamp will be executed first, and a priority scheduling policy, which starts the executed of all jobs with a higher priority class before starting jobs with a lower priority class. The priority scheduling also enables a boosting of very long running and compute intensive     Figure 2: Genome Browser: From top to bottom, comparison of reference genome and a selected cell line at a specific locus on chromosome 12. A Single Nucleotide Polymorphism (SNP) is depicted on the left. Combined information from international research databases about the selected mutation are shown on the right.

tasks. Therefore, the overall job execution time for a specific task is supervised and evaluated corresponding to the history of already performed jobs statistics. Once a long-running job has been detected, is automatically assigned to a higher priority level to a) finish its execu- tion and to b) free compute resources for new work as soon as possible.

The scheduler is contacted by the web service, i.e.

the scheduler is the central coordinator for asynchronous job execution. For keeping the global system state of all running processes, the scheduler persists assigned tasks and resources and status information in the IMDB.

Furthermore, the scheduler supervised the responsive- ness of individual compute resources. For example, it performs checks of known worker instances using regular heartbeat calls [16]. If a predefined response behavior is no longer guaranteed, e.g. due to an overloaded compute node or a crashed worker process, workers are marked as unresponsive. As a result, work-in-progress tasks of the unresponsive worker are reassigned to a new worker to guarantee their execution and the unresponsive worker is scheduled for a restart or the administrator is informed.

The scheduler derives the concrete tasks for a selected Genome Data Processing Pipeline (GDPP) model in- stance. Models of GDPPs are modeled in BPMN in a graphical workbench. The GDPP model is stored in the eXtended Markup Language Process Definition  Language (XPDL) data format [17].

Once a concrete GDPP model is instantiated by as- signing specific values for all parameters, it is available for genome data processing. The scheduler retrieves the selected model instance from the IMDB and creates corresponding data structures representing the depen- dencies between individual process steps. All ready-to- process tasks are added to the work list and assigned to available worker instances. The scheduler keeps track of there execution and retrieves intermediate results comparable to the MapReduce approach [18].

Tasks that can be executed in parallel, e.g. alignment of chunks of DNA data, are split into subtasks and dis- patched to individual workers. The scheduler combines intermediate results of individual subtasks to form the final result set. We focused on high-availability while designing important system components, e.g. the coor- dinator or the web service. Each worker is equipped with the code for becoming a scheduler. Once the first worker is started, it checks for existing scheduler instances and launched a new one if no scheduler is detected. Thus, in case of a crash or unavailability of the task scheduler, any worker instance can fulfill its task. After launching, it performs cleanup, rollback, and roll-forward tasks to migrate the system to a consistent database state.

2) Updater Framework: We consider the use of latest international research results as enabler for evidence-     based therapy decision [19]. The updater framework is the basis for combining international research results.

It periodically checks all registered Internet sources, such as public FTP servers or web sites, for updated and newly added versions of annotations, e.g. database exports as dumps or characteristic file formats, such as CSV, TSV, and VCF. If the online version is newer than the local available version, the new data are automati- cally downloaded and imported in the IMDB to extend the knowledge base.

The import of newly available research databases is performed as a background job without affecting the system?s operation. We import the new data without performing any data transformations [20], [21]. As a result, new data are available for real-time analysis without any delay.

For example, the following selected research databases are supervised regularly by our updater framework: National Center for Biotechnology Information (NCBI), Sanger?s catalogue of somatic mutations in cancer, Uni- versity of California, Santa Cruz (UCSC). [22], [23], [24].

C. Data Layer  The data layer holds all required data for performing processing and analyzing of genomic data. The data can be distinguished in the two categories: master data, and transactional data [25]. For example, human reference genomes and annotation data are referred to as master data, whereas patient-specific NGS data and Electronic Medical Records (EMR) are referred to as transactional data [26], [27]. Its analysis is the basis for gathering specific insights, e.g. individual genetic dispositions, and for leveraging personalized treatment decision in course of personalized medicine [3].

The actual step of analyzing the genetic data requires answering very specific questions. Thus, the application layer consists of specific applications to answer these questions. They make use of the platform layer to ini- tialize the data processing.



IV. Benchmarks  In the following, we share insights about the gathered benchmark results with multiple GDPPs processed by our HIG research prototype.

A. Benchmark Setup  All benchmarks were performed on a compute cluster consisting of 25 identical compute nodes. Each of the nodes was equipped with four Intel Xeon E7-4870 Cen- tral Processing Units (CPUs) running at 2.40 GHz clock speed, 30 MB Intel Smart cache[28], interconnected by 6.4 GT/s Quick Path Interconnect (QPI), and 1 TB of main memory capacity. Each CPU consisted of 10 phys- ical cores and 20 threads running a 64-bit instruction set.

Exp. Primary Storage Split Size I FS 1 II IMDB 1 III FS 25 IV IMDB 25  Table II: Comparison of benchmark setups using BWA in HIG. Split size describes the number of distributed compute nodes (Exp. = Experiment).

All compute nodes were equipped with Intel 520 series Solid State Drives (SSDs) of 480 GB capacity combined using a hardware raid for local file operations [29]. The average throughput rate of the local SSDs was measured with 7.6 GB/s cached reads and 1.4 GB/s buffered disk reads. All nodes were interconnected via a network file system using dedicated 10 Gb/s Ethernet links and switches to share data between nodes.

Instead of using generated test data, we only used real NGS data, i.e. FASTQ files, from the 1,000 genome project for individual measurements [30]. We used the FASTQ file of patient HG00251 for our benchmarks.

It consumed 160 GB of disk space, consists of approx.

63 Gbp, approx. 695 M reads with 91 bp individual read length forming approx. 20x coverage.

The aim of all conducted benchmarks was to minimize the overall execution time for a single GDPP run, i.e. to use the maximum available compute power to achieve best parallelization.

B. Performance Key Indicators  We investigated the following impact factors for con- trolling the overall pipeline execution:  1) Integration: We implemented GDPPs based on existing alignment and variant calling tools in our system architecture without any modification of the established tools,  2) Adaption: We adapted existing GDPPs to use the IMDB as primary storage for data processing, and  3) Optimization: We optimized the split size pa- rameter controlling the number of distributed com- pute nodes.

C. Results  For our benchmarks, we integrated Burrows Wheeler Aligner (BWA) in our HIG research prototype. We designed our benchmarks to compare the impact of the incorporated storage and the level of parallelization on the overall execution time as outlined in Tab. II. Exp. I and III used a FS as primary storage while an IMDB was used for Exp. II and IV. Exp. I and II were executed on a single compute node, while Exp. III and IV were executed on 25 compute nodes to evaluate the impact of a fully parallelized execution environment.

Size [Gbp] tpIq [s] tpIIq [s] tpIIIq [s] tpIV q [s] ImppIIq [%] ImppIIIq [%] ImppIV q [%] 0.5 1,100 808 283 130 27 74 88 1.0 2,159 1,622 520 245 25 76 89 2.0 3,900 2,860 943 470 27 76 88 4.0 7,029 5,259 1,761 893 25 75 87 7.9 13,626 10,364 3,377 1,733 24 75 87  15.8 25,147 18,707 6,609 3,387 26 74 87  Table I: Comparison of execution times in HIG for I) BWA, split size 1, II) the adapted pipeline using the IMDB as primary data storage instead of the FS, split size 1, III) split size 25, and IV) for the adapted pipeline using the IMDB as primary data storage, split size 25. tpxq = Execution time for Exp. x , Imppxq = Improvement of execution  time for Exp. x compared to Exp. I calculated as Imppxq ? tpIq?tpxq tpIq (Exp. = Experiment).

0  2  4  6  8  10  12  14  16  Pi pe  lin e  Ex ec  ut io  n Ti  m e  [s ]  FASTQ File Size [Gbps]  Exp. I Exp. II  Exp. III Exp. IV  Figure 3: Exp. II shows improvements of 24-27 % on single compute node compared to Exp. I. Exp. III and IV show improvements up 76 % and 89 % resp. on 25 compute nodes compared to Exp. I.

The overall pipeline execution for varying FASTQ file sizes was measured. BWA version 0.6.2 was configured to use 80 threads to use the fully available hardware resources of our benchmark systems [31].

Exp. I and II describe the overall pipeline execution time on a single compute node as shown in Tab. I. It depicts that the use of the IMDB as primary storage for intermediate results is for all file sizes beneficial.

Through this pipeline optimization the runtime can be reduced by at least 25 percent in average.

Exp. III and IV as shown in Tab. I document the impact the tuning parameter split size, i.e. the parallel execution of individual process steps, on the overall pipeline execution time. Parallel execution of selected pipeline steps reduces the overall execution time by at least 74 percent in average for BWA. Additional improvement can be achieved by using the IMDB as primary storage. Thus, the overall execution time can by reduced by at least 87 percent in average.



V. Evaluation and Discussion  Our benchmarks verify two hypothesis: Firstly, the use of an IMDB as primary storage improves the overall execution time of established alignment algorithms, such as BWA, integrated in our HIG system architecture as depicted in Fig. 3. Secondly, our system supports parallel execution of intermediate process steps across multiple compute nodes, which results in an additional performance improvement compared to the execution on a single compute node. The result incorporating 25 compute nodes show that the system was not completely loaded by our benchmarks since we did not adapt in- dividual processing tools, which still implement single threaded execution models.

The best relative improvement shows the adapted pipeline using the IMDB as primary storage with at least 74 percent on single compute node and up to 89 percent on 25 compute nodes. It shows that the overall pipeline execution time correlates to the number of base pairs contained in the FASTQ file in a linear way. The scaling factors for the overall execution time varies between 1.80 and 1.96 across all experiments and file sizes. This indicates a very constant and predictable system behavior of our HIG system for varying input file size. For example, a doubled number of reads results in an overall response slightly below a factor of two. It helps to predict execution times and to supervise the correct system functionality, e.g. in case of a broken compute resource or worker process as outlined in Sect. III.

Furthermore, our results stress the benefits of an IMDB for operating on intermediate results. The pipeline optimized for the IMDB replaces individual tools operating on files for specific process steps, such as sorting, merging, and indexing. In contrast, these operations are replaced by the IMDB operations without the need to create intermediate files in the File System (FS). We integrated existing alignment and variant call- ing tools into our HIG architecture without modifying their code. Thus, the speed-up documented in our bench- marks is mainly achieved by replacing selected file-based operations by IMDB operations.



VI. Conclusion and Outlook  In the given work, we presented our HIG system architecture for genome data processing based on an IMDB system. Based on our in-memory research ac- tivities, we outlined the applicability of this technology for processing of genome data to enable its real-time analysis. Furthermore, we shared insights in the specific architecture layers from an IT perspective and outlined details about select IMDB extensions for genome data processing, such as scheduling, worker framework or updater framework.

The obtained benchmark results showed that our HIG system architecture improves overall pipeline execution time by at least 25 percent on a single compute node and up to 89 percent involving 25 compute nodes. The performance boost is mainly derived from substituting intermediate processes, such as sorting, merging, and indexing by native IMDB operations.

In future, we will investigate the impact of optimized alignment and variant calling algorithms that directly incorporate IMDB technology. We expect to further eliminate media breaks and to improve performance due to data proximity.

