A Bandwidth-Conscious Caching Scheme for Mobile Devices

Abstract?While a substantial amount of big data are con- sumed via mobile devices, accessing content via wireless data connections on mobile devices has its own set of challenges.

Among these challenges, speed of data transfer is usually our first priority. Although there are many fast data connections available for Web surfing (3G, LTE etc.), the actual connection speed could vary significantly among different regions where fast connections may not be always available. As a result, the user experience of viewing information varies with different type of data connections in different locations. This paper proposes utilising the Type Of Data Connection (Bandwidth) to determine whether a dataset needs to be cached or pre-fetched to reduce the response time and thereby providing a better user experience. The role of the mobile device owner will form the basis of dataset construction criteria by using the technique of role mining. As the mobile devices are not confined to a particular space, an effort to trace the owner?s movement determines where the owner with the device is heading towards. This helps to identify the different connection speed patterns along the owner?s path, so that different caching or pre-fetching strategy can be deployed beforehand to aim for consistent quality of services.



I. INTRODUCTION  Mobile devices are more popular than desktop computers today. The advantage of mobile devices is that it fits well in a dynamic environment. Although it may be hard to predict their geographic presence due to the constant motion of the devices, the opportunity to provide services relevant to the region in which the mobile devices lie is vast. This ability, where users are able to identify their own locations, to get relevant information services is a concept called location-dependent in- formation services (LDIS). These services produce the answer to a query according to the location of the client issuing the query [5], [6], [32]. Some examples of mobile LDIS?s include nearest object searching (e.g., finding the nearest restaurant) and local information access (e.g., local traffic, news, and attractions).

Traditionally internet applications, when accessed through regular information systems like laptops or desktops, utilises the available memory and processing power of the systems which are usually superior to the mobile devices and also can exchanges data at a higher rate. Like mentioned before that the computing power of mobile is much less and limited than a regular computer no matter whether it is a laptop or a desktop computer. Added to this are the concerns of unstable wireless connections and the connection speed, which are usually in kilobytes on a mobile device instead of megabytes / gigabytes on a wired connection. To overcome some and many  of these limitations of the mobile network, approaches like caching, replication and broadcasting have been highlighted. In simple terms, caching frequently-used data allows applications to continue to function even when there is no data connection, e.g., an offline newspaper. While saying this may be easy, the complexity of wireless networks may make the implementation of caching quite a challenging task.

A dynamic context-aware caching scheme [8] is introduced to utilize the context as a mechanism to effectively improve the performance by caching data items related to a context or a set of contexts. As a general definition in many cases, contexts are either time-based or location-based. However, [1] generalises context as ?any information that can be used to characterize the situation of an entity, which could be a person, a place or an object that is considered relevant to the interaction between a user and an application, including the user and the application themselves?. This provides much wider contexts to look for when developing models on caching and as applicable to mobile devices.

The effect of geographical tagging for user actions may be very useful in the scenario of caching considering the fact that a regular pattern may exist in certain type of information usually being fetched. The significance of location based pre- fetching is defined in [12]. The argument is that when a bound geographical location is considered, for example, a college campus or a cinema hall, the data to be fetched for the users in that area can be pre-fetched in advance. The importance here is given to the location and not just the user habits [16].

Most users going to a cinema hall will be interested in movie reviews, trailers, best deals, etc., irrespective of the individual interests. Likewise in college campus, people are most likely to surf for timetables, course descriptions, dinner coupons, etc.

Like explained before, the attribute Geographical Presence adds numerous benefits to the mobile device. On similar lines, a sensed context [1] can be considered as a parameter to narrow down on a dataset to make it more useful to the user.

One such context discussed in this paper is the Speed Of Data Connection or generally called the Bandwidth which is used to get information on the mobile device. Additionally defined contexts [1] like user preferences, which are mined from role mining [29] [9] [27], will be discussed to understand the user behaviour patterns. On similar grounds, the trajectory movement prediction [19] will be considered to sense the movement of the object towards a particular region. The target region will then be sensed for faster or slower bandwidth. In summary, this paper concentrates on how the Type Of Data  2013 IEEE International Congress on Big Data  DOI 10.1109/BigData.Congress.2013.20     Connection coupled with a few other parameters that can be utilised to pre-cache dataset based on user interests and contexts.

The rest of the paper is organized as follows. Section II summarizes the related work. Section III describes the overall architecture. Section IV talks about pre-caching algorithms. In particular, it focuses on regional relationship mining and role mining with data connection type as a key parameter. Section V presents the experiments and Section VI discusses cache invalidation. Finally, Section VII concludes the paper.



II. RELATED WORK  Caching or pre-fetching is a concept that we can trace back from the advent of computers or information processing systems. However the way and the reason why pre-fetching is done has introduced new methods and technologies.

In traditional client-server type of architecture, caching data is an important technique that is provided to enhance re- usability of anticipated data. It assumes that the environment is a fixed set of assets which means that the server and client are attached to a location. Also as these models are built with the understanding that the servers or clients have dedicated resources and are available for exclusive use to them. In such scenarios caching of data can be concentrated mainly on effec- tive utilisation of cache as applicable to the system deployed.

Earlier client-server based architecture was extended to suit mobile environments by introducing application-transparent adaptation [10]. In these examples, a local proxy runs on the mobile host and provides an interface for regular server services to the applications. The concept of File System Proxy, Web Proxy was utilised to adapt the architecture to mobile devices. Later Application-Aware adoption was utilised as application-transparent adoption was sacrificing functionality and performance. Application-aware adaptation allowed appli- cations or their extensions to react to the mobile resource changes. In a mobile environment, the distinction between clients and servers may have to be temporarily ignored. This is because depending on the context, certain functionalities of either the client or the server may needs to be exchanged and thereby resulting in an extended client-server model.

While pre-fetching is a technique that is mainly concerned with improving the system performance, it is in generally used as an extension or support to the most basic data manage- ment method called the caching. Caching alone is generally not enough to improve the performance of mobile systems.

Moreover, pre-fetching has a broader application range than simply storing already used data in a cache.

When accessing information over mobile devices, there is always a server providing or serving information and a client receiving and using it [11]. The mode for client-server data delivery can be server-push, client-pull, or hybrid. While the server-push delivery is initiated by server-functions that push data from the server to the clients, in the case of client- pull delivery, what initiates the process are client functions which send requests to a server and pull data from the server in order to provide data to locally running applications. The hybrid delivery however uses both server-push and client-pull delivery.

Pre-fetching (or hoarding) data into the client cache prior to data disconnection may be a challenging task in mobile client- server computing and in this scenario concept of Automatic- Hoarding is discussed in [11], where the data is cached prior to the disconnection of client connection. Choosing which dataset to cache is another challenge and generally the two options used are: 1) Recently used 2) asking the user to mark the priority. While the first one may sometimes lead to space loss and the second one may seem cumbersome for some users.

In the SEER system [15], an automated predictive pre-fetch approach is proposed. The automated predictive pre-fetch is based on the concept that when a system can observe user behavior, then the observed user behaviour is used to make inferences about the semantic relationships between files and usage pattern and further use those inferences to provide better cache management to the user. There has been many research which highlights the need and usefulness to pre-fetch data.

A location specific concept of pre-fetching mentioned in [21] discusses how an information transfer can be done on users mobile device which might be needed in future by the user. While the paper talks about user defined preferences, it is however limited to a particular set of pre-defined preferences and restricted movement, and it is not dynamic. There is less that can be learnt by user actions over a period of time and improve the performance based on individual user activities. A model to better utilise bandwidth in cellular network is presented in [17], which used the concept of context shift, where software agents are placed to monitor user and network context and provide information to network operators to provide delay tolerant data services. Prioritized Transfer Of Objects applicable to Distributed Virtual Environments (DVE) is discussed in [20] where consideration of access priority is made.

While there has been many pre-fetching techniques used in general like mentioned above, value derived from role- based access control (RBAC) model on caching seems to be rarely discussed and the focus is mainly on enterprise systems. [35] [13]. By identifying user roles [27] [29], it opens up an opportunity for suggesting more suitable services.

And one more application of role management can be to pre-fetch data that may be useful to the user. The pre-fetch will be predominantly based on the various activity histories on the device performed by the user. In this context, a role based caching mechanism is proposed which will also consider activities of a user?s likes and tagging them with the Type Of Data Connection used to perform that activity and there by determining datasets to be cached. The overall importance is to improve or maintain consistent user experience when information is accessed over low speed data connections.

To enable location specific pre-fetching capability, we propose to make use of density-based clustering and Voronoi diagram to determine regions; whilst historical movement patterns between regions can be captured and modelled by Bayesian networks to allow for the execution of pre-fetching strategies. DBSCAN [7] is one of the popular density-based clustering methods that groups related objects by using density threshold composed of two parameters:  1) a maximum radius ? around each object, and 2) a value MinPts which defines the minimum number  of objects to form a cluster.

Allowing for imperfection in the dataset, the objects are classified into the following categories: core objects, border objects and noise. The core objects are joined to form clusters based on their proximity to each others.

Density-based clustering methods are argued [19] to be the best solution for clustering moving objects due to the following reasons:  1) they are able to handle clusters with no predefined shape, e.g. a cluster could be in snake-shape rather than spherical,  2) they are able to cope with noises in the data, and 3) one can base on the parameters to fine tune the  methods to fit a particular problem.

We adopt Voronoi diagram [3] to partition a plane with n clusters into polygons, namely Voronoi cells, based on the centroids of clusters (regions), such that each polygon contains only one of the centroids. Voronoi diagrams were invented by Rene? Descartes in the 1600s and were extended by Voronoi into higher dimensional spaces in the 1900s.

Given a set C of n data points c1, c2, ...cn on a plane, Voronoi diagram V (C) is a subdivision of the plane into Voronoi cells represented by V (ci) for ci, such that V (ci) = {p ? P|dist(ci, p) ? dist(cj , p)?i ?= j} where P is a set of points on the plane and dist(a, b) is a function returning the Euclidean distance between point a and point b.

Voronoi diagrams are frequently used in computer graph- ics applications. An example of using Voronoi diagrams in analysing traffic data is [30]. The other recent examples are mainly in the space of aeronautics and astronautics, e.g., airspace sector redesign and airspace monitoring [34].

Bayesian network (BN) is one of the probabilistic graphical models representing relationships between random variables by directed acyclic graphs [14]. The edges of BN record the dependencies between vertices which are conditionally related.

The strength of the relationships between vertices is quantified by probability functions associated with each vertex. The function takes the values from its associated parent vertices and outputs with the probability of the variable associated with the vertex. Song et al. [26] argue that the Dynamic Bayesian Networks (DBN) [18] and Non-Stationary Dynamic Bayesian Networks (NS-DBN) [23] [24] are unlikely to be scalable and also prone to over-fitting, and propose Time-Varying Bayesian Network (TV-DBN) to provide a better solution.

For TV-DBN [26], let graph Gt = (V, E t) represents the conditional dependence between the random vectors ?Xt?1 and ?Xt. Each vertex in V corresponds to a sequence of variables X1:Ti , and the edge set E t ? V ? V contains directed edges from components of ?Xt?1 to components of ?Xt. The time dependent transition model pt = ( ?Xt| ?Xt?1) can be expressed by an auto-regressive form of DBN ?Xt = ?At ?Xt?1+ ?E, where ?E ? N (?0, ?2?I). In this model, the estimation of the strength of dependencies is accomplished by minimizing a set of square loss functions, one for each vertex at each time point with regularization.



III. OVERALL ARCHITECTURE  This section describes the components of the model pro- posed in Figure 1. The components mainly are sub-divided  Fig. 1. Pre-Fetch Architecture  into:  1) User Role Mining 2) Pre-Fetch Association 3) Identify Datasets  Each of these components will be fed by a stream of constantly monitored information and some components feed into others for further processing of data to be identified for pre-fetch.

The component User Role Mining draws its inputs based on the Context-Aware Role Mining discussed in [28] and [29]. The model assumes that the user data which consists of activities done by the user in various contexts and roles are present. And this data is applied with the role mining techniques to understand user contexts and behaviours. Based on the role mining data, the set of information to be pre-fetched will be marked. For example, consider some user activities on a daily basis like viewing the morning news around 8AM at home, viewing movie reviews while travelling around 9AM, downloading his favourite play list during noon which consists of music and its reviews and probably get back to viewing news in the evening when travelling and so forth. All these information are not something fixed but may give rise to a said pattern over period of time and the role mining helps here to understand the nature of these activities. This vital piece of information provides a starting step to analyze the most relevant data that is needed to serve the user and hence can be marked for pre-fetching.

The module Pre-Fetch Association does further clean up on the role mining data and concentrates on improving the quality of dataset to be pre-fetched. This module is fed with information that is collected based on two important aspects discussed in this paper: 1) prediction of the object movement and 2) the type of the data connection used to fetch the data.

We assume a region which can be subdivided into sub regions and tagged with various signal strengths for the data connec- tion (refer Figure 4). Considering the mobile object to be in one of the regions and having a potential to move into any of the surrounding regions and beyond, the trajectory of the object is predicted which will constitute Predict Object Movement component. The prediction of movement of the mobile object     is based on density based clustering methods [19] [26] making use of DBSCAN. Another important component the Type Of Data Connection, plays a pivotal role in deciding what needs to go into the pre-fetch dataset. It is evident that not all information that will be accessed on the mobile device will use the same type of data connection. It is highly unlikely to predict that a particular type of connection only will be used.

User while travelling on public transport normally has to fall back to his mobile data provider connection which usually will be slower when compared to his browsing speeds he gets when using a high speed connection at home or office through a Wi-Fi connection. In this regard the Type Of Data Connection when coupled with the Predicted Object Movement, will be a providing a vital piece of information that may be applied on the dataset to check if it requires a Pre-Cache or not. We believe this method considerably enhances the quality of cache by removing datasets that may not require a pre-fetch as they can any way be downloaded quicker over a faster internet connection.

The module Identify Datasets is a continuously evolving and dynamically changing piece like any other component in the model. The feed from the components User Role Mining and Pre-Fetch Association percolates into this component providing a finer approach to maintain what needs to be pre- fetched. Like discussed before, the dataset to be pre-fetched is narrowed down based on the Type Of Data Connection used and the predicted regional movement of the mobile object.

However to make the to-be-cached data be more optimum for the user, a factor of probability is required to set the priority or order in which the data should be considered to be cached while the mobile object is in an area where faster connection speeds are available. Consider a scenario where there are ten data items that are marked for pre-fetch and currently the mobile object is in a high speed connection area and sensed to be moving towards a slower connection area. To prioritise what needs to be first fetched a ranking based on probability [22] is adopted. The component Usage Probability Matrix kicks in to start monitoring the usage of the cache as expected.

For example, based on the User Role Mining, Type Of Data Connection, Predicted Movement, there was a dataset that was pre-fetched to be used in a certain context, say while travelling back home and that data item was never used, then there should be a weightage added which pushes the priority of that item down. And here, the probability matrix plays a role of flagging data items that are not used as expected. We should note that the probability table for the context and the associated data will be built over time and thus considers multiple occurrences of non-usage or usage. Thus this component helps in prioritising what needs to be cached over the existing priority list. Higher the probability, higher is the preference. The Assumption here is that the data viewed by the user has a pattern and is not just random in nature.



IV. PRE-CACHING ALGORITHMS  A. Region and regional relationships mining  Rather than using a basic method to divide an area into regions by using naive grids and/or external knowledge about the area, we achieve a better result by learning regions directly from the trajectories of moving objects. We select density- based clustering methods, as they fit well to trajectory data  analysis [19]. Although the region structure can vary through- out a day, we obtain one set of regions by using DBSCAN based on the trajectories of moving objects in the mid-day of a working day for illustration. The centroid of each cluster is interpreted as the center of a region and the physical region areas are mapped based on Voronoi diagram by inputting the centroids as the data points as shown in Figure 4 later in this paper, where the larger black dots are the centroids (region centres), the regions are divided by black lines, and the small dots represent the moving objects.

We adopt TV-DBN from Song et al. [26] for the region time-varying structure mining based on the assumption that the underlying network structures are sparse and vary smoothly across time. Let graph Gt = (V, E t) represents the conditional dependence between the random vectors ?Xt?1 and ?Xt, where the vector represents a feature value of the traffic from different regions at time t? 1 and time t in our model. Each vertex in V corresponds to a sequence of variables X1:Ti , and the edge set Et ? V ? V contains directed edges from components of ?Xt?1 to components of ?Xt, where time T is the end of the time period of our concern.

The time dependent transition model pt = ( ?Xt| ?Xt?1) can be expressed by an auto-regressive DBN form ?Xt = ?At ?Xt?1+ ?E, where ?E ? N (?0, ?2?I). The region time-varying structure is represented by the non-zero entries in the estimated matrices ?At at time t. In this model, the estimation of the strength of dependencies is accomplished by minimizing a set of square loss functions, one for each vertex at each time point, with regularization terms [26].

We follow the approach proposed by [26] to estimate the network by decomposing the problem along the time (t) and region feature vector (?x), in which t ? ?x. We estimate the neighborhood for each region separately by using linear regression and then join these neighborhoods to form the overall network. The estimation problem is reduced to set of optimizations with one for each node i ? {1 . . . |V|} for time points t? = 1 . . . T (time points from the start to the end of time interval):  ?? At  ? i? = argmin  ?At ?  i? ?R1?n T  T?  t=1 wt  ? (t)( ?At  ? i? ?x  t?1 ? xti)2 + ?? ?At ? i? ?1  where ? is a regularization parameter which controls the sparsity of the networks, and wt  ? (t) is the weighting of an  observation from time t defined as wt ? (t) = Kh(t?t  ?) ?T  t=1 Kh(t?t?) in  which Kh(?) is a symmetric and non-negative kernel function and h is the kernel bandwidth. We have selected ?x to be either the count of trajectory fragments in each region or the average velocity of trajectory fragments in each region in our investigation.

The regions mined by DBSCAN is applied to calculate the movement feature, of each region to form matrix ?X where the value of ?xt?1 and xti for t ? {1 . . . T} can be derived from.

The end product of TV-DBN estimation is a set of ??At ? i?  (one per region) which can be combined to give an estimate of ?At where t ? {1 . . . T}. The non-zero and zero entries in the matrices ??At represent network connections and disconnections     respectively, i.e., the time-varying network structure over the time period.

B. User roles and data connection type relationship mining  It is important that a location-aware pre-fetching engine acquires the data consumption behaviors (role patterns) in the user community before any pre-fetching recommendation can be made. In this paper, we follow the definition in [28] and [29] to define the context-aware role mining problem (RMP):  Given a user behavior pattern configuration bpc = ?U,C,B,UCB?,  where U is a set of users, C is a set of contexts, B is a set of behaviors, UCB ? U ?C ? (B ?{?}) is the user-context- behavior relation, RMP is to find a state ?R,UA,CBA? that is consistent with bpc, such that for any ?R?, UA?, CBA?? that is consistent with bpc, |R| ? |R?|, where R, R? is a set of roles, UA, UA? ? U ?R is the user-role assignment matrix, CBA, CBA? ? R ? C ? (B ? {?}) is the role-context-behavior assignment matrix. The state is consistent with bpc, if every user in U has the same set of context-behavior assignment as in bpc.

The user role context matrix provides very useful informa- tion to suggest suitable services. This concept when coupled with a few of other parameters may yield a better caching mechanism. One of the possible methods of caching is to associate roles with the data available in the network based on a correlation based on role mining [25] [27]. Predicting the preference of user is one of the highlights made [29] and this can be used to determine the possible datasets for caching.

Suppose that there is a user set U = {u1, u2, u3, u4, u5}, a context set C = {c1, c2, c3, c4, c5}, and a behavior set B = {1, 2, 3}. A sample UCB, namely UCB1, can be constructed based on users behavior patterns as shown in Figure 2(a) where each column denotes a context, each row denotes a user, and the value b in cell {i, j} represents that the user ui has the behavior b under the context cj. Please note that b=0 means that the user does not have any behavior under that context. After mining roles from the behavior pattern configuration, we obtain a state ?R,UA,CBA?, where R = {r1, r2, r3}, the resulting CBA and UA are shown as in Figure 2(b) and Fig 2(c), respectively. As shown in Figure 2(b), three mined roles r1, r2, and r3 are listed in a role- context-behavior matrix, e.g., r1 has behavior 1 under context c1 and c3, and behavior 2 under context c2. Figure 2(c) shows a user-role matrix, where a 1 in cell {i, j} represents that the user ui can play the role rj. e.g., user u1 can play role r1.

In the example as in Figure 2(c), if user u3 has two roles r1 and r2, and r1 has context (c1, c2, c3) and r2 has context {c4, c5} then the network can be scanned for the associated data relating to the roles r1 and r2 and behaviour associated with context c1, c2, c3 and fetch that data to be stored in the mobile device.

In this example we are just working on the concept of roles and contexts. The overload of this method will be that ? data that may otherwise be accessed quickly over a fast internet connection will also be cached. This effectively does not provide optimum cache utility. Here is where we are introducing a new parameter to isolate data in the cache  Fig. 3. User and Context with Data Speed  dataset which may not be required to be pre-fetched and that parameter is the Type Of Data Connection that is used to fetch information from internet.

Apart from the roles and contexts, if we can apply an additional parameter ?Type Of Data Connection? as catching condition which can be used to perform a specific information fetching activity by the user, then the information in cache set can possibly be concentrated to have only the data that add value to user experience. As a result, the improvement can be in terms of the speed of data fetch and also give importance to the fact of low data storage capacities on the mobile devices.

With this concept, a condition to the dataset to be cached can be defined as:  CacheDataSet = Data for (u3) relevant to role r1 and r2 having behaviours in context (c1,c2,c3,c4,c5), where context are occurring in location where (TypeOfDataConnection) = Slow.

Like illustrated in Figure 3, if user actions are in contexts c1 = slow, c2 = slow, c3 = fast,c4 = slow, c5 = fast, then c3 and c5 will be ignored for caching as it was performed using a faster data connection and can be fetched quickly anyway.

Caching such data may just reduce the data storage capacity on the mobile device.

Continuing further, if we consider the fact that using User Role Mining, we can identify the dataset consisting of (D1, D2, D3, D4, D5) and this is what the user is pre- dicted to be viewing in different contexts (regions) with slow connection, then pre-caching the dataset will help to save time in downloading them when the user is in a context where (TypeOfDataConnection) = Slow. For example, like GPRS/2G/3G.

To illustrate the savings in time for downloading if the dataset is not pre-fetched, for example let us consider that the time taken to download 1MB of data is in ratio of 1:5 for a Wi-Fi and 3G. We can then see that there is a data access time difference of around 104 seconds for the dataset shown in the following table.

(a) User-context-behavior matrix (UCB1) (b) Role-context-behavior matrix (CBA) (c) User-role matrix (UA)  Fig. 2. An example of role mining  Data item Size (MB) Time taken** Time taken** in sec. in 3G in sec. in Wi-Fi  D1 10 50 10 D2 3 15 3 D3 1 5 1 D4 5 25 5 D5 7 35 7  130 26  ** Assumption: Time taken is not reflecting actual speed 1 of data measured. It is a comparison with an average ratio of 1:5 with 1 for Wi-Fi and 5 for 3G.

In effect, using the concept of pre-fetch which is fine tuned by introducing a parameter TypeOfDataConnection, we are highlighting a saving of (130-26) = 104 seconds in total. This is the time that was saved for downloading data prior moving to an area where slower bandwidth is present.

Additionally, a factor of probability is introduced to deter- mine, what data item must be cached on a priority basis. A probability model like one discussed in [22] could be used to increase the cache usability.

If a data item that is pre-cached is not used as expected, then by using a matrix to hold the probability over time will help improve cache performance. A simple matrix is proposed which holds the probability against the dataset usage.

The probability will be incremented or maintained at the same probability level (on reaching maximum) if the cache is utilised (the pre-cache is based on the user usage pattern).

The probability will be decreased when the cached dataset is not used after being identified for a pre-fetch. By maintaining this kind of a data-probability table, the priority that needs to be given to a dataset can be determined using the probability value in the table.

The table below holds information on data items (D), its context (C) and the probability index:  1http://mobileoffice.about.com/od/wifimobileconnectivity/a/wireless- internet-comparison.htm  Data item context Probability of happening  D1 C1 65% D2 C2 75% D3 C3 100% D4 C4 45% D5 C5 28%  As we can see visually from the table data, set D3 stands out clearer with highest probability. Thus if a conflict should arise as to what data item needs to be cached when the mobile device is sensed to be moving to an area having lesser bandwidth, D3 sits at top priority with 100% probability. Thus D3 will be marked as the first item to be cached when a high bandwidth is available and then continue to cache other datasets that are next in the priority as per the probability table.

In summary this probability ranking provides a mechanism to mark the most relevant set of data items for caching which will contribute in providing a homogeneous user experience.



V. EXPERIMENTS  We evaluate our proposed model by using real moving objects data - Beijing taxi trajectory data downloaded from the website of Complex Engineered Systems Lab, Tsinghua University, China2. The taxi is considered to be having an occupant possessing a mobile device. By this understanding, we can analyse the movement of the mobile users using the taxi data collected. For the reasons of privacy, the taxi data which has been made public is considered for analysis and hence data that could be collected by tracking individual mobile devices is not attempted.

The trajectories are firstly extended with derived attributes, e.g., speed and direction. We then cluster the trajectories based on DBSCAN. Each cluster is assigned with a cluster identifier and the centroid of the cluster is calculated (refer Figure 4).

The overall region structure is formulated by considering the samples of cluster-set of each time point t? = 1 . . . T mined within our time period of interest. Density-based clustering is again applied to summarise the cluster-sets into one set representing the regions for the time period. The physical regions are drawn by using Voronoi diagram. We then assign each region with a signal strength by random generator as shown in Figure 4. This assignment is required to determine the movement of the mobile object towards a region having high or low signal strength.

2http://sensor.ee.tsinghua.edu.cn/datasets.php     Fig. 4. Region structure with signal strength  Once the regions are ready, we then calculate the features of the regions from the trajectory data. The features could be the number of taxi or average speed of taxi in a region. The data are summarised into a matrix ?X and ready to transform into ?xt?1 and xt.

We then go through the TV-DBN estimation process to come up with time dependent transition matrices ??At, as illustrated by Figure 5, where non-zero entries represent the set of regions ?xt?1 at time t ? 1 that lead to a response on region xt at time t.

The more dense the region looks, the chances of the vehicles moving to that area is more. The question arises as to which region to choose. Consider a comparison with a snapshot of time t and t? 1 as shown in Figure 5. This com- parison provides information on the possible movement. Let us consider, say four regions R1,R2,R3,R4. They represent the strength of connections between regions R1 . . . R4. The strongest connection from t?1 to t is region R1 to region R4.

It can be noted that R4 has the highest cell value equal to (0.8).

By this experiment the mobile object will most likely move towards region R4. The tagging of random signal will help to identify if the region R4 is indeed having low bandwidth and thereby requires caching.

By this experimental analysis, we have shown a process to determine possible movement of the mobile object to a specific region. In this example, the region R4 does have low bandwidth. There can be a case when the object moves into a different region Rx than to R4 as predicted. However, if region Rx falls into a low bandwidth category, the caching will still be successful. Thereby we can conclude that TV- DBN structure estimation usually contributes to improve the caching mechanism discussed in this paper.



VI. CACHE INVALIDATION  Cache invalidation is a process where the entries in the cache will be removed so that new data can be stored.

Moreover, this helps in removing unused data items which otherwise take up space. There are many cache validation methods in use in the industry with its own benefits and limitations. The spatial property when attached to a data value poses challenges about the validity of the information when the object moves to a different location. Location dependent  Fig. 5. Regions relationship between t and t ? 1 calculation by using DBSCAN and TV-DBN model (cell values in ??At are for illustration purpose only)  cache invalidation [33] talks about the maintenance of validity of the data that was cached for a device with dynamically changing geo-location. There are techniques [2] [4] [31] which discusses cache invalidation scheme and cache replacement policy. However they do not cover the scenario for location dependant data.

Considering the fact that the proposed model discussed in this paper is targeted for mobile devices, techniques of cache validation applicable to mobile devices is referenced to be used. In this regard, the location dependant replacement strategy mentioned in [36] which considers valid scope area of a data value is suited well.

In this mechanism a geometric location model is assumed where a location is identified with a two-dimensional co- ordinates. The devices which are non stationary transmits its location using a Global Positioning System (GPS). Two parameters namely Valid Scope and Scope Distribution are used. The Valid Scope of an item value is defined as the region within which the item value is valid. The set of Valid Scopes for all of the item values of a data item is called the Scope Distribution of the item. The idea is to attach complete/partial invalidation information to various data values. The advantages of this idea are that the attached invalidation information provides a way for the client to check the validity of cached data with respect to a certain location without connecting to the fixed data server. There may be situations where validity checking is necessary. For example, the same query may be issued later when the client has moved to a new location or a mobile client may keep moving after it submits a query and the client may have moved to a new location when the response is returned if there is a long data access delay. The invalidation information can be utilized by cache replacement policies to enhance performance too.

A probability-based policy is to replace the data with the least access probability. Policies such as LRU, LFU, and LRU-K are various implementations of the probability-based policy. However, in location-dependent services, besides access probability, there are two other factors, namely data distance and valid scope area, which should be considered in cache replacement.



VII. CONCLUSIONS  Nowadays, a substantial amount of big data are consumed via mobile devices due to the popularity of smartphones. While the technology of mobile network is continuously improving, connection speed could still vary depending on what type of connection is available in a region as well as the connection capability of the device. In this paper, we have proposed using data connection type to control dataset pre-fetching subject to the contexts of user actions, and hence this control saves data space on mobile devices where data storage is limited.

Apart from space saving, we also highlight that this dynamic information can lead to much better user experience (or to maintain a homogeneous user experience) by pre-fetching dataset that is anticipated to be used in a location where only slower data connection is available. The concept of region- relationship mining was used to predict the movement of device owners. Further advancement to this model can be made by considering additional parameters, e.g., user like and dislikes, preferred locations, roles that the user may belong to in a wider crowd, and improving probability calculation and incorporating other variables that may affect the pre-fetching mechanism. In addition, a thin mobile client application can be built to track data usage patterns to allow for the fine tuning of the dataset pre-fetching control model.

