Contradiction Detection between Opinions  From a Big Data perspective

Abstract? This paper offers a solution to the problem of  detecting contradictions among opinions on the same topic. The  opinions are extracted from a large number of unstructured  documents and stored in a structured format. Due to the increase  in data available for analysis, we focus on providing a  storage/retrieval and analysis solution suitable for managing  large quantities of data while maintaining the speed and  reliability present in smaller scale systems. Our approach  consists in building a distributed system able to scale horizontally  with the increase in input data without any significant  performance decay. We represent opinions in a tuple based  structured model, more suitable for retrieval and analysis. This  approach allows us to formalize an algorithm for detecting  contradictions between opinion tuples. Furthermore, we present  a method for improving the recall of the system by using  synonyms for the opinion target to expand the set of possible  contradicting opinions. Our main focus is to optimize the  structure of the opinion tuple to provide the best retrieval time  and to allow for a simple, structured approach for detecting  contradictions.

Keywords? scalability, big data, information retrieval,  contradiction detection, opinion.



I.  INTRODUCTION  As corporations grow larger it is hard to keep track of the consistency in the opinions expressed by the employees in time. As the number of documents written by employees to express opinion and the number of meeting transcripts grow very large, the possibility to detect contradictions in opinions by human analysis disappears. Therefore, automated detection of inconsistencies in opinions, or contradictions, is essential.

Inconsistencies found in opinions expressed in the politics field or in the legal domain might also make a difference by detecting fraud and other misdeeds and help in bringing a better interpretation to facts.

The purpose of our work is detecting possible contradictions between opinions extracted from a very large corpus of opinionated documents. These documents can be large documents in the form of articles or short documents originated from social networks. Our main objectives are: to provide an efficient structured manner for storing the opinions existing in the documents and to ensure good response time for both detecting contradictions and for opinion search and  retrieval. Due to the fact that the original opinionated documents offer unstructured information, we used a tuple- based structured representation for the opinions. The advantage of such a representation is that it allowed us to define a straightforward algorithm for contradiction detection between two or more opinions. We have focused on providing real-time contradiction detection while maintaining an acceptable accuracy. The contradiction detection system that we have envisioned will perform a coarse grained analysis on the opinions and prioritize the most common and most obvious cases of contradictions. However, our solution allows for a more fine-grained, text based contradiction detection system to be used to further analyze the contradictions detected and validate or invalidate them. Our second objective is to obtain good response times when searching for existing opinions and when detecting contradicting opinions for one or more opinions extracted from new documents. This led us to focus on improving the response time of the system for retrieval- oriented tasks. We therefore propose a scalable storage and retrieval solution that allows for near real-time opinion analysis in order to provide the contradictory opinions. To ensure faster retrieval, we use an external index, which will be used for the searching tasks.

The rest of the paper is organized as follows. In section II, we review the current trends in Information Retrieval and Big Data analysis and present related work which has been done in the domain of contradiction detection. In section III we describe our approach and the main flows of the system described. The results we obtained by evaluating our system are presented in section IV. Finally, in section V we conclude the paper.



II. RELATED WORK  One can define Information Retrieval as the act of finding information sources that satisfy a certain information need from a large collection. With the evolution of search engines and the internet, information retrieval is rapidly becoming one of the most common manners to access information. In [1], the authors describe various approaches for designing and implementing information retrieval systems. There are a number of Information Retrieval models that are used today.

The simplest and most commonly used model is the Boolean retrieval model, in which the documents are grouped in two categories with respect to the query, the documents that match     the query, or the result of the query, and the documents which do not match the query. This model can be extended by using term weighting techniques to obtain a measure of the relevance of a document with respect to the query. Other techniques that can be used to enhance the retrieval are relevance feedback and query expansions. Finally, probabilistic techniques can be used to compute the probability of a document to be relevant to an input query. This probability can be used as a score in ranking the documents when providing the response to the query.

Evaluating the performance of an Information Retrieval is influenced largely by the user utility of the system response.

User happiness is the key measure of user utility. While user happiness is largely correlated with the user interface design and its responsiveness, some quantifiable factors like the speed of the response and the size of the index also influence user happiness. The relevance of the response is another important factor, due to the fact that the user will not be impressed by fast responses that return irrelevant information.

In the recent years, there has been increasingly more research focusing on Information Retrieval and Big Data. As the available data amount increased, scalability has become a vital requirement for any system performing operations on data. In [5], the authors present the Google File System (GFS), a file system intended for large distributed data-intensive applications. Their main objective was to obtain high performance and fault tolerance while running the file system on a very large number of commodity hardware machines.

Based on the assumption that inexpensive commodity components fail often, the file system is able to monitor itself, detect failures and recover.

A similar system, The Hadoop Distributed Files System (HDFS) is presented in [6]. As opposed to GFS, a proprietary system, HDFS is open source and has been reported to be successfully used for datasets of PB scale.

The evolution of these distributed file systems has determined the evolution of NoSQL data stores. Such data stores differ from the relational database as they do not enforce a fixed schema onto the data and can be easily scaled horizontally. BigTable, a distributed data store based on the GFS is presented in [4]. BigTable is designed to scale reliably to PB of data and thousands of machines. This data store is a sparse, distributed, persistent, multi-dimensional map. The map is indexed by a row key, a column key and a timestamp, and each value in the map is represented as an array of bytes. Each row can be partitioned in groups of columns called tablets, which can be stored in different locations. The system proposes a Master/Slaves architecture, where data is stored on Tablet Servers, while Master servers are responsible for monitoring the available Tablet servers.

Due to the fact that our work is focused in both big data analysis and contradiction detection, we will shortly present the latest research in the field of sentiment analysis and contradiction detection.

Bing Liu [3] has done some extensive work in the area of sentiment analysis and opinion mining. He has described several approaches for opinion extraction and has also proposed a model used for opinion summarization.

In [7], the authors present a method for detecting contradictions based on negation, antonymic, semantic and pragmatic information associated with the discourse relations.

Another approach for detecting contradictions, based on linguistic analysis and alignment between sentence graphs is presented in [8]. However, both of these approaches, although efficient, are fine-grained and rely and on intensive text processing.

We have decided on storing the opinions extracted from documents in the form of tuples consisting of their most important features. This approach reduces the size of the data that needs to be stored and allows us to analyze/process structured data for contradiction detection and therefore to decrease the processing time significantly as opposed to processing text representations of opinions.



III. SYSTEM DESCRIPTION  A. Concepts and terms  From the logical point of view, an opinion is a belief about facts or entities, usually viewed as being subjective. An opinionated sentence has a form similar to the following sentence:  John likes the display of the camera.

Considering the above sentence, one can extract several grammatical entities. In this example, John represents the opinion holder, or the entity that expresses certain beliefs. The entity on which the opinion is expressed is the camera. This entity can have more attributes, also called aspects, on which sentiments can be expressed. In the example presented above, the display represents an attribute of the entity camera. The actual sentiment that defines the opinion is given by the word likes, which we will call the sentiment word. This sentiment word also gives a polarity to the opinion.

These terms can be used to structure any opinion from a given text to a tuple of the form:  ? ? h, e, a, so, sw ????? ????  In (1), h represents the opinion holder, e represents the entity, and a represents the attribute that describes the entity.

The entity and the attribute of the entity can be grouped together and thus, the group (e, a) can be viewed as the opinion target. The sentiment word is given by sw, which also determines the polarity or sentiment-orientation. We have quantified the sentiment orientation as a real value between -1 and 1, following the model presented in [3]. This would imply that positive opinions would have a sentiment orientation close to 1 while negative opinions would have a sentiment orientation closer to -1. A value close to 0 of the sentiment orientation will coincide to neutral opinions.

To further describe the opinion, we also add the document identifier, which is a generated string that uniquely identifies the document, and the time ts at which the opinion was expressed to the tuple.

A problem that arises when attempting to formally represent opinions is that individuals can use different words when expressing opinions on certain targets. For example, the same user can express two different opinions on the same concept, but the use of different, synonymic, expressions for the same concept will cause the system to fail to detect the contradiction. We address this problem by extending the opinion tuple with a set of target expansions. Thus, each target has an associated set of pairs of the form (tik,dk). tik represents a synonym of  the target ti, while dik  is a real value bound in the interval [0,1], representing the strength of the synonymy relationship between ti and  tik. A distance of 0 would imply perfect synonymy, while a distance of 1 would imply that ti and tik are totally unrelated.

? Ti=[(ti1,di1), (ti2,di2),?, (tin,din)]? ????  We refer to the set Ti as the set of target expansions of an opinion Oi. Another observation that can be made is that the same procedure can be applied for sentiment words.

Therefore, we extend the representation of the opinion further using the set Si of sentiment word expansions.

? Si=[(swi1,di1), (swi2,di2),?, (swin,din)]? ????  For each opinion tuple, the sets T and S are stored in the repository.?  B. System architecture  Our approach for solving the problem is represented in the diagram in Fig 1. The two central modules marked with red will be described in this paper as a storage and opinion analysis solution integrated in the contradiction detection system. The Repository is the core of the system providing data management services while ensuring high availability and scalability. The Opinion Extraction Module extracts a set of opinions for each document received as input and passes them to the Repository and the Contradiction Detection Module for storing and processing purposes. The Expansion Module will work offline to provide close synonyms to the entities and sentiment words of stored opinions, which will be stored as different versions of the same opinion. The distances di, corresponding to each synonym will also be provided by the Expansion Module. The Community Detection and Contradiction Detection module uses the opinion data stored in the repository perform clustering on the set of opinion holders and opinions on those clusters. The Text Based Contradiction Detection module used text-based techniques to validate the contradiction detected by the Contradiction Detection module.

These last two modules are part of the whole system, but are not relevant for the functionality discussed in this paper.

Given a new opinion, the Contradiction Detection module will extract the set of contradicting opinions of the same holder and on the same target. Due to the real-time constraint, only shallow contradiction detection is possible, therefore marking the relation between the input opinion and each of the contradiction opinions as suspected contradictions. The pairs of opinions, considered suspected contradictions, are further evaluated, by another module in the system, offline, using more   Fig 1. Proposed architecture     time consuming techniques to give more accurate results and validate or invalidate the suspected contradictions.

For storing the opinions and documents, we propose an  approach that is optimized for retrieval  response time. The  repository will integrate an indexing mechanism to increase the  performance in terms of response time. To allow the repository  to gracefully handle a large number of documents, we consider  using a distributed database.

C. System flows  The functionality of the system, viewed through the main  flows, is presented in the following section.

1) Opinion Search Flow In addition to contradiction detection, the Repository can be  used to manage and analyze previously stored opinions. Some example use cases are: retrieving all opinions on a certain target or the opinions that contain a certain sentiment word.

Such queries can be resolved by simply retrieving opinion tuples with the same target and the same word. To improve the recall for the cases when users refer to the same targets by using synonymic expressions, the input target can be matched against the set Ti of previously stored tuples. The input sentiment word can also be matched against the sets Si.

2) Storing expansions flow At discrete time intervals, the Query Expansion module  will be notified to check the repository for new opinions (marked as not-expanded) with new targets. It retrieves the set of new opinions and returns a sets T and S for each unexpanded opinion oi. These sets are then stored in the repository to increase the recall for the contradiction detection operations.

3) Contradiction Detection Flow The contradiction detection flow consists of finding and retrieving opinions that are suspected to be contradictory to an input opinion. If we consider the holder and target of the input opinion a query, we can view the task of finding contradicting opinions as an opinion retrieval task.

A set of opinion tuples [o1,o2,...,on], which has been mined from new documents by the Opinion Extraction module, is passed to the Contradiction Detection module, but will also be stored in the repository for further use. Further on, the Contradiction Detection module takes each opinion from the set and compares it with contradiction candidate opinions retrieved from the repository which have the same holder and the same target, to detect the possible contradictions. The pairs of opinions are compared and only the ones with a difference in the sentiment orientation above a threshold are kept:  ? | sok  - soi  | > thresh? ????    For example, applying (4), if soi and sok represent the sentiment orientations of the opinions oi and ok, the two  opinions are marked as suspected contradictions. The sentiment orientation of an opinion can take values from the [-1, 1] interval. If the signs of two sentiment orientations corresponding to two opinions, which refer to the same target, are different, then there is a greater chance that the opinions are contradicting. For example if we consider the following two sentences and their corresponding opinion tuples:  Jenny thinks that bicycles are an excellent means of transportation in large cities.

(h: Jenny, e: bicycles, sw: excellent, so: 0.9)  Jenny thinks that bicycles are a good means of transportation in large cities.

(h: Jenny, e: bicycles, sw: good, so: 0.3)  For the above pair of opinion tuples and a threshold of 0.6, the system will detect a contradiction. This is not accurate, because considering a bicycle to be ?good? is included in considering a bicycle to be ?excellent?, so it is just a partial reconfirmation of the same statement. Considering the same threshold of 0.6 and this pair:  (h: Jenny, e: bicycles, sw: good, so: 0.3)  (h: Jenny, e: bicycles, sw: bad, so: -0.3)  the system will detect a contradiction, but this time it will be correct. A threshold of value 1 would help to eliminate the possibility of these errors to occur as no pairs of sentiment orientations with the same sign will be marked as contradictions. The opinions which have a sentiment orientation close to zero are considered neutral or objective and should not be taken in consideration when searching for contradictions as they may result in false positive contradictions. An example of such a neutral opinion would be:  Jenny realized that bicycles have two wheels.

(h: Jenny, e:bycicles, a: -, so: 0.0, sw: realized )  By choosing a threshold value of 1, we reduce the chance to obtain false positives determined by the neutral opinions, because even if an opinion is considered fully positive ? with a sentiment orientation of 1 ? a contradiction will be detected an opinion is found to have a sentiment orientation smaller than 0.

Fig 2. Contradiction detection flow     The strength of a contradiction, which refers to the level of certainty that two opinions contradict each other, can be controlled by the value of the threshold. A higher threshold, such as 1, will provide fewer, stronger contradictions and will possibly omit more subtle contradictions, while a lower threshold such as 0.6 will detect the subtle contradictions but might also introduce some false positives.

To improve the recall, we can also match the target of the input opinion against the target expansions sets Ti of the opinions in the repository. For each match, one would need to modify the sentiment orientation of the opinion oi from  the repository by the distance dik corresponding to the target expansion tik before subtracting from the input opinion sentiment orientation and comparing to the threshold.

? | so  - (soi  - dik)  | > thresh? ?	??   The pseudocode for the contradiction detection operation is described in Fig. 3, through the procedure CONTRADICTION- DETECTION(O, n).

The input set O represents the set of new opinions mined from the new document. At lines 6, the RETRIEVE- CANDIDATES(h,t) procedure receives as arguments the holder and target of each new opinion. The function retrieves existing opinion tuples stored in the repository that have the same holder h and the same target t to form the set Candidates of opinions candidate for contradiction. To further increase the search space for candidate opinions, existing opinions having the same holder and do not have the same target t, but have t in the set T of target expansions, are also added to the Candidates set. The DISTANCE-TEST is applied on all the pairs formed between the new opinion and each opinion from the Candidates set to discriminate between the candidates which are actually contractions and those that are not. This function can use either one of the tests presented in equations (4) and (5).

The opinions from the repository for which the sentiment orientation is larger than sentiment orientations of opinions from new documents by the threshold thresh will the form the Contradictions set of possible contradictions.

? Contradictions = [ck1, ck2,..., ckn ]? ? ??    Thus, for each input opinion ok of the set O and its corresponding Contradictions set, a set of pairs of the form [ [ ok, ck1], [ ok, ck2],?,[ ok, ckn] ] is created. This set of pairs can be viewed as a graph, where opinions represent vertices and each pair represents a ?suspected contradiction? edge?.



IV. METHODS AND EXPERIMENTS  A. Experimental setup description  Our solution for modeling the repository consists of a distributed NoSQL database and a separate indexing server.

We chose a NoSQL database over an SQL relational database due to the fact that NoSQL databases do not suffer from the performance penalty induced by joins when dealing with large volumes of data. Due to the distributed architecture and storage model, NoSQL databases provide the possibility to scale horizontally. This means that an increasing volume of data can be easily handled by simply adding more data nodes, compared with relational databases, which require better hardware and are much harder to scale.

We have used HBase, a distributed column oriented database for storing all the data in the system. This includes all the opinion tuples, all the documents from which the opinions were extracted and the contradiction graph.

To increase the performance we stored the opinions in a separate index. We have chosen Apache Solr for implementing the opinion index. Our implementation allows the distribution of the index over a larger number of machines. The index is split in a number of logical partitions, also called shards.

Distributing the index allows us to gracefully scale the retrieval time when the number of total opinions in the system is increased.

To prevent the index from becoming too big to affect the search times, we have decided to limit indexing to opinions.

This is mainly due to the fact that it is desirable to keep as much of the documents indexed in the computer main memory and avoid the penalty of disk input/output operations.  By only storing the fields of the tuple that are either used for querying or for the contradiction detection flow, we can decrease the space required for storing an opinion in the index and thus allow more opinions to be stored on the same space dimensions.

A complete list of the  tools we chose for the implementation are:  ? (1) Apache HBase. This distributed datastore provides high performance and scalability when dealing with very large data, billions of rows and millions of columns.

? (2) Hadoop File System (HDFS) is required for configuring HBase to run in a distributed fashion.

CONTRADICTION-DETECTION(O, n)  1. Contradictions = [];  2. for i = 1 to n  3.   s = SENTIMENT-ORIENTATION(O[i])  4.   h = HOLDER(O[i]);  5.   t = TARGET(O[i]);  6.   Candidates = RETRIEVE-CANDIDATES(h,t)  7.   for j = 1 to SIZE(Candidates)  8.    so=SENTIMENT-ORIENTATION(Candidates[j])  9.    if DISTANCE-TEST(so,s) then  10.      ADD(Contradictions, O[i], Candidates[j])  11.  Return Contradictions.

Fig 3. Pseudocode for Contradiction Detection     ? (3) Apache Zookeeper is an orchestration framework used for coordinating and maintaining the database cluster.

? (4) Apache Solr will be used as an external indexing server and will allow complex lookups on the data.

? (5) The SpringData project is used for accessing the HBase functionalities in the Java programming language.

? The communication with the Repository will be made through a REST API, which will create very little coupling between the repository and modules that will access it.

B. HBase Experiments  In order to perform these experiments, we implemented the  HBase database using two servers which have been deployed  in the cloud. These servers have the following specifications:  10 GB of HDD memory, 2 GB of RAM, a single CPU core,  Ubuntu Linux 12.04 OS and a fast network connection, which  provided a smooth communication between the servers.

The HBase implementation requires a Hadoop Distributed  File System (HDFS) to store the data files on and also an  instance of HBase. The HDFS has been configured as follows:  the first server has the responsibilities of a master as well as a  slave, while the second server had only slave responsibilities.

The HBase has been configured similarly with the first  server having master and slave responsibilities while the  second one is only a slave. The recommended settings suggest  that the master should have a server of its own and use the  whole server?s computing power to orchestrate the slaves, but we did not have the necessary hardware available at that  moment.

For these experiments the REST API has been deployed on  an Apache Tomcat server on a local PC with the following  specifications: 4 GB of RAM, two CPU cores, Windows 7 OS.

The experiments have been done by using a simple Java  console application, which acts as a REST client for the API  and calls a set of random queries on the API, which  communicates with the HBase cloud servers to return the  result.

One of the most important queries from the point of view  of retrieval time is finding all opinions that match a certain  holder and a certain target, because these opinions are the  candidates for possible contradictions, as contradicting  opinions must have the same holder and must refer to the  same target. The searching speed for certain records in HBase  is highly dependent on the design of the table structure. The  fastest search is done by matching the row key, which is the  unique identifier for a row in an HBase table and thus it is  most efficient to store data attributes for relevant searches. For  these experiments, the table containing the opinions has the  row key constructed from the name of the holder concatenated  with the target entity of the opinions stored in this row, which  gives us the ability to rapidly find the desired row using the  holder name. Each row contains the opinions from the holder  and referring to the entity, which are stored in the row key.

The opinions are stored as nested entities in each row on  columns, which means that each column represents an  opinion. After finding the right rows, we need to find the right  opinions, which means finding the right columns. The query is  finding all opinions by holder and target; by placing the holder  in the row key we have optimized the table for finding all  rows of a holder very fast and by using the column as the key  for each opinion and constructing it by concatenating the  opinion target with the generated id of the opinion we have  optimized the intra-row search to find the right target fast. In  order to obtain relevant results regarding the retrieval speed of  the HBase system a fairly large amount of data has been  generated randomly. As we had the intention to test the  opinion table, we needed to generate opinion tuples of the  form presented in section III. To do this we used three files  containing: names, nouns and sentiment words with their  orientation and randomly generated 200 000 opinion tuples  and for each of these a set of 10 expanded opinions by the  target expansions so that would result in a total of 2 000 000  stored opinions.

By running the query to find all opinions by holder and  target with randomly generated holder and target parameters  over this data, we have obtained an average retrieval time of  approximately 2 seconds with a maximum spike of 6.63  seconds. The average time is the most relevant result as it  shows what the user should expect when it comes to the  response time of such a request as finding contradictions. Two  seconds is a fairly good response time, but as we have the Solr  indexer as the primary query handler for most important  queries we will consider HBase as being the backup solution  for important queries, when and if Solr fails, and as being the  primary storage database, because of its scalability and its  reliability.

The scattered line in Fig. 5 shows the response time of the  REST API given the above mentioned generated queries,  which is plotted on the same values that have provided the  above test results. As 100 random queries were generated,  their number is placed on the horizontal axis, which represents  the order in which they have been generated.

Fig 4. Implementation architecture     C. Solr/Index Experiments  For evaluating the performance of the indexing mechanism, we have varied the number of partitions for the same index and have measured the performance of system response time for each case.

For the following index performance test, each shard was deployed on a machine having 1 CPU core, 2GB of RAM, 10GB SSD for disk storage and Linux 12.04 OS.  The orchestration was performed by a dedicated node which ran an instance of Apache Zookeeper.

We have generated the opinions by using a list of 150,000 holders, 2300 targets and 2,500 sentiment words. The sentiment words used were taken from the AFINN list of affectionate words. We generated 100 opinions for each holder.

For each of these opinions, a target and a sentiment word were chosen randomly from the word lists. For each opinion, we have also generated 10 targets and 10 sentiment words. We obtained around 5.1 GB of data, consisting of roughly 15,000,000 opinion tuples.

Fig. 6 shows the evolution of average contradiction detection response time by having the index partitioned in 1, 2 and 3 shards. The times depicted in Fig 6. represent the average over 1000 executions of the contradiction detection flow for a random input opinion. The blue column represents the average response time for a contradiction detection query when the index resides on a single machine and has a value of 261ms.

The red and orange column represent the average response time for an index partitioned into 2, respectively 3 shards. The response time for 2 shards is 192 ms, while the response time for 3 shards is 156 ms. We observe that the response time decreases by increasing the number of shards that host the index. However, it is of note that the improvement decreases with each new shard added.

We have tested the impact of the index cache to the overall response time of the system. For each query that receives a response, a certain number of the files returned will be stored in the index cache. For smaller indexes, all the response  documents could be stored in the cache. However, in the case of larger collections, where the response can have hundreds or even thousand results, it is possible that storing all returned documents in the cache will add too much locality information in the cache. We have tested for 2 different values of the maximum number of documents from the query result stored in the cache per query.  Fig. 7 presents a comparison between the average response times for 3 different queries for the 2 different values of the maximum number of documents cached.

The index contained approximately 4,500,000 opinions generated from 150,000 holders and 30 opinions for holder.

The queries we have used to measure the performance are the most common ones for opinion search or contradiction detection.

These queries are:  (1) Retrieving all opinions which have the same holder. This query is represented by the leftmost two columns in Fig 7.

(2) Retrieve all opinion by holder and target. This query retrieves all opinion with a holder h and a target t and is represented by the two middle columns in Fig 7.

(3) Retrieve all opinions by holder, target and target expansions. This query retrieves all opinions with a holder h and a target t or which have t as a target expansions. This query is represented by the rightmost two columns line in Fig 7.

For the experiment we have used a single Solr Node and the SolrMeter benchmarking tool to create 60 queries per minute, each with variables chosen at random. We have performend the experiment  on an index where the maximum number of results stored in the cache for each query was 200 and then performed the experiment again on an index where the value for the maximum number of results sotred in cache is 2000. The blue color column represent the cases with 200 maximum results stored in cache for a query, while the red column represents the cases where the maximum number of documents cached was 2000. From these experimenst we learn that larger cache value offers better performance for the described dataset. This is due to the fact that the number of   Fig. 6 Evolution of index response time given the increase in indexing nodes  Fig 5. HBase scatter plot     maximum elements received on the response, and thus eligible for caching, is usually small, and therefore a larger number of queries can take use the cache directly for the results.



V. CONCLUSIONS  This paper presents an approach to perform  contradiction detection on very large opinion datasets. Our  approach addresses the challenge of real-time retrieval of  structured opinions against a given query in order to identify  the set of possible contradictory opinions. We employed an  architecture that consists in combining a sharded index with a  distributed NoSQL data store to provide both scalability and  performance.

We have presented the opinion model and main  procedure we have used for performing the contradiction  detection. We have evaluated our system and presented our  findings. The results we have obtained show that increasing  the number of partitions of the same index gives a  performance increase. We have also noted that query  configuration can affect the system response time.

