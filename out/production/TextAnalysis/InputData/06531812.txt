The Framework of Cloud Computing Platform for  Massive Remote Sensing Images

Abstract?In recent years, due to the rapid development of remote sensing technology, a single high-quality image will occupy larger storage space, and video has become so widespread in the usage of environmental observation and record. Hence, digital data is growing exponentially, and how to manage them and make image processing more effectively is a key issue in Geographic Information System. Additionally, the limitation of hardware resource and time-consuming images' processing is a bottleneck to cope with such big data by commercial software in single PC. The aim of this paper is to propose a framework based on some standards of the interface (WCS, WMS, and WPS) from Open Geospatial Consortium (OGC), cloud storage from HDFS, and image processing from MapReduce. Within this framework, we implement image management as well as simple WebGIS and test a read/write performance under four kinds of data sets (Normal Distribution, Skew to Left, Skew to Right, and Peak in Left and Right). The results reveal write/read performance of HDFS are outperform than the local file system in the situation of larger files (most files range in size from 8 MB to 10 MB) and a large number of threads (threads equal to 40 or 50).

Keywords-HDFS; MapReduce; Cloud Computing; Remote Sensing Images

I.  INTRODUCTION The meaning of ?remote sensing? refers to the activities  of recording, observing, and perceiving (sensing) objects or events remotely [1], [2].  We can achieve this task by Unmanned Aerial Vehicle (UAV) to gather large volumes of images, then a further step is to analyze and recognize.

Modern image processing technology helps scientists to extract meaningful regions from acquired images [3], [4], [5].

However, high resolution images will occupy more hard disk space, and images processing will cost more times; therefore, we need to have a well-designed platform to store remote sensing images and process images effectively in a distributed environment.

Recently, ?cloud? was discussed in many books [6], [7], [8], and we think ?cloud? is not just an adjective; it should be a real workable infrastructure. Under cloud environment, manager can have a large pool of easily usable and accessible virtualized resources, that is, hardware, development platforms and/or services. These resources can  be dynamically reconfigured to adjust to a variable load (scale), allowing also for an optimum resource utilization.

Further, resources are typically exploited by a pay-per-use model where guarantees are offered and followed by customized Service Level Agreements (SLA) by the resource provider. Monitoring of surface deformation, land cover classification, and change detection in tropical zones are examples for applications that rely on multi-temporal remote sensing images of urban areas [9], [10], [11]. To improve the computational performance of processing large amounts of real-time geodata and overcome the limited storage space, Cloud Computing provides appropriate tools [12], [13], [14], [15], [16].

The remainder of this paper was organized as following.

The source of remote sensing images was introduced in section II. Related works (remote sensing images processing in single machine and cloud computing environment) were discussed in section III. Then, we propose a suitable framework for remote sensing images processing in section

IV. Section V presents a prototype implementation of WebGIS embedded image post-processing presentation layer.

In section VI, we design four types of data sets to test write/read performance of local file system and HDFS.

Finally, the last part concludes this paper in section VII.



II. THE SOURCE OF REMOTE SENSING IMAGES To collect aerial images, GIS Research Center of Feng  Chia University developed Unmanned Aerial Vehicle (UAV) that integrates aerial engineering and electronics, wireless transmission, image post-processing, and GPS technique's coordination with OGC-SWE compatible software for comprehensive cross-platform environmental investigation.

Figure 1.  Unmanned Aerial Vehicle (named for AS-4) of GIS, FCU.

DOI 10.1109/AINA.2013.94     The appearance of our UAV (AS-4) is shown in Fig. 1, and related specification is in the following: maximum carried weight is 15 KGs; maximum altitude is 10,000 feet (about 3000m); it can fly one-hour with standard oil box; range is 30 KM radius; and the highest speed is 100 KM/h.

Figure 2.  Related modules of AS-4.

Since AS-4 is configured with the related modules given in Fig. 2, UAV can shoot high-resolution picture or HD movie with camera in sky, and we can control UAV by real- time monitoring software in Fig. 3 installed in the personal computer on the ground. Consequently, rescue workers can also plan a flight path and shoot information of the disaster area.

Figure 3.  Automatic flying system in ground control station.

Fig. 4 depicts the flight path of UAV (CP01-START POINT is the start of the shot) after the take-off point in Taichung City of Taiwan.

Figure 4.  The flight path of AS-4 in Taichung city of Taiwan.

After shooting multiple images, the subsequent images can be mosaicked into a large high-resolution image, so that the researchers can get the overall picture of the environment in the following Fig. 5. Meanwhile, system will keep metadata of each aerial photo (ex. *.jgw of *.jpg and *.tfw of *.tiff).

Figure 5.  Mosaicked aerial images photographed by AS-4.



III. RELATED WORK In this section, we studied and executed remote sensing  image processing in single machine and cloud computing environment.

A. Remote Sensing Images processing in single machine There are many unsupervised classification algorithms  [3], [9], which have been widely used in the classification of remote sensing image. Two of most frequently used algorithms are K-means [4], [12], [13] and ISODATA [16].

In this paper, the input of image processing is a color remote sensing image, a set of pixels each of which represented by RGB value. We apply the transformation of each pixel from [4]. They transfer each pixel from RGB-value to L*a*b*- value where L is a brightness layer and can be ignored, a* indicates where color falls along the red-green axis, and b* indicates where color falls along the blue-yellow axis  In this section, we demonstrate how to use these images in a single machine by real case. Firstly, a researcher can retrieve one image from the repository returned by AS-4 in Fig. 6. Then, this paper implements normal steps referred to [4] of processing clustering for one image as follows: 1. Read image form aerial image repository.

2. Image transformation (RGB?L*a*b*).

3. Extract a pair (a*, b*) of each pixel in above step and  keep them in an array.

4. Apply clustering algorithm (K-means is used here).

5. Label every pixel in the image using the results from  K-MEANS.

6. Clusters are done and rendered on a graphics layer.

In Fig. 6, 7, and 8, we illustrate the results of implementation of image processing by Matlab (read image using imread()).

Figure 6.  Original image photo (5184*3456) graphed by AS-4.

Figure 7.  The result of image transformation by  makecform('srgb2lab') of Matlab.

The Fig. 7 and Fig. 8 are implemented by Matlab 2011b (image transformation using makecform('srgb2lab') and clustering algorithm using kmeans method [20] ).

Figure 8.  The results of clustering by K-means method in Matlab.

Implementing this process requires some programming background and skill; therefore, researchers can also use commerical software to render the result visually by simple image loading and parameter's settings. Here, we quickly apply K-means (K=5) algorithm embedded in ENVI 4.7 illustrated in Fig. 9 in which the result of a real case shows that the parts of red and green is the trees and lawn, deep blue is the road; yellow is the playground; and light blue is buildings.

Figure 9.  Test Aerial Image Classification Results by K-means rendering  by ENVI 4.7 and K=5.

B. Remote Sensing Images processing in Cloud Computing Remote sensing (RS) image processing work can be done  by standalone software, ENVI, but the limitation of computing and storage resources and the tolerance of time consuming are two bottlenecks in processing a large amount of RS images [13]. Therefore, researchers have developed many kinds of variants of the algorithm executing in parallel, and most of them are implemented by using MPI. However, writing programs in MPI requires sophisticated skills.

Because of the convenience of cloud computing, the cloud lets you create and manage VMs and storage more cheaply, quickly, and efficiently.

Lv et al., [12] introduced the programming model MapReduce and a platform Hadoop. Wang, He, and Liu proposed a classification algorithm for high spatial resolution remote sensing data based on mapping mechanism [5].

Almeer [15] employed Hadoop MapReduce framework to implement parallel processing of remote sensing images and built an experimental 112-core high-performance cloud computing system in the Environmental Studies Center at the University of Qatar.

Besides the scholar?s effort in Hadoop MapReduce, there is MapReduce enabled clustering implementations in Apache Mahout [18]. It offers user to create scalable machine- learning algorithms included including k-Means, fuzzy k- Means, Canopy, Dirichlet, and Mean-Shift.



IV. PROPOSED FRAMEWORKS Cloud Computing = Internet = Computing on  the Internet shows a concept that computers can collaborate with each other, and services spread far and wide.

In remote sensing images repository, we have lots of high- resolution images called as big data, and related services will access these data by standard interface. We encountered some questions that how do we cope with these big data, and users/applications can use them in the following situations: 1.

Hardware expansion is not easy, 2. SW and HW are costly, 3.

Storage capacity is hard to expand, 4. Multiple-user access makes the poor efficiency result, 5. Ensure Reliability of data.

Therefore, based on these issues and requirements, this paper proposes a cloud computing framework that is suitable for remote sensing images. This framework consists of four major parts and is described as follows. A. User can upload and retrieve aerial images by UAV image Management; B.

WebGIS used to render aerial images and put a dynamic layer in any web page; C. Data Analysis and processing module is serious part of the framework to store and process images; and D. Cloud Computing Environment is a basic infrastructure. We implement part A and B in section V and test performance of part C and D in section VI.

Hadoop  WCS  WMS  WPS  Service Interface  Data Management  Unit  HDFS  MapReduce  Image Retrieval  Image Manager  User Interface  Metadata Unit  Image Analysis unit  Image Recognition  Image Classification  Applications (OpenLayers)  Users  Cloud Computing Portal Module  Data Analysis and Processing Module  Cloud Computing Environment  HDFS Adapter  MapServer   Figure 10.  Proposed Framework of Cloud Computing Platform.

A. UAV Images Management UAV Image Management is a system for users to upload  images and manage these images afterwards. This system includes image retrieval and image manager by the user interface. An image retrieval system is a web system for browsing, searching and retrieving images from the database of aerial images repository. Most traditional and common methods of image retrieval utilize some methods of adding metadata to the images so that retrieval can be performed over the annotation words. Manual image annotation is time- consuming, laborious and expensive; to address this, there has been a large amount of research done on automatic image annotation. By Image Manager, user can upload related images, and all uploaded images stored in the data warehouse.

B. WebGIS Service Interface WebGIS is an interface that can accept user?s parameters  setting and show the relevant map information that adds layer objects to your map by OpenLayers [19]. The presentation should communicate with the service interface by standard of OGC; that is, WCS, WMS, and WPS.

? OpenLayers ? Google Maps gives you a quick and easy way to add maps to your Web site, but when you're using Google's API, your ability to display other data is limited. If you have your own data you want to display, or data from sources other than Google, OpenLayers, an open source JavaScript library, can give you more options. OpenLayers works either with data you're serving yourself, using a package such as GeoServer or MapServer, or with data others are publishing via WMS.

? WCS ? The OGC Web Coverage Service (WCS) allows for the publication of ?coverages?- digital geospatial information representing space-varying phenomena.

? WMS ? A Web Map Service (WMS) is a standard protocol for serving georeferenced map images over the Internet that are generated by a map server using data from a GIS database.

? WPS ? The Web Processing Service (WPS) Interface Standard provides rules for standardizing how inputs and outputs (requests and responses) for geospatial processing services, such as polygon overlay. The standard also defines how a client can request the execution of a process, and how the output from the process is handled. It defines an interface that facilitates the publishing of geospatial processes and clients? discovery of and binding to those processes.

C. Data Analysis and processing module An image retrieval system is a computer system for  browsing, searching and retrieving images from a large database of digital images. MapServer [17] is a popular Open Source project which purpose is to display dynamic spatial maps over the Internet. HDFS adapter we proposed holds a feature to mount HDFS as a file system. Image Classification utilizes Mahout [18] to process image clustering.

D. Cloud Computing Environment Under cloud computing environment, we clustered 2-  dimensional points that are the values of a* and b* discussed above and applied KMeansDriver of Mahout to image classification module in Fig. 10 and computed similarity by EuclideanDistanceMeasure. For more details, refer to the book of Mahout by Owen, Anil, Dunning, and Friedman [18].



V. IMPLEMENTATION By uploading images to the data warehouse in HDFS.

Researchers can query images by year, country, town, and village to obtain query results. Then these images can be fully or partially downloaded as a zip file in the following prototype. Furthermore, image processing module executed in back-end and this module integrates with MapServer [17], through the front-end of the display interface, showing layers of overlapping effects in part B of this section.

A. User Interface Metadata is used to present "data about image" here (it  records images by year, location, and description), and user can retrieve related images from metadata by user interface and double click ?Submit? button in Fig. 11, then the result of query is shown in the right side where the Open function is to list the thumbnail of images photographed at the same time and places.

Figure 11.  Implementation of Part A in Fig. 10.

Fig. 12 summarized the results of querying data from warehouse of UAV in the cloud computing environment in GIS Research Center of Feng Chia University. These photos were taken in Fengshan Village, Alishan Town, Chiayi County, Taiwan after Typhoon Morakot in 2009-08- 17. Researchers can download these images as a zip file.

Figure 12.  Query results of UAV photographed in Alishan area of Taiwan.

B. Presentation of MapServer by OpenLayers To have a better understanding of images processing  results in aerial images, we build a simple user interface by OpenLayers [19]. Original image is shown in Fig. 13(a), and overlapping layers presents the result of combining the original layer and clustering layer (70% transparency) in Fig.

13(b).

(a) Disable checkbox of ?Clustering Results? in original image layer   (b) Enable checkbox of ?Clustering Results? to combine two layers  (original image layer and clustering result layer) Figure 13.  Implementation of Part B in Fig. 10 by OpenLayers [19].



VI. EXPERIMENTATION There were 2 difficulties confronted during the  experiment. The first is the storage of large number of aerial image, and second is image processing. In this section, we just test the performance of storing and accessing image files in local file system and HDFS (replication = 1). We simulated four types of datasets (100 files included in each dataset) depicted in Fig. 14: (a) Normal Distribution with average of around 5MB and a standard deviation of around 1MB in dataset 1; (b) Skew to Left with eighty percent of 1- 3MB; (c) Skew to Right with eighty percent of 8-10MB; and (d) Peak in Left and Right with forty percent of 1-3MB and forty percent of 8-10MB. And we also simulated the number of threads (10, 20, 30, 40, and 50) to test concurrent users in writing and reading performance.

Our cluster environment includes one NameNode and four DataNode, and each node equipped with 8 ? 2.53 GHz CPU, 4 GB RAM, 1 TB disk space.

In Fig. 15 and Fig. 16, the results revealed that read/write performance in four kinds of data sets. Compare HDFS with local file system performance, the HDFS writing performance is lower than the local file system in  Fig. 15(a) and Fig. 15(b), and  the HDFS reading performance is lower than the local file system in  Fig. 16(a) and Fig. 16(b).

These results delivered that local file system outperforms than HDFS in Normal Distribution and Skew to Left.

However, it is noteworthy that write/read performance of HDFS increases as concurrent users increase. Overall, the results have been very positive; that is, HDFS can serve more threads and have better performance than the file system in data set (8-10 MB). Fortgeschrittene indicated HDFS writing performance scales well on both small and data set in Hadoop Performance Evaluation [21]. Our experiments also confirm this trend, especially in the threads more than 40. The write/read performance of HDFS is better than the local file system in the situation of larger files (most files range in size from 8 MB to 10 MB) and a large number of threads (threads equals to 40 or 50).

(a) Data Set 1: Normal Distribution   (b) Data Set 2: Skew to Left   (c) Data Set 3: Skew to Right   (d) Data Set 4: Peak in Left and Right  Figure 14.  Distribution of different data sets.



VII. CONCLUSIONS AND FUTURE WORK Based on the remote sensing images from UAV by GIS  of FCU, we proposed a cloud-based framework for massive remote sensing image storage and process. We have also demonstrated how to process real sensing image by Matlab and ENVI in a single machine and by Mahout in a cloud computing environment. This framework also implements image management by communicating with metadata unit and data management unit; furthermore, prototype WebGIS can accept user?s parameters setting and show the relevant map information of MapServer included clustering result by OpenLayers. Finally, we utilize four types of data distribution and simulate concurrent users by threads to test  massive image files in writing and reading performance in local file system and Hadoop HDFS.

