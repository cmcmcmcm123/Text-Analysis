An Improved Hebbian Neural Network with  Dynamic Neuronal Life and Relations

Abstract- In the last years, artificial intelligence has been an  important field as the environments in which human-made devices have to operate become more and more complex, and designing a new algorithm for each environment can be very time and resources consuming. Neural networks have been successful in a lot of applications, since the same basic implementation can be used in a virtually unlimited number of situations, by modifying the structure of the network and the tests that are used for constructing it. In this paper we present an improved hebbian neural network that has the capability of adding new neurons to it and can connect neurons using an association rule. Since the main problem in neural network design is the actual construction of the inter-neuronal relations, we try to solve this issue at least partially by allowing the network to modify itself depending on its response to different stimuli.



I. INTRODUCTION  In complex and highly dynamic environments, controlled by a large number of state variables, normal human-designed algorithms are usually either ineffective, or very hard and time-consuming to build. Artificial intelligence tries to overpass these difficulties by creating computer-based structures and algorithms that imitate at a small level some aspects of the human behavior. Neural networks are a special type of structures that try to imitate the human brain in order to create a structure that is self-built (under the control of a feedback algorithm) in the environment where it is supposed to run. After it has been built, it remains unmodified and is used as is.

The process of designing the structure of the neural network and of building it with the optimal environment conditions is more of an art than a science, since the number of possible environments is theoretically infinite, and the possible state variables might occur with different frequencies in the environment. However, neural networks have been used successfully in performing several simple tasks.

In the rest of the paper, we will define the problem (what the Hebbian theory is), we will describe our modifications and implementation for a more advanced Hebbian Neural  Network, then we will describe some experimental results we have obtained using our method, and some final conclusions.



II. PROBLEM DEFINITION  The Hebbian theory describes a mechanism by which the repeated and persistent stimulation of the postsynaptic cell results in an increase in synaptic efficacy. This theory was introduced by Donald Hebb, therefore the theory took his name (the Hebbian theory). Other names for this theory are also: Hebb?s rule, Hebb?s postulate and cell assembly theory.

This theory says the following:  We assume the following situation takes place: an axon of cell X is near enough to excite another cell Y and it fires it in a persistent and repeated way. In this case, a metabolic change or growth change takes place in either one or both cells. The efficiency of cell X is consequently increased [1].

This theory could be summarized as cells that fire together. This is somehow similar to the nervous system, as an oversimplification of it. This theory explains the process of associative learning. In this process, the simultaneous activation of cells leads to produce increases in synaptic strength [2], also called Hebbian learning.

Since the rules of hebbian learning are simple, they can be easily encoded in a computer neural network, in a very easy weight-selection program. However, because of this simplicity, hebbian neural networks (HNN) can be used in a limited range of applications [3].



III. OUR MODIFICATIONS AND IMPLEMENTATION  The purpose of this paper is to create a more advanced HNN that uses the advantages of this kind of association learning, but also adds some complexity to the neural interactions, allowing these networks to be used in a wider range of applications [7]. We are also trying to build a more dynamic network, that adds new neurons and new connections to itself. While this capacity does not bring many significant improvements, it is interesting to observe the     transformations that appear in the network, to be able to further improve this self-transformation.

The changes appear in several parts of the network design.

First of all, an arbiter is used to offer feedback to the  network, depending on its output (see Fig. 1). This arbiter is only active during initial training and, depending on the inputs, the outputs of the HNN and the optimal outputs, the arbiter returns a real number in the [-1; 1] interval. From now on, we will call this number alpha. The function used to determine this feedback number is built such as a maximum value -1 is returned when the highest one-space distance appears between the two output values: the one returned by the HNN, and the optimal one. A value of 1 is returned when the two outputs are equal, and a 0 when the HNN?s output is neutral (neither bad, nor good). Tests with different feedbacks have been performed, by using non-linear functions that were stricter or more relaxed, but in average, the linear function worked without any problems.

Depending on the feedback from the arbiter, the network updates its connections (change, creation, deletion) depending on the activation states of each neuron [6].

During the execution of the network, each neuron has an activation value in the interval [0; 1] (neuron?s state). The threshold is set at 0.5: above this value the neuron is active, below it, it is inactive. The threshold is thus only used during the running of the HNN. The activation value however is going to be used when updating the weights of the connections.

Fig. 1. Schematic representation of the feedback circuit    The updating function is run for each pair of neurons that  are connected, and it depends on the feedback value, on the activation values of both neurons and on the learning speed (this can be used as a variable and be set higher when the current learning set has a higher priority) which is constant.

This function is also run when the HNN has produced a good output (alpha > goodOutputThreshold, where goodOutputThreshold is a constant set at 0.5 ? remember that alpha has a range of [-1; 1], with values for good outputs in [0; 1]) between pairs of unconnected neurons that have activated at the same time. The value returned by the function is multiplied with a probability constant, probNewConnection and the resulting number is used as the probability of creating a new connection between the two neurons. If a connection is added between the two neurons, its initial weight is set to the value returned by the updating function.

The inter-neuronal connections are deleted when they reach a critical lower value, killConnectionThreshold. This value has been set at 0.0012.

The updating function is given in the following algorithm:   TABLE I UPDATING FUNCTION  LINE OBSERVATIONS If (alpha > 0) Correct output If  (state1 > 0.5 OR state2 > 0.5) Return alpha * (state1-0.5) * (state2-0.5) * K Else Return -alpha * (state1-0.5) * (state2-0.5) * K Else Incorrect output If (state1 > 0.5 OR state2 > 0.5) Return alpha * (state1-0.5) * (state2-0.5) * K Else Return -alpha * (state1-0.5) * (state2-0.5) * K   Where:  - state1, state2 are the activation states of the neurons (values between 0 and 1 inclusive),  - K is a constant representing the learning speed.

Analyzing all of the cases, if the feedback is positive:  ? If both neurons activated, a positive value is returned, proportional with the value of the feedback, and the activation values of the neurons (state1, state2). Since the states are greater than 0.5 (as the neurons activated) the total product will be a positive value.

? If just one neuron activated, a negative value is returned, since one of the terms state1-0.5, state2-0.5 will be negative, and the other positive. Since the neurons activated differently, the strength of the connection must decrease.

? If neither neuron activated, a negative value is returned, reinforcing their behavior (non activation).

Likewise, if the feedback is negative (bad outputs):  ? If both the neurons activated, the strength of their connection is decreased (a negative number is returned).

? If just one of the neurons activated, a positive value is returned, reinforcing the communication between neurons with different activation states.

? If neither of the neurons activated, a positive value is returned.

On each run, depending on the number of the neurons, on the absolute value of the feedback and on a probability constant, a new neuron might be constructed, adding to it some weak connections to the most active (positive feedback) or most inactive neurons (negative feedback) [4] [8].

In the following algorithm, P(x) represents a probability function, where x is an expression whose value is between 0 and 100. P returns a Boolean value, which will be true in x out of 100 cases, and false in the other 100-x cases.

|x| represents the absolute value of x.

If ( P( |feedback| * probNewNeuron * networkSize ) ) addNewNeuron for ( each neuron in HNN ) if (  ( stateNeuron-0.5 ) * alpha >= 0 AND P( | stateNeuron-0.5 | * probNewConnection ) connectNeurons( current, new ) end if end for end if  The network is run as a normal neural network, and the input and output neurons cannot be killed. They are connected to the external world, so they cannot be changed. A visual representation of this aspect is shown below, with the input/output neurons fixed, and the internal neurons and inner-connections dynamic.

Fig. 2. The input and output neurons are fixed and can?t be removed. The rest  of the network is dynamic

IV. EXPERIMENTAL RESULTS  A number of tests have been designed for testing the functionality of the network and several networks with different initial structures and numbers of neurons were used for each test. The tests and their results are presented below:  1. The networks had to compute the function XOR between three input variables. The output was given on four output neurons: the XOR between the three pairs formed by the input variables, and the total XOR. The reason for using four outputs instead of just one was to allow the arbiter to return a wider range of numbers, instead of just +/-1. The weights of the output neurons were: +/- 0.5 for the total XOR, and +/- 0.1(6) for the other three outputs and the sum of these weights gives the feedback from the arbiter. 10 different initial networks were used, with the first two being built with a hierarchical structure- after a structure was set for computing the XOR between two variables it was repeated for computing the intermediary XORs, and the final one.

After different runs of the networks, 6 out of 10 (including the two networks with the pre-designed structure) produced the correct results, and the other 4 had a correctness average of 74%.

2. Another set of tests was designed using randomly-built polynoms of the 3rd degree, with the coefficients being selected to be smaller than 15. For each polynom, 30 neural networks with 15 hidden (neither input, nor internal) neurons were built with random connections between the neurons. The inputs and outputs of the network were encoded in binary code. The total number of input and output neurons was selected such that, if the largest value of the polynom (with X in the [1; 30] interval) was N, log(N)+1 output neurons were present. The same principle was used for the input (since the largest input value was 30, 5 input neurons were present). The arbiter returned after each run a feedback value that depended linearly on the response of the network, the value of the polynom for the current X, and the maximum distance in the direction of the neuron?s output of the polynom in the [1; 30] interval. For example, for an output of 12 from the network, a correct value of 6, and a maximum value of 34, the arbiter returned the value 8/14: a 1 would be returned for 6, -1 for 34.

Drawing a line in the XoY plane between these points, the intersection with X=12 would be at 8/14. After multiple runs, an average correctness of 68% was obtained for this test.

3. The third and final test was a practical implementation of the neural network on a simple line-following robot that received information from two light sensors, each encoded on 8 bits. The output of the network was encoded on 6+6 bits, each representing the speed of the engine from the respective side (with stop at 0 and maximum speed at 63). After developing a program for this line-following robot, its output was used by the arbiter to compute the feedback value. This feedback value depended on angle difference between the two directions (the one chosen by the robot?s program, and the one suggested by the neural network). The robot was controlled only by its program during the building of the network. After the end of the building period, the control was given to the neural network. Different tests were made on this robot, with different reduction values for the two engines, to control the maximum speed of the robot mechanically. At slow and medium speeds, the network was able to keep the robot on the track, but at higher speeds, after 6-7 seconds, it got off tracks. Another test was made, when the arbiter     remained active during the period when the network was controlling the robot. No significant improvement was observed in the behavior of the robot.



V. CONCLUSIONS  Our neural network is an improved version by allowing the possibility to add new neurons to it. Also, our network can connect neurons using an association rule.

Another advantage is the fact that we allow our network to modify itself depending on its response to different stimuli.

This solves a problem in neural network design, more exactly the construction of the inter-neuronal relations.

This type of network can further be improved by adding a sub graph based analysis of the neuronal connections, and updating the weights depending on the activity in each sub graph. In choosing these sub graphs, a good technique could be to select the dense sub graphs that are isolated from the rest of the network (working separately), and by using a more advanced arbiter, a feedback could be generated for the respective sub graph.

Another improvement can be the inclusion of genetic algorithms in the building of the networks. The genetic algorithm will be used to modify the different parameters that appear in the network self-construction (the probabilities for creating new neurons, new connections etc.), or to change the function of the arbiter for each network, thus controlling the curve of the positive-negative response to a non-linear one.

