A Novel Fuzzy Positive and Negative Association Rules Algorithm

Abstract?According to the existing mining algorithm of fuzzy association rules, a novel fuzzy positive and negative association rules algorithm will be proposed in this paper. We focus on the membership function of fuzzy set and minimum support parameters of positive and negative association rules and adopt a method that selects parameters automatically which is based on the k-means clustering. Besides, multi-level fuzzy support and correlation coefficient are chosen to restrain the quantity and quality of rules generated by the algorithm.

Finally the validity and accuracy of the algorithm are proved by an experiment.

Keywords- data mining; fuzzy association rules; membership function; multi-level fuzzy support; correlation coefficient

I. INTRODUCTION Association rules mining, which aims to discover  relevant valuable knowledge describing interrelation between data items from huge numbers of data, is a extremely important research subject of data mining domain.  Since it was first proposed in 1993 by Rakesh Agrawal etc[1], association rules extraction has received widespread concern and in-depth research both in algorithms and efficiency[2-3]. For numeric databases, quantitative association rules mining [4-5] is a significant branch. Since the fuzzy association rules mining technology was put forward combined with fuzzy set theory [6], this field has got more and more attention. However, the selection of membership functions, a key issue of the fuzzy association rules mining technology, gets little research. In most cases, the methods developed by experts are adopted by making use of a priori knowledge, but there is a certain blindness, which will cause an influence on the accuracy and efficiency of the final rules extraction. In addition, most studies focus on the extraction of positive association rules such as X ? Y no matter in the traditional Boolean association rules mining or quantitative association rules mining and many mature algorithms come into being.

Negative association rules in the form of X??Y, ?X?Y or ?X??Y have been received widespread concern[7-8], but such issues as the parameter selection of support degree etc.

call for further study. Negative association rules stand for a negative correlation knowledge of things and they also plays a very important role compared with the positive association rules.

According to current research status, a new fuzzy positive and negative association rules mining algorithm is proposed, which determines the membership functions  based on k-means clustering method. And its advantage lies in discovering the cluster center of data set guidelessly in the absence of sufficient prior knowledge, thereby identifying the membership functions reasonably and avoiding wrong mining results caused by false parameter selection of the membership functions. Meanwhile, it adopts the multiple fuzzy supports in the fuzzy association rules for the first time and introduces the correlation coefficient criterion, controlling the quality of rules effectively and ensuring the accuracy and efficiency of algorithms.

The remainder of this paper is organized as follows: An introduction of positive and negative association rules and multiple support degree theories are given in Section 2. In Section 3, the fuzzy association rules and the selection of membership functions are introduced. In Section 4, the new fuzzy positive and negative association rules mining algorithm is presented. After that, Section 5 introduces an experimental simulation of the proposed algorithm. Finally, some conclusions are drawn in Section 6.



II. MULTI-SUPPORT POSITIVE AND NEGATIVE ASSOCIATION RULES  Suppose that I={i1, i2,?, im} is a set of binary attributes, and T={t1,t2,?,tn} is a set of n data records, where ti ? I, namely, each record in T can be viewed as a subset of I. The association rule (AR) is the logical implication of such form as X?Y, where X ? I, Y ? I, and X?Y=?. When the support degree and the confidence degree of the rule are greater than a given minimum support and minimum confidence threshold separately, then it is considered as a correct one. And its support degree is supp(X ? Y)=|TX?Y|/|T|, while the confidence degree is conf(X? Y)=|TX?Y|/|TX|, where |TX| represents the count of transactions containing X in T. When a considered thing does not happen, that is to say, ?X shows that itemset X does not occur, bringing about such negative rules as X? ?Y, ?X ? Y and ?X ? ?Y. The support degree and confidence degree can be counted by the corresponding positive item sets:  s(?X)=1-s(X); s(X??Y)=s(X)-s(X?Y); s(?X?Y)=s(Y)-s(X?Y); s(?X??Y)=1-s(X)-s(Y)+s(X?Y); c(X??Y)=1?c(X?Y);  2010 Ninth International Symposium on Distributed Computing and Applications to Business, Engineering and Science  Unrecognized Copyright Information DOI 10.1109/DCABES.2010.163     c(?X?Y)= s(X)-1  Y)()( ?? XsYs ;  c(?X??Y)= )(1  )()()(1 Xs  YXsYsXs ?  ?+?? =1-c(?X?Y)  In fact, negative association rules exist not only in infrequent itemSets (inFS), but also exists in the frequent itemSets (FS), so negative rules need to be mined in inFS, while in FS, both positive and negative rules need to be mined. In theory, inFS can be regarded as a complement of FS, but, in practice use, it is often very large, generating plenty of negative rules, which are not all meaningful. The size of inFS can be restraint by 2-level Supports[9] and multiple level minimum supports(MLMS)[10], in which the later establishes different minimum supports for those candidate itemsets which have different lengths, ms(1)?ms(2)?...?ms(n)?ms>0, where ms represents the threshold of inFrequent itemSets and ms( k) stands for the minimum support of frequent K-itemsets. If s(X)?ms(k) then X is a frequent itemset. But if s(X)<ms(k) and s(X)>ms, then X is an inFrequent itemset. This model MLMS can control the number of the frequent and inFrequent itemSets by establishing different m(k).

The correlation between the preceding paragraph X and consequent paragraph Y of association rules can be  measured as follows: )()( )(  , YsXs YXscorr yx  ?= . If corrx,y>1, then  X and Y are positively correlated, that is, the occurrence of X will promote the occurrence of Y. But if corrx,y=1, then X and Y are independent, that is, the occurrence of X and Y has nothing to do with each other. If corrx,y<1, then X and Y are negatively correlated, that is, the occurrence of X conflicts with the occurrence of Y. The correlation between negative itemsets can be counted by corresponding positive itemsets.

When corrx,y>1, )( YXs ? > )()( YsXs , so )()()()()( YsXsYsYXsYs ?<?? ,  while )()()( YXsYXsYs ??=?? , )()()](1)[()()()( XsYsXsYsYsXsYs ?=?=? ?  hence, )()()( YXsYsXs ??>? ?  thus,  )()( )(  , <? ??=  YsXs YXscorr yx  , And in the same way, we can infer that corrx,?y<1,  corr?x,?y>1.

When corrx,y>1, Certainly, the greater corrx,y, the stronger  the positive correlation between X and Y. While when corrx,y<1, the closer corrx,y comes to zero, the stronger the negative correlation between X and Y.



III. FUZZY ASSOCIATION RULES When datasets containing continuous numeric attributes  emerge during association rules mining, the method  discretizing data is usually adopted. As to a specified continuous numeric attribute Q, it will be divided into p intervals, and then the new generated attributes Q1, Q2, ..., Qp are used to replace the original attribute Q. However, a simple division of continuous attributes into several intervals may lead to so-called "hard boundary" issues, such as the record "Those who are 31 years old age 31 spend 6 hours online per day? does not support the rule: Age[20,30]?Average daily online duration[5,10]. However, in fact there is little age difference between 31 and 30, in other words, such fuzzy association rules as "young adults are more likely to spend a long time online" seem more correct and more instructive [11-12].

For the continuous numeric dataset T=(t1, t2, ..., tn), and I=(i1, i2, ..., im), the set containing all the attributes of T, each continuous attribute ik has a corresponding fuzzy set  },...,,{ 21 liiii kkkk fffF = , where j  ik f  represents the j-th fuzzy  set. For example, the continuous attribute "income" has three fuzzy sets: high, middle and low, so it can be expressed as "F Income = {high, middle, low}".

The form ????? BYAX ,,  is a fuzzy association rule, which means that when attribute X is A, then it can inferred that attribute Y is B. Where X ? I and Y ? I are the sets of attributes, A and B are corresponding with the fuzzy sets of attributes which belong to X and Y respectively. The standards for valid fuzzy rules are the same as traditional Boolean rules. Namely, fuzzy support and fuzzy confidence of the fuzzy rules should be greater than the given thresholds of minimum fuzzy support and minimum fuzzy confidence respectively. However, the calculation of fuzzy support and fuzzy confidence is different from that of traditional Boolean rules. In the mining of traditional Boolean association rules and quantitative association rules, the transaction of a record either appears or not, and the degree of transaction support a property can be counted by the times which the attribute appears in all the transactions.

While in the mining of fuzzy association rules, fuzzy support can be counted by the membership of data items to each attribute, and described by the form of probability.

The support of ?? AX ,  is calculated as follow:  ||  ])}[({ , T  xt S  jiaXxTt AX  jji? ? ?? ?? =  ? ,  Where ti[xj] represents the value of the j-th attribute in the i-th record, ])[( jia xtj?  stands for such fuzzy support of ti[xj]  that attribute xj is equal to aj, and ? ? ])}[({ jiaXx xtjj ? represents the result which is multiplied by the  fuzzy support of each attribute xj. Here, T-mode TP(x,y)=x*y is adopted instead of other T-modes, such as TM(x,y)=min(x,y); TW(x,y)=max(x+y-1,0) etc, for the reason that operation ? not only considers the membership of all attributes, but also the convenient calculation of the algorithm  The fuzzy confidence of ????? BYAX ,,  is calculated as follows:     ? ? ? ?  ??  ??  ??  ?? ?????? == ])}[({  ])}[({  ,  , ,,,  jicXxTt  kicZzTt  AX  CZ BYAX zt  zt S S  C kji  kki  ? ?  ,  Where ?? CZ ,  is the frequent fuzzy item set, ZX ? , Y=Z-X, CA ? , B=C-A.

How to determine a Membership function (MF) of the sample data is a key issue of fuzzy association rules. So the determination of the parameters of MF is particularly important. This paper adopts the method based on k-means clustering, which identifies the cluster center of data sets by self-learning, and hence, determines the parameters of MF.

As to the data set T, first of all, cluster p continuous numeric attributes that need discretization into specified q clusters by k-means, and generate a p * q cluster center matrix C, where the j-th center point of the i-th attribute can be represented by Ci,j. Then, combine with MF of triangle to find out the fuzzy MF of each attribute. Attribute ik has q cluster centers described as },...,,{ ,2,1, qiii kkk CCC , the fuzzy set MF of which is shown as .Figure 1.

Cik,qCik,2 Cik,1 Fig.1  MF of ik determined by the clustering center  The ik attribute?s fuzzy set },...,,{ 21 qiiii kkkk fffF = , where  ,1  ,21 ,1 ,2  ,1 ,2 ,2 ,1  ,2      k  k  k k k  k k k k  k  k i  ik i i k i  i i i i  i k  i C  Ci f C i C  C C C C  C i  ? ? ? ?= + < ?? ? ?? ? <?  ;  ,1 ,1 ,2  ,2 ,1 ,1 ,2  ,32 ,2 ,3  ,2 ,3 ,3 ,2  ,3 ,1      0                                          or  k  k k  k k k k  k  k kk  k k k k  k k  ik i k i  i i i i  ik i k ii  i i i i  i k k i  Ci C i C  C C C C  Ci C i Cf  C C C C  C i i C  ? + ? ?? ? ??  ?? + < ?= ? ? ?? ? ?  < <??  ;  , 1  , 1 , 1 ,  , , 1 , 1 ,  ,      k  k  k k k  k k k k  k  i q k  i qq k i i q k i q  i q i q i q i q  k i q  C i  Ci f C i C  C C C C  i C  ?  ? ?  ? ?  ? ? ? ?= + < ?? ? ?? ? ??

IV. FUZZY POSITIVE AND NEGATIVE ASSOCIATION RULES ALGORITHM  This paper proposes a new mining fuzzy positive and negative association rules algorithm, which can be divided into two steps. Firstly, adopt k-means clustering algorithm to process continuous numeric attributes of data sets, and determine the MF of each attribute by cluster center points.

Secondly, convert original data set T into fuzzy data set T? according to the generated MFs. This step can be viewed as a pre-processing stage. The algorithm is shown as follows:  Input: original data set -T, the number of clusters -K Call k-means to cluster data set T, and get k  cluster centers {C1, C2,?,Ck}.

For each attribute Ai do  Determine Mi, the MF of attribute Ai, by {C1,C2,?,Ck}.

End for For each record ti?T  Make the record ti fuzzy by Mi End for  Output: fuzzy data set T? MS_FPNAR is adopted in the second step. Multi-level  Fuzzy support is used to generate Frequent Fuzzy itemSet and infrequent Fuzzy itemSet in the fuzzy data set T?. Then, fuzzy positive and negative association rules, which are greater than the minimum fuzzy confidence, are mined in frequent fuzzy itemsets and fuzzy negative association rules are mined in infrequent fuzzy itemsets combined with correlation coefficient corrx,y constraints. The algorithms for generating frequent fuzzy itemsets and infrequent fuzzy itemsets are shown as follows:  Input: fuzzy data set T?, Multi-level minimum Fuzzy Support mfs(k), Infrequent fuzzy itemset threshold mfs.

C1=a fuzzy itemset which has a support ? mfs FFS1= a fuzzy itemset which has a support  ? mfs(1) in C1 inFFS1=C1-FFS1; For (k=2;Ck-1!=NULL;k++)  Ck=apriori_gen(Ck-1, mfs); For each c?Ck  If c contains multiple fuzzy sets in the same attribute then delete c from Ck  Ct=subset(Ck,t); Calculate the support of each c?Ct  End for Ck= a fuzzy itemset which has a support ? ms  in Ct; FFSk=a fuzzy k itemset which has a  support ? mfs(k) in Ck; inFFSk=Ck-FFSk; add FFSk into FFS, and add inFFSk into inFFS  End for Output: frequent fuzzy itemset FFS, infrequent fuzzy  itemset inFFS     The algorithm which is mining fuzzy positive and negative association rules in FFS and inFFS as follows:  Input: frequent fuzzy sets - FFS, infrequent fuzzy sets - inFFS, minimum fuzzy confidence - mfc, minimum correlation information number- min_corr  For each fuzzy set ?? CZ ,  in FFS Calculate the correlation coefficient  of ???? BYAX ,, ? When X ? Y=Z, A ? B=C and X ? Y= ? , A ? B= ? ;  If the correlation coefficient of ???? BYAX ,, ? >min_coor  If the fuzzy confidence ),,( ????? BYAXc ? mfc then add ?? CZ ,  into FPAR  If the fuzzy confidence ),,( ??????? BYAXc ? mfc then add ?? CZ ,  into FNAR  If the correlation coefficient of ???? BYAX ,, ? <1/min_corr  If the fuzzy confidence ),,( ?????? BYAXc ? mfc then add ?? CZ ,  into FNAR  If the fuzzy confidence ),,( ?????? BYAXc ? mfc then add ?? CZ ,  into FNAR  End for For each fuzzy set ?? CZ ,  in inFFS  Calculate the correlation coefficient of ???? BYAX ,, ? When X ? Y=Z, A ? B=C and X ? Y= ? , A ? B= ? ;  If the correlation coefficient of ???? BYAX ,, ? >min_coor  If the fuzzy confidence ),,( ??????? BYAXc ? mfc then add ?? CZ ,  into FNAR  If the correlation coefficient of ???? BYAX ,, ? <1/min_corr  If the fuzzy confidence ),,( ?????? BYAXc ? mfc then add ?? CZ ,  into FNAR  If the fuzzy confidence ),,( ?????? BYAXc ? mfc then add ?? CZ ,  into FNAR  End for Output?fuzzy positive association rules -PAR, fuzzy  negative association rules -NAR

V. EXPERIMENTAL RESULTS A standard data set consisting of 150 samples, which  belongs to three different kinds of rocks separately and contains data with four oxide components, is used in the experiment. Moreover, each sample has a six-dimensional attribute, where the first one represents the sample number, and the second to the fifth one represents the content of SiO2, Al2O3, MgO, Fe2O3 respectively, while the sixth stands for the rock class number which the sample belongs to. Besides, the second to the fifth dimension attribute are continuous numeric variables. The boundary points of  which are decided by the domain experts based on the prior knowledge before the modeling of association rules mining.

However, due to the diversity, variability and complexity of the geological phenomena and conditions, there is plenty of uncertainty and imprecision. The inaccuracy in choosing boundaries may directly affect the quality of extracting rules.

According to the proposed algorithm, the second to fifth dimension of the original data set are firstly clustered with k-means, and discretized to two-dimensional fuzzy attribute: {high, low}. As a result, Two cluster center points are generated: center1={50.0566,33.6981,15.6038,2.9057}; center2={63.0103,28.8660,49.5876,16.9588}.

The membership functions of the content of SiO2, Al2O3, MgO, Fe2O3 are shown respectively as figure 2 to figure 5. According to these MFs, a new fuzzy sets T? will be generated if the value of each attribute of every sample in the original data set T is changed into a form of a fuzzy set.

63.0103 50.0566   SiO2  33.6981 28.8660   Al2O3   Fig.2 the MF of SiO2  Fig.3 the MF of Al2O3  49.5876 15.6038   MgO  16.9588 2.9057   Fe2O3   Fig.4 the MF of MgO  Fig.5 the MF of Fe2O3  In the following, a comparison will be done to T?, the generated fuzzy set, with traditional fuzzy association rules algorithm and   MS_FPNAR algorithm proposed in the paper respectively, the results of which are shown as figure 1 to figure 10 and table 6 to table 7, where the multi-level fuzzy support vector is expressed by mfs(k)=[mfs(1),mfs(2),mfs(3),mfs(4),mfs(5),mfs] and the minimum fuzzy confidence is expressed as mfc. The minimum correlation coefficient is stated as min_corr. The number of the fuzzy positive association rule is expressed in PAR. The number of the negative association rules is expressed in two different variables: NAR1 and NAR2. The difference between the variables is the expressions. NAR1 is expressed as ?????? BYAX ,, and ?????? BYAX ,, , while NAR2 is expressed as ??????? BYAX ,, .

Rules_num is stated as the total number of the positive and negative association rules.

Mine the fuzzy association rules by the traditional fuzzy association rules algorithm at first. Then set mfc = 0.6 and min_corr = 1.Use the uniform minimum mfs and set mfs equal to 0.3, 0.2, 0.16, 0.12, 0.10 and 0.08 respectively. It can be seen that, when mfs gets a larger value, as shown in Table 1, the number of the rules extracted from the frequent itemsets is limited. Take for example, while mfs(k) = 0.3, small amounts of frequent fuzzy two itemsets, three itemsets and four itemsets are generated. Some meaningful rules, especially some longer rules fail to be mined for their higher supports. However, in order to mine more long rules, turning more four itemsets and five itemsets into the frequent fuzzy itemsets to get smaller fuzzy supports, which turns out the other way. Take Table 6 for example, when mfs = 0.08, moderate frequent fuzzy five itemsets are generated, but amounts of frequent fuzzy two itemsets and three itemsets are extracted and the number of mined fuzzy rules which may contain lots of redundant and meaningless rules is multiple. The relation between the value of the mfs in traditional fuzzy association algorithm and the rule number of fuzzy association is shown in figure 6. Thus the uniform mfs used in the traditional algorithm has a great effect on the accuracy of the final rule mining if its value is either too big or small. How to find a more moderate fuzzy support threshold is a common problem.

To solve this problem effectively, a method based on multiple minimum fuzzy supports is adopted. Suppose mfs (k) = [0.3, 0.2, 0.16, 0.12, 0.1, 0.1]. As shown in table 7, each layer has the same rules as the corresponding layer from table 2 to table 5 when k=2,3,4,5 respectively. In this way, not only the large number of meaningless rules is avoided, but some meaningful rules also cannot be removed.

However, it doesn?t take into account the negative association rules generated in the infrequent itemsets. By comparison of table 7 and table 8, certain infrequent itemsets (inFFS), in which some meaningful negative rules could be generated, can be produced by setting the threshold of the infrequent fuzzy itemsets. But it does not mean that the lower the threshold, the better. Comparing table 8 with table 9, we can see that plenty of fuzzy negative rules, most of which are meaningless and redundant, will be generated when inFFS is the complement of FFS. It is clearly inadvisable.

TABLE I.  FPNAR WHEN MFS(K)=0.3  mfs(k)=[0.3,0.3,0.3,0.3,0.3,0.3];mfc=0.6;min_corr=1 FFS inFFS PAR NAR1 NAR2 Rules_num  k=2 14 0 25 0 25 50 k=3 9 0 43 0 46 89 k=4 1 0 9 0 10 19 k=5 0 0 0 0 0 0 Total 24 0 77 0 81 158  TABLE II.  FPNAR WHEN MFS(K)=0.2  mfs(k)=[0.2,0.2,0.2,0.2,0.2,0.2];mfc=0.6;min_corr=1 FFS inFFS PAR NAR1 NAR2 Rules_num  k=2 25 0 38 2 40 80 k=3 22 0 98 0 114 212 k=4 9 0 93 0 114 207  k=5 1 0 26 0 30 56 Total 57 0 255 2 298 555  TABLE III.  FPNAR WHEN MFS(K)=0.16  mfs(k)=[0.16,0.16,0.16,0.16,0.16,0.16];mfc=0.6;min_corr=1 FFS inFFS PAR NAR1 NAR2 Rules_num  k=2 26 0 38 4 40 82 k=3 26 0 106 0 127 233 k=4 11 0 104 0 135 239 k=5 2 0 40 0 55 95 Total 65 0 288 4 357 649  TABLE IV.  FPNAR WHEN MFS(K)=0.12  mfs(k)=[0.12,0.12,0.12,0.12,0.12,0.12];mfc=0.6;min_corr=1 FFS inFFS PAR NAR1 NAR2 Rules_num  k=2 30 0 38 20 40 98 k=3 29 0 112 7 133 252 k=4 15 0 122 4 167 293 k=5 2 0 40 0 55 95 Total 76 0 312 31 395 738  TABLE V.  FPNAR WHEN MFS(K)=0.1  mfs(k)=[0.1,0.1,0.1,0.1,0.1,0.1];mfc=0.6;min_corr=1 FFS inFFS PAR NAR1 NAR2 Rules_num  k=2 34 0 38 32 40 110 k=3 36 0 121 27 154 302 k=4 18 0 138 10 194 342 k=5 4 0 60 4 97 161 Total 92 0 357 73 485 915  TABLE VI.  FPNAR WHEN MFS(K)=0.08  mfs(k)=[0.08,0.08,0.08,0.08,0.08,0.08];mfc=0.6;min_corr=1 FFS inFFS PAR NAR1 NAR2 Rules_num  k=2 36 0 38 38 40 116 k=3 40 0 126 32 164 322 k=4 19 0 142 13 206 361 k=5 4 0 60 4 97 161 Total 99 0 366 87 507 960  TABLE VII.  FPNAR WHEN USE MULTI-LEVEL FUZZY SUPPORT  mfs(k)=[0.3,0.2,0.16,0.12,0.1,0.1];mfc=0.6;min_corr=1 FFS inFFS PAR NAR1 NAR2 Rules_num  k=2 25 0 38 2 40 80 k=3 26 0 106 0 127 233 k=4 15 0 122 4 167 293 k=5 4 0 60 4 97 161 Total 70 0 326 10 431 767  TABLE VIII.  FPNAR WHEN USE MS_FPNAR  mfs(k)=[0.3,0.2,0.16,0.12,0.1,0.08];mfc=0.6;min_corr=1 FFS inFFS PAR NAR1 NAR2 Rules_num  k=2 25 11 38 38 40 110 k=3 26 14 106 32 164 302 k=4 15 4 122 13 206 342 k=5 4 0 60 4 97 161 Total 70 29 326 97 507 930  TABLE IX.  FPNAR WHEN MFS=0  mfs(k)=[0.3,0.2,0.16,0.12,0.1,0];mfc=0.6;min_corr=1 FFS inFFS PAR NAR1 NAR2 Rules_num  k=2 25 23 38 78 40 156 k=3 26 77 106 378 235 719 k=4 15 92 122 819 564 1505 k=5 4 39 60 702 486 1248 Total 70 231 326 1977 1325 3628       Fu zz  y ru  le s  Fu zz  y ru  le s  mfs  Fu zz  y ru  le s  Fu zz  y ru  le s  mfs Fig.6  mfs and Fuzzy rules in Traditional algorithms  Table 10 and Figure 7 reflect the relationship between the minimum correlation coefficient (min_corr) and fuzzy positive and negative association rules (FPNAR) where the former is used to remove those frequent fuzzy itemsets of weak correlation. Table 10 presents the number of fuzzy positive and negative association rules, which are generated with min_corr varying from 1 to 2.8 under such pre- conditions as mfs = [0.3, 0.2, 0.16, 0.12, 0.1, 0.08] and mfc = 0.6.As can be seen from Figure 7, with the min_corr increasing, the number of fuzzy association rules attained shows an obvious decreasing trend, as the minimum correlation coefficient can eliminate the rules which are generated by frequent itemsets of weak correlation, leaving more meaningful rules. So, the minimum correlation coefficient can effectively remove those meaningless or less meaningful rules to ensure that the final mined fuzzy rules are meaningful.

TABLE X.  RELATIONSHIP BETWEEN MIN_CORR AND FPNAR  mfs(k)=[0.3,0.2,0.16,0.12,0.1,0.08];mfc=0.6 min_corr= 1.0 1.3 1.5 1.7 2.0 2.3 2.5 2.8 PAR 326 292 249 192 133 106 72 44  NAR 604 522 435 322 193 130 80 48 TotalRules 930 814 684 514 326 236 152 92   Fig.7  relationship between min_corr and FPNAR  According to the above analysis, the algorithm is adopted to mine rules from the rock sample data set. If correlation  coefficient constraints min_corr = 2, and multiple minimum fuzzy support mfs (k) = [0.3, 0.2, 0.16, 0.12, 0.1, 0.08], then 326 fuzzy rules, including 133 fuzzy positive rules and 193 fuzzy negative rules, are generated after mining. Compared with the traditional fuzzy association rules mining algorithm, this algorithm solves the problem about the selection of fuzzy support, and generates more accurate and effective fuzzy positive and negative association rules.



VI. CONCLUSION There are broad development space and prospects for the  mining fuzzy positive and negative association rules, however, there are still many drawbacks in the selection of the membership function and minimum support, and the accuracy of selected parameters directly affects the result of the final mining rules. This paper proposes a novel fuzzy positive and negative association rules algorithm for the first time, and utilize k-means clustering method to determine the membership function, avoiding uncertainty problems which may be brought about in current existed related algorithms that need to identify the membership function subjectively.

Meanwhile, the multi-level fuzzy support and the correlation coefficient criterion are introduced based on fuzzy positive and negative association rules. In the end, the proposed algorithm is proved to be more effective and accurate in comparison with the traditional algorithm through an experiment.

