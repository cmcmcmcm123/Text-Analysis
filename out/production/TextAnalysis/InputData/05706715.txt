Context Ontology Driven Relevant Search  Using Data Mining Techniques (CODT)

Abstract-The size of the publicly indexable World Wide Web (WWW) has probably surpassed 14.3 billion documents and as yet growth shows no sign of leveling off.

Search engines encounter the problem of ambiguity in  words; therefore, search engines use ontology to find pages with words that are syntactically different but  semantically similar. The knowledge provided by ontology is extremely useful in defining the structure and scope for  mining web content. Context-ontology is a shared vocabulary to share context information in a pervasive computing domain and include machine-interpretable definitions of basic concepts in the domain and relations  among them. This paper proposes an architecture for relevant searching of web documents using data mining techniques such as clustering and association rules. These techniques together with context and ontology extract potentially useful documents from the database. Also, an  algorithm has been devised which shows the working in  sequence of steps. Finally, the results are compared with the prevailing approaches and with the help of an example it has been seen that CODT is better in context of  relevancy.

Keywords: Ontology, Data Mining, Association rules mining, Context

I. INTRODUCTION  The World Wide Web today provides user's access to extremely large number of Web sites [12], many of which contain information of education and are of commercial values. Due to the dynamism of the web, it acts as a challenge for search engine in retrieving relevant documents. Search engines uses ontology to find pages with words that are syntactically different but semantically similar. Ontology's [8] are (Meta) data schemas, providing a controlled vocabulary of concepts, each with an explicitly defmed and machine process able semantics. By defming shared and common domain theories, ontology's help both people and machines to communicate concisely, supporting the exchange of semantics and not only syntax. Ontology is used for knowledge sharing and reuse. It has a significant role in the areas dealing with vast amounts of distributed and heterogeneous computer based information, such as World Wide Web, Intranet information systems, and electronic commerce.

Ontology building from data mining can be achieved in two phases. The data-mining phase is related to data   mining process including data mapped, rule formulator and extraction of knowledge. The ontology-building phase is related to the process of building the ontology from the extracted knowledge, which represents the output of the data mining. As the web becomes more pervasive considering the context [7] in the query matching process can improve the quality of the retrieved results. However, contextual information is highly interrelated and has many alternative representations that make it difficult to interpret and use. Again, the use of ontology's to specify the interrelations among context entities can ensure common, unambiguous representation of these entities.

By using contextual information, the quality of the returned URLs is enhanced. In context-ontology based Web mining, the instances of concepts and relationships in a given ontology, or using them to discover other useful knowledge based on contextual information are discovered. The returned results are relevant according to the needs of user and less non-relevant results are filtered off. Contextual information of the user is therefore an essential aspect to accomplish transparency in the searching process. Ontology [9] can take the simple form of taxonomy or as a vocabulary with standardized machine interpretable terminology supplemented with natural language defmitions.

Context ontology'S are divided into upper ontology and domain-specific ontology'S. The upper ontology is a high-level ontology, which captures general context knowledge about the physical world in pervasive computing environments. The domain-specific ontology'S are a collection of low-level ontology'S [10] which defme the details of general concepts and their properties in each sub domain. The aim of this paper is to outline the role and the usage of data mining techniques together with context and ontology for retrieving relevant documents from the database. The proposed architecture capture the semantics of the user's query and of the contextual information that is considered relevant in the matching process thereby improving the quality of returned results.

This paper is organized in the following way.

Section II discusses related work done in this domain.

Architecture of the proposed system is presented in  section III. Sequence of steps of the work and    Context Ontology Driven Relevant Search Using Data Mining Techniques (COOT) ? 35  performance analysis is discussed in Section IV and  Section V respectively. Finally Section VI comprise of  the conclusion

II. RELATED WORK  Clerkin [2] used concept clustering algorithm (COBWEB) to discover automatically and generate ontology. They argued that such an approach is highly appropriate to domains where no expert knowledge exists, and they propose how they might employ software agents to collaborate, in the place of human beings, on the construction of shared ontology's.

Wrobel[3] used different ways to build ontology's automatically, based on data mining outputs represented by rule sets or decision trees. They used the semantic web languages, RDF, RDF-S and DAML+OIL for defming ontology's. OntoKhoj [4] is a system developed by the University of Missouri. It crawls the Web searching for ontology's which it aggregates and classifies. Searching its index is performed using a keyword based search interface, which is similar to Swoogle. OntoKhoj differs from ONTO SEARCH and Swoogle in that it only allows searching of ontology's, not of other Semantic Web documents which reference ontology's. A semiautomatic ontology engineering environment called OntoEdit has been developed [5, 6].

The workbench supports ontology import, extraction, pruning, refinement, and evaluation. Merging existing semantic structures or defining mapping rules between these structures allows importing and reusing available ontology's.



III. ARCHITECTURE  Fig. 1: Proposed Architecture (CODT)  A proposed architecture for relevant searching of web documents using data mining techniques is shown in Figure 1. Ontology building from data mining can be achieved in two phases. The data-mining phase (passive phase) is related to data mining process including data  mapper, rule formulator and extraction of knowledge.

The ontology-building phase (active phase) is related to the process of building the ontology from the extracted knowledge, which represents the output of the data mining. Phases of CODT are discussed in following sub sections.

A .  Database  Database is the repository of raw data residing over WWW. Database contains web documents, multimedia files, images, web pages etc. Information in database is in unstructured form. This raw data acts as input to next phase for preprocessing.

B. Data Mapper  Data mapping is done to process raw data. Raw data is cleaned first. In this phase, stemming and stop listing of documents is done to remove commonly used words such as \it" and \can". Tables and its attributes are also specified by knowledge engineer as shown in Figure 2. Finally raw data is filtered and stored in their corresponding assigned tables.

,m? I t)? ? 9 1;1  n.m:  size datedaem d.lted noiic:atb1  ? type  DatejTine Datelfne Text  ---- -+-  tme d Ooc\m:rt Size ri Doa.rnent Trne of cbaJnert aem TIne of ImJnert ? T? Ii Dccuneri  Fig. 2: Specification of Attributes  C. Rule Formulator  In this phase data mining techniques are used for pattern discovery. In CODT combination of clustering and association rule mining is applied for clustering keywords based on their relationship. Context repository is referred for extracting semantics between objects. Also association rule mining is applied for fmding association between the keywords based on the context.

D. Knowledgebase  The result of rule formulator forms the knowledge base that consists of related keywords which act as an input to the next phase i.e. Ontology builder.

E. Ontology Builder  During the passive phase when the user fires his  query and by the time control reaches this phase it will  first of all check ontology repository whether the  ontology for the context of searched query is already  there or not. After it fmds it will check for the search  keyword, if present it won't do anything else it will     update the present ontology for the same. In worst case  if the ontology for the context is not present, ontology  builder will build it from the scratch.

F. Context Repository  It is a database of context information. In this all the keywords with their context are specified. It is a predefmed repository and the rule formulator extracts the context information from it. For example: If mouse is the search keyword, then all the context related to mouse i.e. animal, computers , mouse named "Mickey Mouse" in Disney World character can be extracted from context repository.

G. Query Generator  Search query generated by the user is fed to the query generator as shown in Figure 3, which converts the user query in to SQL query.

Enter SCRrch Q.\I?.tY I Mou.c (AJumol)  &0 Cancel  Fig. 3: Query to be Searched  The working has been shown with the help of following query:  Case 1: In case of existing search engines If conlext ? allO given then  Sel!ct byword from da?1bale Union  Select context from d.1tabale Union Selectke)word 'II' context flom databale  Result: G ke)word (d.1tabale) U G (OllIext (d.1tabale) U G b)wol'd 'II' context  (d.1tabale) l)MtpJlenwili .. dia.!!rWiIlI!"", (lD!!!!!IiN) Moos, ?bJr? mi:, ornooses) Iimm:os ? ? willi;" device by dete:ting two-ditonsi<mahrdiln .!alm ? is rupportingswfac,. P?i:aThJ, .moos, consists ri asmallc?',"M wrc ?? oftle""is lIlnIs, wih"" orno.

00t1ms.

2) MtpJi.wrw . ..oopeJia.ccllllTERli!munoose.liml AdevicethilDmo.the"""",lIrithocumrc.?",.dispJ.r"'.1.

3) MtpJlenwili .. dia.c!!lMModeli Rodell?' anC<derofl!W!l!la!s ablllDWl! ? JJdells,c"""'cised bylll<> IDllimJsl?? icccim intle uppo accdbver;"'which!lllSt b,lept sIcat by"","".

4)Mtp:llenwili .. dia.!!rWiIlI!"", A .... ,?bJr?mic,) ?? JJdelithatb,!!I1pto""ri_""?ofsmalllllO!ll!la!s.

5)Mtp:II,n:wl1IS."", .. ",lopedia 161$9m?oos, (JOdentllmU Moos, (rode!I) 1D...,.1IUIIe ?ral\)l small ...... rolt .... fus ofJJderis; large s..., .. of""olthe fus ?whichmi:tbeb",,,,lmmas"s.

6)MtpJ...,..f"lw!fbeliaJM!ooseJ .... , "'Hcms.b.1 Mic, .. 0JrreJIt? ",ailabJ. wih. wi.le variety,f mmb,. and typeJ or.ttcms. The mmb"riootlllls may be ""  (Apple's inf'anoos des?hlll<> (ol!.rPCmht .... (Unixmi:, aol ..... rPCmic,), 1)MtpJ""'.fvwm.<dxiJnst"Ie?,.!Unl  Def .. s ..... , b?or""""sthebinding if Men", "?'.BI"" ? tie .... , butlm ? .m".lfBln"" .!I) tie. any ooHon p""'" t .. s...,if.d limill.

Case 2: In case of COOT  If colltext II Illlo given tMII Select keyword 'II' context fl?m da?1bale  Rl\Iult: G keyword (dc1?1bale),11' G context (dc1?1bale)  1)l!!plknwiliiwdia.mLlROOeIl  Rodellia ? anctdmf l1Ill1II1iIs akl hDlI'!! is Dlelis,chlIld!riled oytwo OJ!liv:oJsl)-? incisors it the  upp!!llIdlJwer,ilNswhi:hlllJStoeiept shatby?.

2)li!plknwiliiwdia.mLIMouse  AlIllIlS!?lllllrni:e)?aDleritlat'oe?to[ll!cf_lOOS?ofsmillllllllllll!ls.

3)li!plkrearlalllSnmll!lII:\SklJedia 161:6m21Aoose (Dlent)1mnI  Moose (rodaI) OJllI1Dnmme ?r any smillmernleroftll!e filllilies of rodaIs; ? s??s of [II! ofthe filllilies  towhicltrni:e bebn;lI!&iS Ills.

H Query Processor  This is the last phase of COOT, it evaluates the result. Finally desired results are returned to the user.



IV. ALGORITHM  Query given by user s saved n database and then data mapper maps this query into appropriate cells. For example:- Initially a URL or any.gif ,.bmp etc. graphic image is there, then no need to create its ontology, directly query executes on the query processor from database. Otherwise stemming and stop listing is done on the query given by user and keywords are retrieved from the query. Then the rules are formed from these keywords using the context repository. For example if mouse is a keyword, then rules are formed with animal as well as computer. After formation of rules, inference is retrieved in knowledge base for all rules and then ontology builder checks whether the ontology exists for these keywords or not. If yes then changes are made and if no, then ontology is created and saved in ontology repository. After that SQL query is formed from the keywords as Select mouse 'II' animal from database; and query processor executes this query on database using its ontology repository.

Searchqueue ( ) is the queue sequence given by the user and it is mapped by the data mapper. Stem and stop (searchqueue ( ? is the function to remove stop listing and stemming.

Substr ( ) is a function to remove sub strings.

Associate (context, keyword) associates the  keyword with the context example Mouse can be associated with animal/ computers.

Cluster [ ] makes the cluster of keywords with context and inference ( ) is obtained from these clusters.

Ontology builder (keyword, context) builds the ontology for these keywords.

Query processor ( ) executes the query on database using the corresponding ontology repository.

Context Ontology Driven Relevant Search Using Data Mining Techniques (COOT) ? 37  CODT(search queue [ ]) {  Push (search queue [ ], database) Data mapper (search queue [ ]) {  if ( !URL and LOIF and LBMP ) {  } else  stem and stop (search queue [ ] ) ..... hile (search queue[ ] !='\O' or ' , ) {  x = substr (search queue [ ]): Push ( keyword[ ], x ):  }  dO\vuload ( search queue [ ], database):  while (keyword [ ] != NULL) {  for ( i=l to array size ( context repository 0 ) ) {  }  if ( keyword[j] = = context[ i] ) {  retrieve ( context [i] ); associate ( context[i] , keyword [j] );  for ( i=l to keyword[ ] != NULL) {  cluster ( context [i] ): } for ( i=l to cluster [ ] != NULL) {  Inference (cluster [i] ): }  for (i=l to keywordO!=null) {  {  }  Ontologybuilder (keyword[i], context[i])  if (exists ill ontology repository) update (ontology [ill; else  { ontologybuild (keyword [i], context [i]); push (y, ontology repository);  S=null: For (i=lto keyword[]!=null)  { S=S'II' keyword[i]; Query=Select S from database: }  Queryprocessor (quety, Ontology repository, database):  }  V, PERFORMANCE ANALYSIS  Extensive experiments have been conducted over 2 search engines like Google, Alta Vista and compared with the proposed approach and it has been assumed that the our approach results in best performance as compared to Google and Alta Vista [IS], This can be shown with the help of the following graph (Figure 4) drawn on the basis of Table I,  TABLE I: COMPARATIVE ANALYSIS  Performance Relevance Precision  0.8  0.7  Q) 0.6 ? 0.5 16 E 0.4 ? 03 Q) Il.

0.2  0.1   Se<Ydl Engines  Fig. 4: Performance Comparisons

VI. CONCLUSION  Ontology plays a vital role in ensuring the homogeneity of information through the sharing of semantics, This paper summarizes the use of context? ontology along with data mining technique for relevant searching of web documents. The architecture is mainly divided into two phases. The initial phase i.e. passive phase is related to data mining process including data mapper, rule formulator and extraction of knowledge.

The ontology-building phase is concerned with the process of building the ontology from the extracted knowledge. Finally, the SQL query is matched with the context and ontology repository and useful documents are returned. The algorithm has also been proposed and with the help of an example it is clear that this approach clearly outperforms the existing approaches. Since CODT is making use of contextual information, therefore only relevant documents are returned and irrelevant documents are filtered off.

