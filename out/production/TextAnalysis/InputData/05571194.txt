An Improved Method of Outlier Detection based on Frequent Pattern

Abstract?Outlier detection is an interesting data mining task, which detects rare events. This paper focuses on the method of outlier detection based on frequent pattern (FP method for short). First we analyze the drawback of this method, and then an improved method (LFP method for short) has been presented. Finally, we evaluate the two methods by using several datasets and the experiment results show that LFP method outperforms FP method.

Keywords- data mining; association rules; frequent pattern; outlier detection

I.  INTRODUCTION Data mining is the process of extracting interesting  patterns from large amounts of data [1]. Outlier detection and analysis is an interesting data mining task, which detects rare events, deviant objects, and exceptions. It has been widely used in many practices, such as fraud detection, marketing analysis, medical analysis and network intrusion. In the field of data mining, there are many useful methods of outlier detection [3-6]. They are useful techniques on outlier detection available for numerical data. However, they perform not well in discrete data or transaction data. This paper proposes a method especially for dicovering outliers in discrete datasets, which performs well in transaction datasets and is efficent and easy to implement.

In this paper, we focus on the method of outlier detection based on frequent patterns (FP method for short). First we describe the core algorithm and analyze the drawback of this method, and then we propose an improved method (LFP method for short) and also present its algorithm. Finally, we evaluate the two methods by using several datasets and the experiment results show that the LFP method outperforms the FP method.

This paper mainly makes the following contributions: a) Summarize the FPOF measure and the FP  algorithm for outlier detection. Zengyou He et al. propose this outlier detection method based on frequent patterns in [8], we name it FP method for convenience.

b) Analyze the drawback of FP method. FP method has duplicate computing problem so that it couldnot detect outliers precisely.

c) Propose an improving method, LFP method. In this method we define a new outlier measure LFPOF, and we offer a new algorithm to detect outliers.

d) The proposed LFP algorithm is easy to implement and efficent in time complexity.

e) Experimental evaluation. We evaluate the two methods by using several datasets which are real world dataset and the experiment results show that LFP method outperforms FP method.



II. FREQUENT PATTERN BASED OUTLIER DETECTION  A. Frequent Pattern based Outlier Detection Zengyou He et al. proposed a frequent pattern based  outlier detection method [8]. This method regards as outliers those data points which contain infrequent patterns. In other words, if a data object contains more frequent patterns, it means that this data object is unlikely to be an outlier.

1) FPOF Measure for Outliers FP method defines a measure called FPOF that reflects  the normal degree of a transaction. Let F be a complete set of frequent itemsets mined from input data with a given threshold min_sup and let sup(X) be a support value of an frequent itemset X and X?F. The normal degree FPOF(t) of a transactions t is derived as:    sup( ) FPOF(t)=  | | X t X F  X  F ? ? ? ?  (1)  The numerator of this formula (1) represents the sum of support degree of all frequent patterns contained in transaction X. The denominator defines the number of frequent patterns that F contains. Therefore, a transaction that contains more frequent patterns is more normal, while one that contains less frequent patterns is more abnormal and more possible to be an outlier.

2) FP Algorithm This FP algorithm is listed in Table ? . First the  algorithm generates the frequent pattern set F from the dataset with a given minisupport. Then, for each transaction t in the dataset T, traverse every frequent pattern X in F, if t?X, then FPOF(t) = FPOF(t) + support(X). When the traversing is finished, the sum of support degrees of all satisfied frequent patterns is clear, and the final value of t?s FPOF is computed. After all transacion in T is computed, Order all the transactions by their FPOF value in ascend.

Finally, the top-k FP-outliers are output.

TABLE I.  FP ALGORITHM DESCRIPTION   DOI 10.1109/ICIE.2010.97     Input: transaction dataset T, user defined threshold minimal support min_sup, user defined threshold value for top k fp-outlier Output: top k outliers corresponded with the k lowest FPOF values  1. Mining the set of frequent patterns F on database T using minisupport min_sup  2. for each transaction t?T 3.       FPOF(t) = 0 4.       for each frequent pattern X?F 5.             if t?X 6.                   FPOF(t) = FPOF(t) + support(X) 7.             end if 8.       end for 9.       FPOF(t) = FPOF(t) / F.size() 10. end for 11. Order the transactions in the ascending by their FPOF values.

12. Output the top k transactions as outliers  B. Drawback of FP Method Let t be a transaction in transaction dataset T, t?T, let X =  {I1, I2, I5}, Ii?I, I is the itemset of T. We suppose X is a frequent pattern of frequent pattern set F, X?F. All the nonempty subsets of X are derived as: {I1, I2}, {I1, I5}, {I2, I5}, {I1}, {I2}, {I5}. Let t contains X, so that t?X, and t also contains all the subsets of X. Because X is a frequent pattern, the subsets of X must be frequent patterns too. Therefore, when FP algorithm is used to compute t?s FPOF value, the support degrees of X and X?s subsets are duplicate added.

This duplicate computing will enlarge the differentials of normal degrees among transactions. In such a case, the outlier measure FPOF cannot reflect the normal degree of transactions accurately.

Targeting at the above drawback of FP method, we propose an improved method, named LFP method. LFP method redefines the outlier measure and has solved duplicate added problem well, so this method could detect outliers more precisely and increase the rate of accuracy.



III. AN IMPROVED METHOD  A. LFPOF Measure for Outliers We assume that here exist frequent pattern fp1: {I1, I3,  I5, I6}?fp2: {I3, I5}?fp3: {I5, I6} and fp1?fp2?fp1?fp3, then frequent pattern fp1 is defined as a superset frequent pattern of fp2 and fp3, frequent pattern fp2 and fp3 are defined as subsets frequent pattern of fp1.

Importantly in the frequent pattern mining process, a superset frequent pattern that contains more items (has long length) is combined by subset frequent pattens that contains less items (has short length). So the longer a superset frequent pattern is, the more its subset frequent patterns are.

Then we could conclude that a transaction that contains longer superset frequent patterns is more likely to be a normal transaction because it has more subset frequent patterns than other transactions. In contrast, a transaction that contains short frequent patterns is more likely to be an outlier.

According to the above idea, we define a new measure called LFPOF that reflects the normal degree of a transaction. Let t be a transaction in T, let F be a complete  set of frequent itemsets, F(t) is a frequent pattern set which composes of  frequent patterns contained in t. F(t) is derived as: F(t) = {X | X?F ? t?X}.

Let Xmax be the longest frequent pattern in F(t). |Xmax| represents the length of Xmax, |t| represents the length of transaction t, then we have:   max| |( )  | | XLFPOF t  t =  (2)  The numerator shows that a transaction contains longer frequent pattern is more normal.

B. LFP Algorithm This LFP algorithm is shown in Table ?. The process of  LFP algorithm is as follows. First the algorithm using FP- growth algorithm to generate the frequent pattern set F.

Then, for each transaction t in the dataset T, get t?s frequent pattern set F(t). Find the longest frequent pattern Xmax in F(t).

After that, we could compute t?s normal degree LFPOF(t).

When the traversing is over, the value of every t?s LFPOF is computed. Then order all the transactions by their LFPOF value in ascend. At the end, the top-k FP-outliers are output.

TABLE II.  LFP ALGORITHM DESCRIPTION  Input: transaction dataset T, user defined threshold minimal support min_sup, user defined threshold value for top k lfp-outlier Output: top k outliers corresponded with the k lowest LFPOF values  1. Using FP-growth algorithm to mine the frequent pattern set F on database T using minisupport min_sup  2. for each transaction t?T 3.       LFPOF(t) = 0 4.       for each frequent pattern X?F 5.             if t?X 6.                   F(t).add(X)       /* add frequent pattern X to F(t) */ 7.             end if 8.       end for 9.       Find the longest frequent pattern Xmax in F(t) 10.       LFPOF(t) = | Xmax | / |t| 11. end for 12. Order the transactions in the ascending by their LFPOF value 13. Output the top k transactions as outliers  C. LFP Algorithm Performance Analysis The computational cost of LFP algorithm is mainly  composed of two parts: fisrt, the cost of generating frequent pattern set using FP-growth algorithm [9]; second, the cost of double circulation in line 2?9. The time complexity of generating frequent pattern set using FP-growth algorithm increases fast as the scale of the transaction dataset gets larger. When the scale of dataset is extremely large, the algorithm?s computational time will get quite long. Anyway, FP-growth algorithm is much more efficent than Apriori algorithm. The double circulation has O(|T|?|F|) time complexity. When |T| and |F| are getting larger, the running time of algorithm is getting longer, however, this O(|T|?| F|) time complexity is acceptable as long as |T| and |F| are limited in certain scale.



IV. EXPERIMENTAL RESULTS In this section, we make experiments to compare FP  method and LFP method on the detecting accuracy. We run the two algorithms on 3 real world datasets all obtained from the UCI Machine Learning Repository [10].

A. Experimental Environment The experimental environments: Windows XP?Intel(R)  2.66GHz CPU?1G main memory and JDK 1.6.0.

B. Data Sets These 3 datasets are: Intrusion dataset, breast-cancer-  winsconsin dataset, lymphography dataset.

Intrusion dataset is a network connection records dataset  that includes a variety of intrusions from U.S. military, Attributes include length of the connection, the type of protocol, network service on the destination and so on, each record is classified into the normal class or one of the intrusion classes such as guess password, warezmaster and so on. Most attributes take continuous values, we discretize them into 5 levels using AlphaMiner [11] software. The treated experimental dataset is combined of the guess password class as the true outlier records and the normal records. It contains 97% normal records and 3% outlier records, in total 1000 records. We converted this record data to transaction data in which each item corresponds to a pair of an attribute and its value. The final experimental dataset is shown in Table ?.

TABLE III.  CLASS DISTRIBUTION OF INTRUSION DATASET  Class Number Percentage Total number Normals 970 97% 1000 Outliers 30 3%  The second dataset used is breast-cancer-winsconsin dataset, which contains 699 records with 9 attributes. All attributes are considered as categorical. Each record was labeled as benign or malignant. In our experiment, We pick up 14 records (3%) of the malignant records and 443 records (97%) of the benign records. The 14 malignant records are treated as outliers and others are normal records. The final transaction form dataset is listed in Table ?.

TABLE IV.  CLASS DISTRIBUTION OF BREAST-CANCER-WINSCONSIN DATASET  Class Number Percentage Total number Normals 443 97% 457 Outliers 14 3%  The third dataset is the Lymphography data set, which contains 148 records with 18 attributes. All records in the dataset are categorized into 4 classes. Classes 2 and 3 have the largest number of records. The remained classes were regarded as outlier class labels. The corresponding class distribution is illustrated in Table ?.

TABLE V.  CLASS DISTRIBUTION OF LYMPHOGRAPHY DATASET  Class Number Percentage Total number Normals 142 96% 148 Outliers 6 4%  C. Accuracy Comparisons In order to evaluate LFP method proposed by this paper,  we adopt Kazuyo Narita?s experiment method [6] to compare FP method and LFP method. We take two accuracy measures, the detection rate (D_rate) and detection precision (D_prec) defined by the following formulas:  number of  detected true outliersD_rate = number of  all true outliers number of  detected true outliersD_prec=  number of  detected transactions as outliers For fair evaluation, we provide fixed parameters for each  method, and regard transactions which have the top-k lowest normal degree as outliers. Changing the k value, we draw a comparison chart. Fig. 1 shows the change in D_prec as D_rate increases of two methods, and the horizontal axis of this figure represents detection rate, the vertical axis represents detection precision. The parameter min_sup is set 50%, which is most proper for the two methods. We could find that LFP method?s D_prec keeps maintaining higher values than FP method as the D_rate increases (or k value increases), especially under the circumstance that D_rate is quite low. Through this phenomenon we can deduce that the top outliers detected by FP method contain much normal records so that its detection precision gets low. In contrast, when D_rate is quite low, LFP?s D_prec is quite high because the top outliers detected by LFP method are almost correct. Therefore, we can see that LFP method gets a higher accuracy than FP method.

Accuracy Comparison of LFP Algorithm and FP Algorithm (Intrusion)             5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100  Detection Rate(%)  D e t e ct i o n  P re c i s i on ( % )  LFP(min_sup=50%)  FP(min_sup=50%)   Figure 1.  Accuracy Comparison between LFP Algorithm and FP  Algorithm (Intrusion)  In the second experiment, we use breast-cancer- winsconsin dataset and the result is shown in Fig. 2.

Accuracy Comparison between LFP Algorithm and FP Algorithm (breast- cancer-winsconsin)             5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100  Detection Rate(%)  D e t ec t i o n P r ec i s i on ( % )  LFP(min_sup=25%)  FP(min_sup=25%)       Figure 2.  Accuracy Comparison between LFP Algorithm and FP Algorithm (breast-cancer-winsconsin)  It is clear that the detection precisions of LFP method and FP method are both high when D_rate is low, however, as D_rate increases, the curves of two methods split apart gradually and LFP method?s D_prec is higher than FP method?s.

In the third experiment, we use lymphography dataset and the result is shown in Fig. 3.

Accuracy Comparison between LFP Algorithm and FP Algorithm (lymphograhy)             5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100  Detection Rate(%)  D e te c t io n  P re c i si o n (% )  LFP(min_sup=50%)  FP(min_sup=50%)   Figure 3.  Accuracy Comparison between LFP Algorithm and FP  Algorithm (lymphography)  We can see that the detection precisions of LFP method and FP method are both quite high when D_rate is low. But, when D_rate is more than 75%, LFP method?s detection precision gets higher than FP method?s a little bit.

D. Parameter Sensitivities The detection result of LFP method depends on the user  threshold min_sup, so it is necessary to provide an analysis with regard to parameter sensitivities. Fig. 4 shows that LFP method may detect a different set of transactions, when different minimal supports, 12.5%?25%?50%?75%, are provided. From this analysis, although the proposed method has excellent performance on outlier detection, it is sensitive to the parameter given by the user. The problem of how to select the proper parameters for input data is important.

LFP Algorithm Accuracy Comparison under Different Min_sups (breast-cancer- winsconsin)             5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100  Detection Rate(%)  D e t e c t i o n  P r e c i s i o n ( % )  LFP(min_sup=50%)  LFP(min_sup=75%)  LFP(min_sup=25%)  LFP(min_sup=12.5%)   Figure 4.  LFP Algorithm Accuracy Comparison under Different  Min_sups (breast-cancer-winsconsin)

V. CONCLUSIONS In this paper, we focus on the method of outlier detection  based on frequent patterns proposed by Zengyou He et al, we name it FP method. First we describe the core algorithm, summarize the FPOF measure and the FP algorithm for outlier detection, and then we analyze the drawbacks of FP method. We find that FP method has duplicate computing problem so that it couldnot detect outliers precisely.

Targeting at this drawback, we propose an improved method (LFP method) and also present its algorithm. LFP method solves the problem above well and it is easy to implement and efficent in time complexity. Finally, we evaluate the two methods by using several datasets and the experiment results show that the LFP method outperforms the FP method. A future work is to solve the parameter sensitivity problem of LFP method, figure out how to fix the most proper min_sup for LFP method.

