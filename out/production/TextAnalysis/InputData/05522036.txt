An Improved Apriori Algorithm

Abstract Apriori algorithm has some abuses, such as too many scans of the database, large load of system?s I/O and vast unrelated middle itemsets. This paper proposes an improved Apriori algorithm to overcome these abuses. The improved algorithm reduces the set of candidates and accelerated the speed of the algorithm by adding the interest items. Breaking the traditional steps of the algorithm to reduce the database scans and bring down the load of system?s I/O. The algorithm improves the readability of the strong association by constructing the model of the interest measure. Experimental results show that the algorithm can improve the speed and efficiency of operation effectively.

1 Introduction Apriori algorithm is the most classic algorithm of Association Rule Mining[1]. Apriori algorithm needs to scan the database many times to find candidates of frequent itemsets and generates great amount of unrelated middle itemsets during the iterative process. With the evaluation criteria of support and confidence the algorithm may generate many uninteresting strong association rules. The drawbacks that proposed above increase the load of system I/O and greatly affect the efficiency of the algorithm.

Against the drawbacks of the Apriori algorithm, this paper presents a fast and efficient Apriori algorithm. The algorithm introduces the concept of user interest items and with the user interest items to reduce the emergence of the candidate itemsets[2]. It changes the realization steps to reduce the number of database scans and the load of system I/O. In the stage of strong association rules evaluation, more useful strong association rules are mined with the establishment of the user interest model.

2  Apriori algorithm  2.1 The steps of the Apriori algorithm  Apriori algorithm uses iterative method layer by layer to find candidate itemsets. The main steps of the Apriori algorithm are showed as follows[3]: Step 1: Producing one frequent itemset Scaning the database D to find the frequency itemsets L1.

Step 2: Connection  Using the connection method to have Lk (K>1). Generating candidate itemsets k with itemsets Lk-1 and itself.

Step 3: Pruning Supposed: ck Ck, that ck is a itemsets of candidate k, ck +1 is a (k-1)subset of ck , if 11 kk Lc , that the itemsets of candidate ck should be deleted from the itemsets of candidate Ck.

Step 4: Generating strong association rules Strong association rules are mined according to the minimum confidence level and then end of the algorithm.

2.2 Apriori algorithm analysis  The Apriori algorithm has certain limitation on the speed and efficiency as follows: (1) Apriori algorithm will produce a large number of middle- itemsets. Candidate itemsets Ck are generated by Apriori-Gen function with itemsets Lk-1.The number of itemsets Ck is k LkC 1 . Obviously that the number of candidate itemsets Ck  will be in large quantity if the k is big enough.

(2) Scaning the database too many times. Apriori algorithm needs to scan the database every time when it generates candidate itemsets. It will increase the load of system I/O and impact the speed of the algorithm when it scans massive database.

(3) Misleading strong association rules are mined. Apriori algorithm uses evaluation criteria of support and confidence.

Not all of the strong association rules are useful to the users.

For example, transaction database is showed as follows. We use TID to mark the transaction, Items to stand for itemsets in the transaction, Num to stand for the times of the itemsets and L stand for the length of the itemsets.

Tab.1 Example of transaction database TID Items Num L 1 I1,I2 20 2 2 I1,I3,I4 5 3 3 I2,I5,I6 70 3 4 I6,I7 5 3  For itemsets (I1,I2), the support of (I1,I2) is Sup(I1 I2)=20/100=0.2 and the confidence of (I1,I2) is conf(I1 I2)=20/25=0.8. When the min_sup is not bigger than 0.2 and the min_con is not bigger than 0.8, Itemsets (I1,I2) is choosed as strong association rules. However, when I1 does not appear, the confidence of I2 is conf = 70/75 = 0.93. In other words, if we suppose I1 and I2 as products the effect of putting itemsets(I1,I2) together is not good to put them separately. So we need to find another evaluation criteria: interest measure.

3 Improved Apriori algorithm The improved Apriori algorithm made the following adjustments according to the three drawbacks.

3.1 Constraints of the user interest itemsets  Interest items are selected by users. We use Itsn to stand for them. Interest itemsets are collection of interest Itsn and Its={its1,its2,?itsn}.

The improved algorithm uses interest itemsets to exclude non- relevant items in the transaction database D and the length of the itemsets will be changes too. For example: the number of uninterested items in itemsets whose length is n, then the length of the excluded itemsets is Ln =L-n. Shown in Table 1 as an example of transaction database, the itemsets of transaction database is I={I1,I2,I3,I4,I5,I6,I7}. We want to know the strong association rules of I1,I2,I3,I4,I5, so the interest itemsets is Its={I1,I2,I3,I4,I5}. The excluded transaction database is shown in table 2.

Tab.2 New example of transaction database TID Items Num L 1 I1,I2 20 2 2 I1,I3,I4 5 3 3 I2,I5 70 2  Compared the new transaction database with the original we know: (1) The number of database scans that the new transaction database compared to the original is seven to five. The efficiency improves about 30%.

(2) We assume that I1,I2,I3,I4,I5,I6,I7 are frequent items. The number of candidate three sets is about 1330 which generate by the original transaction database however the number of candidate three sets is about 120 which generate by the new.

The efficiency improves about 91%.

3.2 The steps of the improved algorithm  Against too many times of database scans, the improved Apriori algorithm changes the steps of the traditional algorithm. We use arrays to store the datas and reduce the number of the database scans. We introduce the steps of the improved algorithm with table 2.

Step 1: Traverse the new database The existence form of transaction itemsets in table 2 is shown as follows:  Tab.3 The existence form of transaction itemsets in table 2 TID Items Num 1 I1 20 1 I2 20 2 I1 5 2 I3 5 2 I4 5 3 I2 70 3 I5 70  The unique identifier of itemsets in transaction database is TID. We put the itemsets into array A according to the TID.

We use ?,?to separate the items under the same TID with  different items and ?;? to separate itemsets with different TID.

The organizational form is A[]={I1,I2;I1,I3,I4;I2,I5,I6}.

Step 2:Traverse the array A and generate frequent itemsets The improved algorithm generates frequent itemsets according to the min_sup by traversing the array A. We put the frequent itemsets and the corresponding support into {A1,A2,?An}, n stands for the length of the itemsets. We use ?,? to separate the itemsets and the corresponding support and ?;? to separate the different itemsets. If we set the min_sup is 0.2 then we have frequent itemsets as follows:  Tab.4 Frequent itemsets Items I1 I2 I5 I1,I2 I2,I5 Number 25 90 70 20 70 Sup 0.25 0.9 0.7 0.2 0.7  The organizational form of frequent itemsets in array is A1[]={I1,0.25; I2,0.9; I5,0.7};A2[]={I1,I2,0.2 I2,I5,0.7}.

Step 3: Candidate frequent itemsets The improved algorithm generates frequent itemsets k by using Ak-1 and itself to do a connection. Compared the generated frequent itemsets with the itemsets in array Ak then add the non-existed itemsets in array orderly.

Compared the implementation steps of the improved Apriori algorithm with the traditional algrorithm we know: (1) The improved algorithm greatly reduces the number of database traversal and the system I / O load because it scans the database only once.

(2) The improved algorithm puts the frequent itemsets and support into one array. With this array we can generate strong association rules rapidly.

(3) We can use the sequence of the frequent itemsets in corresponding array to know which frequent itemsets are generated by itemsets in database and which are generated by candidate itemsets. This improvement will help users to achieve practical applications.

3.3 Model of interest  The evaluation criteria which based on the measure of support and confidence will not reflect the real strong association rules in some cases. So we need to build a new model of interest.

The interest measure mainly includes the subjective interest measure and the objective interest measure. Now studies mainly focused on the objective interest measure. Some models of the objective interest measure are shown as follows: (1) The interest model of Gray and Orlowska[4] The interest model of Gray and Orlowska is used to assess the associated degree between the itemsets. The definition is shown as follows:  mk ypxp ypxp  xypI ))()(()1) )()(  )(((   (1)  )()( )( ypxp  xyp is the deviation. k and m stand for factor  parameters.

(2) The rule template of Klemettinen[5] The rule template is an extension of syntax. It is used to bound which properties can appear on the left side and which properties can appear on the right side. The definition of the     rule template is A1,A2 ?Ak =>A m. A j may be a name of property or class. The model is proposed by users and if a rule matchs this model then the rule is interest.

(3)The function of J-measure[6] The function of J-measure is proposed by Gray and Orlowska.

It is the average information of probability of classification rules and it is the best rule to find the properties of the discrete rules. The definition of function is :  ) )(1 )(1log())(1()  )( )(log())()((  XP YXPYXp  XP YXpYXPYP   (2)  Close analysis of the interest model that proposed above we know: (1) The parameters k and m in the Gray and Orlowska's interest mode does not have determined computation rule. It is easy to add subjective factors and affect the accuracy of the evaluation model.

(2) Klemettinen?s rule template is a rule-based method.

Although the rule template can select the valid association rules accordance with the rule template, it does not give the effective template to suit every rule.

(3) The model of function J-measure considers the coupling degree of the probability distribution between X and Y. But the function does not consider the impact of P(Y).

So the interest model that we build must meet the following requirements: (1) The interest model of YX must meet that if the probability of X is big then the same to the model.

(2) The new model must consider the coupling degree between X and Y. The value of the model is proportional to the coupling degree.

(3) From the analysis of examples in chapter 3 we know if we do not consider the impact of post item I2 we will elicit misleading strong association rules. So we must pay attention to the post item Y.

(4) The interest model of YX  should be proportional to the support of X and Y.

Consider the analysis above we set the interest model as follows:  )( ))(1))((1(  )(1)( YXSup YXconfXSup  YSupYXInte   (3)  )( ))(1))((1(  )(1)( XYP XYPxP  YPYXInte (4)  The interest model that we proposed above meets the premise that X is a big probability event and consider the coupling degree between X and Y. The model also adds the factor of probability Y. The practical application value of the strong association rules is proportional to the interest measure.

We use the interest model to verify the example of chapter 2.2.

)( ))(1))((1(  )(1 )( 21   21 IISupIIconfISup  ISup IIInte (5)  13.02.0 )8.01)(25.01(  9.01)( 21 IIInte   (6)  From the result we know that the interest measure of I1 I2 is 0.13. It is too low to let us trust this association rule.

According to the new interest model and combining the traditional evaluation criteria of support and confident we  make the new definition of strong association rules. We assume that the minimum support threshold is min_sup, the minimum confidence threshold is min_con and the minimum interest measure is min_int. We call it strong association rules if the association rules meet that supmin_)( YXSup ,  conYXCon min_)(  and intmin_)( YXInt  .

4 Experiment results The algorithm uses C # as a code development platform and Microsoft SQL Server2005 as a database development platform. The number of test record is 52761 which exist in the vAssocSeqLineItems of AdventureWorksDW sample database. OrderNumber and Model will be used as identifiers and items of the transaction. The operation platform of the algorithm is shown in table 5.

Tab.5 Experiment platform Experiment platform  CPU Pentium(R) Dual E2200  2.2GHz Memory DDR2, 2048MB Hard Disk ST3160815AS,160G  The runtime that the improved Apriori algorithm compares with the traditional is shown in figure 1. The abscissa of the figure stands for the threshold of support (100 /%) and the ordinate stands for the runtime.

Fig.1 The time ratio of two ways to find frequent itemsets We assume the min_sup is 0.01, the min_con is 0.2 and the min_int is 1.45. The result that the improved algorithm compares with the traditional is shown in table 6.

Tab.6 Compared the improved algorithm with the traditional  Apriori Improved Apriori  Efficiency improvement  Frequent itemsets 114 44 61.4%  Strong association  rules 51 20 62%  Time 79 24 69.62% The experiment results show that the improved Apriori algorithm can quickly and efficiently get the useful strong association rules. Figure 1 shows that the improved algorithm finds frequent itemsets faster than the traditional under different levels of support. It reflects that the rapid characteristics of the improved algorithms. As can be seen     from Table 6, the number ratio of frequent itemsets that the improved algorithm compared with the traditional is 114:44.

This stands for that the number of superfluous itemsets is 70.

And the number ration of strong association rules is 51:20. It shows that the improved algorithm can get scientific strong association rules accurately.

5 Conclusions This paper proposes an improved algorithm of Apriori. User interest items and a new model of interest measure are added into the algorithm and the steps of the algorithm are restructured. Compared with the traditional algorithm the improved algorithm has a great advantage in both speed and efficiency. But there is also room for improvement, such as improving the integrity of the frequent itemsets and doing more experiments  to verify the scientificalness of the interest model.

Association Rules algorithm has broad application prospects of the market. How to optimize the efficiency of database operations, how to select the more scientific min_sup, min_con and min_int, how to further explore the practical application of the algorithm will be the future research work.

Acknowledgements This research is supported by National Natural Science Fund for Nature Program (60872115), Shanghai?s Key Discipline Development Program (J50104).

