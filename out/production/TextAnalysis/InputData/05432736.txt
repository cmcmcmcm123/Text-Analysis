Efficiently Using Matrix in Mining  Maximum Frequent Itemset

Abstract?an efficient way to discover the maximum frequent itemset can be very useful for mining association rules, correlations, episodes patterns, etc. Most existing work focuses on the technique for mining candidate maximal frequent itemset and ignores the technique for MFI checking. However the efficient of a MFS mining algorithm lies on these two parts. In this paper, a new MFI checking method is presented based on the optimizing of the former called MaxMatrix and an additional constraint for association rules generating is discussed to save mining time.

In order to understand the process of MaxMatrix easily, an example is provided in detail.

Keywords-maximum Frequent itemset; MFI checking; MaxMatrix; Association Rules

I.  INTRODUCTION Frequent itemset mining has been recognized as a  fundamental and essential problem in many data mining tasks including association rules mining, sequential patterns mining, correlations, and multi-dimensional patterns et al. A frequent itemset is a set of items appearing together in a number of database records meeting a user- specified threshold.

Starting with the pioneering work in [1,2], itemset mining algorithm has been studied extensively by researchers. Many of the proposed itemset mining algorithms are a variant of Apriori, which employs a bottom-up level-wise search in the itemset lattice that enumerates every possible single frequent itemset. This implies candidate k+1-itemsets are generated only after all k-itemsets have been generated. For each level, all candidate itemsets are tested for frequency by scanning the database.

The drawback of mining all frequent itemsets is that in order to produce a frequent itemset of length l, all l2 of its subsets must be enumerated, which is computationally unfeasible. Thus there has been recent interest in exacting only the maximal frequent itemset, because the set of all maximum frequent itemsets is orders of magnitude smaller than the set of all frequent itemsets. An itemset is maximal frequent if it has no superset that is frequent. Wherever there are very long patterns (pattern contains many items) are presented in the data, it is often impractical to generate the entire set of frequent itemsets [3]. Also, in some situations it is sufficient to mine the maximal frequent itemsets rather than all the frequent itemsets. We will use MFS to denote the set of the maximal frequent itemsets, and MFI to denote one maximal frequent itemset.

Therefore, many algorithms [3,4,5,6,7] have been proposed for generating MFS directly instead of all the  frequent itemsets to ?shortcut? the process. In general, a MFS mining algorithm includes two main parts. The first is the techniques to find candidate maximal frequent itemset efficiently, and the second is the methods used to perform fast MFI checking to eliminate non-maximal itemsets. However, the second part MFI checking hasn?t drawn adequate attention. This paper is written with the primary aim of developing a method for fast maximality checking.

In this paper a new method is proposed called MaxMatrix which uses the pseudo-projection matrix of the MFS matrix to do MFI checking. It can not only test fast, but also significantly save resources. Because only logical operation is used to delete the related ranks of the matrix for testing the candidate MFI in algorithm MaxMatrix, it does not need to allocate new memory space for pseudo- projection matrix. An all-confidence constraint is also used to facilitate the further generation of association rules from MFS if necessary.

A. Related Work There are considerable researches on methods for  generating the set of maximal frequent itemsets.

Lin and Kedem [4] proposed an algorithm called  Pincer-search for mining maximal frequent itemsets. It combines both the bottom-up like Apriori and top-down directions to maintain and update the maximal frequent candidate set which do not contain any known infrequent itemset. This method can help in reducing the number of database scans by eliminating non-maximal set early. But the overhead of maintaining the candidate maximal frequent set can be very high.

MaxMiner [3] also mines only maximal elements. It abandons a strict bottom-up traversal of the search space, and instead always attempts to ?look ahead? in order to quickly identify maximal frequent itemsets. i.e., if a node with all its extensions can be determined to be frequent, there is no need to further process that node. It also employs item order based on support instead of the lexicographic order to keep the search space as small as possible. Though these strategies reduce the search time dramatically, MaxMiner still needs many passes over datasets to get all maximal frequent itemsets.

DepthProject [5] finds long patterns by using depth- first search on a lexicographic tree of itemsets. It uses bitvector and hierarchical projections to make the process of support counting more efficient. A bitvector contains the information about transactions which contain the itemset for a node as a subset. By using hierarchical projections, it can reuse the information from counting k- itemset to count (k+1)-itemsets. It also uses an effective   DOI 10.1109/WKDD.2010.27     lookahead strategy in order to avoid creation of those subtrees of the lexicographic tree which contain only non- maximal itemsets.

MAFIA[6] also uses the depth-first search strategy for mining maximal frequent itemsets from transactional database like DepthProject. It integrates a variety of old and new algorithmic ideas to improve performance, such as three type of pruning ideas to trim the tree including PEP, FHUT(also used in MaxMiner and DepthProject) and HUTMFI, dynamic reordering the children of each node and a compression form of vertical bitmap representation for the database.

In general, these methods are all trying to improve the performance for mining maximal frequent itemset and have varying performance depending on the database characteristics mainly the distribution of maximal frequent patterns by length. While they all maintain a superset of the MFI and would require post-pruning, it is not clear how these algorithm would do maximality checking efficiently.

GenMax [7] uses a novel technique called progressive focusing to perform maximality checking and diffset propagation to perform fast frequency computation in the process of mining to mining exact MFI. But it needs to construct a list of local maximal frequent itemsets which is most relevant superset of candidates. G.Grahne and J.Zhu proposed a MFI-tree in [8,9] to store all MFI, which is constructed like FP-tree [10] and returns all and only the maximal frequent itemsets. However, for large datasets, the MFI-tree will be quite large, so one itemset may need thousands of comparisons for subset testing.

In this paper, the algorithm MaxMatrix will integrates pruning of non-maximal itemsets in the process of mining using matrix of MFS to maintain an exact set of maximal frequent itemset, which is proved to be an efficient method.

B. Overview The organization of the rest of the paper is as follows.

Section 2 discusses the conceptual ideas of the MFS mining problem and the principle of MFI checking of MaxMtrix. In section 3, we provide a pseudo-code description of MaxMatrix and implementation details about how it uses pruning techniques to restrict the search space. Section 4 discusses the integration of all-confidence constrains into the generation of association rules from MFS. The algorithm is illustrated with an example in section 5. Section 6 discusses the conclusions and summary.



II. PRELIMINARIES  A. Terminology Defining Let { }miiiI ,,, 21=  be a set of m distinct items. A  database D  is a set of transactions that are sets over item domain I . Each transaction is associated with a unique identifier, called TID . A set of items is more succinctly called an itemset. An itemset with k  items are referred as k -itemset. The support of an itemset IX ? , denoted  )sup(X , is the fraction of the transactions in D  that contains all items of X . An itemset is frequent if its support is above or equal to the minimum support(minsup) predefined by the user. Otherwise, it is infrequent.

We will use generic set-enumeration tree search framework [3] to search each MFI. The idea is to expand sets over an ordered and finite item domain as illustrated in figure1, where five items { }EDCBA ,,,, are denoted by their position in the ordering. We assume that a lexical ordering exists among the items in the database. The item- name is replaced with item-number in order to facilitate the construction and pseudo mapping of MFS-matrix (defined in section 2.3). MaxMatrix constructs the set enumeration tree mainly in depth-first order for finding the exact MFI. Figure1 also shows the itemset frequency testing order in the process of MFS mining by the number on the top-right side of the itemset.

A candidate group 2g is employed to represent each  node in the set-enumeration tree like [3] at the initial step of algorithm MaxMatrix. A candidate group 2g  consists of head )( 2gh  and tail )( 2gt . )( 2gh represents the itemset enumerated by the node and )( 2gt is an lexical ordered set containing all items not in )( 2gh which can potentially appear in )( 2gh ?s sub-node.

B. Initialization Figure 1 shows the tree does not grow in pure depth-  first order. A hash technique of the DHP [11,12] is used to initialize the step of group. A direct-addressing hash table  H2 and hash function ? ?  =  ??+?=  1)()(),(  x  i xyiNyxh , are  illustrated in figure2. N is the amount of the item and 5=N  in figure 2.

item- name  A B C D E  item- number   itemset 2H hash address  1,2 0 1,3 1   3,5 8 4,5 9    Figure2. Example of H2 generation  C. MFS Checking Based Matrix First we need to construct a MFS-matrix, each row of  which represents a frequent item ordered according to lexical sequence. Every determined MFI will be added in the matrix as a new column, of which the element corresponding to item included in MFI will be set to 1 and  ? ?  =  +?=  )(),(  x  i iNyxh  1)( ?? xy  {}0  11 21 31 41  1,21 1,31 1,41 2,31 2,41 3,41  1,2,32 1,2,42 1,3,46 1,3,56  1,2,3,43  Figure 1.  set enumeration tree for searching   1,51 2,51 3,51  1,2,52 1,4,58 2,3,49 2,4,511 3,4,512  4,51  1,2,3,53 1,2,4,55 1,3,4,57 2,3,4,510  1,2,3,4,54  2,3,59     others set to 0, so each column represents a MFI. For each candidate MFI X , pseudo projection is operated on MFS- matrix to check whether it has a superset in MFS-matrix. If item Xi ? , the columns of MFS-matrix is shielded, of which the ith element equal to 0. Iterating the shield process from the last item to the first one of X , a pseudo projection matrix ? of the original MFS-matrix will be obtained. If ? = ? , it verifies there is not a superset of X , and if X is frequent then X is a MFI, X will be added to the original MFS-matrix; otherwise X is not a MFI, the iteration will be continued until no candidate MFI is produced.

Since the mapping is based on the designated ranks, it does not require new memory space to storage new matrix.

It just needs to establish a vector to shield the corresponding ranks in MaxMatrix, which can save memory greatly.



III. PSEUDO-CODE FOR MAXMTRIX MaxMatrix consists of four parts as follows.

1) In the first round, scan the database D to count the support of all 1-item sets and build a hash table H2;  2) Generate L1 and L2 3) Geberate first-level and second-level nodes of  search tree; 4)  MFS-searching algorithm and MFI checking.

The pseudo-code of MaxMatrix algorithm is given below:   MaxMatrix Algorithm()  Begin //generate the initial candidate node 2g 1 for each itemset  2Fxx ji ?  generate a new candidate group 2g  2    let ji xxgh =)( 2 3       =)( 2gt { ,2Fxxk ki ? k follows j in the ordering} //invoke as MFI-search( 2,, 22 CI ) for current node 2I 4 for each 2gx ? 5  Let )(.2 xhxI = , )(.2 xtxP =  2C =Tail-gen ( 22 , PI ) 7  MFI-search( lCI ll ,, ) //function MFI-search( lCI ll ,, ) until ?=lC 8 MFI-search( lCI ll ,, ) 9 for each lCx ? 10   }{1 xII ll ?=+ 11   }{1 xyandCyyP ll >?=+ 12    While flag=0 do 13   {If 11 ++ ll PI ? has a superset in MFS-marix 14         return// all subsequent branches pruned} 15     =+1lC Tail-gen( 11, ++ ll PI ) 16           if 1=C and flag=1 17               {put 11 ++ ll CI ?  in MFI 18                  let ?=lC } 19           if 1=C and flag=0 20           if 11 ++ ll CI ? has a superset in MFS-matrix  21                 return// all subsequent branches pruned 22            put 11 ++ ll CI ?  in MFS-matrix 23                    return// all subsequent branches pruned 24           if 0=C 25            if 1+lI has no superset in MFS put 1+lI in  MFS-matrix 26        else MFI-search( 1,, 11 +++ lCI ll ) //can 1+lI joint with other item in lC 27 Tail-gen( 11 , ++ ll PI ) 28 ?=C  0=C  flag=1 29  for each 1+? lPy 30     if sup( }{1 yI l ?+ ) ? minsup 31        if sup( }{1 yI l ?+ )=sup( 1+lI ) 32          }{11 yII ll ?++ = 33        else{ yCC ?= 34             1+= CC } 35     else flag=0  End  MaxMatrix employs PEP (lines 30-32) and HUTMFI  (lines 12-14) pruning strategies. PEP has the biggest effect of the pruning method on the performance gains proved in [6]. HUTMFI proposed also in [6] determines whether a superset of the HUT is in the MFS, and thus it ensures the exact MFI generated without post-pruning and can prune some branches early to reduce search space. If a superset does exist, then the HUT must be frequent and the subtree rooted at the node can be pruned away.

Many algorithms adopt support increasing order to dynamically reorder the children of each node, such as, MaxMiner, MAFIA, GenMax etc. There are also algorithms adopting support descending order [9,10].

While ordering strategy isn?t always an effective means of cutting down the search space, since the effect of item ordering is very much dependent upon the characteristics of the data sets. Here, MaxMatrix constructs search tree based on lexical order in order to facilitate the MFI checking with MFS-matrix.

To avoid redundancy generated during each recursive superset checking, items? count C  of 1+lC and a status flag are used. If flag is true, it implies no items are deleted from 1+lP . That is, ll PI ?  of current node is the same as 11 ++ ll PI ? , so superset checking do not needed to operate again (lines 12-14). If flag is true and C =1, we can inset  11 ++ ll CI ?  into MFS directly and end current lI ?s extension (lines 16-18). If flag is false and C =1, 11 ++ ll PI ? will be performed superset checking subsequently without the need to return to MFI-search() (lines 19-23).



IV. FURTHER CONSTRAINT FOR ASSOCIATION RULE MINING  Though the frequent patterns themselves are often of interest to the decision maker, they often need to be transformed further before being presented for understanding. The problem of mining association rules is to generate all rules that have support and confidence greater than some user specified minimum support and       minimum confidence thresholds respectively. The confidence of a rule YX ? is defined as the ratio )sup(/sup( XYX ? . So in order to find those association rules with high confidence, another database pass is required after finding all maximal frequent itemsets to obtain the supports of all frequent itemsets for producing association rules. If some frequent itemsets are long, this step will be very costly [3]. To solve this problem, we incorporate an additional constraint called all_confidence into MaxMatrix for association rules searching from MFS. This constraint is quite powerful since all_confidence ensures a lower bound on confidence for any rule of an itemset by which we can further reduce the number of subset of MFI to be counted.

All_confidence is defined as the minimum confidence of all the association rules that can be derived from the itemset X , which is formulated as follows [13].

})max{sup( )sup()(  Xii XXallconf  jj ?? =                          (1)  A pattern that has all_confidence of no less than a given minimum confidence threshold? , indicates a high correlation among all the items in the pattern. This is because all association rules derived from the pattern have confidence of no less than? , as implied by (1).

All_confidence has a desirable property for the efficient mining of all association rules from MFS. The property called the downward closure property [13] can be  directly adapted as effective pruning tools for mining association rules, which is formally stated as follows.

Property1. (Downward closure property of all_confidence)  Given two itemsets, X  and Y , if YX ? then )()( YallconfXallconf ? .

By property 1, we are able to perform the following pruning: if a pattern X  has an all_confidence value no less than? , then the all-confidence of all its subset will greater than? , so we can get the association rules directly without counting the supports of these subset.



V. EXAMPLE The process of MaxMatrix is given in figure3 with  minsup=2, ? =0.5 and initial MFS-matrix= ? . The fist time scanning of D returns 1C and 2H . Comparing  1C and 2H with minsup, 1F and 2F can be determined. Based on the items in 2F , itemgroup 2g can be acquired. Then the MFS search tree for the database D  is constructed like figure 1, in which itemsets painted with sloping line are MFIs and itemset below dashed line are infrequent itemsets. MFS searching starts from the second level. For example, when =2I 1,2 and =2P 3,4,5, through the Tail- gen(), 5,4,32 =C .Though the first calling of the function      MFS-search(), 3,2,13 =I  and 5,43 =P is produced.

5,4,3,2,133 =PI ? is checked subsequently whether it has a  superset in MFS. As MFS-matrix= ? , 5,4,3,2,133 =PI ? doesn?t have a superset in MFS and  53 =C from Tail-gen ( 33 ,PI ). In this phase, =C 1 and flag=0, so 5,3,2,133 =CI ?  will be checked whether it has a superset in MFS. Similarly, it doesn?t have a superset in MFS. 5,3,2,133 =CI ? will be added in MFS-matrix as a  Figure3   the mining process of MaxMatrix     MFI. The node 3,2,13 =I extension is finished. Then the function MFS-search( lCI ll ,, ) will be called repeatedly until all the nodes are checked or ?=lC .

The checking process with MFS-matrix is showed in figure4 when 5,3,233 =PI ? . First, starting from the last item 5 of 33 PI ? , the column of the original matrix figure4(a) with the fifth element equal to 0 is shielded, then the matrix figure4(b) is obtained. Second, to the second item 3 from back to front of 33 PI ? , the column with the third element equal to 0 is shielded and matrix figure4(c) is generated. Third, to the last item from back to front, the column is shielded with the second element equal to 0 and matrix figure4(d) is produced, which is the final pseudo projection matrix ? . Because ? ?? ,  5,3,233 =PI ?  is not a MFI.

? ? ? ? ? ?  ?  ?  ? ? ? ? ? ?  ?  ?            ? ? ? ? ? ?  ?  ?  ? ? ? ? ? ?  ?  ?           ? ? ? ? ? ?  ?  ?  ? ? ? ? ? ?  ?  ?          ? ? ? ? ? ?  ?  ?  ? ? ? ? ? ?  ?  ?          a                         b                    c                      d   Figure4  MFS-matrix pseudo projection based 5,3,233 =PI ?   Through the iteration calling of the function MFS-  search() and MFI checking with MFS-matrix, MaxMatrix can get all the exact MFI without post-pruning. In this example, MFS  is ( ) ( ){ }4,3,2,5,4,2,1),5,3,2,1( .

If we need to get all the association rules of the database D , we could compute all_confidence of every MFI in MFS firstly. For example, 33.0)5,3,2,1( =allconf ,  50.0)5,4,2,1( =allconf , and 33.0)4,3,2( =allconf  from the formula (1). Since 50.0)5,4,2,1( =allconf ? ? , all the association rules exacted from the pattern are interesting and it does not need to count the supports of its subset.



VI. CONCLUSION This paper present an efficient MFI mining algorithm  MaxMatrix based on the analysis of the previous work, which mainly relies on a depth-first search technique to construct the lexical set enumeration tree of itemsets. The algorithm is optimum through hash technique at initial stage, node pruning with PEP and HUTMFI and some means avoiding redundancy. At the same time, it uses MFS-matrix to do superset and MFI checking during the hole searching process efficiently. An additional constraint for discovering association rules from MFS is also discussed, which can save a lot of time for counting the support of the subset of MFI. MaxMatrix can reduce both the time the exact MFI is generated and the number of subset considered for association rule mining.

