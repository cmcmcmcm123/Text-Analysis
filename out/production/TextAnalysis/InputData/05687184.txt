An intruder detection approach based on infrequent rating pattern mining

Abstract?This work presents a novel proposal for incremental intruder detection in collaborative recommender systems. We explore the use of rare association rule mining to reveal the existence of a suspected raid of attackers that would alter the normal behaviour of a rating-based system. In this position paper we have extended our previous G3PARM algorithm, which has already proven to serve as a solid method for extracting frequent association rules. G3PARM is an evolutionary algorithm that uses G3P (Grammar Guided Genetic Programming), which provides expressiveness and flexibility enough to adapt and apply the base context-free grammar to each specific problem or domain. We fully outline, moreover, the complete exploration and detection model, which includes some further post-analysis steps. Finally, as a proof of concept, we validate the scalability, efficiency and accuracy of our proposal showing the results obtained when different malicious intruders want to attack an on line recommender system.



I. INTRODUCTION  In our daily life, it is customary to take our decisions based on the opinions and suggestions of others whose tastes are apparently similar to ours. So, with the advance of virtual communities and collaborative recommender systems (CRS), to share views and interests among users has become a routine activity, and it is usual for users to act on the basis of what they hear from others (e.g., when purchasing goods, booking a flight, etc.). Thus, CRS use historical data on user preferences to recommend items. A common way to generate these recommendations is to analyze how other users behave, and predict the afinity for items that were not rated yet by the target user. An user-based collaborative recommendation algorithm [1] attends to such predictions, which are usually calculated based on the similarity between neighbors to the target user.

Nevertheless, these systems are not free of problems, and prediction models have to face the manipulation and fraudulent use of the system by malicious parties (aka. attackers), which may inject fake user profiles in order to influence the rating of certain items that want to be promoted or demoted. Although most systems apply different techniques to prematurely detect attackers and restrict their registration, it is really difficult to anticipate the attackers? behaviour once they have successfully joined the application. In consequence, most current propos-  J.M. Luna (Student Member, IEEE), A. Ram??rez, J.R. Romero (Member, IEEE) and S. Ventura (Senior Member, IEEE) are with the Dept. of Com- puter Science and Numerical Analysis, University of Co?rdoba, Rabanales Campus, 14071 Co?rdoba, Spain. Email: {i32luarj, i72raqua, jrromero, sven- tura}@uco.es.

als [2], [3], [4] are actually based on the analysis of the system data sources and existing user profiles.

A profile-injection attack is a common way to distort recommendations. Basically, it consists in adding several new users to the system using different fictitious identities. Each of these users will rate a target item, as well as other random items that other regular users belonging to the group of interest would also rate. In this way, real intentions are concealed, and it makes the attack more difficult to trace. There are different types of profile-injection attacks [5], depending on whether the target item should be promoted (push attack) or demoted (nuke attack).

Intrusion detection does not only concern rating-based sys- tems. Indeed, there exists many other application domains for which anomaly detection [6] is an important issue too. Exam- ples include network intrusion, frauds (e.g., banking, assurance companies, etc.), medical anomalies, industrial damages, sen- sor networks, text processing, and so on. In general, anomaly detection searches for patterns in data that do not follow the behaviour expected. Therefore, different approaches for intrusion detection have been proposed (e.g., neural networks, statistical techniques, etc.), data mining (DM) being a widely used process to explore and extract comprehensible and useful knowledge from these large data sources.

More precisely, association rule mining (ARM) is a very well-known method for discovering interesting patterns and close relations between items in datasets. An association rule [7] is an expression of the form ? ? ?, where ? and ? are sets of items and ? ? ? = ?, ? being the antecedent and ? the consequent. So, an association rule should be interpreted as follows: if all items in ? exist in a transaction, then it is highly probable that all items in ? are also in the transaction, and ? and ? should not have any common items. Rare association rule mining (RARM) is a recent trend in ARM that, on the contrary, searches for non-frequent, unusual or exceptional association rules by mining rare (or infrequent) itemsets, i.e., itemsets that do not occur frequently in the data.

RARM deserves our special attention, since searching for non-ordinary items can help to discover potential intruders throughout the dataset maintained by the rating system. Many techniques have been already proposed to mine association rules, Apriori [8], [9] and FP-Growth [10] being the most ref- erenced classical algorithms. Furthermore, evolutionary pro- posals are also remarkable, and their results usually go beyond the performance achieved by the former, e.g., in terms of scalability. Precisely, G3PARM (Grammar Guided Genetic     Programming for Association Rule Mining) [11] is a novel evolutionary approach in this field. Its behaviour is based on a context-free grammar (CFG) that permits us to adapt the rules syntax to each specific application domain. G3PARM makes use of a fixed size auxiliary population comprised of those individuals (each individual represents an association rule) that exceed a certain support and confidence threshold.

On the other hand, most current RARM proposals are based on variations of these classical approaches. Apriori-Inverse [12], ARIMA [13] or Rarity [14] are some relevant examples.

In this position paper we explore the use of RARM to detect and extract infrequent rating patterns from CRS-specific data sources. To do this, we have developed an extension of the G3PARM, specially devoted to the discovery of infrequent (or rare) rules. However, this is just a first but core step in the entire process, as explained later. Note that it is necessary to analyze the rules mined too, and subsequently to apply this knowledge to the dataset evolved over time, as it can contain malicious ratings from an attacker.

This paper is structured as follows: Section II presents the whole intrusion detection process, and describes the different steps followed to fix the dataset after a potential malicious attack until intruders are completely removed from the system.

Then, Section III details the experimentation, including a de- scription of the dataset used, the experimental set-up, and how the approach is applied to the case study. The results obtained are also presented in this section. Finally, some concluding remarks and future work are highlighted in Section IV.



II. THE SUSPICIOUS ATTACKER DETECTION PROCESS  In this section we outline an overview of the intruder detection process and explore, with an example, each step required to the process be successfully completed, including the mining of rare rules, the analysis of rating patterns, and the subsequent detection of suspicious attackers.

A. An overview of the approach  The process for detecting suspicious attackers in user-based recommendation systems implies several different steps, as shown in Figure 1. Originally, the ratings dataset only contains uncorrupted user preferences per item, i.e., votes and scores casted in the course of time by users concerning to a given subject of matter (movies, books, music, or whatever). Table I, extracted from [5], shows an example of ratings using some generic kind of items, where each cell represents the specific score given by the user to an item. Scores are bound from 1 (i.e., the user dislikes the item) to 5 (i.e., the user likes the item). For the sake of clarity, this dataset will be used in this section to facilitate comprehension of the approach.

A first step to perform over the uncorrupted dataset is to mine those association rules that are comprised by infrequent combinations of ratings. A modification of the G3PARM algorithm is used with this purpose, as it returns the set of best individuals (i.e., most infrequent association rules) obtained from the final generation after the evolutionary process. Each attribute of the rule is encoded as an item with a quantitative  Dataset  Dataset ? Rare association rules  Attack injection  G3PARM modified  Analysis of the rating patterns  List of attackers  A1           C1 A2           C2 ...

An           Cn  Dataset ?? Dataset ? Attackers  Fig. 1. Overview of the intruder detection process  TABLE I EXAMPLE OF A PUSH ATTACK FAVORING THE TARGET ITEM Item6  Item1 Item2 Item3 Item4 Item5 Item6 User1 5 2 3 3 User2 2 4 4 1 User3 3 1 3 1 2 User4 4 2 3 1 1 User5 3 3 2 1 3 1 User6 3 1 2 User7 4 3 3 3 2 User8 5 1 5 1 Attacker1 5 3 2 5 Attacker2 5 1 4 2 5 Attacker3 5 2 2 2 5  value that represents the rating of the item, the support of the attribute being the number of user profiles that satisfy the attribute rating.

With the elapse of time, the uncorrupted dataset evolves and new suspicious user profiles are included (attack injec- tion), containing malicious ratings that may alter the normal behaviour of the recommendation system. For example, in Table I three new attacker profiles (Attacker1-3) have been injected to promote Item6. Then, using the rating rules pre- viously obtained from the uncorrupted dataset, new recom- mendations must be analyzed in this corrupted dataset, so we determinate whether significant suspicious changes were made     in rating patterns with time. More specifically, the support variation of the attributes comprised by the infrequent rules obtained in the previous step must be analyzed. Hence, if there is a support variation greater than a minimum threshold, then the item referred could probably be considered as attacked.

Finally, having these suspicious items, the list of attackers is obtained, and their scores removed from the dataset. As a result, a new uncorrupted dataset is obtained, so the detection process cycle begins again.

B. Discovering infrequent rating patterns  The G3PARM algorithm (see Figure 2 for a general descrip- tion) is a very efficient algorithm in mining knowledge, and allows us to obtain feasible solutions without requiring large amounts of memory. Precisely, this is a major advantage over classical proposals, which are usually restricted in terms of scalability and performance. G3PARM is an evolutionary al- gorithm that makes use of G3P to define individuals and allows us to obtain association rules from datasets with different types of attributes (i.e., both categorical and numerical attributes).

G3P is an extension of Genetic Programming (GP) [15] where each individual is a derivation tree that generates and represents a solution using the language defined by a CFG.

It permits to adapt the rules mined to each specific scope of application. In fact, in case of intruder detection, we will only consider continuous attributes, since they represent the score per rating. Figure 3 shows the CFG modified to only deal with quantitative attributes.

Fig. 2. General description of the G3PARM algorithm  Fig. 3. Context-Free Grammar used by G3PARM in intruder detection  The evaluation of each individual is performed by cal- culating the value returned by the fitness function. Unlike G3PARM, this variation of the algorithm searches for the  minimum support for each rule, this measure being defined as the ratio of records that contain both the antecedent and the consequent to the total number of records in the dataset.

Instead, our proposal defines a new fitness function (see Equation 1) to be maximized, where ???? is the support value of the association rule, and ??? states for the support threshold predetermined by the configuration parameters. Notice that G3PARM uses two genetic operators (i.e., crossover and mutation) to generate new individuals in each generation of the evolutionary process. The crossover obtains offsprings by swapping the derivation subtrees of two parents from two compatible selected nodes. On the other hand, the mutation operator selects a node from a rule and acts according to the node type. If the node is a non-terminal node, a new derivation is performed from this node; if the node is a terminal node, the genetic operator changes the value of this node at random.

??????? =  ?? ?   ????? ??? if ???? > ??? 0 otherwise  (1)  Once the new individuals are obtained by applying the crossover and mutation operators, the algorithm updates an auxiliary population by ranking individuals according to the support measure and those that exceed a certain threshold for this measure and confidence measure are included in the auxiliary population. In order to update the auxiliary population, two thresholds are applied to the support measure: a minimum and a maximum threshold. Only those individuals that have a confidence value greater than a minimum confi- dence threshold, and a support value greater than the minimum support threshold, but less than the maximum are included in the auxiliary population.

Unlike the original G3PARM algorithm, this new proposal performs an important postprocessing step once the algorithm execution is completely finished. This step takes the resulting individuals from the auxiliary population and simplifies rules that contain redundant attributes or inconsistent expressions (e.g., the rule ? > 3 ??? ? > 4 ? ? < 4 might be simplified in the rule ? > 4 ? ? < 4). Furthermore, this postprocessing also applies an order for the attributes that comprise each rule (e.g., the rule ? > 3 ??? ? > 4 ? ? < 4 would be ordered as ? > 3 ??? ? > 4 ? ? < 4).

C. Analysis of the rating patterns  For each rare rule mined by the evolutionary algorithm using the original uncorrupted rating dataset, the relative support, ?0, of every attribute should be calculated. Later, once the dataset has evolved comprising suspicious ratings, these calculations should be computed again, so each attribute will have a new support value, ?1. As a result, the increment of this relative support measure, ????, is obtained for each attribute, and serves as an input to calculate ??????? (defined by Equation 2), i.e., the probability that an attribute (or item) is attacked.

Thus, those values of ??????? greater than any other value and exceeding a minimum threshold should be considered as a potential attack to this item.

??????? = ????  ???(??0 ? ???, ??1 ? ?? ?) (2)  where ?? is the relative support obtained by dividing the absolute support (obtained by counting votes of the original dataset) by the number of instances of the corrupted dataset, i.e., none of the new instances of the dataset (the attack injection) satisfies the attribute of the rule. Similarly, ?? represents the relative support obtained if all the instances of the attack injection are satisfied by the attribute of the rule.

For example, based on Table I, the following infrequent combinations of ratings are obtained and expressed in terms of rare association rules:  Rule1: ????1 < 3 ??? ????2 > 3 ? ????6 ? 4 Rule2: ????3 ? 4 ??? ????5 > 3 ? ????4 < 2  Then, we first calculate absolute and relative supports for each attribute that appears in those infrequent rules mined from the uncorrupted dataset, i.e., counting votes of User1-8.

Rule1: absolute: [1, 1, 6] relative: [0.16, 0.14, 1.00 ] Rule2: absolute: [1, 2, 4] relative: [0.20, 0.33, 0.66 ]  After a potential malicious attack, this measure is calculated once again, but including the users Attacker1-3, too.

Rule1: absolute: [1, 1, 6] relative: [0.10, 0.10, 0.66 ] Rule2: absolute: [2, 2, 4] relative: [0.25, 0.25, 0.57 ]  From these rules and measures, the values of ?0, ?1, ??, ??, ?? and ??????? can be calculated, as shown in Table II.

TABLE II RESULTING MEASURE VALUES FROM THE EXAMPLE  Item1 Item2 Item3 Item4 Item5 Item6 ?0 0.16 0.14 0.20 0.66 0.33 1.00 ?1 0.10 0.10 0.25 0.57 0.25 0.66 ???? 0.06 0.04 0.05 0.09 0.08 0.33 ?? 0.11 0.10 0.12 0.44 0.22 0.66 ?? 0.44 0.40 0.50 0.77 0.55 1.00 ???(..) 0.28 0.26 0.30 0.22 0.33 0.33 ??????? 0.23 0.15 0.16 0.40 0.24 1.00  Notice that, according to the previous results, Item6 is the item that achieves the highest value of ??????? (i.e., a probabil- ity of 100% is properly obtained by the item under attack), and extremely difers from the other items. The attribute Item4 has the second highest probability value. According to the original scores of Item4, once the user Attacker3 votes as 3 in favor, ??????? is raised to 0.40. Whether this value is considered as a potential attack or not depends on a predetermined threshold for the value of ??????? that should be experimentally defined, depending on the dataset-specific characteristics.

??????? indicates whether an attribute is being potentially attacked or not. However, different factors may meddle in this value, so a high value of ??????? does not always im- ply that the item of interest was intentionally promoted by malicious attackers. Therefore, it is also important to analyze  how effective the potential attack is in the dataset. With this purpose, we define the influence measure, ????, as indicated in Equation 3, where ???? and ???? are the minimum and maximum values of the score rating scale allowed by the recommendation system, respectively, and ?? is the increment of the average score for an item before and after the potential attack.

???? = ????  ???? ? ???? (3) Following the Mobasher?s example, Table III shows the  average rating (?0) for each attribute using the original uncor- rupted dataset, and the average rating (?1) for each attribute using the dataset evolved. Finally, ?? shows the increment that the average score has undergone with time. Notice that negative values imply that the average score of a given item has decreased (i.e., the item has been demoted), whereas positive values imply an increase (i.e., the item has been promoted).

TABLE III ANALYSIS OF THE AVERAGE RATINGS  Item1 Item2 Item3 Item4 Item5 Item6 ?0 3.50 2.71 3.00 1.66 3.00 1.33 ?1 4.00 2.44 3.00 1.77 2.75 2.55 ?? 0.50 -0.27 0.00 0.05 0.25 1.22  With these values, Table IV gives the resulting attack influence on each attribute (or item). As can be noted, Item6 obtains the highest influence value (0.30), as well as the highest attack probability (??????? = 1.00). In consequence, we can assure that this item was promoted, despite its influence in the entire dataset is too limited (noticed that only three different attack profiles were injected). In any case, the value of ???? obtained for Item6 is significantly greater than the influence values obtained by the rest of attributes. Remember that, according to ??????? in Table II, Item4 would have been potentially attacked, too. However, the influence value clarifies this point, since such an attack would not have any influence on the dataset, i.e., no other item, except Item6, was significantly influenced by the malicious users Attacker1-3.

TABLE IV ???? MEASURE VALUES FOR EACH ATTRIBUTE  Item1 Item2 Item3 Item4 Item5 Item6 0.029 -0.010 0.000 0.005 0.005 0.300  D. Extraction of the intruders list  The final step in the attacker detection process consists in finding out which users should actually be considered as intruders. A preliminary list of attackers can be experimentally built by analyzing both the attack probability, ???????, and the injection influence, ????, as previously done in Section II-C.

So, for each item potentially attacked, we need to carefully study which new user profile satisfies the item. Then, those     profiles that only appear in the potentially corrupted dataset and stand out from others because of the values of both measures will be considered as malicious intruders. Once these profiles are completely removed from the dataset, a new iteration of the process would start with the elapse of time.

In the Mobasher?s example, Item6 was clearly identified as an attacker. Thus, according to Table I, we just need to know which users voted for Item6 with a high score (if a push attack is considered). Attacker1-3 are the malicious users that interfere in the normal behaviour of the user-based recomendation system.



III. EXPERIMENTATION AND RESULTS  Several different experiments have been carried out to detect potential attacks over an user-based recommendation system.

With this purpose in mind, the aforementioned variation of the G3PARM algorithm was executed using a specific rating-based dataset. Moreover, the whole approach proposed in Section II has been followed. All the experiments used in this study have been performed on an Intel Core i7 machine with 12Gb main memory and running CentOS 5.4. The algorithm proposed has been written in Java using JCLEC [16], a Java library for evolutionary computation.

In the following sections, we describe the dataset used, detail the experimental set-up and introduce a brief description of the attack profiles injected for the experimentation. Finally, we show the results obtained by different experiments.

A. Dataset and experimental set-up  In our experiments we used the free available Jester dataset (Anonymous Ratings from the online Jester Online Joke Recommender System1). This dataset consists of 4.1 million continuous ratings of 100 jokes from 73,421 users. Table V summarizes the configuration parameters used for the experi- mentation.

TABLE V EXPERIMENTATION SET-UP  Parameter Value Population size 50 individuals Number of generations 100 ?????????? 0.9 ????????? 0.2 Maximum number of derivations (CFG) 24 Auxiliary population size 30 individuals Confidence threshold 0.9 Minimum suppport threshold 0.0005 Maximum suppport threshold 0.125 ???? -10 ???? 10  B. Execution of the RARM algorithm  In order to obtain a diverse set of association rules, five different executions of the G3PARM modified algorithm have been carried out with five different seeds. Once the G3PARM  1Jester Collaborative Filtering Dataset. http://goldberg.berkeley.edu/ jester-data/  algorithm reaches a certain number of generations (100 gen- erations in our proposal), individuals from the auxiliary pop- ulation are returned. As explained before, this population comprises the best individuals, i.e., those that exceed a mini- mum threshold of confidence and support and have a support value less than a maximum threshold. Finally, the set of rules obtained from the auxiliary population are normalized by using the post-processing step implemented in this G3PARM algorithm version.

Table VI shows the average support and confidence of the rules obtained in each experiment. The value ? ????? is the number of rules that compose the auxiliary population once the algorithm reaches the maximum number of generations.

TABLE VI AVERAGE RESULTS FOR EACH MEASURE PER EXECUTION  Support Confidence N Rules Experiment1 0.0340 0.9796 146 Experiment2 0.0324 0.9864 146 Experiment3 0.0431 0.9742 149 Experiment4 0.0312 0.9814 149 Experiment5 0.0499 0.9835 148 Average 0.0381 0.9810 147.6000  Finally, we present some significant rules obtained in this first step of the intruder detection process, described in this paper:  Rule1: ????78 > ?2 ??? ????57 ? ?6 ??? ????57 ? ?8 ??? ????67 < 2 ? ????54 ? ?6  Rule1 normalized: ????57 ? ?6 ??? ????67 < 2 ??? ????78 > ?2 ? ????54 ? ?6  Rule2: ????100 < ?6 ??? ????82 ? ?2 ??? ????98 ? ?6 ??? ????10 ? ?6 ? ????52 ? 6  Rule2 normalized: ????10 ? ?6 ??? ????82 ? ?2 ??? ????98 ? ?6 ??? ????100 < ?6 ? ????52 ? 6  These rules show the infrequent ratings of 100 different jokes. Scores are bound from -10 (i.e., the user dislikes the item) to 10 (i.e., the user likes the item).

C. Attack injection  As we know, the main goal of an attacker is to distort the normal behavior of a filtering recommender system in order to promote or demote a specific item. Formally, a profile- injection attack has a set of profiles added to the system through an attacker with different fictitious user identities. To     conceal the real intentions of an attacker, it is necessary to rate items that are not the target item.

This paper is focused on the use of push attacks that consist in promoting an item selected by adding high ratings to the target item. It also requires some filler rating in order to simulate a normal user behavior, e.g., rating the most popular items. There are many ways to create a push attack [5], [17]:  ? Random attack. This attack assigns the highest rating to the target item and random ratings to the filler items.

? Average attack. In this attack, a previously knowledge about the system is required. The average rating of each item is assigned to each filler item. In order to promote the target item, the highest rating is assigned to this item.

? Bandwagon attack. The attacker inserts some filler ratings like the random attack, but also high rating in the most frequently rated items. This model allows the association between the most visibility items and the target item.

? Segment attack. This attack tries to reduce the knowledge needed to create a push attack by pushing an item to a group of users with specific preferences.

Focusing on the average attack and in order to create this kind of attacks (see Figure 4), a set of filler items, ?? , are randomly chosen and a random rating is generated in the domain [? ? ?, ? + ?], ? being the average rating for the item ? and ? being its standard deviation. On the other hand, the highest rating is assigned to the target item. This process must be repeated in order to generate a set of attack profiles (the attack size). The cardinality of the set ?? , ?, can also be different. In our experiments, we created six attacks (with different ? values) over three items with a low number of highest rating (joke58, joke74 and joke79). The attack size used in these experiments was 2500 that approximately represents the 10% of the dataset size. Then, every new attack profile is inserted into the dataset and a new dataset with an attack injection (dataset) is obtained.

Filler items Target item  Null itemsl in-l-i  n items  If Io It  Fig. 4. Average attack schema  D. Detection of suspicious attackers  Once we have the dataset and a set of rare association rules, we analyze the rating patterns. For each experiment, we obtain a subset of rules that have undergone a significant change in some attributes (higher than a user-defined threshold probability). For these rules, the ???? measure will indicate the current item attacked.

With a threshold probability of 80%, more than 30 rules were obtained as shown in Table VII. All of these rules present  the item attacked in their expression (with 92% or 100% of attack probability). In this case, no rules with a significant change in a filler item have been found. The values of the ???? measure are always higher than zero in the attacked items.

For the rest of attributes (filler items) less than zero values are obtained so the suspicious item (the item with a high attack probability) is really the attacked item.

TABLE VII NUMBER OF RULES WITH THE ATTACKED ITEM (P = 0.8)  Attacked item ? = 20 ? = 30 ? = 40 ? = 50 ? = 60 Joke58 32 32 32 32 32 Joke74 37 37 37 37 37 Joke79 36 36 36 36 36  Using this threshold probability, the number of filler items inserted in the dataset is not significant, because the number of rules obtained for each ? value is the same. With a high value of the threshold probability, only the attacked item presenting a great change in the corrupted dataset will exceed this threshold, because the filler items are inserted with a less frequency than the target item.

If we change the threshold probability to 50%, some new rules are found with the item attacked (Table VIII). If the number of filler items increases (? takes values over 50), there will be some filler items that will appear in the new dataset close to the frequency of the target item. Thus, these items can be confused with the items attacked. Table IX shows the number of rules with a higher change than the threshold probability caused by the high appearance of filler items in the attack. In these cases, the filler items can be considered to be attacked items, because their attack probability is higher than the real target item probability. When this happens, the ???? measure gives us the current influence of the attack in the dataset. For example, one of the association rules obtained in our experiments has one filler item with a probability to be an attack of 50% and the target item of 20%. Yet the influence measures obtained were -0.006 for the filler item and 0.022 for the target item.

TABLE VIII NUMBER OF RULES WITH THE ITEM ATTACKED (P = 0.5)  Attacked item ? = 20 ? = 30 ? = 40 ? = 50 ? = 60 Joke58 44 44 44 44 44 Joke74 37 37 37 37 37 Joke79 39 39 39 39 39  TABLE IX NUMBER OF RULES WITH FILLER ITEMS  Attacked item ? = 20 ? = 30 ? = 40 ? = 50 ? = 60 Joke58 0 0 0 51 265 Joke74 0 0 0 81 279 Joke79 0 0 0 143 359

IV. CONCLUDING REMARKS AND FUTURE WORK  This position paper has shown a novel proposal for the detection of malicious attack injections in user-based rec- ommendation systems. A core step in this process consists in mining infrequent combinations of user ratings on items (e.g., movies, books, music, and so on). With this purpose, we have introduced a variation of our previous algorithm G3PARM, that is specially devoted to rare association rule mining. Since G3PARM is an evolutionary algorithm that uses G3P, we have taken advantage of some important character- istics aforementioned, such as its adaptability to the scope of application as well as its scalability, which allows it to face up to large datasets comprising a great deal of attributes (or items). Precisely, this latter point is an usual shortcoming of current attack detection proposals.

The attack probability ??????? and the ???? measure used in the analysis of the rating patterns allows us to extract the suspicious attacked items, state the real influence of these items and, finally, extract the target item that the attacker promoted. In our experiments, both the attacked items and some filler items were catalogued as suspicious, but the filler items are discarded later thanks to the influence measure.

As a future work, we plan to test different types of attacks, because CRD are susceptible to a wide range of attacks. In this respect, we will be able to prove our new detection process in more complex attack injections like the bandwagon attack.

Although most of the current proposals analyzed datasets with attacks, we also propose to explore how this method would react in non-simulated environments, i.e., where the increment of the dataset presents both usual rating profiles and attacker profiles.

