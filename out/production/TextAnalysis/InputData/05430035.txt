Mining Several Kinds of Temporal Association Rules Enhanced by Tree Structures

Abstract?Market basket analysis is one important appli- cation of knowledge discovery in databases. Real life market basket databases usually contain temporal coherences, which cannot be captured by means of standard association rule mining. Thus there is a need for developing algorithms, that reveal such temporal coherences within this data. This paper gathers several notions of temporal association rules and presents an approach for mining most of these kinds (cyclic, lifespan- and calendar-based) in a market basket database, enhanced by two novel tree structures. We called these two tree structures EP- and ET-Tree, which are derived from existing approaches improving standard association rule mining. They are used as representation of the database and thus make the discovery of temporal association rules very efficient.

Keywords-Knowledge Discovery in Databases; Market Bas- ket Analysis; Temporal Association Rule Mining

I. INTRODUCTION  Organizations of many different areas are collecting sev- eral kinds of data. Since this resulting bulk of data might contain usual information, and since it is far too big for manual analysis, algorithms for automatically discovering potential useful information are developed. One of the major tasks in this area of data mining is association rule mining (ARM). An association rule (AR) is an implication of the form X ? Y , where X and Y are two itemsets. A typical application of ARM is market basket analysis, for instance in a mall, where customer transactions are recorded in the cash register for later analysis. An itemset in this example could be {beer, potato crisps}, which means that a customer bought together the two items beer and potato crisps. If more transactions support this itemset an AR {beer} ? {potato crisps} could be generated from the itemset, which expresses that customers, who buy beer, also likely buy potato crisps. Two measures for the interesting- ness of such an AR are support, which states how often a rule is applicable to a given database, and confidence, which is stated in our case by the ratio of transactions that contain potato crisps in the transaction that contain beer.

Time, for the example of market basket analysis stated by the timestamp of a customer?s transaction, does not play a major role in general data mining. The time component is processed like any other component of the given data. But as real life shows, in many cases time needs particular attention.

Imagine for instance the itemset of the example above: Regarding the whole day, beer and potato crisps are bought  together probably relatively seldom, which will be expressed by a low support value for this itemset. But regarding only the evening and all transactions that occurred in this time, for example from 7-9PM, the amount of transactions that support {beer} ? {potato crisps} in this segment of the database will probably be much higher. Depending on the minimum value for support that is needed to discover an AR like that, standard ARM might overlook this rule, whereas a temporal approach would find it due to its temporal nature.

The contribution of this paper is an approach for mining several kinds of temporal association rules (TARs) which makes use of two novel tree structures. Most of the existing approaches are limited to the discovery of one specific kind of TARs, whereas our approach considers several kinds, namely cyclic, lifespan- and calendar-based ARs. The two novel tree structures that are used are the EP- and the ET- Tree, which represent a given database and allow to mine TARs very efficiently. As a first step in constructing the ET- Tree, the database is reorganized in one single pass. The EP-Tree is an extended version of the P-Tree [1], which is used to speed up standard ARM, extended with additional temporal information. Due to its special structure the EP- Tree can be used to calculate the support of itemsets and to collect important temporal information with only little additional effort. These pieces of information, namely the itemsets, their standard support and lists of their timestamps, are stored in the ET-Tree, which provides the basis of our approach to efficiently discover several kinds of TARs.

Besides our tree-based approach for TARM, we present an overview of several kinds of TARs, discuss some related work and demonstrate the superiority of our approach in a short evaluation.

The rest of the paper is organized as follows: Section II provides the basic knowledge about ARM in general, whereas Section III provides the special knowledge about TARM and some approaches that are of interest for this paper. After introducing these foundations, we briefly dis- cuss some further related work in Section IV. The EP- Tree, the ET-Tree and related tree structures are presented in Section V, which also integrates them in the TARM process.

Details about the implementation of our tree-based approach for TARM are given in Section VI, and an evaluation is contained in Section VII. Finally, we present our conclusion and identify directions for future work in Section VIII.

DOI 10.1109/eKNOW.2010.16    DOI 10.1109/eKNOW.2010.16

II. ASSOCIATION RULE MINING  This section presents the fundamental terms of association rule mining (ARM). It deals with ARM in general, i.e. ordi- nary ARM without regard to temporal coherences. Temporal association rule mining is presented in the next section.

The following definitions are taken from [2]. Let I = {i1, i2, ..., id} be the set of all items in a market basket database and T = {t1, t2, ..., tN} the set of all transactions.

Every transaction ti consists of a subset of items Xi ? I , called itemset. Items in an itemset are supposed to be ordered according to the lexicographic order. An itemset with exactly k elements is called k-itemset. A measure for the interestingness of an itemset X is its support count.

The support count is the number of transactions in T , which contain the itemset X . Formally, it can be stated as ?(X) = |{ti | X ? ti, ti ? T}|.

An association rule is an implication expression of the form X ? Y , where X and Y are two disjoint itemsets.

The interestingness of an AR can be measured in several terms, two terms that are important for this paper are support and confidence (cf. [3] for more terms and details).

Support determines how often a rule is applicable to a given database, and confidence determines how frequently items in Y appear in transactions that contain X . They are defined as support(X ? Y ) = ?(X?Y )N and confidence(X ? Y ) = ?(X?Y ) ?(X) . An AR with a very low support can simply occur  coincidentally and can thus be uninteresting for the outcome of the market basket analysis. To avoid this, a threshold minsup for the minimal support of a rule is given by the user. Itemsets that have a support higher than minsup are called frequent or large itemsets. A maximal large itemset is a frequent k-itemset, for which applies that there is no frequent l-itemset in I , with l > k. The confidence is a measure for the reliability of an AR and thus again a threshold is defined: minconf for the minimal confidence a rule must have in order to be discovered.

The task of association rule mining in a given market basket database is the discovery of every AR, whose support is larger than minsup and whose confidence is larger than minconf. It can be decomposed in the two subtasks of (1) finding all frequent itemsets, and (2) generating rules from frequent itemsets.

Much interesting work has been done and many algo- rithms have been developed for ARM. Subtask 2 is a task rather easy to solve: Given frequent itemset Z, generate every two possible disjoint subsets X and Y of Z, with X ? Y = Z, and check whether confidence(X ? Y ) ? minconf. For this reason we sometimes switch between the terms itemset and AR in this paper. For more information about the generation of rules confer [4].

The remaining subtask 1 is the crux of the discovery of ARs, thus we will focus on the generator of frequent itemsets in this paper. The probably best-known algorithm  for solving it is the Apriori Algorithm [5], which makes use of the following monotonicity property: an itemset X can only be frequent, if every subset of X is frequent too.

Thus, the Apriori algorithm for finding frequent itemsets starts by creating a candidate set of 2-itemsets, by means of composing all frequent 1-itemsets, which are easy to find by simply counting in the database. This candidate set is pruned by checking the minsup constraint and afterwards all frequent 2-itemsets are found. In the next step the candidate set of all possible 3-itemsets is composed from the frequent 2-itemsets, it is pruned by checking the minsup constraint and so all frequent 3-itemsets are found. This step is repeated until no more frequent k-itemsets come up. For more details about the Apriori principle see [5], for overviews of other ARM approaches confer [3] and [6].



III. TEMPORAL ASSOCIATION RULE MINING  In this section we present the basic idea of temporal association rule mining (TARM) and some interesting ap- proaches.

Formally, the only difference in the database for TARM is the fact that every transaction has a timestamp. In the example of market basket analysis in a supermarket these timestamps denote the time when a customer purchases his products. So most of the definitions of Section II can be used in temporal data mining as well, except for the definition of support, which has to be modified. There are many different kinds of temporal association rules (TARs) one could think of, e.g., from events that happen sequentially [7], cyclically [8], periodically [9] or in special times which can be described by calendar-based patterns [10], thus there are many different kinds of support definitions.

A. Lifespan-Based Temporal Support  One straightforward approach is [11], which regards the lifespan of an itemset. Intuitively the lifespan of an itemset X is the span of time in which X occurs in the transactional database T , and the temporal support of X is defined as the number of occurrences of X in T divided by the number of transactions which happen in the lifespan of X . This approach makes sense, because in large databases one could find information related to products that do not necessarily exist throughout the whole time when a database was gathered. With the standard definition of support products or itemsets could be found which already have been discon- tinued at the time the mining process was performed, and new products that were introduced at the end of the time in the database might not be found due to support restrictions.

This problem is solved by an alternative definition of the temporal support, which is stated formally as follows.

We assume that every transaction ti ? T is associated with a timestamp, denoted by t(ti), which stands for the time when the transaction occurred. Naturally, a total order <t is defined, where t(t1) <t t(t2) denotes that transaction     t1 happens before t2. Let X ? I be an itemset. The lifespan of the itemset is defined as the interval IX = [t(ti), t(tj)], where ti is the first transaction, which contains X , and tj the last transaction in T , with t(ti) <t t(tj). Let T [IX ] denote the segment of the database T , which contains all transactions, that happen in the lifespan IX of X . Then the temporal support of X is defined by tempsup(X) = |?(X)||T [IX ]| .

B. Cyclic Association Rules  Another interesting approach is [8], which introduces the notion of cyclic ARs. An AR is called cyclic, if it represents regular cyclic variations over time. An example for this kind of ARs is the rule {beer} ? {potato crisps}, which we already introduced in the abstract and Section I. It is an example of a rule which support will be probably relatively low during the whole day, but in certain regular time intervals, e.g., every day from 7-9PM (and in the corresponding database segment, respectively), it will have probably a much higher support. To state this approach formally some definitions and another perspective of time are needed, which will be explained in the following.

We assume that time is given in a fixed unit ? , and that the i-th time interval, i ? 0, is denoted by ?i, which corresponds to the time interval [i ? ?, (i+ 1) ? ? ]. Let T [i] denote the set of transactions that were executed in ?i. We refer to T [i] as time segment i. The cyclic support of an AR X ? Y in the time segment i is the fraction of transactions in T [i] that contain the itemset (X ? Y ). The confidence measure for T [i] is defined analogously. A cycle c is a tuple (l, o), which consists of a length l and an offset o, 0 ? o ? l, both given in time units. An AR is said to have a cycle c = (l, o), if it holds in every l-th time unit starting with time unit ?o. An AR that has a cycle is called cyclic. The beer and potato crisps rule for instance would have the two cycles c1 = (24, 19) and c1 = (24, 20), that denote ?every 24 hours in the 19th hour? and ?every 24 hours in the 20th hour?, which is is exactly every day?s time from 7 till 9PM.

C. Calendar-Based Association Rules  An approach that scales even more [10], which tries to discover TARs that hold in certain time intervals, that are specified by a former defined calendar schemata. An example for such a calendar schema could be (year, month, day), and in this schema for instance every year?s Christmas Eve could be represented by the tuple (?, 12, 24), where ? denotes every arbitrary integer in the domain of the accordant attribute, in this case year. As well as in both foregoing approaches, the support measure is calculated relatively to the number of the transactions that occur at the specified time intervals. Thus, we omit the formal defi- nitions of calendar-based support, refer to [10] and give one more example for clarification instead: In the calendar-based schema (month, day, hour) our beer and potato crisps rule would hold in the time represented by (?, ?, 19)? (?, ?, 20),  because this denotes the 19th and 20th hour of every day in every month, what refers to the time from 7 to 9PM.

Obviously, calendar-based ARs can express many cyclic ARs, depending on the calendar schema use. In addition to that, the calendar-based framework can be extended to ARM with respect to fuzzy match, by means of a threshold m (0% ? m ? 100%) which expresses, in how many cases a certain rule has to hold.

D. Other Approaches  Two other TARM approaches are [7] and [12]. The first one deals with sequential patterns, i.e. with patterns that can express ARs like the following one: People who rent the DVD ?The Fellowship of the Ring? and then ?The Two Towers?, will most likely rent the DVD with the third part of the ?Lord of the Rings? trilogy, namely ?The Return of the King?, thereafter too. Sequential patterns in this case just state that if someone rents the first and then the second movie, he will most likely rent the third movie afterwards some day, but they do not state when this happens. Such kinds of ARs can be captured with the second approach mentioned above: A rule X ?t Y expresses, that if X occurs, Y will occur within the time span t.



IV. FURTHER RELATED WORK  After Section II and Section III introduced the general foundations of ARM and TARM, as well as some approaches for TARM (cyclic AR [8], lifespan- [11] and calendar- based AR [10]) that are of special interest for our tree- based approach, this section presents some further related approaches.

An approach directly connecting two of the above men- tioned approaches is [13]. It is a rather straightforward extension of [11] and [10], which results in a system for mining two kinds of TARs (lifespan- and calendar-based) by means of only a small alteration of the primary algorithms.

Another straightforward approach is [14], which combines the approach for calendar-based ARM [10] with tree struc- tures. These tree structures for standard ARM are the P- and the T-Tree [15], on whose base we also developed our EP- and ET-Tree for improving TARM. In standard ARM one P- and one T-Tree is created for the whole database, which yields a good speed-up. The temporal version from [14] creates one P- and one T-Tree for every possible calendar- schema and thus yields a speed-up too, but on cost of a huge overhead. (In contrast, our approach for TARM needs only one EP- and one ET-Tree for representing the whole database, cf. Section V.)  So far all these works had their focus on events existing at one or certain points in time. An interesting approach that focuses on temporal intervals is ARMADA [16], which generates ?richer? interval-based TARs, what corresponds approximately in merging ?smaller? TARs.

Further information about TARM can be found in the two overview papers [17] and [18], and in [19], which provides a large bibliography of temporal data mining research.



V. EP-TREE AND ET-TREE This section presents the idea of the EP- and the ET-  Tree, which are the basis of our tree-based approach for TARM. In addition to that, it presents three further tree structures, namely the SE- [20], the P- and the T-Tree [1].

The SE-Tree is a simple tree structure that contains all itemsets enumerated from the items, the node from all other mentioned tree structures are arranged in this manner. The P-and the T-Tree can be used for speeding up standard ARM, and this section shows how to transfer this quality to TARM.

The ET-Tree is a data structure that stores itemsets together with their (standard) support and temporal infor- mation about their occurrences. With this information it is easy to calculate the temporal support of an itemset and to analyze it for further temporal coherences. The ET-Tree is built level-by-level up to a certain size on base of the EP- Tree, which itself is inferred from the P-Tree [1]. The EP- Tree extends the P-Tree with temporal information. Both make use of the set enumeration framework developed in [20], through which structure the process of calculating support and gathering temporal information about itemsets is simplified. The creation algorithms of the EP-Tree scans the database and reorganizes it in only one pass in form of the EP-Tree, from which the ET-Tree is built in one pass.

For more clearness about the basic idea how the EP-Tree is created and works, we first regard algorithm 1, which is a very simple algorithm that scans the transactional database T in one pass, in order to calculate the support of every itemset X and collect the timestamps of every transaction, in which X is contained. The number of database accesses is minimal, N in a database containing N transaction, but the number of computational steps and the space required is exponential to the number of different items. Thus, this algorithm is infeasible for databases that contain many items, e.g., 1,000 or more, which is usual in market basket analysis.

for i = 1, ..., N do forall subset s ? Xi do  begin supportCount(s)++; timestampListOf(s).add(t(ti));  end end  end Algorithm 1: A simple brute force algorithm for cal- culating support and gathering temporal information of every subset s ? I . The itemset contained in transaction ti ? T is denoted by Xi, the timestamp of ti by t(ti).

Let us assume that during the pass over the database in algorithm 1 a transaction is read that contains an itemset  {A,B,D}. This single itemset would cause the incrementa- tion of the support counts for {A,B,D}, {A,B}, {A,D}, {B,D}, {A}, {B} and {D}, and it would add a timestamp to every timestamp list of theses 7 sets. This is much effort for one single set and actually not necessary, because the changes could be inferred subsequently from the information stored for {A,B,D}.

We formalize this interference by defining the expressions partial support and total support. From this point on we omit the treatment of the temporal information for a while, because it would make both the understanding and the explanation of the approach unnecessarily more complicated.

The temporal information can be handled analogously to the support, what we will point out in detail later on. The partial support PX of an itemset X is defined as the number of transactions, whose itemsets are exactly equal to X . The total support TX of an itemset X can then be calculated by evaluating TX =  ? ?Y :Y?X PY .

Obviously the support values calculated by algorithm 1 are total support values. Algorithm 2 makes use of the principle of calculating total from partial support, and is thus more efficient than algorithm 1. Under the plausible assumption, that databases with realistic data contain a high degree of duplication, this algorithm again will be significantly faster.

for i = 1, ..., N do begin  PXi++; P.add(Xi);  end end forall X ? P do  forall Y ? T, Y ? X do TY = TY + PX ;  end end  Algorithm 2: A efficient algorithm for calculating the support of every itemset of the database T . The set P contains all occurring itemsets, T the total support values of every itemset in P , both initially set to zero.

To renew the example with itemset {A,B,D} that is contained in a transaction ti ? T , we now regard the set of all subsets of I = {A,B,C,D} presented as tree and arranged according to the set enumeration framework mentioned at the beginning of this section. (The arrangement of the nodes is exactly the same as in Figure 1.)  The arrangement of the subsets is done according to the lexicographic order, where every node represents a certain subset. It is easy to see that this tree-based representation can aid in the support calculation and the gathering of temporal information: While walking through the tree to a certain node - or a certain set, respectively - starting at the root node, several other nodes are traversed, which all represent subsets     of the certain set of the destination node. This can be used to accumulate an interim support count in the nodes traversed, which eases the calculation of the total support later on.

Algorithm 3 describes this procedure of inscribing a single itemset of the database in the tree structure. The length of the way from root node to a certain node is at most N . The tree filled like this without temporal information is exactly the P-Tree (Partial Support Tree), which was introduced in [1], and as already mentioned, it can easily be extended with temporal information to the EP-Tree, what we will explain after the rest of the basic idea is presented.

forall nodes X do P (X) = 0; Q(X) = 0;  end for i = 1, ..., N do /* for every database entry do */  X = root node; while node X 6= NULL do  if Xi ? X then /* if itemset Xi ? X */  Q(X) + +; if Xi = X then /* if itemset Xi = X */  P (X) + +; exit while loop  else if Xi ? X then /* if itemset Xi ? X */  X = eldestChildOf(X); else  X = youngerSiblingOf(X);  end Algorithm 3: Accumulating partial and interim support counts during one pass over the database. In this algo- rithm X denotes both an itemset and the node in the tree, that contains the itemset.

After algorithm 3 is executed for every database entry, the P-Tree is filled and completed, and its nodes contain itemsets, partial support counts and interim support counts.

The value of the interim support count Q(X) in the node that contains itemset X is Q(X) =  ? ?Y :(Y?X, X<lY ) P (Y ),  where <l denotes the lexicographic order. With this it is possible to calculate the (total) support of an itemset X by evaluating the following expression:  T (X) = Q(X) + ?  ?Y :(Y?X, Y <lX)  P (Y ) (1)  By now the basic idea is obvious: the itemsets of the database are inscribed itemset-by-itemset in the P-Tree using algorithm 3. After that the total support of every itemset can  Figure 1. An example of an EP-Tree for P({A, B, C, D}), containing some interim support counts and lists of timestamps (indicated by [...]).

be determined by adding the value of the interim support count from the according node in the P-Tree and some partial support values, given by equation 1, which makes the process very efficient.

As already mentioned, the EP-Tree has the same structure as the P-Tree, but additionally it has two lists that contain timestamps in every node, a partial and an interim list. Every time the interim support count of a node Y is increased on the way to a node that contains an itemset X , the timestamp of the current transaction that is being inscribed is added to the interim list of node Y , and every time the partial support count of X is increased, the according timestamp is added to the partial list. Thus the complete list of timestamps for an itemset X can be determined in the same manner the total support of itemset X is calculated, namely by accumulating the timestamps of the partial list stored in the node that contains X and the timestamps of some partial lists directed by equation 1. The complete timestamp list contains every timestamp that belongs to a transaction, where itemset X was part of, or in other words, this list contains all points in time, when a itemset has occurred. This list is a formidable basis for mining several kinds of TARs, and our prototype system described in Section VI makes use of this. An example of an EP-Tree is given in Figure 1.

It is important to state that we used a static tree with nodes for every element of P(I) only to illustrate the procedure.

The P- and the EP-Tree both must be built in a dynamic manner, which is explained in detail in [15], in order to be feasible. By doing so the trees consist of considerably less nodes, while the basic arrangement and thus the desired functionality are still given.

In [15] another tree structure is introduced, which is in- tended to find frequent itemsets: the T-Tree for representing the target set of items for which the total support is to be computed on base of the P-Tree. The nodes of this tree again represent the itemsets and are designed to contain their total supports. Its structure is the dual structure of the P-Tree, i.e.

that every subtree includes only supersets of its root node which contain an attribute that precedes all those of the root node (see Figure 2). In order to prevent an exponential size in the number of items, it is built up level-by-level, starting     Figure 2. The T-Tree for P({A, B, C, D}).

with all 1-itemsets, for which the total support is calculated by means of the P-Tree. According to the Apriori principle the support of the supersets of a certain itemset X can only exceed the threshold minsup, if the support of X is greater than minsup. Thus, if the T-Tree is used to find frequent itemsets, only those nodes of the second level have to be created, for which the support of the parent node is adequate.

The following informal algorithm (algorithm 4) displays this process, which ensures that the size of the tree is only linear in the size of the number of frequent itemsets.

set k = 1;1 build level k in the T-Tree according to its2 structure; calculate the support of every node in level k by3 means of the P-Tree; remove any node in level k which support is lower4 than minsup; increase k by 1;5 build level k in the T-Tree according to its structure6 (just nodes that have a parent); repeat line 3-7 until no new nodes are adequately7 supported;  Algorithm 4: Informal T-Tree creation algorithm.

The ET-Tree is the extended version of the T-Tree. The main difference is the fact, that all nodes contain a complete list of timestamps of the accordant itemset. It is built in almost the same manner, but without pruning of itemsets (line 4), because otherwise it would not be possible to find TARs, whose standard support is too small for being discovered. Thus there are three possibilities for discovering different kinds of TARs as introduced in Section III:  i) Decrease minsup to a smaller value in order to find a larger set of frequent itemsets, which can be analyzed for temporal coherence (with the original larger value of minsup for an itemset to be large).

ii) Decrease minsup to a minimum value (an itemset has to occur at least once in the database) and abort the algorithm at a certain level k-max in the tree. The resulting set of frequent itemsets can be analyzed for temporal coherence (with the original larger value of minsup for an itemset to be large).

iii) Leave everything as it is and discover only TARs whose support is high enough in the standard sense.

Obviously, the adjustment of the parameters minsup and k-max directly effects the size of the ET-Tree and the number and kinds of TARs that can be discovered.



VI. IMPLEMENTATION In this section we present some details about the imple-  mentation of our approach as a prototype system, which allows the mining of different kinds of TARs by using the tree structures mentioned in Section V, and we explicate some further interesting points.

Our whole prototype system is implemented in Java.

Following the idea of Section V straightforward, it consists of the following three major components: ? A tree maintenance component to read the database,  construct the EP-Tree and provide the possibility to construct the ET-Tree with several options, among oth- ers the adjustment of minsup and k-max as discussed at the end of the preceding section.

? A temporal analysis component, that handles inputs in the form of a T-Tree or simple in form of an itemset with a complete list of all its timestamps gained by the means presented in Section V. This component is capa- ble of discovering TARs as presented in Section III-A to Section III-C (lifespan-based, cyclic and calendar- based ARs), and of course of discovering standard ARs.

? A main component that manages the other two compo- nent, which is capable of processing optional ?hints? given by the user and also offers several heuristics for the combination of parameters.

The tree maintenance component is based on an im- plementation [21] of the Apriori-TFP algorithm [15] for standard ARM, extended by the treatment of temporal in- formation as described in Section III and Section V. Simply spoken, the input of the temporal analysis component is an itemset together with its complete list of timestamps. On this base the calculation of the temporal support as described in Section III-A is straightforward. The support notions for the discovery of cyclic and calendar-based TARs are implemented by making use of sliding window techniques with several different parameters, like window size, step size, number of windows that are regarded in one step and the form of the sliding window.

The main component manages the two other components and provides them with their parameters. The parameters can be adjusted straight by the user, or by use of several heuristics to combine the mining of the three different kinds of TARs, and the user can also optionally enter some ?hints? about the range of the parameters. The parameters play an important role what kinds of ARs can be discovered and how many space and time is required for building and processing the trees. The most important parameters in this relation are minsup and k-max, as already noted at the end of Section III, and thus the main component tries to find a balance between effort and finding every possible TAR.

Finding every possible TAR exceeding a given support is possible in a small database, but if the dataset grows bigger this task should be constrained to certain kinds of rules or granularities, because otherwise the run-time will be rather long and the needed space rather large (cf. Section VII).



VII. EVALUATION  This section describes the evaluation of our tree-based approach for TARM. We briefly present the generator that we used to create test datasets that contain temporal coher- ences and present our results in comparison to several other approaches of TARM.

The datasets we used for testing purposes were created by a synthetic dataset generator [22]. For this evaluation we decided not to work with real life datasets, because unfortunately up to today, there are only very few real life market basket datasets, that contain timestamps (which is a natural precondition for TARM), available to the public.

We conducted some experiment with a small set of real life market basket data from a supermarket, which yielded results quite comparable to synthetic dataset, but which were less meaningful due to the small size. In addition to that, real life datasets might contain interferences, e.g., through seasons or mode, and thus do not provide a totally controllable testing ground, whereas the use of a dataset generator enables us to remain in total control of every phenomenon that could occur in the generated data. The dataset generator we used bases on the basic idea of IBM?s Almaden Research Center Data Generator [4] for modeling general customer behavior and the idea of [8] for modeling cyclic temporal coherences, and is augmented with mechanisms to create calendar-based and lifespan-based temporal coherence. In addition to that, it models customer group behavior. Timestamps are created adapted to the mechanism of [23], which considers several user behavior studies in order to generate data with a distribution of timestamps that is very similar to real life.

All in all the generator produces timestamped market basket datasets, that are very close to real life. The datasets contain temporal coherences, so that algorithms for temporal data mining can find three different kinds of TARs in the data, depending on the adjustment of the appropriate parameters.

These three different kinds are cyclic, calendar-based and lifespan-based ARs, and thus the created datasets are an one- in-all solution for the evaluation of our tree-based TARM approach.

We set up several series of experiments. All experiments were conducted on an Intel Core 2 Duo 3.0 GHz desktop PC running Windows Vista with 3 GB of main memory. The first three series of experiments follow the tree possibilities at the end of Section V: in series 1 we set minsup to a smaller value than normal in order to find a larger set of frequent itemsets, which are analyzed for temporal coherence with the original larger value of minsup. In series 2 we set minsup to the minimum value (an itemset has to occur at least once  in the database) and we pruned the T-Tree at a certain level k-max (where again the original larger value of minsup is used as constraint for an itemset to be large), and in series 3 we used a ?normal? value for minsup, i.e. a value for standard ARM. As expected, every standard AR was found in all three series, and in series 3 only TARs were found, that were already found by standard non-temporal ARM algorithms. Series 1 also made clear, that with decreasing minsup more TARs are found, but only in series 2 all contained TARs have been found, depending on the size of the underlying frequent k-max-itemsets, and of course with a larger run-time.

Another series of experiments (series 4) with the use of the heuristics mentioned in Section VI decreased the run- time in a massive way, but some TARs were missed.

To compare the results of our approach we implemented the algorithms proposed in [5], [11], [8], [10] for mining standard, lifespan-based, cyclic and calendar-based ARs, respectively, in Java as well and run them on the same datasets. For discovering all three kinds of TARs we had to run each of the corresponding algorithms one after the other, to what we will refer simply as sequential algorithm.

Table I shows the results of our evaluation for one large conventional dataset in terms of run-time and number of discovered TARs for series 1-4 of our prototype system and for the sequential algorithm. From table I it is easy to see, that our approach clearly outperforms the other approaches.



VIII. CONCLUSION AND FUTURE WORK  In this paper we presented a tree-based approach for mining several kinds of TARs (cyclic, lifespan- and calendar- based), which makes use of two new tree structures, namely the EP- and the ET-Tree. These trees provide the basis for the efficient discovery of several kinds of different TARs, that were also presented. We have shortly described our implementation of a prototype system, and presented an evaluation of our approach on synthetic datasets, which proves that our approach works very well.

There are some issues left that have to be examined more in depth in order to enhance the basic idea and the prototype system. First of all, at the moment our approach allows to detect three different kinds of TARs, namely cyclic, temporal support based and calendar-based. In Section III-D we have presented two more kinds of interesting TARs (sequential patterns and ARs of the from X ?t Y ), whose integration in our approach would be an enrichment. In addition to that, pruning techniques especially regarding the construction of the T-Tree could make our approach more efficient. Another direction for future research is the adaption of other tree structures for our approach. The FP-Tree [24] for example is used to speed up standard ARM as well as the P- and the T-Tree, and thus an adapted version is possibly an alternative to our tree structures. The dataset generator we used for     experiment accordant parameters run-time (in seconds) number of discovered TARs series 1 minsup= 0.01 32.241 4,313 series 2 minsup= 1  10,000 , k-max= 4 42.189 7,281  series 2 minsup= 1 10,000  , k-max= 6 49.189 9,956 series 3 minsup= 0.05 19.500 1,949 series 4 minsup= 0.05 35.231 9,157 sequential algorithm minsup= 0.05 122.400 9,956  Table I EVALUATION RESULTS FOR A CONVENTIONAL DATASET (CONTAINING 10,000 TRANSACTIONS, 1,000 ITEMS, AVERAGE SIZE OF LARGE ITEMSETS IS  4). EXPERIMENTS WITH THIS DATASET SHOWED THAT A REASONABLE MINSUP VALUE FOR STANDARD ARM IS 0.05.

evaluation purposes generates three kinds of temporal coher- ences, but of course tests with other datasets, which possibly contain more than these kinds of coherences or interfering coherences, like large real life datasets, would be desirable, in order to evaluate our approach in an environment, that is not totally controlled, too.

