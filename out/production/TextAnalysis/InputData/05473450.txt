A Study of Improving Apriori Algorithm

Abstract?The Apriori algorithm is one of the most influential apriori for mining association rules. The basic idea of the Apriori algorithm is to identify all the frequent sets. Through the frequent sets, derived association rules, these rules must satisfy minimum support threshold and minimum confidence threshold.

This paper presents improved algorithms, mainly through the introduction of interest items, frequency threshold, to improve the mining efficiency, dynamic data mining to facilitate the needs of users. Confirmed by many experiments, this algorithm is better than traditional algorithms in time and space complexity.

Keywords- Apriori algorithm; dynamic mining; interest item; frequency threshold

I.  INTRODUCTION With the development of artificial intelligence, database  technology and mathematical statistics, the transaction database for mining association rules is an important research direction for data mining. Association rule is an important research in the knowledge discovery research. In large amounts of data, some interesting correlation would find in itemsets or related links[1,2].

The mainly technology of data mining is association rules, clustering, rough sets, neural networks, genetic algorithms and so on. Association rules are a group of objects in the database which associated with the relationship between the rules. It is widely used in data mining. It can be divided into two sub- problems [3,4].One is to find the frequent item sets which meet the minimum support. The other one is using the frequent item sets to generate association rules, according to the minimum credibility. The first problem is the overhead of time and space, so most of current association rule mining algorithms are committed to improving the efficiency to find frequent item sets. There are some ways to extend the association rules, such as the numeric association rules [5], multi-level association rules [6].

A large number of mining association rules algorithm has proposed. In this rules, Apriori algorithm is the most classical algorithms. This article is based on the Apriori algorithm by introducing the number of interest items and frequency threshold to reduce the times of database search. Dynamic mining can be well positioned to meet customer?s need, and improved the efficiency of the algorithm.



II. ASSOCIATION RULES Association rules derived from analyzing the problem of  supermarket shopping. Using this rules to detect the link between different commodities in the database. These links reflect the patterns of customer buying behavior. Found such a link can be applied to analyze customer shopping, directory design, commercial advertising mail. The area of research in data mining for association rules mining was more in-depth research. It has carried out a number of association rules mining algorithm. At present, the association rule mining has been successfully applied in various related areas. The data mining is one of the most mature, most important and most extensive research details [7, 8]  A. Related Concepts In order to facilitate description of our algorithm, we  hereby agree: i in this transaction database is a property, }...,,{ 21 niiiI =  is a collection of all attributes in this transaction database, )}(,...,,{ 21 nmiiiT m ?= is a transaction,  },...,,{ 21 nTTTD = is a transaction database, D  is indicated the number of transaction database transactions. In this place, the elements in },...,,{ 21 nTTTD = can be repeated. In order to avoid duplication of transactions are covered .In this article, we give a unique mark to each of transaction in the transaction database TID.

Supportive degree of the itemset )(XSup is the proportion how much transaction X included in the entire database D.

Confidence )( BAConf ?  of association rule BA?  is the conditional probability that itemset B occurred in the condition that itemset A have occurred. Minimum support threshold  Supmin  is the minimum one which item sets must be met in the mining process. Minimum confidence threshold Confmin is the minimum one which association rule must be met.

Itemsets whose supportive degree are greater than or equal to  Supmin  are defined as frequent itemsets.

B. The introduction of traditional Apriori algorithm Firstly, we need dig out the frequent 1-itemsets, then,  continue to use the recursive way to mining frequent k-itemsets (k> 1).Specific practices is to dig out the candidate frequent k- itemsets, according to the smallest minimum confidence  Supported by National Natural Science Foundation of China (Grant No. 60773008), Key Laboratory of Aerospace Information Security and Trust Computing of Ministry of Education., National Science Foundation for Post-doctoral Scientists of China, Natural Science Foundation of Hubei Province and ?Dawn? Program of Wuhan (No. 200950431183).

threshold Supmin  to filter some candidate, to get frequent k- itemsets. Finally, combine all of the frequent k-itemsets(k>0).

The rule's confidence is greater than given minimum confidence. In this step, firstly, you need start from the frequent itemsets, to dig out all the association rules, and then to get the frequent association rules.

C. The example illustrates the Apriori algorithms Transaction database as shown in Table I, Supmin =50%, Confmin =70%. Request the frequent association rules in  transaction database D.

TABLE I.  TRANSACTION DATABASE  Tid Itemsets  1 A B C D E 2 A B C 3 C D E F 4 A B E    The implementation process is as follows:  The first step: Find the frequent itemsets  1) Frequent 1 - itemsets{{A}?{B}?{C}?{D}?{E}}.

2) Frequent 2 - itemsets{{AB}?{AC}?{AE}?{BC}?  {BD}?{CD}?{CE}}.

3) Frequent 3 - itemsets{ABC}.

4) Summary 321 LLLL ??= ={{A}? {B}? {C}? {D}?  {E}?{AB}?{AC}?{AE}?{BC}?{BD}?{CD}?{CE}? {ABC}}.

The step two: seeking association from {ABC}  Only {AC} ? {B},{BC} ? {A},{A} ? {B},{B} ? {A} meet the requirements. Confidence level is 100%.



III. THE DESCRIPTION OF IMPROVED ALGORITHM  A. Introduction of Improved algorithm From the above process, we see that some disadvantages in  the traditional data mining. Firstly, the process of scanning database is too frequently. Secondly, the definition of Supmin and Confmin  cannot be changed. If we want to change  Supmin or Confmin , we need re-excavation. It is inconvenience to users. Thirdly, we are not interested in EF, so it should not be start to operate on EF.

Property1. If A B? exists in the association, then ?AB Countmin .so if T < Countmin , Then, the  relationships composed of any subset of T not meet the minimum confidence.

Property2. If A B? exists in the association, then A and B are frequent itemsets, but AB is not a necessarily frequent itemsets.

Definition1: Interested Item I is a collection of items which are interested in some users. It is also a key objective of the excavation.

Definition2: Item frequency refers to a subset of items from the interest in the composition of the items set in the transaction database number.

Definition3: Support the frequency threshold SupCountmin  is a minimum number of items in association  rules.

SupCountmin = D * Supmin  Definition4: Frequency threshold Countmin  is the minimum number in the association rule of BA? .

Countmin = SupCountmin * Confmin  B.  Algorithm Steps To sum up the three inadequate in traditional mining  algorithms and the two properties, we have improved Apriori algorithm as follow:  The first step: This paper presents the various items of interest in a subset of items of frequency.

1) Enter interest items and mining transactional database 2) Scan the transaction database 3) Records each sub-set of items in the database. You can  record frequency and the total number of articles D . Save the subset.

The second step: find the association  1) Enter Supmin and Confmin .Put Supmin  into SupCountmin  2)  Scan the subset of items of interest which you have saved. Find out frequent itemsets and delete some subset whose frequency is less than Countmin .

3) Find each association rule whose confidence is greater than Confmin .Output the rules.

C. The improved algorithm pseudo-code Step 1: Find the item frequency of all the subsets of  interested items.

Input: Transaction database (D); Interested items (I)  Output: Item frequency of all the subsets of interested items and record item numbers in the database.

For each candidate Ii ?  Do // traversing each Interested items  Count++         // Record numbers of interested items  End for  sumI = )(Isubset   // Find all the subsets of Interested items  For each log Dd ?  Do  For each candidate di ?  Do // traversing each Interested items      If ( Ii ? )    // if this item belongs to Interested items  idi =?   // Find all the Interested items in this record  End if  )( id dsubsetI =  End for  For each Item in dI  // traverse each item in the collection  ++countItems.     // each item add 1 in the collection  End for  Count++         // record the item numbers in the database  End for  Pseudo-code of )(Isubset  as follows:  );;1( . ++<= icountIiifor  Return  sumI =? countiiiii IIIIII ...... 11 ++ ??  End for  Step 2: Find the association in sumI  Input: Minimum support threshold ( Supmin ); Minimum confidence threshold ( Confmin )  Output: The AR to meet the requirement and credibility  SupCountmin =Count* Supmin * Confmin  For each candidate sumII ?  Do  )min( .. SupCountcountItemsIif <  Delete I  // if the frequency of I is smaller than SupCountmin , delete it from sumI  Else  )min( .. CountcountItemsIif ?  IL =?  // Save I as a frequent item into L, if its frequency is greater than Countmin  Count1++   // record the numbers of frequent items  End if  End if  End for  For each candidate LI ?  Do // traversing all the items of L  );1;1( ++<= icountiifor  // traversing each element of L  )..( ItemsLItemsLif ki ?  // if the items in iL  and kL  are different  ))..(( sumki IItemsLItemsLif ??   // if the union of items in iL  and kL belongs to sumI  )min ..

)...(( Conf countItemsL  countItemsLItemsLif i  ki ??  return ItemsLi . ItemsLk .? ?  countItemsL countItemsLItemsL  i  ki  ..

)...( ?  End if  End if  End if  End for  End for  Time complexity analysis of the algorithm: the record number in database (m) is always very large. Actually, constant n, the items which user interested is smaller. The complexity of the algorithm is O ( )12(* ?nm ).



IV. EXPERIMENT AND EXPERIMENTAL ANALYSIS  A. The improved algorithm flowchart At the beginning, input the target data forms and interested  items. Scan all the item collections in the database, and save the frequency in the list-L. Input the threshold of support degree and credibility, judge whether they are legal, then scan L, delete items whose frequencies are smaller than the frequency threshold, mine AR according to the related rules. At last, need further mining or not. If so, keep inputting new threshold of support and credibility to continue mining.

Otherwise exit from the program. The flowchart of the improved algorithm is shown in Fig.1.

Figure 1.  The improved algorithm flowchart  B. Experiment examples of improved algorithm All data and parameters have listed on the Table I,  interested item is ABC.

1) frequencies of A?AB?AC?ABC?B?BC?C are 3 ?3?2?2?3?2?3  2) The frequent items are {A?AB?AC?ABC?B?BC ?C}  3) Candidate association relations are on the list: {A} ? {BC}?{B} ? {AC}?{C} ? {AB}?{AB} ? {C}? {AC} ? {B}? {BC} ? {A}? {A} ? {B}? {A} ? {C}? {B} ? {A} ? {B} ? {C} ? {C} ? {A} ? {C} ? {B}. The credibility are as follows?67%?67%?67%?67%?100% ?100%?100%?67%?100%?67%?67%?67%.

4) As a result, only these items {AC} ? {B}?{BC} ? {A} ? {A} ? {B} ? {B} ? {A}meet the requirement ? their credibility have reached to 100%.



V. PERFORMANCE EVALUATION OF IMPROVED APRIORI ALGORITHM  At first, the minimum support of degree and credibility are changeable in the algorithm provided in this paper, which greatly facilitate the customer's requirements. Secondly, the advanced mining algorithm has explicit object, improves the mining efficiency, reduce the time and space complexity. The author have test the traditional algorithm and the advanced one based on the same situation that all the data are from Table I, and lead to the results showed in Fig. 2(a).

Fig. 2(a) showed that improved algorithm improved a lot on time. When it comes to the case that the transaction database is huge and the number of interested items is much smaller, the improved algorithm runs much better. As shown in Fig. 2(b), we set that each storage object accounted for 3 bytes.

(a)                                                              (b)  Figure 2.  Performance results of improved apriori algorithm

VI. CONCLUSION The paper do some research on the Apriori algorithm, it  showed that the biggest challenge of the Apriori algorithm faced is the computational efficiency issue. We reach a conclusion after an analysis on Apriori algorithm: reduce the frequency we scan the database; reduce the item collection that  impossibly become a mining relationship; improved the flexibility to be a user-friendly mining algorithm; the above measures can make the algorithm efficient. The algorithm provided in this paper can get the target to improve the efficiency.

For the future research and development, association rules mining can take these important aspects into consideration, such as, how to improve mining efficiency of association rule especially in the situation that processing large amount of data; how to set multiple supportive degree and creditable in multi- dimensional multi-layer database that user interested in order to mine more valuable association rule; how to mine related valuable rare item collection in a more efficient methods [9, 10].

