Research on Mining Positive and Negative Association Rules   Based on Dual Confidence

Abstract?Mining of association rules has become an important area in the research on data mining. However the traditional approaches based on support-confidence framework maybe generate a great number of redundant and wrong association rules. In order to solve the problems , a correlation measure is defined and added to the mining algorithm for association rules. According to the value of correlation measure, association rules are classified into positive and negative association rules. Therefore,the new algorithm can mine the negative-item-contained rules. In the paper, the algorithm which based on the correlation and dual confidence, can mine the positive and negative association rules.The experimental result shows that positive and negative association rules mining algorithm can reduce the scale of meaningless association rules, and mine a lot of interesting negative association rules.

Keywords- data mining; positive and negative association rules; dual confidence; minimum correlation

I. 0BINTRODUCTION Association rules was proposed by Rakesh Agrawal et al  [1] in 1993 for initially, which is an important technique in data mining. Traditional association rules, mainly for mining customer transaction database relationship between sets of items, that is of the form A B? , high frequency, high correlation rules, which we call positive association rules, is a strong correlation of the dominant model, and there are many mining algorithms[2-7]. In fact, many databases which use these mining technology can not find the hidden patterns, one of these important hidden pattern is the negative association rules, which has a low frequency and strong correlations, showing the HpropertyH of the strong correlations in the data itemsets which is hard to find. The rules tell us that which data items less to occur together, and they share a very strong correlation, and contain very valuable information, such as rules A B? ? ? A B? ? ?  A B? ? ? ,so mining negative association rules is very important.

Currently used for the negative association rules mining algorithm is not too much, such as [3] proposed a positive and negative association rules mining algorithm based on interestingness,a negative association rules mining algorithm based on support, confidence, correlation coefficient in [4],  and a negative association rules mining algorithm based on matrix in [5].

Negative association rules of the search space for all non- frequent itemsets, and the non-frequent itemsets in the database D is exponential, which is also the main reason of study negative association rules more difficult than  positive association rules.While obtained the support of all non- frequent itemsets is unrealistic, but also meaningless. For example, for the negative association rules A B? ? , A B? is the non-frequent itemsets, but both A and B are  frequent itemsets, Therefore, a negative association rules mining can be divided into two sub-problems: ?  the database D, find all the frequent itemsets L; ? Determine negative association rules based on frequent itemsets L.

There are many algorithms can be used directly to solve the first sub-problems, such as the Apriori algorithm, FP-growth algorithm. This paper gives a negative association rules mining algorithm to find hidden rules in massive data.

Negative association rules are used to discover the meaningful association beteween the itemsets and others in the large data,  giving the interesting relationship between these items.



II. 1BPROBLEM  FORMULATION Set I={iR1R,iR2R,?,iRmR}that contains a collection of m  different items. Given a transaction database D, where each transaction T is a group itemsets of I. If A is a subset of I,with A T? , we can say that a transaction T contains A. A negative association rules are an implication of the form  A B? ?  (or A B? ? ,or A B? ? ? ) ,Where ,A B T? , and A B? = ? .

Given support s and confidence c. If D has (100 ? s)% of the transaction contains B but does not contain A, the support of negative association rules A B? ?  is s,denoted as sup( A B? ? )=s. If the transaction does not contain A, there are (100 ? c)% of the transaction contains B, the confidence of negative association rules A B? ?  is c, denoted as conf( A B? ? )=c. So the support and confidence of negative association rules A B? ? ? A B? ? ?  can also be defined.

Negative association rule discovery seeks rules of the form A B? ?  (or A B? ? ,or A B? ? ? ) with support and   DOI 10.1109/ICICSE.2010.28    DOI 10.1109/ICICSE.2010.28     confidence greater than, or equal to, user-specified minimum support (minsup) and minimum confidence (minconf) thresholds respectively, where A and B are frequent itemsets.

In this paper,  introducting the minimum correlation theory, so it can reduce the production of the meaningless association rules.



III. 2BALGORITHM DESIGN  A. 4BConfidence With goods A?B, by sup(A) and sup(B) small (e.g. less  than 5%), then sup(A ? B) is smaller , while the confidence ( )conf A B?  may be large, may also be small, but ( )conf A B? ? ? positive large. If the uniform rules for all  the confidence bound, there will be such an embarrassing situation: If the less confidence, would be a lot of rules, the customer can not choose the genuine needs of the rules, even presence of a large A B? ? ?  type rules are not necessarily meaningful; if confidence is greater, may miss many valuable positive association rules. Therefore, the best solution is to use different confidence thresholds, and we set two confidence thresholds, P_minconf and N_minconf.

P_minconf show that the minimum confidence threshold of the rules A B?  and A B? ? ? ; N_minconf show that the minimum confidence threshold of the rules A B? ? and  A B? ? .

Property 1 Let A I? , B I? , A B? = ?  then ?sup( A? )=1 ? sup(A) ?sup( A B? ? )=sup(B) ? sup( A B? ) ?sup( A B? ? )=sup(A) ? sup( A B? ) ?sup( A B? ? ? )=1 ? sup(A ) ?  sup(B)+ sup( A B? ) Property 2  Let A I? , B I? , A B? = ?  then  conf( A B? ? )= sup( ) sup( ) sup( )  A A B A  ? ?  =1 ( )conf A B? ?  conf( A B? ? )= sup( ) sup( ) 1 sup( ) B A B  A ? ?  ?   1 sup( ) sup( ) sup( )( ) 1 sup( )  A B A Bconf A B A  ? ? + ?? ? ? = ?    =1 ( )conf A B? ? ? Where ( )conf X  as the confidence function, such as  ( )conf A B? ?  is the confidence of negative association rules A B? ? .

The relationship between them as follows: (1) ( )conf A B? + ( )conf A B? ? =1 (2) ( )conf A B? ? + ( )conf A B? ? ? =1 Proof omitted.

We can see from the above analysis, the two confidence  P_minconf + N_minconf = 1  B. 5BCorrelation Most association rules mining algorithms use the  framework of support-confidence. Although it may exclude some meaningless rules, it still produce some rules which the users are not interested in. Suppose there are 10000 sales data items in the set , purchase of goods X denoted as the item A, purchase of goods Y denoted as the item B, purchase of X and Y denoted as item A ? B. Assume the purchase of goods X is 6000, purchase of goods is 5000, purchase of goods X and Y are 2500.Given minsup=0.2,minconf=0.3,then sup( )A B? =0.25>minsup, ( )conf A B? =0.42>minconf, so A B?  is a strong association rules. Then considering  negative association rules A B? ? ,since sup(A ? B)=0.35 >minsup, ( )conf A B? ? =0.58>minconf,therefore, A B? ? also is strong association rules. This is in contradiction with the A B? , meanwhile, because of ( )conf A B? ? > ( )conf A B? , so A B? ? should be more reliable.

Because of ( )conf A B? =P(B?A)< ( )P B , the occurrence of A lead to probability B is decreased, so A and B should be a negative relation. For this, it introduced another measure of association rules - Correlation. The correlation of association rules show the relationship between the itemset.,through the correlation threshold, we can remove some meaningless  negative association rules.

Definition 3.1  If ( ) ( ) ( )P A B P A P B? = ,then itemsets A and itemsets B are independent; Otherwise, itemsets A and itemsets B are correlated.

The correlation of itemsets A and itemsets B: , sup( ) sup( )sup( )A Bcorr A B A B= ? ?  Which ,A Bcorr is the correlation of itemsets A and B; sup(A ? B)?sup(A)?sup(B), respectively, the support of itemsets A ? B?A and B.

There are three kinds of ,A Bcorr : If ,A Bcorr >0,then itemsets A and B is positive  correlation; If ,A Bcorr <0,then itemsets A and B is negative  correlation; If ,A Bcorr =0,then itemsets A and B is independent of  each other.

The correlation reflects the relationship between the  itemsets A and B , when the correlation is equal to 0, indicating that two itemsets appear together does not have special meaning, namely, A and B are independent of each other, called the rules are not relevant rules; when the correlation less than 0, indicating that the possibility one of the itemsets would be decreased by another itemsets, Tcalled the rules are negative correlation rules;Twhen the correlation greater than 0, indicating that the possibility one of the itemsets would be increased by another itemsets, Tcalled the rules are positive correlation rulesT.

Because of the meaning expressed by the three cases vary widely, according to the traditional rules generated by Apriori algorithm is no distinction for them, Tso some rules are contradictory or uninteresting     The paper [6] proposed that if a rules to meet sup(A ? B) ? sup(A)sup(B)?0, then the rules are  no interesting, in other words, only the correlation of rules is greater than a certain threshold, the user will be interested in, Therefore, we set the minimum correlation threshold (mincorr), that only the association rules to meet sup(A ? B) ? sup(A)sup(B) ? mincorr is our interest. mincorr specified by the user or expert. For the negative association rules, the value of sup(A ? B) ? sup(A)sup(B) may be less than 0, therefore, it need to join the absolute value on the left of the formula, that is, if A ? B is interested in the rules, if and only if ?sup(A ? B) ?  sup(A) sup(B)? ? mincorr. The following will discuss the relationship between the minimum correlation of four forms of association rules .

Theorem 3.1 If?sup(A? B) ? sup(A)sup(B)?? mincorr, then (1)?sup( ? A? B) ? sup( ? A)sup(B)?? mincorr (2)?sup(A? ? B) ? sup(A)sup( ? B)?? mincorr (3)?sup( ? A? ? B) ? sup( ? A)sup( ? B)?? mincorr Proof.  (1)?sup( ? A? B) ? sup( ? A)sup(B)? =?sup(B)?sup(A?B) ?  (sup(B)?sup(A)sup(B))? =? ? sup(A?B)+sup(A)sup(B)? =?sup(A? B) ? sup(A)sup(B)?? mincorr (2), (3) for the same reason.

The theorem show that select an appropriate minimum  correlation can be prune to four association rules.

C.  Algorithm Design In the PAR&NAR_Mining algorithm, assuming that the  frequent itemsets have been obtained and saved in the set L.

Input: frequent itemsets L, minimum confidence minconf,  the minimum correlation mincorr; Output: positive association rules set of PAR, negative  association rules set of NAR; PAR= ? ,NAR= ? ; For any frequent itemsets X in L do begin For any itemsets A ? B=X and A ?  B= ?  do begin If?sup(A ?  B) ? sup(A)sup(B)? ? mincorr do begin If ,A Bcorr > 0 then begin   // Produce rules forms such  as A? B and ? A? ? B If conf(A? B) ? P_minconf  then PAR=PAR ? {A? B}; If conf( ? A? ? B) ? P_minconf  then NAR=NAR ? { ? A? ? B}; End; If ,A Bcorr <0 then begin   // Produce rules forms such  as A? ? B and ? A? B If conf(A? ? B) ? N_minconf then NAR=NAR ? {A? ? B}; If conf( ? A? B) ? N_minconf then NAR=NAR ? { ? A? B}; End; End; End; End; Return PAR and NAR;  The algorithm to generate Tpositive Tassociation rules set PAR and negative association rules set NAR. PAR and NAR is initialized to empty set. First, check ? sup(A ?  B) ? sup(A)sup(B) ? , whether to meet the minimum correlation, and then, determine its relevance based on  ,A Bcorr ,and generate rules. Which, if A and B are positive correlation, production rules of the form A ? B and ? A? ? B; if A and B are negative correlation, production rules of the form ? A? B and A? ? B. Finally back to PAR and NAR, and end of the algorithm.



IV. 3BALGORITHM ANALYSIS Let n Tfrequent items in L, T Tfrequent itemsets X contains  two frequent item, T Twhere X T ? T L? TA ? B=X and A ?  B=  ?, Tthere are T 2nc T frequent itemsets X in L, T Teach X requires two comparative analysis, T so Tthe operation frequencyT of the aTlgorithm is T2* 2nc =n(n-1)T , T Tthat is the time complexity is TO(n P2P).TThe TToperation frequencyTT of Apriori algorithm also reached the square level ,or even higher.T TTherefore, in theory, the algorithm is feasible and effective.

TTo illustrate the algorithm efficiency and accuracy,T Tin the same experimental conditions,T Tto achieve PAR&NAR_ Mining algorithm and the positive and negative association rules mining algorithm in [7],T Tand using the same experimental data set to analyze and compare the performance of the algorithm.T  TThis experimental platform is the Intel (R) P4 dual-core processor, 1.5G RAM, WindowsXP operating system, programming language is JAVA, programming environment is JBuilder2006. Data set used in the experiments is the social security audit data set, which is a real data set.

TThere are two comparison for the experiments:T a) TPositive and negative association rules mining  algorithm in  [7]; b) T7BPAR&NAR_Mining algorithm based on TTcorrelation  and dual confidence thresholdsTT. T Given minsupp=0.2,P_minconf=0.2,N_minconf=0.8T. T Tthe  comparison results shown in Figure 1?2.

40% 35% 30% 25% 20% 15% 10% minimum correlation  th e  nu m  be r  of A  R      the algorithm in literature[7]  the algorithm of PAR&NAR-Mining   Figure 1.  The number of AR change as minimum correlation  As can be seen from Figure 1, the number of association rules generated by PAR&NAR_Mining algorithm is     significantly less than [7], this is because the algorithm introduction of the minimum correlation and double confidence theory, filter out the association rules  of meaningless, allowing the rules to become more objective and reasonable.

40% 35% 30% 25% 20% 15% 10% minimum correlation  th e  ru nt  im e(  s)      the algorithm in literature[7]  the algorithm of PAR&NAR-Mining    Figure 2.  The runtime change of algorithems as minimum correlation  TAs can be seen from Figure 2, PAR& NAR_Mining algorithm execution time is much better than [7] .TTThese experiments fully demonstrate that the algorithm is effective.



V. TCONCLUSION TSince the topic of association rules mining proposed,T Thas  proposed a number of association rules mining algorithm, but can be used for negative association rules mining are few. T TThis paper TpresentsT a both positive and negative association rules mining algorithm based on relevance and confidence , TTexperiments show that the algorithm is effective and feasible.T TIn addition, this paper only discusses the problem of mining TTpositive and TT negative association rules, in the future, we will study the following two aspects:  a) T8BTo improve the efficiency of the algorithmT.

b)  TDepth study of the issue of its updatedT .

10BACKNOWLEDGMENT This work is sponsored by the National Natural Science  Foundation of China under grant number 60873038, the Fundamental Research Funds for the Central Universities of China under grant number HEUCF100603 and the National Science & Technology Pillar Program under grant number 2009BAH42B02.

11BREFERENCES [1] Agrawal R,Imielinski T,Swami A, ?Mining Association Rules  between Sets of Items in Large Databases, ?In:Proc of the ACM Data,Washington DC,1993,pp,207-216.

[2] Agrawal R,Srikant R, ?Fast algorithms for mining association rule, ?In:Proe.20th Int. Conf.on VLDB.Santiago,Chile,1994,pp,487-499.

[3] Mojdeh Jalali-Heravi, Osmar R. Za?ane, ?A Study on Interestingness Measures for Associative Classifiers, ? TProceedings of the 2010 ACM Symposium on Applied Computing,2010,pp,T1039-1046.

[4] He Jiang, Yuanyuan Zhao, Chunhua Yang, Xiangjun Dong, ?Mining Both Positive and Negative Weighted Association Rules with Computer Science and Software Engineering,2008,pp,407-410.

[5] Ling Zhou, Stephen Yau, ?Association Rule and Quantitative Association Rule Mining among Infrequent Items,? Proceedings of the 8th international workshop on Multimedia data mining: associated with the ACM SIGKDD 2007.

[6] HLiqiang GengH, HHoward J.HamiltonH ,?Interestingness measures for data mining: A survey.? ACM Computing Surveys ,2006,pp,1-32.

[7] SHANG Shi-ju,DONG Xiang-jun,LI Jie, ?Algorithms for mining negative association rules in multi-database, ?Computer Engineering and Applications,2009,45(24),pp,150-152.

