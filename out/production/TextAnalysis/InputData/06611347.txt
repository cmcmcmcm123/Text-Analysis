Unstructured Data Extraction in Distributed NoSQL

Abstract ?While ?Big data? has brought good tidings in terms of easy accessibility to voluminous data, we are faced with challenges too. The existing Knowledge Discovery in Database (KDD) processes which have been proposed for schema-oriented data sources are no longer applicable since today?s data is unstructured. Previously, we deployed a tool called TouchR which relies on the Hidden Markov Model (HMM) to extract terms from unstructured data sources (specifically, NoSQL databases).

This paper has advanced on the initially deployed version where we introduced re-usable dictionary and association rules to improve on the quality of the extracted terms. Also, the tool in its present stage is more adaptable to the user search based on the most frequently searched term.

Keywords: Unstructured data, big data, Hidden Markov Model (HMM), terms extraction, NoSQL, Re-usable dictionary, Association rules.

1 Introduction The explosion of online services and the high data consumerization across the enterprise spectrum is leading the business stakeholders to re-align their products and services [1]. Thanks to the Internet and the steady decline in cloud services cost, there is vast amount of data that can be accessed readily for most enterprise specific purposes.

Taking marketing and sales enterprises for example, the online information can be used to reach wider audience on product advertisement.

But, there is a challenge. The vast amount of data is unstructured; which means the data is schema-less, and comes in different formats such as documents/text, email messages, customer feedbacks, audio clips, video files, images, blogs from online collaborative forums, and posts and conversations on social networking platforms [1].

According to Rupanagunta et al. [1], the influx of unstructured data is tightly coupled to big data considering the fact that Twitter users alone generate 12 terabytes of data every day.

As if Pareto?s 80-20 rule is carefully designed for this topic, Feldman [21-22] bemoaned that there is lack of tools to effectively manage the exponential growth in data while noting that out of the current existing data, only 20% are in structured databases and 80% are unstructured. This phenomenon which is also reported a decade later by [12] and [23] directly leads to challenges regarding the  management of the data from analytical, processing, interpretation, extraction, and storage points of view.

Further, the existing data mining techniques have been designed to work with schema-oriented databases for structured data styles [2]. However, these existing techniques are no longer relevant to the modern challenges of information extraction.  Modern researchers in the areas of cloud computing, artificial intelligence, big data analytics, etc. have devised techniques based on linguistic and Natural Language Processing (NLP) to make sense of the unstructured data debris. To this effect, we have seen approaches on unstructured data mining such as: templates [3], association rules [4-5], topic tracking and topic maps [6], term crawling (terms) [7][23-4], document clustering [8], document summarization [9], Helmholtz Search Principle [10], re-usable dictionaries [11], and so on. The works in the area of unstructured data mining is summarized in Table I.

Moreover, in an attempt to accommodate the growing high- dimensional data, NoSQL databases have been proposed.

This style of databases support schema-less, semi- structured, and structured data storage while some accommodate file attachments (e.g., CouchDB). Examples of NoSQL storages are: MEGA, Dropbox, and Amazon S3, and so on. Further, there is also a growing trend in deploying databases which is graph-based. Currently, we have seen the deployment of graph-oriented services such as Facebook Open Graph [16], Google Knowledge Graph [17], Bing one-ups Knowledge Graph [18], and Twitter Interest Graph [19].

In our previous studies in [29], we deployed a tool called TouchR that employs the Hidden Markov Model (HMM) [26] to extract terms from distributed NoSQL databases.

Though RSenter shows high performance boost in terms of the optimization of search time, there were challenges with adaptability to search terms. Also, the tool has problems with semantics where we are not able to separate two terms that are the same (i.e., exact writing/representation) but have different meanings. The presence of these issues leads to the introduction of False Negative results where search terms are returned that the user does not want.

We have since advanced on the TouchR by adopting the techniques of association rules between terms from [4-5] and re-usable dictionaries from [11]. The remaining sections of the paper are structured as follows. The next section gives an overview of the TouchR tool and the     advances on the existing work are discussed in Section 3.

Section 4 details the evaluation of TouchR and the paper concludes in Section 5.

2 The Architecture of TouchR The TouchR framework as illustrated in Fig. 1 is deployed based on our vision which seeks to aid terms mining in NoSQL data silos. The implementation is done in the Erlang programming language [27] and the user interface is browser-based. In the next section, we discuss the architectural overview of the framework.

2.1 The Architectural Composition TouchR is a standalone application that has Erlang backend and an HTML5 interface to enhance user interaction.

Currently, the user interface relies on a visualization tool called JavaScript InfoVis Toolkit [28]. The user interface (TouchR App) allows the user to specify the query terms? which are the actual artifacts that the user is interested in extracting from the data debris.

Once a query term is selected, the selection is forwarded to the semantic engine which contains two components; the thesaurus and the dictionary. As already posited, topic extraction focuses on the actual keywords being searched while terms require the extraction of other features (keyword dependencies). For instance, in an organization, topic extraction can be done by searching for the keyword ?contract?, where contract may refer to all files and information regarding contractual issues. In that case, the search will return all results containing the exact topic ?contract?. However, terms extraction for the same keyword ?contract? will require other dependencies such as agreements, technical description documents, non- disclosure agreements, and so on. In effect, terms are specified by the user because sometimes, the expected result may not even contain the actual keyword being searched for because that keyword may not literally exist in the data sources while a synonym may exist and be returned. Hence, the thesaurus allows the user to specify the dependent terms and synonyms. For enterprise users of TouchR, we encourage the system administrators to pre- populate the thesaurus with possible terms and their  TABLE I.  SUMMARIZED METHODOLOGIES OF UNSTRUCTURED DATA MINING [29]   Information Extraction  Association Rules Topics Terms  Document Clustering  Document Summarization  Re-Usable Dictionaries  Goal Data Retrieval, KDD Process  Trend discovery in  text, document or file  Topic Recommendation  Establish associative  relationships between terms  Organize documents into sub-groups with closer identity  Noise Filtering in Large  Documents  For Knowledge  Collaboration and Sharing  Data Representation  Long or short text, semantics and ontologies,  keywords  Keywords, Long or short  sentences  Keywords, Lexical chaining Keywords  Data, Documents  Terms, Topics, Documents  Words, Sentences  Natural Language Processing  Feature extraction  Keyword extraction Lexical chaining  Lemmas, Parts-of- Speech  Feature extraction  Lexical chaining  Feature extraction  Output Documents  (Structured or semi-structured)  Visualization, Summary  report Topic linkages Visualization, crawler depth Visualization  Visualization, Summery  report  Summary report  Techniques  Community data mining,  Tagging, Normalization  of data, Tokenizing,  Entity detection  Ontologies, Semantics, Linguistics  Publish/Subscribe , Topics-  Associations- Occurrences  Linguistic Preprocessing,  Term Generation  K-means clustering,  Hierarchical clustering  Document structure analysis,  Document classification  Annotations, Tagging  Search Space Document, Files, Database Document,  Files, Database Document, Files,  Databases Topics vector  space Documents, Databases  Databases, Sets of documents  Databases, Sets of  documents  Evaluation metrics  Similarity and relatedness of Documents,  sentences and keywords  Similarity, Mapping, Co- occurrence of  features, correlations  Associations, Similarity, Sensitivity, Specificity  Frequency of terms,  Frequency variations  Sensitivity, Specificity, Balanced Iterative  Reducing and Clustering (BIRCH)  Transition and preceding  matrix, Audit trail  Word extensibility  Challenges and Future  Directions  Lack of research on  Data Pedigree  Applies varying approaches for different data  Identification of Topics of interest  can be challenging  Community based so  adoption can be challenging  Can be resource intensive  therefore needs research on  parallelization  Needs research on Data Pedigree  Lack of research on dictionary  adaptation to new words       Figure 1. Architectural design of TouchR [29]  dependencies before the actual mining process commences by novice users. However, the terms and their dependencies can be specified and stored in the thesaurus at the time of performing the terms extraction task. Typically, the data being sent across the system components is JSON so an example of a specified query term can appear as:  {"R Lomotey": { "project": " iOS?, ?unit2?: ?Admin Dept?, ?unit3?: ?HR Dept", } }  The thesaurus will store this information using ?R Lomotey? as the main artifact while the project and units are dependency keywords that will also be extracted as part of the terms mining process. The dictionary is implemented to provide the TouchR framework with adaptability features. Once a terms-extraction task is completed successfully, we allow the users to specify their satisfaction rate from (0 ? 5). The terms extraction is rated very poor (0) to excellent (5). Apart from the human rating, we analyze the accuracy, precision, and recall of every search at the application level. This will be discussed later in the paper. But, highly rated terms extraction tasks by the users which correspond to the systems accuracy and precision are moved into the dictionary. The user does not interact with the dictionary but only the system. So, in the future when users specify a query term such as ?R Lomotey? who is an employee but the only dependent or synonymous keywords that are specified is project and unit2 or even completely different units, the system will add to the query result unit3  or all the previous results that are returned when other users perform the query tasks and report high satisfaction. The dictionary actually stores human rated values from (3 ? 5).

At the moment, the thesaurus and dictionary are implemented using DETS which is disk storage in Erlang.

When the semantic definition tasks are completed, the query term and its dependency keywords (either specified by the user or from the dictionary) are forward to the transactor component. The transactor is the main engine that determines the number of available NoSQL databases, their different MapReduce functions, their REST API formats, and their returned results formats. The challenge we have at the moment is that, the transactor is not adaptable. So, prior to the terms extraction process, the query nature of the expected NoSQL databases has to be specified. For example, the transactor does not support cloud storage such as MEGA or Dropbox so if these frameworks are specified as the NoSQL databases, then there will be no terms extraction. However, to use these storages, their REST APIs has to be pre-defined in the transactor; and this activity requires expertise in Erlang programming as well as API usage.

At the moment, TouchR supports NoSQL databases from the following providers: Bigdata, CouchDB, MongoDB, Neo4J, Cloudata, DynamoDB. The list of the supported NoSQL is heterogeneous in the sense that some are the traditional NoSQL storages and a few (e.g., Neo4J) are graph databases. So, the query engine performs the terms extraction tasks on the NoSQL using the key/value pair format which is the property of these NoSQL storages.

However, the graph databases rely on both properties and indexes to access the data on the distributed nodes. The transactor takes every query term as a key and every dependent term is also treated as a key. Hence, the transactor generates MapReduce queries with the terms to extract the data from the NoSQL sources. We consider the details of MapReduce queries of all the NoSQL being studied here outside the scope of this paper for brevity. We encourage the reader to consult the documentations on the websites of each of the products.

Further, there are some instances where file reading may be required (e.g., attachments in CouchDB). This case is simplified by just downloading the file and reading its content and treating it just as an actual data. All the returned data from the queries are sent back to the query response engine on the client side. The query response engine then displays the result on the user interface.

In order to traverse the distributed NoSQL databases, we employed the Hidden Markov Model (HMM) which aids us to reduce the search complexity. The traversing of the distributed NoSQL follows the exponential complexity but the HMM aids us to reduce the complexity to linear. This further aids in the optimization of the time to traverse the NoSQL databases. A sample output of the tool in HTML5 is shown in Fig. 2. The reader is referred to the work in [29] for further reading on the HMM.

Figure 2. Clustering tree result for the extracted term ?R.

Lomotey? who is an employee [29].

3 Re-Usable Dictionary and Association Rules In order to make TouchR more adaptable, we adopted the re-usable dictionary technique that is proposed by [11] and [30]. The challenges with the initially deployed version of TouchR in [29] are that, the search criterion is not adaptive to search history and semantic issues were not overcome.

Specifically, when two keywords (artifacts) are written same but have different meanings, TouchR is not able to determine the difference in meaning so this leads to False Negative and False Positive results. We further explain these indices below:  ? True Positive (TP): The search term as specified by the user is found and returned.

? False Positive (FP): The search term specified exists in the data source but is not found by the search tool. This is a case that is never entertained in any working system.

? True Negative (TN): The specified search term does not exist in the data source and the search tool reports that it does not exist.

? False Negative (FN): This is a case of returning undesired results. Sometimes, what the user is not looking for is equally returned.

The increasing volume of unstructured data also requires the implementation of re-usable dictionaries to further facilitate collaboration in a working group. In software engineering for example, dictionaries could enable a group of developers to rely on shared knowledge (which is communicated in an unstructured data format) to better speed up the development process. Dictionaries are mainly used for annotation and tagging of words. The challenges however relate to how dictionaries are built and re-using dictionaries. If dictionaries can be re-used, the domain experts can just rely on the experiences of previous tasks.

Godbole et al. [11] built a set of tools that will enable end users to construct dictionaries. A dictionary, D, is defined  as D = Dict(C, X) where C is a concept in a document of collection X. The authors further extended the dictionary to support single seed words, set of seed words, and positive and negative seed sets (i.e., the user can choose to provide words of interest as well as words of no interest). The possibility of re-using the dictionary is as a result of the fact that there is an existing algorithm that supports the dictionary agility such that the function adapt(n, D) is true.

Meaning for n-number of new terms to be added to the dictionary, the dictionary D can adapt to accommodate the update.

On the issue of system adaptive learning, Gonzalez et al.

[30] implemented a dictionary-base framework that employs tagging to map entities. The challenge in adaptive learning systems is that, new jargons are being added every day from the cloud and social networks; which make the area evolving. Hence, the idea behind the implementation of the dictionary is to adopt semantic data to improve on the information extraction process, as well as using the information extraction output to discover new terms.

Moreover, the Association Rules (AR) is applied in discovering text with co-occurrences in features [6].

Simply put, association rules are employed to achieve pattern discovery in the text, document or file. AR works by identifying a set T of transactions which is a subset of a bigger transaction I.

FORMALISM: To formalize the AR transaction, Delgado et al. [4] express I and its subset T as associative if A ? C with A, C ? I, A, C ? null and A ?C = null, where |C| = 1; to mean that ?C? is present in every transaction that ?A? is present in.

Association rules are closely related to information extraction since AR aims at establishing relationships between records [31]. As further outlined by Delgado et al.

[4], one application of associative rule is trend discovery, a very salient measure in accomplishing search tasks. Trend discovery can enable us understand from the textual content what reports are being generated and how are those reports being handled. This is achieved by building relationships between the T transactions (or activities) and labeling these transactions using timestamps and other identifiers.

In order to improve on the TouchR tool, we adopted the re- usable dictionary technique proposed by [11] and [30].

Then we further adapted the association rules technique proposed by [4] and [6]. We restructured the thesaurus and dictionary components of TouchR to store keywords (artifacts) with their synonyms and antonyms as illustrated in Fig. 3. The synonyms and/or antonyms can be specified at the time of performing the terms extraction task or can be pre-populated. As noted earlier, the challenge that the TouchR framework had was with the differentiation between similar terms with different meanings. From Figure 3 for instance, previously when searching for the term ?Contract?, the output will include all terms relating     to ?Agreement? and ?Acquire?. This situation leads to high False Negative result which can affect the sensitivity and accuracy of the terms extraction.

Figure 3. Sample structure of the stored Terms  With the introduction of the of the re-usable dictionary, the user can perform the terms extraction in three different ways that can lead to higher accuracy.

1) Search Choice 1: The user can specify the search term plus the synonyms of the term so that similar terms but different meanings can be eliminated.

2) Search Choice 2: The user can specify the search term plus the antonyms which tells the TouchR tool what not to search for.

3) Search Choice 3: Specify the search term and the result will include a lot of False Negatives. Then, the user can choose any keyword out of the result to further refine the serach criteria. This situation leads to higher latecny but it is also a sure way to identify existing synonyms. For example, if the dictionary is not verbose enough, it may not contain some synonyms that can be specified by the user.

Next, we establish association rules between terms.

However, association rules are not generic; rather, they apply to specific domains. For example, association rules can be defined as: influenced by, caused by, dependent on, related to, searched by, etc. In essence, the association rules aid in making the search adaptable. So, when users search for a term, those terms are rated high when others are searching for those terms later. Thus, assuming previously ?Contract? was searched to mean ?Agreement?, subsequent searches will rate the ?Agreement? contract ahead of ?Acquire? contract.

4 Evaluation We deployed TouchR on our Windows powered system with the following specifications: Windows 7 System 32, 3.20 3.12 GHz, 8GB RAM, 1TB HDD. We considered training data sets from thesaurus.com where we crawled over five (5) million terms and their dependencies. The crawled terms are stored in a CouchDB database which is deployed on Amazon EC2 instance. Using the above highlighted indices, we calculate the reliability of the search based on the parameters in Table II. The experimental result is reported in Table III.

TABLE II.  EXTENDING ON THE INDICES  Precision  Recall (Sensitivity)  Specificity  Accuracy    TABLE III.  RELIABILITY OF THE TOUCHR SEARCH TOOL  1  Million Records  2 Million Records  4 Million Records  5 Million Records  True Positive 100.00% 100.00% 100.00% 100.00%  False Positive 0.00% 0.00% 0.00% 0.00% True Negative 100.00% 100.00% 100.00% 100.00%  False Negative 0.00% 0.00% 0.00% 0.00%  Precision 100.00% 100.00% 100.00% 100.00% Recall (Sensitivity)  100.00% 100.00% 100.00% 100.00%  Specificity 100.00% 100.00% 100.00% 100.00%  Accuracy 100.00% 100.00% 100.00% 100.00%  Search Time 502.76s 689.95s 734.02s 967.14s  From Table III, we employ the Search Choice 1 technique where we specify search terms with synonyms. Then, we repeat the term extraction process using the Search Choice 2 where terms are specified with antonyms specified. In each case, we achieve 100% accuracy for varying number of terms (1 million to 5 million) because the False Negative and False Positive results are 0%. This is a huge improvement on the initially deployed version of TouchR in [29]. However, the duration (i.e., the search time) to extract the terms has increased in comparison to the previous version.

5 Conclusion As data is increasing at an exponential rate, the challenge is how to make meaning out of the data. This requires information extraction task from the debris of unstructured data. Previously, we proposed a tool called TouchR which relies on the Hidden Markov Model to extract terms from     distributed NoSQL databases. However, there was a challenge with the tool regarding the differentiation between two similarly written terms with different meanings.

In this paper, we have solved the problem by adopting the re-usable dictionary and association rules techniques. The users are given three search options that allow them to specify search terms with synonyms, antonyms, or summarize the search from initial returned result. The future direction will consider the implications of the same work from other textual and NoSQL sources.

