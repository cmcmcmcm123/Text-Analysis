An Improved Incremental Mining Algorithm Based on Risk Analysis of the  Association Rules for Bank Cost Analysis

Abstract?This paper introduces improving rate and proposes the incremental mining algorithm with the weighted model for optimizing association rules based on CBA mining algorithm. The risk analysis of the strong association rules is proposed for trend forecasting. And the risk degree of the lost rules based on the incremental mining is also analyzed. Comparing with the traditional algorithm, the improved algorithm is fast, efficient in incremental data mining and can find trends in association rules. The decision making reliability is enhanced by the association rules obtained from the improved algorithm. The algorithm was used in bank cost analysis with test results showing that the prediction precision of the algorithm is better than that of the traditional algorithm.

Keywords-incremental mining; risk analysis; bank cost  analysis    ?.  INTRODUCTION   Data Ming means extracting potential and valuable information from a mass of data and forecasting development trends. Data mining is the new field with fast development, and it is the crossover application field of many study fields. Data mining is very important for the decision-making system in every walk of life.

Association rules mining in transaction data is the important portion of data mining research.

Apriori algorithm is the way that is commonly used for mining association rules? frequent item set. But it mostly finds association rules from the static information database. In factual application, this algorithm has some shortcoming. The paper analyzes the change of the strong association rules with data updating in database by incremental mining algorithm according to factual need of decision-making. We analyze the strong association rules by the weighted model and consider the risk degree of the lost association rules. Accordingly, we improve the significance of incremental updating association rules mining and efficiently forecast the trend of rules.

?. TRADITIONAL CBA ALGORITHM   Although association rules roots in POS, it can be used in many fields. The basic data mining processes of association rules are: first, choose right element, decide different statistic level, choose specific degree, and only with element appearance degree in data is the same. The effect of association rules is the best; second, produce rules, then propose sup. and cof. Given one transaction data set D , association rules mining?s work is to find association rules that is not less than the appointed min- sup and min-cof.

CBA is one traditional mining algorithm using in bank cost analysis. CBA is classification based on association.

This algorithm integrates classification mining algorithm and association rules mining. CBA algorithm produces classifier through two processes. The first process, find classification association rules(CAR). The second process, choose high prior degree rules for cover training set from the discoverable CAR, that is, if the left of the associations rules are the same and the right of them are different, we choose high-cof. rules as possible rules.

After obtaining association rules that satisfy the min-sup and min-cof. between the conditional attributes and the decision attributes, the importance of the rules is defined as[4]: the importance of rule A is ( )imp A , rule A   and B  is given.

If  ( ) ( )cof A cof B> ,then, ( ) ( )imp A imp B> ; If  ( ) ( )cof A cof B= , sup( ) sup( )A B> ,then,  ( ) ( )imp A imp B> ; If ( ) ( )cof A cof B= , sup( ) sup( )A B= ,rule A  is created before rule B ,then,  ( ) ( )imp A imp B> ;  The algorithm is as follows: ( )R sort R= ;  for each rule r R?  in sequence do tcmp = ? for each case d D?  do  if d   satisfies the conditions of r then store .d id  in tcmp  and mark r  if it correctly classifies d ; if r  is marked then insert r  at the end of C ;   DOI 10.1109/ICCCS.2009.35     delete all the cases with the ids in temp from D ; select a default class for the current C ; compute the total number of errors of C ;  end end find the first rule p  in C  with the lowest total number of errors and drop all the rules after p  in C ; add the default class associated with p  to end of C , and return C .

(our classifier) [4].

Traditionally, CBA was used in bank cost analysis.  In part 2 and part 3, we?ll discuss a new mend of the original algorithm.

?. INTRODUCTION OF THE IMPROVING-RATE FACTOR   The higher the cof. is, the stronger the association rules is, namely, the strong association rule. But sometimes it is wrong. In circumstance of precondition and conclusion both with high-sup, although the precondition and conclusion are irrelative, their association cof. is high. One better way to judge the intensity of association rules is to compare the cof. with the standard value of the rule, here we suppose that relative item set?s generant probability created with every rule and generant probability of former item set is independent. We can use frequent item set?s frequency to calculate the standard value. Standard cof. is the concomitantly generant association?s sup divided by the number of transaction in database. And this can help us calculate ?the improving-rate? of the rule. ?The improving-rate? is the cof. of the rule that is divided by the cof. of generant association supposed to be independent. If the rate is bigger than 1, it means that the rule is useful. And the bigger ?the improving rate?? is, the higher the association rule?s intensity is.

?. INCREMENTAL MINING ALGORITHM   Apriori algorithm is the way that mines and analyzes the static information data. When the data in database keeps invariability, it is useful. But when the data is changed, it needs to scan the new database over again for adapting the increase of data in database. With the updating of the database, the original rules are not likely to keep identical. In the modern data management circumstance that information increases rapidly, it results in much repeated work and over-load of database? s operation. And it wastes the original result obtained by old database mining.

We use the incremental mining algorithm to mend the original algorithm. The incremental mining algorithm takes full advantage of the old mining results and mines  updating association rules with the incremental portion of the database. And it can efficiently decrease the database scanning times and sufficiently improved the efficiency of data mining. Suppose D for the original database, and d for changing data set. The incremental updating of the association rules mostly means how to get association rules of D d?  when the new data set d is added to the original database D or d is deleted from D with the changeless min-sup and the changeless min-cof (sometimes they can changed). For the incremental updating database, incremental mining concerns the following four instances of item set: (1) frequent in D , frequent in d , then frequent in D d? ; (2) frequent in D, not frequent in d , then uncertain in D d? ; (3) not frequent in D, frequent in d , then uncertain in D d? ; (4) not frequent in D , not frequent in d , then not frequent in D d? .

For satisfying high efficiency updating of association rules, it creates many kinds of data mining algorithm as FUP, IUA, AIUA, NEW FUP and FUFIA.

FUP algorithm solves (1), (2) and (4), but it can not solve the third. IUA and NEW FUP algorithm solve (3), but the efficiency isn't high.

?. IMPROVEMENT OF ORIGINAL ALGORITHM BY INCREMENTAL MINING ALGORITHM   In Apriori algorithm of original association rules  mining, if the database is updated, the rules created by original database mining will be not appropriate. The ecumenical way is to mine the new database again using the algorithm. In the modern data management circumstance that information increases rapidly, it results in much repeated work and over-load of database?s operation. And it wastes original result obtained by old database mining. The ameliorative algorithm pays attention to the trends of rules development when mines database by association rules algorithm. The new algorithm reduces the number of database scan, and improves efficiency of data mining. It has better precision in decision-making support.

We use incremental mining algorithm to mend the original algorithm. For protecting rules, we present a rule protection model with weight. This rule protection model with weight will exert forecast function in the latter work of incremental mining. Suppose 1W  and 2W  are the weight of D  and d respectively. For association rule X Y? , we define the sup and cof. as the following[5]:  1 1  2 2  ( ) ( ) ( ), ( )  ( ) / ( )  Supp w X Y W Supp X Y W Supp X Y confw X Y  Supp w X Y Supp w X  = + ? =    ? i ? i ?  ?      Here, 1( )Supp X Y?  and 2 ( )Supp X Y?  are the rule?s X Y?  sup. in D  and d  respectively.

( )Suppw X Y?  and ( )confw X Y? are the rule`s X Y? sup. and con. in D d?  respectively.

For association rule X Y? , its sup. and cof. are defined as the following[5]:  1 1  1 1  ( ) ( ) ( ),  ( ) ( ) ( ),  n n  n n  Supp w X Y W Supp X Y W Supp X Y Confw X Y W Conf X Y W Conf X Y  = + +  ? = ? + + ?  ? ? ?   Here, ( )iSupp X Y? and ( )nConf X Y? are rule?s  ( X Y? ) sup. and  cof. in incremental set iD .

First, we use AIUA( advanced incremental updating  algorithm ) to mend  incremental association rules when min-sup isn?t changed. The algorithm need respectively scan only once the original database and the new incremental database.

The algorithm is as the following [6]: Input: DB , the original transaction database  L , the set of DB ?s frequent item set db ;  0S ,the min-sup Output: ''L , the set of DB db? ?s frequent item set (1) ''L ?=  for each X L?  do begin if X .count 0 (| | | |)L S DB db? ? + , then  { }'' ''L L X= + ; { }FL L X= ? ;  Else max max{ sup | }D i iS x D x L? =  ? end  (2) min 0 max 0( )d DS S t S S? ?= ? ? ? ; for each x db? do begin if X . count 0 (| | | |)db S DB db? ? + then  { }'' ''L L X= + ; { }db db x= ? ;  else '  min{ | .

(| | | |)}  i dL x db x count db S DB db  ?= ?  ? ? +    end (3) for each FX L?  do begin for each 'x L? do begin  if X .count FL X+ .count '  0 (| | | |)L S DB db? ? + then  '' '' { }L L X= + ' ' { }L L X= ?  else  { }F FL L X= ? end end (4) ' ' min 0{ | , }d dL L x S x Supd S?= ? ?  ? (5) if 'dL ?=  then output  ''L else for each 'dx L? ,do begin  max max{ sup | }d i iS x d x L? =  ?  min 0 max 01/ ( )D dS S t S S? ?= ? ? ? end end  (6) min( , )D k DL aproiri gen L S ?= ? (7) for each 'dx L?  do begin for each DX L?  do begin if X .count DL X+ .count  ' 0 (| | | |)dL S DB db? ? +  then " " { }L L X= +  else delete X end end (8) output "L  Here: X .count L , X .count db , X .count FL  , X  .count L?  , X .count DL  and X .count dL?  are item set X  sup in L , db , FL  , L?  , DL  and dL?  respectively.

Then, we calculate significative association rules?  sup and cof in new database using the rule protection model with the weight. Calculate sup( x ) in  / sup( )D d x?  in 1D ?  and cof( x ) in / ( )D d cof x?  in 1D ? , then we get 1T  and 2T  .

Here we call them T. T reflects change trend of the strong association rules on the basis of incremental mining. We analyze and forecast the useful association rules by the change trends with database updating every time. Thereby, it supports the decision-making better.

On the other side, we study the lost rules that were the strong association rules in the original database after database updating. Calculate sup( x ) in D d?  and cof( x ) in D d? , and get T . The absolute value of T shows the eliminated risk when the strong association rules in the original database are changed with updating data. The     absolute value of  T for the lost association rules, it is defined as risk degree of the lost. In practical application, people often concern the risk of the strong association rules in the original database, which is the risk of being weak with periodic increase of database. We can also regard the risk degree as the risk that the strong rules turn into the weak rules or the weak rules turn into the strong rules. Higher the risk degree is, lower the universality of the rule is. The introduction of risk degree is for the need of solving the practical problem. It forecasts the trends of association rules based on incremental mining from the different aspect and increases the reliability of forecasting.

?. THE APPLICATION OF IMPROVED ALGORITHM IN BANK  COST ANALYSIS   In process of bank cost analysis, we analyze the basic product attributes and product cost. Based on it, we get the rule that product?s profit is relative to one or some of the attributes and obtain idiographic association rules. The data mining process of bank cost analysis includes: gathering of data, data pretreatment, model training and model evaluating.

We analyze the six months statistic information of bank product. The former five months? data is the original database. And the sixth months? data is the incremental data. We use the original algorithm and the improved algorithm to mine the bank cost analysis database.

The result shows that the improved algorithm is better than the original CBA algorithm. The precision of cost analysis is improved 30 percent. So, with the improved algorithm, we can efficiently mine association rules and mend incremental data mining in database, then improve precision of decision-making.

?. CONCLUSION   We introduce the improving-rate factor to increase the precision for optimizing the original algorithm, and present the improved algorithm for mining incremental data in database. With the data of one bank?s six months statistical information, we test the new algorithm and compare it with the original algorithm. The result shows that the improved algorithm improves the reliability of data mining, and provides more information for decision- maker.

