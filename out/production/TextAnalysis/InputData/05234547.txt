A FUZZY MINING APPROACH FOR AN ENCODED TEMPORAL DATABASE WITH LOWER COMPLEXITIES OF TIME AND COMPUTATION

Abstract? Databases and data warehouses have become a vital part of many organizations. So useful information and helpful knowledge have to be mined from transactions. The principle of data mining is better to use complicative primitive patterns and simple logical combination than simple primitive patterns and complex logical form. This paper overviews the concept of temporal database encoding, association rules mining. It proposes an innovative approach of data mining to reduce the size of the main database by an encoding method which in turn reduces the memory required. The use of the anti-Apriori algorithm reduces the number of scans over the database. A graph based approach for identifying frequent large item sets involves less time complexity. The fuzzy approach that integrates fuzzy-set concepts with Apriori when used for temporal mining involves less computational complexity.

Experimental study has proved that the fuzzy approach performs better by resulting in lesser time and computational complexity then the other approaches for rule mining on an encoded temporal database.

Keywords- Anti-apriori algorithm; Association rules mining; Data mining; Fuzzy approach; Graph based approach; Temporal database encoding.



I. INTRODUCTION  Knowledge discovery in databases (KDD) is often called as data mining. It discovers useful information from large collections of data [1]. The discovered knowledge can be rules describing properties of the data, frequently occurring patterns, clusterings of the objects in the database, etc. The amount of data stored in database is growing rapidly.

Intuitively, these large amounts of stored data contain valuable hidden knowledge [2]. Data mining especially association rule discovery tries to find interesting patterns from databases that represent the meaningful relationships between products and customers or other relationships in some other applications. Because the amount of these transaction data can be very large, an efficient algorithm needs to be designed for discovering useful information.

An association rule describes the associations among items in which when some items are purchased in a transaction, the others are purchased, too. In order to find association rules, we need to discover all large itemsets from  a large database of customer transactions. A large itemset is a set of items which appear often enough within the same transactions. The frequent itemset and association rules mining problem has received a great deal of attention and many algorithms have been proposed to solve this problem.

Discovering association rules in these algorithms are usually done in two phases. In the first phase, the frequent itemset are generated and in the second phase, the interesting rules are extracted from these frequent itemset. If the support and confidence of a rule is above the minimum threshold, the rule will be interest. The task of discovering all frequent itemset is quite challenging especially in the large database because the database may be massive, containing millions of transactions. A famous algorithm, called Apriori, was proposed in [3], which generates (k+1)-candidates by joining frequent k-itemset. So all subsets of every itemset must be generated for finding superior frequent itemset, although many of them may be not useful for finding association rules because some of them have no interesting antecedent or consequent in the rules. This process takes a long time. And it also requires thousands of times of database scan. The complexity of the calculation increases exponentially. Additionally, the size of database is the main problem of this algorithm. Some modified algorithms of Apriori (AprioriTid and AprioriHybrid) are proposed to solve this problem but these algorithms also have the database size problem [2]. A method to encoding the database and an algorithm, which is called anti-Apriori algorithm, is brought into focus. By using this algorithm, only the frequent itemset that are of interest and can be converted into association rules are generated, so it has a lower complexity of time and space. At the meantime, the times of the database scan are also reduced [2].

In real life, media information has time attributes either implicitly or explicitly. This kind of media data is called temporal data. Temporal data exist extensively in economical, financial, communication, and other areas such as weather forecast. Unlike conventional data mining, temporal data mining has its exclusive characteristics.

Temporal data mining can be classified into temporal schema and similarity. Temporal schema mining focuses on time-series schema mining, temporal causal relationship mining, and association rules mining. While similarity study  _____________________________    is mainly concentrated on query algorithms, such as the design of similarity query algorithms and the development of similarity query language [4]. The paper focuses on a fuzzy approach of association rule mining for temporal data which has been encoded.



II. ENCODING AND APRIORI FAMILY In this section, a discussion on the encoding method and the application of the family of Apriori algorithms for association rule mining on a static database is presented  A. The Encoding Method The presentation of database is an important  consideration in almost all algorithms. The most commonly used layout is the horizontal database layout and vertical one [2]. In both layouts, the size of the database is very large. A large database to be transformed into a smaller one with all properties of its original layout is expected.

Database encoding is a new presentation, which can reduce the size of database and improve the efficiency of algorithms. Instead of maintaining a large table in the transaction database, one table is created with only two columns. The first one is the transaction identifier and another is for the entire items that occur in the transaction.

All items in one transaction are converted into only one number that has all properties of these items. By this way, the new database is much smaller than the previous one and can be loaded into memory easily. So the cost of memory is reduced. According to the assumption that only one number represents an itemset, when converting an itemset into a number, a measure attribute is defined, which is a numerical attribute associated with every item in each transaction in the database layout. A binary number expresses a numerical attribute, that is, those items that are occurring in one transaction are depicted with 1 and all the other items are represented with 0. The transaction measure value, denoted as tmv(Ip , Tq ), is a value of a measure attribute related to an item Ip in a transaction Tq . tmv (Ip , Tq )= 0 means item Ip does not occur in the transaction Tq, while tmv (Ip , Tq)= 1 means item Ip occurs in the transaction Tq . In table 1, for example, tmv (I4, T1) is equal to 1. Any item Ip in the set of items is encoded as one prime number, denoted as E (Ip).

Prime numbers are used because any number except 1 and themselves cannot divide them. For any item Ip in the transaction Tq, a new measure denoted as M (Ip, Tq) is equal to the product of tmv (Ip, Tq) and its encoding number E (Ip) is assigned. This value is gotten by equation 1. After this step, for all Ip and Tq, if M(Ip, Tq) equal to 0, then convert M (Ip, Tq) into 1. This operation is described in equation 2. For any transactions, the value MTq is equal to the multiplication of all M (Ip, Tq). The value of MTq is represented in equation 3.

M (Ip, Tq)= tmv(Ip, Tq)?E(Ip) (1) For all (Ip, Tq) If M (Ip, Tq ) =0 => M(I p, Tq ) =1 (2) MTq= ?(Ip, Tq) (3) For any itemset I=(Ip1, Ip2, ?, Ipn), there is one value denoted as MI is equal to the multiplication of all E(Ip) if its Ip occur in I, as described in equation 4. The value MI shows the number corresponding to itemset I. And then this number can be used instead of itemset I.

MI =? E(IP ) (4) IP? I  With this encoding, instead of maintaining all tmv(Ip,Tq) for every item and transaction, the value MI can be stored for every transaction. Example 1 shows the result of using this technique.

Example 1: Convert vertical database layout  Table 1 Binary representation  TID I1 I2 I3 I4 1 1 0 0 1 2 0 0 0 1 3 1 1 1 0 4 0 0 1 1  Table 2 Prime number form  Ip EIp I1 7 I2 5 I3 3 I4 2  Table 3 Single number representation  TID M 1 14 2 2 3 105 4 6  In the case of large databases, encoding an item to one prime number may cause some problems especially in computing the value M (which involves multiplication) for any transaction [2]. As a solution, the database can be divided into smaller parts vertically by having correlated items in one part. Then every part of the database is encoded to one column. Frequent itemset mining is done independently and association rules in every part are discovered. After an encoding of this form, the database has a smaller number of columns which leads to better performance and efficiency.

2.2  Anti-Apriori Algorithm All Apriori-like algorithms for itemset mining start from  finding frequent 1-itemset. In these algorithms, finding frequent itemset is done in bottom up manner. Different from these algorithms, a new algorithm called as anti- Apriori is used, in which the discovery of frequent itemset is done in up to down style. It means that the large frequent    itemset are found at first and then all of their subsets (that are certainly frequent) are extracted. [2]. In this technique, it is supposed that any frequent itemset must be at least one time occurs in the transactions lonely (without any other items that are not member of that itemset). In other words, if itemset (I1, I2, I3) is frequent, the itemset at least in one transaction without any other items, such as shown in table 4.

Table 4 Frequent itemset presentation  I1 I2 I3 ????? Tid 1 1 1 0000000000  In this method for every transaction Tq, the GCD(greatest common divisors) between MTq and MT corresponding to other transactions are computed and frequency of these greatest common divisors are stored in GCD-set. GCD-set is the candidate for frequent set. For any GCD in GCD-set, if its frequency is above the required threshold, it will be selected and inserted into the FGCD-set (frequent GCD itemset). For every transaction maintained, a set is denoted as GCDTid, composed of GCDs and frequency of any GCD.

For example, if GCD-set and frequency between first transaction and other transactions is equal to GCD1={(42,3), (6,8), (21,2), (15,4), (105,1)} and the required threshold for support is equal to 7 and then the set (6,8) has a frequency equal to 8, greater than 7, and then 6 is inserted into FGCD- set.

Discovering association rules is based on all FGCD, which has been found in the previous phase. Measure M corresponds to any frequent itemset maintained in FGCD- set. Every measure M in FGCD-set is decomposed into the multiplication of prime number and each prime number corresponds to one item. The itemset that corresponds to M is identical and frequent, and all subset of it must be frequent. Every M in FGCD-set is decomposed into a candidate head Y and a body X=M/Y. This algorithm iteratively generates candidate heads Ck+1 of k+1 size, starting with k=1. If the head and the body are interesting and valuable, the confidence C of the rule X=>Y is computed as the quotient of the supports for the itemset. C =Support(M) /Support(X) (Support(X) is computed by counting the number of MTid that can be divided by X). If any rule has a C greater than or equal to the given threshold for confidence, the rule will be appended into association rules.

2.3 Apriori, AprioriTid, and AprioriHybrid  The Apriori and AprioriTid algorithms generate the candidate itemsets to be counted in a pass by using only the itemsets found large in the previous pass, without considering the transactions in the database. The basic intuition is that any subset of a large itemset must be large.

Therefore the candidate itemsets having k items can be  generated by joining large itemsets having k-1 items, and deleting those that contain any subset that is not large. This procedure results in generation of a much smaller number of candidate itemsets. The AprioriTid algorithm has the additional property that the database is not used at all for counting the support of candidate itemsets after the first pass [5]. Rather, an encoding of the candidate itemsets used in the previous pass is employed for this purpose. In later passes, the size of this encoding can become much smaller than the database, thus saving much reading effort. Based on the observations of Apriori and AprioriTid, a hybrid algorithm which is called as AprioriHybrid uses Apriori in the initial passes and switches to AprioriTid when the candidate itemset at the end of the pass will fit into the memory.



III. DISCOVERY OF TEMPORAL ASSOCIATION RULES In this section, the graph mining method for a temporal database employs the Apriori algorithm with an added feature (i.e.) time interval expansion and mergence [6]. Also a fuzzy approach to a temporal database that integrates fuzzy-set concepts and AprioriTid is discussed [7].

A. Time based extension of Apriori  Temporal association rules can be viewed as a factor of derivative consideration time, when mining association rules.

Recently, the Apriori algorithm is adapted to temporal association rules mining [4]. Time-interval expansion, and mergence, is combined with the Apriori algorithm to association rules mining on datasets that have valid-time constraints. The key implementation is to add a valid-time attribute on association patterns. If a given tuple owns attribute A, the problem can be decomposed into two sub problems. (1) Check if the valid-time attribute of a given tuple matches another attributes. (2) Check whether the tuple that does not attach any valid-time attribute has attribute ?A? [4]. The logical linkage between two sub problems is that if the sub problem (1) holds, sub problem (2) must hold; otherwise; if sub problem (2) doesn?t, sub problem (1) mustn?t hold. According to the first case, we can scan database to solve these two sub problems simultaneously. Time complexity and space complexity of this case are almost the same as those of Apriori algorithm.

B. Apriori for an encoded dynamic database In this section, the graph mining algorithm is discussed  [4]. The algorithm contains two steps to mine temporal data.

The sample transaction is showed in Table5:  Table5 The general database model  TID Itemset Valid-time 100 ACD [40, 70] 200 BCE [60, 90] 300 ABCE [90, 120]    400 BE [30, 50] 500 ABC [400, 500]  It is found that frequent item sets do not have temporal factor. The search process is listed as:  ? First, enumerate all items. The numbers of A, B, C, D, E are 1, 2, 3, 4, and 5 respectively.

? Second, generate the frequent 1-item set according to support enough, and give numbers to frequent itemset. Assume that the support enough is 2, the frequent 1-item set are expressed as (1), (2), (3), (4) and (5). Correspondingly, the numbers of BV1, BV2, BV3, and BV5, are (1010), (0111), (1110) and (0111) respectively.

? Third, create a relationship graph that shows the relationships among items in frequent 1-item set; and then generate frequent 2- item set.

? Fourth, create a searching frequent 3- item set.

During this process, we determine the execution state of algorithm, because the count of items in frequent 2-item set is 4, which is larger than 3, and the number of the node of which the degree is larger than 2 is 3, it is larger than 3. So the algorithm continues execution. Finally, We travel the list T of candidate frequent itemset to get the tuple (2,3,5), in which x=3. This item can be used to construct a complete graph. At the same time, we check out the BV2 BV3 BV5 , the count of number 1 in the result is less than support enough, so it is a frequent itemset.

? Fifth, the count of the element in frequent 3-item set is 1, which is less than 4, resulting in the termination of the algorithm. Check out whether the valid-time attribute of all frequent items meet each other by making use of the technologies of time-interval expansion and mergence, let support=2, then scan the database. The checkout result is that (1), (2), (3) (5), (1,3), (2,3), (2,5), (3,5) and (2,3,5). These all meet temporal constraints of frequent items. Generate temporal rules by combining confidence enough with the frequent items obtained above performance evaluation.

When the Apriori algorithm searches frequent n- itemset in frequent n-1 item set, it firstly takes joint and pruning operations to construct candidate frequent itemset CK , The joint operation will be executed CS2 times, and the pruning operation will be implemented K. CS2 times. The intermediary result S is the count of candidate frequent itemset. Let the time complexity of executing comparative operation be O(t), The complexity of the algorithm is dependent upon the O(t) order frequent set. Assuming that there are 10-thousand frequent 1-item set, the Apriori algorithm will produce more than ten-million frequent 2- item sets. If we want search frequent schemas whose length is 100, it will require 1030 candidate frequent itemset, which will reduce the efficiency of Apriori algorithm. Also the number of the elements in the candidate frequent itemset is greatly decreased. For instance, the frequent 2- item sets  in this example are (1,3), (2,3), (2,5), and (3,5). From the time-space complexity point of view, the performance of the algorithm is better [6].

C. Proposed Fuzzy AprioriTid for an encoded dynamic database  Fuzzy set theory is being used more and more frequently in intelligent systems because of its simplicity and similarity to human reasoning. Therefore to use fuzzy sets in data mining, a mining approach that integrates fuzzy set concepts with The AprioriTid mining algorithm has been identified.

It finds interesting itemsets and fuzzy association rules in transaction data with quantitative values. The role of fuzzy sets helps transform quantitative values into linguistic terms, which reduces possible itemsets in the mining process. They are used in the AprioriTid data mining algorithm to discover useful association rules from quantitative values.

The fuzzy mining algorithm first transforms each quantitative value into a fuzzy set with linguistic terms using membership functions. The algorithm then calculates the scalar cardinality of each linguistic term on all transaction data using the temporary set. Each attribute uses only the linguistic term with the maximum cardinality in later mining processes, which keeps the number of items the same as that of the original attributes. The mining process based on fuzzy counts is then performed to find fuzzy association rules.



IV. PERFORMANCE AND EVALUATION  The anti-Apriori algorithm in combination with the encoding method decreases the size of the database and also leads to reduction in the number of passes over the static database. The performance of AprioriHybrid relative to Apriori and AprioriTid for large datasets is as follows.

AprioriHybrid performs better than Apriori in almost all cases. In general, the advantage of AprioriHybrid over Apriori depends on the size of the candidate itemset that declines in the later passes. If there is a gradual decline in the size, AprioriTid can be used for a while after the switch, and a significant improvement can be obtained in the execution time. By using this encoding method the efficiency of Apriori, AprioriTid and AprioriHybrid has improved significantly.

The use of Apriori and anti-Apriori algorithm combined with an encoding method for association rule mining in a temporal database has been experimented on complaints database. The encoding method reduced the size of the database, which is depicted by figure1. The use of anti- Apriori on databases with time constraints reduced the number of scans over a temporal database.

Figure1: Effect of encoding Database encoding has been applied to a static database before applying Apriori or anti Apriori. To make it scalable, the same is applied to a dynamic database which involves time constraints. The fuzzy AprioriTid mining approach has been found to reduce the computational time involved.

Figure2 shows the performance of these approaches in terms of time.

Figure2: Performance comparison

V. CONCLUSION AND FUTURE WORK  This paper studied the impact of the Apriori family of algorithms on an encoded database for association rule mining. Each of the algorithms has a different impact and produces effective results. The effect of Apriori and anti- Apriori algorithms on a temporal data base which has been encoded by an encoding method provided advantageous results in terms of lower complexities of time and space.

The graph mining method has been found to involve less execution time. The fuzzy approach to data mining has been  found to be good enough to provide reduction in computation time. As future work, the discovery of association rules may be used to allow the user of a knowledge discovery system to observe the changes and fluctuations in the rules which could be considered as an enhancement. It may also possible to observe the seasonal or cyclical changes and fluctuations in the rules.

