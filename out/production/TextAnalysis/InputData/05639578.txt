

Abstract?One of the challenging problems in the weighted association rules mining is to assign weights to items. For practice, self-assigned weights technique is more useful. In this paper, we proposed a self-assigned weights method to discover positive and negative association rules, instead of assigning the weights by users. To avoid mining misleading and uninteresting rules, a new type parameter, called sawinterest, is proposed to eliminate the redundant rules. The rational results are presented.

Keywords?self-assiged weights,  association rules, health data, data mining

I. INTRODUCTION With the development of computer technology and  biomedical engineering research, computer information technology applied widely in medical field. A great lot of medical records were stored which contain a lot of important knowledge. So it?s meaningful to use data mining tools to analyze the medical records, and mine the hidden, deep-seated, valuable knowledge. Association rule mining is an important technique in data mining, which aims to explore the relation between the data. It has turned into a thriving research topic in data mining and has numerous practical applications, including cross marketing, text mining, Web log analysis, and recommendation systems [1], [2], [3], [4].

The classical model of association rule mining employs the support measure, which treats every transaction equally.

Practically, different transactions have different weights in real- life datasets, in which different items usually have different importance. Much effort has been dedicated to association rule mining with user-specified weights [5], [6], [7]. However, medical and health data do not come with such user-specified weights. In addition, negative rules are also important for data analysis [8].

In this paper, we introduce a new measure of itemsets with boolean attributes, called saw-support. The basic idea about saw-support is that a frequent itemset may not be as important as it appears, because the weights of transactions are different.

The weights in this paper are derived from the internal structure of the database based on the assumption that important transactions consist of important items. This assumption is  exploited by extending Kleinerg?s HITS model and algorithm [3] to bipartite graphs. The weights are assigned by self- learning the data. So we can use these weights in weighted association rule mining algorithm WARM [5], whose item weights are assigned. Experiment results show that the value of sawsupport is not necessary to be pre-set, and more interesting patterns may be discovered through this measurement.

The rest of this paper is organized as follows: First, WARM is discussed. Next we present the evaluation of transactions with HITS, followed by the creation of the weights and the corresponding mining algorithm with a new prune step.

Experimental results on different types of the algorithms are given. Concluding remarks are made in the last section.



II. WEIGHTED ASSOCIATION RULES OVERVIEW Association rules mining was primarily proposed for  market basket to understand consumer purchasing patterns in retailing industry [1]. It proposed the support-confidence measurement framework and reduced association rule mining to discover frequent itemsets. The following year, a mining algorithm, Apriori, was proposed [9]. Much effort has been dedicated to the classical (boolean) association rule mining since then. A lot of algorithms have been proposed to extract the rules more efficiently. WARM generalizes the traditional model to the case where items have weights [5], [6]. Some researchers introduced weighted support and weighted confidence of association rules based on the costs assigned to items or transactions. The definition broke the downward closure property. As a result, the weighted algorithm became more complicated. However, another problem came following the traditional algorithms: the weights need to be assigned by users, but users may not know how to confirm the weights correctly.

Those algorithms follow the classical measurement framework. But if the minimum support and minimum confidence are given, the results are the same. All the classical algorithms produce positive associations between items existing in transactions. What about association of the type: ?one medical record contains disease A but not disease B?.

Recently, mining association rules has received some attention     and is proved to be useful. However, there is little study in negative association rules, especially weighted negative association rules.

Wang and Su proposed a novel approach on item ranking [10]. A directed graph is created where nodes denote items and links represent association rules. A generalized version of HITS is applied to the graph to rank the items, where all nodes and links are allowed to have weights. Base on the link-based models, Ke Su and Fengshan Bai proposed a new weighted algorithm [11]. Unfortunately, that algorithm was not easy to mine negative rules.



III. PROPOSED METHOD The problem of mining association rules that satisfy some  minimum weighted support and weighted confidence can be decomposed into three subproblems:  1.   Rank an item and assign its weight.

2. Find significant itemsets whose weighted supports  meeting the given threshold.

3.   Build rules within the itemsets found in Step 2.

In this section, we provide a method for solving them step  by step.

A. Ranking Items with HITS Let I={I1,I2,?,Im} be a set of items and let T={T1,T2,?,Tn}  be a set of transactions in database. Clearly, D is equivalent to the bipartite graph G= {D, I, E}, where  E= {(T , Ii):Ii ?T, T ?D, Ii ?I} Example 1: Consider the database shown in Fig.1(a). It can be equivalently represented as a bipatite graph, as shown in Fig.1(b).The database contains medical records. The items {Nausea,Lumbar,Urine,Micturition,Urethra,UrinaryBladder,N ephritis}are different records.

Fig. 1. The bipatite model of transactions database  The graph representation of the transaction database is inspiring. It gives us the idea of applying link-based ranking models to the evaluation of transactions. In this bipartite graph, the support of an item Ii is proportional to its degree, which shows again that the classical support does not consider the difference between transactions. Intuitively, an important transaction, which is highly weighted, should contain many important items; at the same time, an important item should be contained by many important transactions. The reinforcing relationship of transactions and items is just like the  relationship between hubs and authorities in the HITS model [12].

Regarding the relationship between the hubs and the authorities, we can apply HITS to this bipartite graph. The following equations are used to each iteration:   : :  ( ) ( ), ( ) ( ) i i  i i T I T I I T  auth I hub T hub T auth I ? ?  = =? ?                   (1)  When the HITS model eventually converges, the auth weights of all items are obtained. These weights represent the potential of transactions to contain high-value items. An item contained by few transactions may still be a good auth if all transactions are top ranked. Conversely, the item contained by many ordinary transactions may have a low hub weight.

B. Weighted Metric After the iteration process, we obtain every auth(Ii). The  auth of the item can reflect the importance of the item. For this reason, we pick up the maximal auth to normalize all auths.

The normalized auth(Ii) is the weight of the Ii denoted as wi.

W= {w1,w2,?,wm} authMax = Max{auth(Ii)| Ii ?I}             (2) wi = auth(Ii)= auth(Ii)/authMax               (3)  The items are always arranged by their weights from the largest one to the smallest one in an item set shown as Table I.

TABLE I Items and their weights of example database   Definition 1. The weighted support of an itemset X is defined as  sawsup(X)=sup(X)*w(X)                        (4) sup(X)=conutT(X)/|T|                          (5)  w(X) =max{w1,w2,?,wp}                         (6) Where w(X) is a weight of X, and countT(X) is the number  of transactions in T containing X. Actually, p is the items? count of the itemset X.

An itemset is called weighted-frequent (large) if its support is larger than a user-specified value (also called minimum weighted support (minsawsup)). For example, If sawsup(X) ?minsawsup, the itemset X is weighted-frequent.

Definition 2. The sawsupport of an association rule X=>Y is defined as  sawsup(X=>Y) = sawsup(X?Y)                   (7) and the weighted confidence is  sawconf(X=>Y) = sawsup(X?Y)/ sawsup(X)          (8) Basically, saw-support measures how significantly X and Y     appear together; saw-confidence measures how strong the rule is. If its weighted support sawsup(X=>Y) and weighted confidence sawconf(X=>Y) meet minimum weighted support (minsawsup) and minimum weighted confidence (minsawconf), X=>Y is a strong rule. The task of mining association rules is to discover the strong rules.

Definition 3. The interest metric between itemset X and Y is defined as sawinterest(X,Y)=sawsup(X?Y)/(sawsup(X)*sawsup(Y))   (9)  If the |sawinterest-1|<mini, X and Y don?t influence each other obviously. The rule between X and Y isn?t interesting.  If |sawinterest-1| ? mini, the rule between them may be interesting.

Definition 4. The positive and negative rules between item set X and Y are defined as  X=>Y is positive rule and it has three corresponding negative rules: X=>?Y, X=>?Y, ?X=>?Y.

Mining negative association rules raises a lot of critical  issues. The number of infrequent itemsets increases by exponential. For instrance, if the number of item is 100 and the number of frequent itemsets is 210, the number of the infrequent itemsets is 2100-210. Therefore, the support and confident of the negative association rules is difficult and disinteresting directly. But we can deduce the negative association rules from the corresponding positive itemsets? support in the frequent itemsets.

We give a set of formulas as following: (1) sup( ) ( ) sup( )  ( )(2) sup( ) sup( ) sup( ) ( )  ( )(3) sup( ) sup( ) sup( ) ( )  (4) sup( ) ( ) ( )( ) sup( ) sup( ) sup( )  ( ) ( )  (5)  saw X w X saw X w X Ysaw X Y saw X saw X Y  w X w X Ysaw X Y saw Y saw X Y  w Y saw X Y  w X Y w X Yw X Y saw X saw Y saw X Y w X w Y  ? = ?  ? = ?  ? = ?  ? ? =  ? ? ?  ?? ?  ?? ?  ? ? ?? ?  sup( )( ) sup( )  ( ( ) / ( )) sup( ) sup( )(6) ( ) sup( )  ( ( ) / ( )) sup( ) sup( )(7) ( ) sup( )  (8) ( ) ( ) ( ( ) / ( )) sup( )  saw X Ysawconf X Y saw X w X Y w X saw X saw X Ysawconf X Y  saw X w X Y w Y saw Y saw X Ysawconf X Y  saw Y sawconf X Y  w X Y w X Y w X saw X  ? =  ? ? ? =  ?? ? =  ? ? = ?  ?  ? ?  ? ?  ? ? ? ( ( ) / ( )) sup( ) sup( )  ( ) sup( ) w X Y w Y saw Y saw X Y  w X saw X ? ? ?  ? ?   As for the frequent items, we apply WARDM [13].

C. Generate Rules  The third step is more time-consuming than the classical algorithm. The classical algorithm (Apriori-ap-genrules) generates rules with the theorem that if confidence(X=>Y-X)< minconf, confidence(X?=>Y-X?) < minconf, X? ? X.

confidence(X=>Y-X) = support(Y)/support(X), confidence (X?=>Y-X?) = support(Y)/support(X?). Without weights, we  can easily find the result. Because support (X?) > support(X).

But when we assign the weight, the result can?t be got. Indeed, when X? is weighted frequent itemset, X may not be. We don?t know the exact relationship between sawsupport(X) and sawsupport(X?). When we get one rule, we should check the weighted support and weighted confidence.

Proof. Let X be an itemset, and the sets X? are the subset of X.

X and X? have the same first item. sawsup(X) ?sawsup(X?).

The items are always rearranged by descending in itemsets.

w(X)=W={w1,w2,?,wp}=max{w1,w2,?,wp}, so w(X)=w1,w(X?)= w1.X? has the same first item with X sawsup(X)=sup(X)*w(X)=sup(X)*w1, sawsup(X?)=sup(X?)*w(X?)=sup(X?)*w1 sup(X)? sup(X?),X? is subitem of X.

Hence, sawsup(X) ?sawsup(X?).

If X? don?t satisfy sawsupp(X?)?minsawwsup, we can prove  that X also don?t satisfy sawsupp(X) ?minsawsup. In the function new-genrules, we can check the itemset X whether it is the frequent weighted itemset. If the result is true, then we check sawinterest and sawconf; if the result is false, we delete the item. That will reduce the cost of the running time of the algorithm.

The method generates the association rules layer by layer, the number of the layer corresponds with the number of the rule consequent.  Firstly, we try the rules that the number of the rule consequent is one. If the rules satisfy the limit, we use them to produce new candidate. For example, if {acd}=>{a} and {acd}=>{b} are the rules satisfied the limit, we can get the new candidate {ad} =>{bc}. If there is a node that can?t meet the given threshold, we can cut the subgraph formed by the node.

Fig. 2 Use the proved theorem to prune the association rule  PARS: positive association rules set NARS: Negative association rules set.

new-genrules (fk, Hm): fk:   frequent itemset   Hm: rule consequent      Overall, the proposed algorithm is shown below:    :  ( ) ( ) i  i t I t  auth I hub t ?  = ? '( ) ( )ihub t auth I+ =

IV. EXPERIMENT RESULT We conducted our experiments on a medical database to  study the relations between the diseases. The database had 140 transactions. The items of this database are {Nausea, Umbar, Urine, Micturition, Urethra, UrinaryBladder, Nephritis}.

TABLE II  Experimental results of our algorithm.

A=>B rules ?A=>?B rules A=>?B rules ?A=>B rules     (Urethra)=>(Urine)    (UrinaryBladder) =>(Urine)     (?Nephritis, ?Urethra) =>(?Nausea)  (?Urethra, ?Nausea) =>(?Nephritis) (?Nausea)=>  (?UrinaryBladder) (?UrinaryBladder)=>  (?Nausea) (?Nausea)=> (?  Nephritis) (?Nephritis)=> (?  Nausea)     (Lumbar)=> (?  UrinaryBladder)   (UrinaryBladder) =>(?Lumbar)        (?Lumbar) => (UrinaryBladder)   (?  UrinaryBladder) =>(Lumbar)    TABLE III Experimental results of Apriori.

A=>B rules ?A=>?B rules     (Urethra)=>(Urine)    (Nephritis)=> (Lumber)  (?Nephritis)=>(?Nausea) (?Micturition,?UrinaryBladder)=>(Nausea)  (?Nausea, ?UrinaryBladder)=>( ?Micturition) (?Lumber)=> (?Nausea)  (?UrinaryBladder)=>( ?Urine) (?Lumber, ?Nephritis)=>(?Nausea)  ( ?Micturition)=> (?Nausea)   We set num_it = 5, minsawsup = 0.10, minswaconf = 0.10,  mini = 0.25.We can find there are twelve rules under those restricts under the new algorithm in TABLE II.

Next we use the classical algorithm (Apriori) in Weak 3.5.8 [14] to mine the negative and positive association rules.

Weka is a software of data mining. It provides the algorithm (Apriori) to mine the association rules. Apriori adopts the support-confidence framework without weight.

In Weka, we set minsupport = 0.4, and minconfidence = 0.9. Although we set higher restrict, the rules is so many. We choose the top ten results to compare with the proposed algorithm. The results are shown in Table III.

We can easily find the difference between Table II and Table III:  Firstly, Apriori may leak some rules like A=>?B and ? A=>B. Those rules may be useful for us to analyze the medical and health records.

Secondly, our algorithm with self-assigned weight missed some rules that Apriori can discover. Conversely, some rules can be found by our algorithm but not Apriori. For example, (UrinaryBladder) => (Urine) and (?Urethra, ?Nausea) => ( ? Nephritis). When we use the new algorithm to mine association rules, we can find other useful rules to help us analyze the data. In essence, the difference is caused by our basic assumption: the quality of transactions and importance of items are in a mutually reinforcing relationship.

But when we use this new algorithm to mine the rules, it is more difficult to assign minsawsup, minswaconf and mini.

These parameters with weight don?t reflect the data directly.



V. CONCLUSION In this paper, we have presented a novel framework in  association rule mining. First, the HITS model and algorithm are used to derive the weights of items from a database with only boolean attributes. Second, we assign the weights to the items. Third, we use those weights to mine positive and negative association rules under the sawsup and sawconf framework.

Experimental results show that the algorithm is efficient to delete many uninteresting rules and mine the negative rules also.



VI. ACKNOWLEDGEMENTS This work was supported by Nature Science Foundation of     Guangdong Province China, and supported by Science and Technology Plan Project of Guangdong Province China, and supported by Science and Technology Plan Project of Shenzhen China.

