OAMS: A Highly Reliable Metadata Service for Big Data Storage

Abstract?As application requirements increase in quantity and popularity, big data storage is becoming an important technology which data centers and Internet companies de- pend on. The cluster file system with centralized metadata management often encounters planned or unplanned down- time which requires higher reliability for metadata service.

Current paradigms use the backup server to take over as the primary when the latter is in the case of failures. But if the backup crashes, the file system is still in an unreliable state. In this paper, we present a novel primary-backup policy (OAMS), which ensures the availability of metadata service in cluster file system. Different from traditional paradigms, OAMS employs multiple standbys to tolerate the single point of failure. It is based on the built-in shared storage pool for metadata synchronization and a series of protocols for active election, active-standby switching and etc. By using a prepared, automatic state transition among metadata servers, OAMS achieves an automatic recovery in the form of hot standby.

It also supports server self-recovery and dynamical addition for standbys at runtime. Evaluation results show that OAMS obviously improves the reliability of metadata service while the average performance degradation is below 8%.

Keywords-big data; cluster file system; metadata service; high reliability; primary-backup paradigm

I. INTRODUCTION  With the expansion of information scale and emergence of massive semi-structured or unstructured data, the big data period is coming. Applications [1][2] in data centers and Internet companies are diversified greatly and often need 24x7 hours service which requires higher reliability. The cluster file system acting as the underlying storage for big data analysis and processing faces new challenges. Current distributed file system usually adopts a centralized metadata management policy. That is, the metadata server manages files and directories of the whole file system and responds to client requests. For example, GFS [3] uses the master to manage namespace of the cluster and provide metadata service. HDFS [4] adopts the similar idea and the namenode is also a single server. As a big data cluster often encounters planned or unplanned downtime which may be caused by software upgrade, system configuration and hardware fail- ures, the design of centralized metadata management easily leads to the single point of failure: once the master crashes, the file system will be unavailable. To solve this problem, the primary-backup paradigm is currently widely used to improve the reliability of metadata service. In this paradigm, the backup server takes over as the primary and continues   DOI 10.1109/CSE.2013.191    DOI 10.1109/CSE.2013.191     to provide service when the latter encounters failures. It tolerates the single point of failure and needs no complicated state transition between metadata servers. However, as the primary-backup paradigm relies heavily on the backup it could lead to another single point of failure. If the backup crashes, the primary is still in an unreliable state.

There are many methods used for the primary-backup paradigm. According to the backup mode, it is divided into active-standby and cluster manner. The paradigm can be classified into three categories denoted as cold standby, warm standby and hot standby with the recovery method. It is also defined as manual and automatic mode according to the switching pattern. When switching from the primary to the backup, it needs to keep consistent namespace states between them. Traditional log file systems [5] combine transaction processing [6] with failover technology to re- cover metadata information. They adopt write-ahead logs to record metadata operations to local disks firstly and then execute them in memory. If the system crashes or restarts, it can recover namespace state by reading and redoing logs. Namespace consistency of the primary-backup paradigm depends on log technology. During running, the backup synchronizes metadata operations from the primary and commits them in its own namespace. With this approach, the backup keeps an up-to-date namespace image with the primary and takes over the service of it in the case of failures. As the backup needs to synchronize metadata information from the primary, the method can be divided into two ways: metadata replication and shared storage.

BackupNode [4] in HDFS is a simple reliable feature.

The backup is a wrapper of the regular namenode instance which implements metadata replication of the primary. It keeps an up-to-date namespace image with the primary but does not provide service. Once the primary crashes, a failover procedure will be done with the manual pattern.

BackupNode uses replication mechanism to synchronize metadata information. When the primary stores log records to local disk it flushes them to the backup simultaneously.

Due to various errors in the cluster, the backup may lose metadata modifications and cannot synchronize with the primary in time. And BackupNode takes a long time for recovery as it needs to reconstruct file locations for failover.

Yahoo! combines BackupNode with Linux tools to achieve active-standby switching. It uses double network interface cards for failure detection and DRBD [7] for metadata synchronization. Yahoo! uses the shared storage to keep metadata consistency between the primary and the backup. With this approach it needs additional facility and has the risk of conflict for concurrent access.

AvatarNode [8] at Facebook is designed for a realtime HDFS that supports online applications. There are two AvatarNodes in the cluster: one providing service as the active while the other working as a standby. AvatarNode uses NFS [9] to store one copy of the filesystem image and one  copy of the transaction log. Metadata operations are written by the active in NFS and read by the standby simultaneously.

AvatarNode acts as a hot standby because datanodes report block locations to both the active and standby. However, AvatarNode depends on NFS and has the problem of IO fencing when sharing transaction logs. The implementation in Cloudera [10] is similar to AvatarNode which avoids the risk of concurrent access. It employs additional tools to prevent the isolated sever from writing shared metadata logs.

Hadoop [11] HA Branch uses NFS or the quorum journal manager (QJM) for synchronizing metadata information.

The further step is to use BookKeeper [12] as the sharing logging service. Though HA Branch achieves automatic active-standby switching to some extent, the reliability will be greatly reduced if the standby crashes. And it increases the complexity of file system with third-party software support. PacaficA [13], HARP [14] and Echo [15] imple- ment storage systems based on log technology. By defining different replication strategies, they ensure metadata consis- tency when recovery. However, these systems are key-value storages and cannot satisfy sophisticated operation semantics of file system. Table I compares different primary-backup paradigms for metadata server.

Different from above paradigms, we propose a novel primary-backup policy called one active multiple standbys (OAMS) to achieve the availability of metadata service in cluster file system. With a series of protocols, OAMS tolerates multiple points of failures and achieves an auto- matic switching in the form of hot standby. It is based on the built-in shared storage pool to synchronize metadata operations. Besides, OAMS supports server self-recovery and dynamical addition for standbys at runtime. Theoretical analysis [16] proves that the reliability of metadata service can be improved by 3 to 4 orders of magnitude comparing to traditional primary-backup paradigms. Performance re- sults show that OAMS can achieve active-standby switching within several seconds while keeping high performance for metadata operations.

The remainder of this paper is organized as follows.

Section II introduces system model of our primary-backup paradigm. Section III describes the OAMS policy and its three protocols. In section IV, we evaluate the reliability and performance of OAMS and compare it with other paradigms.

We conclude the paper in Section V.



II. SYSTEM MODEL  Our policy is deployed in a cluster file system with centralized metadata management, which employs one meta- data server as the active and multiple servers as standbys.

They are connected by high speed network and constitute a primary-backup cluster. Besides providing metadata service, the active and standby are also treated as storage nodes for     Table I PRIMARY-BACKUP PARADIGMS FOR METADATA SERVER  Paradigm Recovery method Switching pattern Metadata synchronization BackupNode Warm standby Manual Replication  Yahoo! Warm standby Manual or automatic Shared storage AvatarNode Hot standby Manual Shared storage  Cloudera Hot standby Manual Shared storage Hadoop HA Hot standby Manual or automatic Replication or shared storage  a shared storage pool. The pool is a built-in virtual storage which is used for metadata synchronization and persistence.

Fig. 1 depicts the system model of the primary-backup cluster, which comprises one active and two standbys.

OAMS acts as a highly reliable backup policy to ensure the availability of metadata service in cluster file system. Under failure free cases, the active responds to client requests and provides file system service. When the active modifies metadata information and updates namespace, it writes logs to local disk and flushes them to standbys through the shared storage pool. Standbys receive metadata operations and apply them in memory simultaneously. They keep up- to-date namespace states with the primary but do not provide metadata service. Namespace image can also be persistent in the shared storage pool for failover after the metadata server restarts. With the heartbeat mechanism, a monitor is used to detect the system status in the primary-backup cluster. If the active crashes, one standby is elected as the new active and takes over its service. To reach a consensus, the Paxos protocol [17] is used for active election among multiple standbys and to prevent the so-called split-brain scenario. After active-standby switching, the client connects to the new active for fault tolerance and resends metadata requests. The new active receives metadata operations and continues file system service. The role of active and standby can be assigned from configuration when starting up. At any time, there is only one metadata server which is in the active state. As metadata and data management are decoupled in the cluster file system, file contents are split into large blocks and replicated in datanodes. For constructing file locations, datanodes talk to both the active and standbys. By using a prepared, automatic state transition among metadata servers, OAMS achieves an automatic recovery in the form of hot standby.



III. OAMS POLICY  In contrast to traditional primary-backup paradigms, OAMS employs multiple standbys for the active to tolerate failures in cluster file system. It provides a highly reliable metadata service with each server acting as different roles.

A global view is cached to maintain states of the active and standbys. Combined with the shared storage pool and Paxos protocol, OAMS processes metadata synchronization, active election and active-standby switching. It includes  ?????? ?? ?? ?? ??  ??	??? ????	?? ????  Heartbeat Heartbeat Heartbeat  ?	???  Active electionConfiguration Active-standby  switching  Figure 1. System Model of the primary-backup cluster  three protocols to achieve an automatic recovery in the case of failures.

A. Synchronization Protocol  When using multiple standbys for backup of the active, it needs to synchronize metadata operations among them.

Synchronization protocol is a replication method which transmits journal streams from the active to standbys. Based on the shared storage pool, a distributed protocol similar to the two-phase commit protocol (2PC) [18] is applied in OAMS to provide namespace consistency.

2PC protocol is a simple and popular atomic commitment protocol for distributed transaction. It is divided into two phases which is called preparation phase and commitment phase respectively. In the preparation phase, a role called the coordinator sends ?prepare? messages to all participants to ask them whether they agree to commit it. Each participant checks its status and decides if it satisfies the condition.

The coordinator waits and collects replies from participants in the second phase. When receiving all ?ready? messages, it sends ?commit? messages to participants for execution.

After all participants have completed operations, they send ACK messages to the coordinator to finish the transaction. If some participants send ?abort? messages, the transaction will be cancelled for all. During this process, logs are written in local disks for recovery. 2PC protocol achieves consistency     of transaction but the state is still indeterminable if there are failures in the commitment phase. The process of metadata synchronization using 2PC is depicted in Fig. 2a.

In OAMS, standbys need to synchronize metadata opera- tions from the active to keep an up-to-date namespace with it. This can be regarded as a transaction because it may result in inconsistent server states if errors occur. Inspiring by 2PC, OAMS presents a synchronization protocol which reduces the overhead of replication and achieves namespace consis- tency among the active and standbys. For comparison, the protocol in OAMS is depicted in Fig. 2b. The key idea here is to combine the shared storage pool with the global log to reduce the processing latency. After the coordinator decides committing or aborting the transaction, it is unnecessary to wait for the operations of participants. The coordinator will respond to clients when it receives ?ACK? messages from participants and write the global log.

For the synchronization protocol, the active is seen as the coordinator and standbys as participants. A batch of metadata operations are buffered in the active and wait for being committed one time. When the active writes log records in local disk, it begins to flush them to standbys.

The standby receives metadata journals and writes ?prepare? logs in local disk. It then sends the ?ACK? message to the active to continue these operations. When receiving all ?ACK? messages from standbys, the active commits metadata modifications and writes a global log in the shared storage pool. If some standby does not respond after a timeout period, the active will cancel all operations and marks a tag in the global log. For 2PC protocol, it needs to notice all participants to commit or cancel operations before the active responds to clients. In OAMS, as the state of metadata operations has been stored in the shared storage pool, the active can return to clients immediately after it writes the global log. As the pool is a reliable virtual storage, the standby can decide whether to commit them from the global log even if it does not receive notice from the active.

To finish the processing of synchronization, the active still sends ?commit? or ?abort? messages to participants. The participant completes subsequent operations and writes logs in local disk. The global log can also be used for recovery after the active or standby crash. With the synchronization protocol, OAMS ensures the consistency of namespace state among the active and standbys while not affecting the performance of metadata operations.

B. Failover Protocol  The failover protocol is used for fault tolerance when the active crashes. With the heartbeat mechanism, OAMS monitors server status in the primary-backup cluster. If the active crashes, a new one will be elected from standbys and takes over the metadata service of it. Combined with Paxos protocol for election, OAMS reaches a consensus for choosing the new active among servers. With more than one  ????   ?????? ???  ????? ??	?? ????  ?? ? ????	?? ????	???  ?	??  ?	?????? ?  ????   ?	??  ???  ????? ?????? ?? ???? ????  ????? ?????? ?? ???? ????  ? ?  ?????? ?? ????  ????? ????	?? ????  ?	??  ???  ? ?  ????? ? ?? ???? ??  ????? ? ? ????  ?	?  ??!?	?? ???????? "????#? ????????? ?  ???????? ????	??? ?  ???????? ????	??? ?  ????   ?????? ???  ????? ???? ? ???	? ???$  ?	??  ????   ?	?????? ?  ????? ????	?? ????  ? ???	? ???$  ????? ? ?? ???? ??  ?	??  ? ?  ? ?  ??? %?? ? ???? ?&	??? ???????? ? '?(?  ?????? ?? ????  ????? ?????? ?? ???? ????  ?? ? ????	?? ????	???  ????? ????	? ??? ?  ??	??? ????	?? ????  ???  ???????? ????	??? ?  ???????? ????	??? ?  Figure 2. Metadata synchronization protocol  standby for backup, server state transition is more compli- cated than that of traditional primary-backup paradigm.

In OAMS, the metadata server starts up in different states with the configuration. A global view is cached to maintain the address and state of each server. It is modified by the active dynamically and stored in the shared storage pool periodically. The active and standby add event triggers in the view which will result in state transition when failures are detected by the monitor. In the failover protocol, the state of server is classified into three types which are active, standby and junior. The active is the master server which provides metadata service for cluster file system. During running, only one active is allowed in the primary-backup cluster while others are in standby or junior states. The standby keeps an up-to-date namespace with the active and takes over as it when necessary. The synchronization protocol contributes to metadata consistency between the active and standby. The junior is in an intermediate status which has a large gap in namespace state comparing to the active. It may be a server which restarts after a short time or is a newly added backup node. The junior needs to learn and download metadata information from the active for synchronization. It will become standby through the renewing protocol (see Sec- tion III (C)) at appropriate time. Under different conditions, the state of server will be switched to each other for fault tolerance.

Fig. 3 depicts the transition among three states. Metadata synchronization and junior renewing are based on the shared storage pool. The solid lines depict server state transition with the failover protocol. Under failure free cases, there are one active and multiple standbys in the primary-backup cluster. OAMS monitors the cluster and judges the server failed when not receiving heartbeats from it after a timeout     period. If the active crashes, OAMS starts the process of active election. With the Paxos protocol, one is selected as the new active among multiple standbys. When reaching a consensus, the candidate active enters a stage of upgrading.

It firstly stops receiving new metadata modifications and waits for current operations to be finished. The candidate active also visits the global view and checks its state. If the standby is in a junior state, it must stop upgrading and needs the protocol to reselect active. After committing latest logs in memory, the candidate active updates server states in the global view. It changes the state of old active to standby and set itself to active. The modifications of the global view will trigger events which inform others to process state transition. To avoid missing operations, the candidate active then flushes last batch of metadata modifications to others with synchronization protocol. As the old active may become standby and receive these logs again, it needs to distinguish duplicated operations. OAMS assigns a monotone increasing serial number for each batch of metadata operations. The standby will decide whether to commit logs by comparing values of serial numbers.

Only if the value from the candidate active is larger than current serial number, the standby applies logs to its own memory. After the candidate active synchronizes metadata modifications to standbys, it receives register information from all servers in the primary-backup cluster. When more than one standby is registered successfully, the candidate active begins receiving new client requests and providing metadata service. During the process of state transition, the candidate active will stop upgrading if any failures occur.

It will launch the reelection process with failover protocol at this time. Due to block reports from datanodes, the new active keeps the same up-to-date file locations as namespace state. It can take over the metadata service and ensure a hot standby. After active-standby switching, the client reconnects to the new active and resends metadata requests to it. As the process is completely transparent to upper applications, the cluster file system seems to work well when failures occur.

C. Renewing Protocol  Once the active is detected failures during running, it will be degraded to standby and not provide metadata service.

If there are fatal errors, such as disk faults, the active will be directly switched to junior state. Or the namespace state of the standby is not up-to-date comparing to the active, it is degraded to junior. The junior is in an intermediate status which cannot provide backup service. As the active does not synchronize logs to the junior, there is a large gap in namespace states between them. With the reduction of standbys, the cluster file system will turn into an unreliable status. To avoid this risk, OAMS adopts the renewing protocol to switch the junior to standby. It also supports dynamical adding standbys at runtime which improves the  ????? ? #???	??  ?????? ?? ??  )# ???  *???	??  *???	??  ??	??? ????	?? ????  ? ???? ?&?+ ??????	?? ????  *???	??  ?? ?" ,??	?? ???? ?  ??-#????  ?	???.???	? ???"  Figure 3. Server state transition in failover protocol  availability of metadata service.

When the active or standby is degraded to junior state, it  enters the state of renewing. The active decides the renewing strategy according to the value of serial number from the junior. If the subtraction between them is large, the protocol firstly launches a process of image recovery. Otherwise, the active flushes missing metadata modifications to the junior.

As the namespace image is stored in the shared storage pool, the junior can obtain it directly from the pool and reduce the cost of downloading. In the course of reading image, the junior applies metadata operations in memory and reaches a consistent state with the active gradually. After loading namespace image, the protocol starts the procedure of synchronization. At this moment, the active commits current metadata operations and then stops metadata service temporarily. It flushes missing logs to the junior and waits for it to reach the same state. Once the junior recovers all metadata operations, the active modifies the global view and changes its state to standby. Then the junior is upgraded and keeps an up-to-date namespace state with the active for a hot standby. With this protocol, the server can be newly added dynamically and is switched to standby finally. It contributes to tolerate multiple points of failures in some scenarios such as the standby crashes.

A server which acts as the junior when starting up will register in the active. The active verifies its state and upgrades it to standby with the renewing protocol. It also watches the global view periodically to check server states in the primary-backup cluster. When the server is degraded to junior, the active launches the process of renewing. As OAMS uses the cluster mode for fault tolerance, there may be multiple juniors in some cases. The active compares values of serial numbers and selects one whose namespace state differs less with it. At the same time there is only one junior which is being renewed. If there are failures occur during the process, the junior will give up and waits for appropriate time to upgrade. To parallel execution, the active     launches the separate thread for junior renewing. Based on the shared storage pool, most of metadata operations can be recovered from the image and it has little effects on metadata service of the active.

With upper protocols, OAMS achieves server state transi- tion among three types under different conditions. It ensures that there always exists one metadata server which is in the active state and provides metadata service whenever failures occur.



IV. PERFORMANCE EVALUATION  To provide a proof of concept, we evaluated a prototype implementation of OAMS. As HDFS is a typical distributed file system which meets the needs of big data storage and supports practical applications such as Hadoop, we implements the policy based on it. For failure detection and active election, ZooKeeper [19] is used to maintain small amounts of coordination data, trigger of event changes in the global view and monitor metadata servers. During evaluation, we compare OMAS with three paradigms: Back- upNode, Hadoop HA with NFS and Hadoop HA using the quorum journal manager (QJM). They are all high available solutions for HDFS. BackupNode is a warm standby with the manual mode while the latter two can achieve an automatic hot standby. All of them use one backup server to provide failover for the active in the case of failures.

Experiments are running on a cluster with five machines.

Each node consists of four Intel Xeon X3320 processors, 8- Gbyte memory and 1-Tbyte Seagate disk. All have Linux kernel 2.6.32 installed on them and are connected with gigabit Ethernet. The configuration of OAMS is one active and two standbys. They also constitute the shared storage pool as storage nodes. BackupNode and Hadoop HA with NFS are deployed with one active and one standby. NFS is as a remote filer and mounted on each of the namenode machines. For Hadoop HA with QJM, the primary-backup configuration is the same as above two while using addition- al three journalnode machines for sharing logs. Five nodes act as datanodes in all paradigms. Except for BackupNode, they reports block locations to both the active and standbys for hot standby.

The evaluation firstly tests failover time with different paradigms. To verify automatic recovery, failures are caused on the cluster file system to simulate different kinds of outage, such as killing the process, powering cycle the machine and unplugging the network interface. Time is measured for recovering metadata service in the case of failures. The second set of test measures the performance comparison among OAMS and traditional primary-backup paradigms. For a more detailed explanation, we write special programs to request various metadata operations, such as create, getfileinfo, delete and etc., with one or more clients.

The evaluation is performed under both failure and failure free cases. Finally, an overall measurement is done to prove  the high improvement on reliability and little effects on performance with OAMS in standard applications.

A. Failover Time  This experiment measures the ability of fault tolerance with different primary-backup paradigms in the case of failures. We compute average failover time on servers for ten times when the active crashes. After triggering the outage, the standby takes over as the active and continues to provide metadata service. As BackupNode is a warm standby with the manual mode, its results do not include the time spend on switching. The amount of time requires to detect a failure in ZooKeeper is heartbeat interval and session timeout, with the values of 2 seconds and 5 seconds respectively.

Table II presents failover time comparing OAMS with traditional primary-backup paradigms. The size of image file indicates the amount of metadata operations in namespace which varies from 16MB to 1GB. With the growth of it, the failover time of BackupNode is increased. It is because BackNode does not involve modifications of the knowledge about file block locations and needs to reconstruct this information. For OAMS and Hadoop HA, there is a fast recovery as datannodes talk to both the active and standby.

The failover time depends on two issues. One is the time it takes for the paradigm to detect a failure, which is directly related to the heartbeat interval for monitor. The other is the cost for switching which includes active election, log synchronization and state transition. Due to different approaches for sharing logs, the failover time of Hadoop HA with NFS is longer than that with QJM. Comparing with Hadoop HA, OAMS spends less time on recovery.

The combination of synchronization protocol with the built- in shared storage pool and maintaining of global view in OAMS has an effect in this case. It demonstrates that OAMS can achieve a faster recovery than others.

B. Performance Overhead  To compare performance overhead, the evaluation is per- formed under both failure and failure free cases. Test pro- grams are written to produce continuous load for metadata operations. The results of HDFS represent the baseline and does not involve in any failures. Outage is triggered one time to make the active crash for failure test.

Fig. 4 presents the average performance of different paradigms in failure free cases. The evaluation varies the number of clients from 1 to 16 on multiple nodes to perform mixed metadata operations, including create, getfileinfo and etc. Each client finishes 100 kilo operations for computing the average value. With the increase of clients, the per- formance is improved as the concurrent processing ability of metadata server. Comparing to HDFS, performance of primary-backup paradigms is respectively worse than the former. This is due to the overhead of synchronizing logs between the active and standby. BackupNode shows better     Table II FAILOVER TIME WITH DIFFERENT PRIMARY-BACKUP PARADIGMS  Size of Image File (MB) Failover Time (s) OAMS BackupNode HA with NFS HA with QJM  16 0.762 2.586 8.395 5.375 32 1.135 5.372 10.931 8.384 64 2.416 9.541 11.834 7.533 128 1.539 21.938 9.673 6.372 256 2.394 38.346 10.817 8.081 512 2.725 80.437 9.653 7.845  1024 2.084 152.634 10.372 7.193  values than others but it cannot meet the goal for hot standby and system reliability is lower. For OAMS, it shows an average decrease by 7.18% in terms of performance with regard to HDFS. The synchronization protocol based on the shared storage pool reduces the latency of log replication comparing to Hadoop HA.

Fig. 5 shows the time spending on metadata operations in the case of failures. For each type, a total of 1 million operations are performed. Failures are caused one time by killing the active process during running except for HDFS.

The failover time of BackupNode includes block reports and manual switching which are 8 seconds and 3 seconds respectively. As the primary directly flushes logs to the standby, it is intelligible that BackupNode needs less time for finishing operations than others. Comparing with Hadoop HA, OAMS achieves better performance with the profits varying from 2.15% to 42.68%. It proves the advantage of synchronization protocol and failover protocol in this policy.

6.5   7.5   8.5   9.5   /  0 1 2 3 4 5 6 /7 // / /0 /1 /2 /3  A v er  a g e  M ix  ed O  p er  a ti  o n  s P  er S  ec o n  d   x103  Number of Clients  HDFS  BackupNode  OAMS  HA with QJM  HA with NFS  Figure 4. Performance overhead under failure free cases  C. Overall Measurement  As OAMS is presented to improve the reliability of metadata service for big data storage, we launch standard applications to measure the overall performance. Evaluation is performed in the Hadoop platform which uses HDFS or primary-backup paradigms as underlying storage. Various MapReduce jobs are submitted to compare the performance          ???	?? ???8???? 8? ?????? ?$??? ?? ?? T  im e  S p  en t  fo r  O p  er a  ti o  n s  (s )  Metadata Operation  HDFS  OAMS  BackupNode  HA with NFS  HA with QJM  Figure 5. Performance overhead under failure cases  in the case of failures. As BackupNode and Hadoop HA rely on one standby for fault tolerance, outage is triggered by making the active crash for one time. To OAMS, the test includes three types: (1) kill the active when there are one active and two standbys (1A2S); (2) kill one standby under upon conditions to generate one junior (1A1S1J); (3) firstly kill one active and then kill one standby which leads to two junior appear (1A2J).

Fig. 6 presents the execution time ratio of OAMS and other paradigms comparing to HDFS in different scenarios.

HDFS represents the baseline which is running in failure free cases. The negative value of ratios means that it needs more time to finish jobs for primary-backup paradigms. Log synchronization and active-standby switching constitute the reason. For OAMS, the metadata service is recovered and all jobs are completed finally under three tests. It proves that OAMS can tolerate multiple points of failures. The performance of OAMS with 1A1S1J differences little with that of 1A2S. This is because OAMS can provide metadata service as long as there are one active and one standby working. And the renewing protocol for switching from junior to standby is mostly performed in the background.

Evaluation shows that it only costs 0.5 second to reach an up-to-date namespace state with the junior for 100 kilo operations. OAMS with 1A2J is in a state of read only and cannot respond to client requests, which is intelligible for the availability of cluster file system. It is worthy for this cost     since OAMS has highly improved the reliability of metadata service while having little effects on performance.

-14.0%  -12.0%  -10.0%  -8.0%  -6.0%  -4.0%  -2.0%  0.0% "?????# ? ???? ???? ?? ? ???!

"?????  ?? ???? ?  E x ec  u ti  o n  T im  e R  a ti  o o  f P  ri m  a ry  -b a  ck u  p P  a ra  d ig  m s  C o  m p  a ri  n g  t o  H D  F S    Mapreduce Jobs Running on OAMS and Others  BackupNode  HA with NFS  HA with QJM  OAMS with 1A2S  OAMS with 1A1S1J  OAMS with 1A2J  Figure 6. Overall measurement

V. CONCLUSION AND FUTURE WORK  In this paper, a highly metadata service OAMS was proposed for big data storage. Different from traditional primary-backup paradigms, OAMS depends on more than one standby to take over the active in cluster file system.

It is based on the built-in shared storage pool and employs a series of protocols to tolerate multiple points of failures.

OAMS achieves an automatic state transition in the form of hot standby. Besides, it supports server self-recovery and dynamical addition for standbys at runtime. Measurements show that OAMS can obviously improve the system relia- bility while keeping the performance with little degradation.

In the future, we intend to optimize and expand the policy, such as supporting failover in the cluster file system with multiple metadata servers.

