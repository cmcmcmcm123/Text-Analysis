

Abstract? Reliability of the Fuzzy Association Rules (FARs) extraction is a challenging research in knowledge discovery and data mining. Reliability refers to the trade-off between the prediction accuracy and the rules diversity. In this paper, an approach called Diverse Fuzzy Rule Base (DFRB) is proposed to extract the FARs which are used later to predict the future values. This approach also aims to ensure high quality and diversity of the FARs. This is achieved through four phases: firstly, the integration of Fuzzy C-Means (FCM) and Multiple Support Apriori (MSapriori) algorithms are applied to extract the FARs. The second phase calculates the correlation values for these FARs, and performs an efficient orientation for filtering FARs as a post-processing method. In the third phase, the FARs diversity is maintained through the clustering of FARs, based on the concept of the sharing function technique used in multi-objectives optimization. After that, the best and the most diverse FARs are evaluated and then stored in the Knowledge Base (KB). Finally, these FARs, stored in the KB, are utilized within the Fuzzy Inference System (FIS) for prediction. Experimental results for two case studies have shown that the proposed DFRB approach predicted the future values effectively, thus, outperforming the existing work.



I. INTRODUCTION ssociation mining remains one of the most important techniques in Knowledge Discovery in Databases  (KDD), increasingly attracting the attention of researchers.

Mining of the association rules can be applied to predict the future value in a particular domain. Association rules can be constructed as: X Y where X is the antecedent (left hand side) and Y is the consequent (right hand side). The association rules are extracted from a database which relies on two metrics (interestingness measures): Minimum Support threshold (minsupp) and Minimum Confidence threshold (minconf). Since minsupp is the time frequency for particular item(s) that are divided by the number of transactions, and minconf is the percentage value of the support value for the antecedent and consequent together, divided by the support value of the antecedent part.

Association rules mining can be divided into two main parts [1]: ? Frequent item sets are found if the support value of the  itemset is greater than or equal to minsupp.

? Association rules are extracted if the confidence value of  the frequent itemset is greater than or equal to minconf.

The definition of the association rules is as follows: let  I i , i , . . , i  be a set of distinct items (attributes), and   B. I. Sowan, Student Member, IEEE, K. P. Dahal, Member, IEEE,  A. M.

Hossain, Member, IEEE, M. S. Alam are with the School of Computing, Informatics and Media, University of Bradford, Bradford, BD7 1DP, UK (e-mails: {b.sowan; k.p.dahal; m.a.hossain; m.alam1}@Bradford.ac.uk).

any set of items is called an itemset. Let D t , t , . . , t be a set of transactions database TID. Each transaction TID in D  consists in a set of items I,  strong association rules are defined in accordance to the form  X Y where, X, Y ? I and X?Y=  approve minsupp and minconf.

Most of the common association rules algorithms are based on level-wises, such as Apriori [2], and others use the tree structure namely Frequent Pattern Growth (FP-Growth) [3].

As a concept derived from the association rules, Fuzzy Association Rule (FAR) applies a fuzzy approach to deal with quantitative attributes (quantitative data or crisp one) and to represent them in a natural and understandable manner.

Fuzzy approach is widely exploited among the intelligent systems, since it is very simple and similar to the human way of thinking [4]. Furthermore, it helps to extract abstract patterns at a higher level than just on the data one (crisp data set). These are then used to transform quantitative data into fuzzy data through the identification of membership functions. The membership functions are defined using different methods, basically, based on human experience/know-how [5], [6]. However, in many occasions, it is too difficult to obtain the information required and the human experts. The Fuzzy C-Means (FCM) is a clustering technique commonly used to provide reliable membership values for constructing fuzzy sets [5]-[7] if data sets are available.

The use of single minsupp for a whole database considers and assumes that all items in the database have the same frequency. However, in real applications, the database contains some items of a high frequency, while others are of a low frequency. The human expert, based on domain knowledge, can set minsupp for a specific value in order to find the frequent items. In that case, if minsupp is set too high it will extract a low number of frequent items. On one hand, the rare items will appear and cause a dilemma (called rare item problem). On the other hand, if minsupp is set too low, it will extract a high number of frequent items, which causes combinatorial explosions. In other words, all the possible associations will be found; thus, some of the items are uninteresting/insignificant [8]. In the literature, the rare item problem can be solved through the adoption of two methods. Firstly, the data set is divided into blocks according to their occurring item frequency, and then the association rules are extracted in each block with different minsupp. Secondly, the related rare items are grouped into one abstract item; therefore, this abstract item becomes a frequent one. It would not be possible for the first method to extract the association rules among these blocks, and the second method is suffering from extracting rules that involve  Diversification of Fuzzy Association Rules to Improve Prediction Accuracy  Bilal I. Sowan, Keshav P. Dahal, Alamgir M. Hossain, and Mohammad S. Alam  A          individual rare items and frequent items. To overcome the dilemma of rare item problem, Liu et al. [8] proposed an algorithm called MSapriroi using Multiple Item Support (MIS). However, the number of generated rules depends on the control parameters used. For instance, if the parameter values are set low, then they tend to extract a large number of rules, most of which are not useful. Otherwise, a small number of rules are generated that do not adequately cover the data.

It is believed that such an approach is applied for extracting the FARs in order to store it in the knowledge Base (KB) and use it in the prediction of future values. This can be accomplished and achieved through FARs assessments, while considering the diversity within the FARs. The prediction system can therefore accept any input data to predict the output of future values. The best FARs, in some cases, do not always lead to good results; therefore, the diversified FARs can offer better results.

In this paper, an approach called Diverse Fuzzy Rule Base (DFRB) is proposed which aims to extract a robust and diverse fuzzy rule base that enables the prediction of future values effectively. These fuzzy rules base are generated from FARs, and should be sustained and proved. The proposed approach facilitates the trade-off between both the prediction accuracy and the diversity within FARs.

This paper is organized as follows. Section II presents the related works. Section III describes the proposed approach.

Section IV reports the experimental results and evaluates the performance study. Finally, section V draws the conclusions.



II. RELATED WORKS Mining association rules is a vital task in data mining research. Several algorithms and approaches are proposed for generating association rules which have support and confidence values higher than user-specified thresholds [9]. Similarly, there are several techniques that can be conducted to prune the huge number of such association rules and transform them into more representative ones [9]- [11]. Marzena [9] introduced an approach to obtain representative rules from a large set of association rules using cover operator; these rules are based on satisfying the minsupp and minconf measures. The use of such measures to generate these rules could be affected at the representative rules level. The representative rules implicates small numbers of rules, which decrease the accuracy when they are evaluated and validated. Many techniques were offered by scholars suggesting objective measures to evaluat the association rules [12], [13]. Lenca et al. [14] proposed an approach for selecting the most interesting rules based on improvement of the objective measurements. Their approach used a Multi-Criteria Decision Aid (MCDA) method to sustain these rules for a non-expert user in a specific domain.

A clustering technique, for association rules, was developed by Dechang and Xiaolin [15] based on the similarity of the antecedent part of the rules. The rules and its similarity coefficient are stored in the fuzzy simulation matrix to be understood by the user and then evaluated.

However, the use of the Apriori algorithm for extracting  these rules and the similarity of the antecedent parts only affects the result performance.

Various approaches have been developed in order to extract FARs from quantitative data sets. These rules are presented in the form of ?IF-Then? statements using statistical significant methods as minsupp and minconf. Huang et al.

[6] proposed a fuzzy data mining approach to discover rules by applying the Apriori algorithm while adapting the discovered rules for the training Adaptive Network based on Fuzzy Inference System (ANFIS). The approach is applied in the human resources department for predicting future employee performance, in either suitable projects or positions. This approach [6] was tested for a small data set with some noise. It uses human expertise/experience (know- how) to define the membership functions. It could be adapted for a small data set, but it is not feasible for large data sets. An approach was implemented by Lu et al. [5] which compared two methods for the prediction of one output value, this was applied to Abalone data set taken from the University of California, Irvine (UCI) of Machine Learning Repository. In the first method, FCM and Apriori algorithms were used to extract FARs and then a Genetic Algorithm (GA) was applied for tuning the fuzzy sets. The second method proceeded as the first, but it used variable thresholds in the prediction. The prediction accuracy in the first approach was 72.16% for training and 70.56% for testing data; while the second approach obtained 72.55% for training and 71.06% for testing data.

Associative classification concept has also been widely investigated. Pach et al. [16] proposed a fuzzy associative classification technique. This technique considers both rules: the interpretability and classification accuracy, but it used the Apriori approach for extracting frequent items.

Most of the above mentioned approaches suffer from one or more of the following problems: ? The single minsupp approach is not fair when using a  single minsupp for the whole data. Single minsupp assumes the same frequency for all items in the data. In this manner, the real application data possesses some items with a high frequency; while others possess a low frequency. Therefore, by using a single minsupp some of the significant association rules could be missed.

? The use of such an objective measure to only assess the rules is not effective. It depends on selecting and tuning a parameter threshold to extract the best rules.

? Association rule mining techniques produce many association rules that will affect the prediction results.

? Extraction of representative rules may assist in understanding the perspective points of the user. Yet, it is not dependable and coverable in case of prediction accuracy.



III. THE PROPOSED DIVERSE FUZZY RULE BASE APPROACH The proposed Diverse Fuzzy Rule Base (DFRB) approach considers both the trade-off between the prediction accuracy and the diversity of FARs to provide robustness in the fuzzy rules base. This approach is based on selecting the strong         FARs in order to increase prediction accuracy and the FARs diversity to maintain more representative rules. As described in Fig. 1, the proposed approach consists of four phases; each phase is detailed as follows:                            Fig. 1. The proposed DFRB approach phases.

First phase: Generating the FARs based on FCM and MSapriori algorithms. FCM is employed as an automatic system which transforms the quantitative data set into fuzzy sets (terms). The MSapriori algorithm is applied to extract the FARs by setting the control parameters, used in MSapriori, at low values. Thus, the number of generated FARs increases.

Second phase: Calculating the correlation coefficient value for each FAR. Correlation values are calculated for each of the FARs using equations (1) and (2). One of the correlation measures is used to evaluate the importance and strength of the association rule [16]-[18] in order to filter a large number of association rules over different objective measures.

corr X. FS Y. FS supp X. FS Y. FS supp X. FS . Supp Y. FSsupp X. FS . 1 supp X. FS . supp Y. FS . 1 supp Y. FS  (1)  where, corr X. FS Y. FS : correlation value of the FAR X. FS Y. FS , the interval of its range is [-1, 1]. supp X. FS Y. FS : support value of the FAR,  whereas the FARs are formed from the frequent itemset X. FS, Y. FS . supp X. FS : support value of the ?IF? as part of the FAR. supp Y. FS : support value of the ?Then? part of the FAR.

. ?    ?   X.FSN N                                                              (2)   where, supp X. FS :support value of a frequent item X. FS .

The following example explains the calculation of the correlation value. Let  r1: X. Low Y. Medium be a FAR and its data set shown in Table I.

TABLE I FUZZY DATA SET X. Low Y. Medium  0.3 0.7 0.9 0.5 0.8 0.2 0.7 0.9  corr X. Low Y. Medium 0.3625 ? 0.5075 . 0.39750.5075 . 0.4925 . 0.3975 . 0.6025 0.6571  Supp .

0.3 . 0.7 0.9 . 0.5 0.8 . 0.2 0.7 . 0.94 0.3625   The FARs with positive correlation values are subsequently considered, they are grouped according to their length size K . The FAR length is determined based on the number of attributes included. For example,   group1 1: . .   2: . .

group2 1: .   . .

2: .   . .

The correlation value is normalized for each FAR within the group as follows:  1. Determine the maximum correlation value MaxCorrK 2. Divide each FAR correlation value by MaxCorrK  For example, MaxCorrK 0.3 and two FARs in the group  0.3=1  0.2=0.66   This normalization is applied to rescale the correlation value for each FAR in each group. The reason behind the length size is that the longer the FAR size increases the smaller the correlation value is. As a result, this assists in selecting the best FAR from each group that satisfies the minimum correlation threshold minCorr.

The motivations behind using the correlation measure are: ? The tuning and setting the minsupp and minconf  have  some difficulties [16], [19].

Third Phase  Group Rules 1  Diversity Rule 1 Diversity Rule n  Best Rules 1 Best Rules n  Prediction  Diversed Rules  Fuzzy Inference System  Knowledge Base  Group Rules n  First Phase  Second Phase  Calculate Correlation Value  Fourth Phase  Fuzzy Association Rules         ? The correlation measure is used as a filtration for the generated FARs after using MIS as minsupp and minconf.

? The correlation measure is robust compared with the confidence measure of equation (3) (as mentioned in [20]).

Conf X. FS, Y. FS S X.FS,Y.FSS X.FS                                       (3) Third phase: Finding the diversity FARs by calculating the distance between the FARs. A diversity of FARs is calculated for each of the FAR groups, it can be found through clustering FARs within each group as follows:  1. The FARs are clustered based on their distance using equations (6) and (7).

2. Clustering the FARs based on their distance, hence the number of FARs and their similarities can be identified within a cluster and other clusters using equations (4) and (5); these equations were applied [21] to maintain diversity within the sharing function technique in multi-objective optimization.

Range ? Accum DistanceN                                              (4) where, Range : the value that can find out whether the cluster contains only one FAR (Range  enumerates the number of rules similar to a rules i); if the Range  value equal to 1 or the cluster contains more than one FAR (crowded cluster) if the  Range  value greater than 1.  Accum Distance : the accumulative distance between i  and all other FAR in the same group, whereas i FARs.

Accum Distance  1 D , if     Distance ?;0         , otherwise.                              (5)  where, ?: the threshold value that represents the cluster size (cluster radius), its range is in the interval [0.1, 1]. Distance : the distance between two individual FARs i and j, whereas i, j FARs. Measuring the distance between two FARs is the main part at this phase using equations (6) and (7); these FARs can be clustered based on their similarities. Actually, the similarity between two FARs can be found as follows: S RAFS RAFS  RAFS RAFS                                                   (6) where, S : the similarity between two FARs(i and j), the interval of its range is [0, 1]. RAFS  (Rule Attribute Fuzzy Set): the fuzzy set concerning an attribute within the FAR . RAFS : the fuzzy set concerning an attribute within the FAR .

Consequently, the distance can be calculated using equation (7).

Distance 1 S                                                             (7)  The following example illustrates the calculation of the distance. Assuming the two rules FAR   and  FAR  then:   FARi: .   . .

FARj: .   . . .

The similarity between FAR   and  FAR  can be calculated by using equation (6): S  |2| |4| 0.5  The numerator 2 comes from FAR . Z. Medium  similar to FAR . Z. Medium   and  FAR . Y. Low  similar to FAR . Y. Low , whereas denominator 4 comes from all attributes fuzzy sets  FAR , . X. Low, X. Medium, Z. Medium, Y. Low Once the similarity between FAR   and  FAR  is calculated, then the distance can be found by using equation (7), below: Distance 1 0.5 0.5  Fourth phase: Selecting the best FARs of the highest correlation values and the diverse FARs; then, store these FARs in the Knowledge Base (KB) to be used by the Fuzzy Inference System (FIS) for a prediction.

The approach for extracting robust and diverse fuzzy rule base is summarized in Fig. 2:                              Fig.2. Extraction of robust and diverse fuzzy rule base algorithm.

Input: Fuzzy Association Rule (FAR), Minimum Correlation threshold value minCorr, ? value, Number of the Diversed Rules (DR).

Output: Robust and Diverse Fuzzy Rule Base.

Method:  1. Calculate the correlation value corr for each FAR 2. Divide FAR into a group based on their length size K 3. Sort (rank) FAR automatically in each group K  based  on their highest correlation value.

4. Select the best FAR from each group K  For each K IF corr  EndIF EndFor  5. Identify the diversed FARs for each group N_ _1=counting the number of  of (   1).

_ _1.

For each K IF Range 1 IF corr While ( ) IF Range 1  EndIF EndWhile EndIF EndIF EndFor         Fig. 3 shows an example of the selection of the fuzzy rule base with robustness and diversity.

Fig.3. Selection of the fuzzy rule base with robustness and diversity.



IV. EXPERIMENTAL RESULTS AND PERFORMANCE STUDY The proposed DFRB approach has been applied in two case studies in order to evaluate its effectiveness. The first case study is a quantitative road traffic data set, which was considered in our previous work [22]. The second case is a quantitative data set called Abalone. The road traffic data has been generated using a traffic simulation model (the METANET macroscopic flow model) [23]. Each record in the data set, as shown in Table II, consists of: ? Traffic state, represented by: traffic demands of road 1 (the  number of vehicles that use road 1), traffic demands of road 2 (the number of vehicles that use road 2), traffic density of road 1 (the number of vehicles using road 1 per km), and traffic density of road 2 (the number of vehicles using road 2 per km).

? The Predicted Average Total Time (ATT) required for a vehicle to cross the traffic network.

Fig. 4 shows information about the input of the road traffic data set, whereas the statistical information regarding this data set is shown in Table III. While Figs. 5 and 6 show the analyses of the data set, which clarify the distribution and consistency.

Fig. 4. Information related to the input road traffic data set.

TABLE II PART OF THE ROAD TRAFFIC DATA SET  Case No.

Demand  Demand  Density  Density  ATT  1 6030 316 5 87 629.7 2 1147 1638 62 50 414.4 3 1277 797 10 14 233.5 4 4061 1198 38 75 581.2 : : : : : :     TABLE III STATISTICAL INFORMATION OF THE ROAD TRAFFIC DATA SET  Demand  Demand  Density  Density  ATT  Min 185 123 1 1 222.8 Max 6986 3498 99 99 729.8 Mean 3670.110 1640.45 48.85 50.32 515.7 SD 2060.326 919.69 28.919 27.376 109.9  Correl 0.438 0.257 0.398 0.527 1      Fig. 5. Road traffic data set analysis for Demand 1 and 2.

Fig. 5 shows the analysis of the road traffic data set. A boxplot (also known as a box-and-whisker diagram) is a suitable method which graphically describes groups of numerical data, such as the: minimum value, lower quartile (Q1), median (Q2), upper quartile (Q3), and the maximum value. Therefore, a boxplot is used for detecting outlier (noisy) data. The data set is found to be consistent and without any outlier data. Also all fields (attributes) were distributed in different ranges of value; however, our aim is to find out if there were any outlier cases for each separate field.

Demand 1 Demand 2          V al  ue s  Density 1  Density 2  Road 1  Road 2  Group1 of FARs, length size  K 2  value Range. .  1 1 . .  0.9 1 . .  0.8 1 . .  0.7 1 . .  0.5 1 . .  0.4 1   Group 2 of FARs, length size  K 3  value Range.    . .  1 1 .   . .  0.8 1.7 .    . .  0.6 2 .   . .  0.5 1 .    . .  0.4 1.8 .    . .  0.4 1    Assuming that minCorr=0.7, and DR=1            . .  . .  . .  . .  .    . .  .   . .  .   . .

We have divided the road traffic data into 75 records for training and 25 records for testing.

The Abalone data is taken from the University of California, Irvine (UCI) of Machine Learning Repository [24]. We have divided the Abalone data into 3133 records for training and 1044 records for testing.

The Proposed approach has been applied to predict the ATT in road traffic data and the Abalone ring that represents the Abalone age in Abalone data.

For the purpose of evaluation and validation, prediction quality is assessed using one of the statistical measures called Mean Absolute Percentage Error (MAPE), highlighted in equation (8). It is defined as follows:   MAPE ?  100                                      (8)   where, PV: the predicted output value, RV: the real output value, N: Total number of the comparison record.

Table IV shows the sensitivity of MAPE adapting minCorr over different numbers of FARs. On the other hand, Table V shows the sensitivity of MAPE adapting minCorr over different numbers of FARs and the diverse FARs, where ? 0.3 in both tables. The results shown in Tables IV and V clearly demonstrate that MAPE is not affected when the diverse FARs are added. This is explained through the usage of an efficient and effective technique to select the diverse FARs.

TABLE IV  THE SENSITIVITY OF MAPE ADAPTING MINCORR MAPE Number of FARs minCorr 22.2% 152 0.4 9.3% 88 0.5 8.1% 53 0.6 10.6% 29 0.7 14.2% 16 0.8 23.6% 8 0.9   TABLE V  THE SENSITIVITY OF MAPE ADAPTING MINCORR AND DIVERSED FARS  MAPE Number of FARs minCorr 22.2% 152 0.4 9.3% 89 0.5 8.1% 54 0.6 10.6% 31 0.7 14.2% 18 0.8 23.6% 10 0.9   Table VI represents the sensitivity of MAPE adapting ?  value (cluster size) over different numbers of diverse FARs when considering 53 FARs. It can be easily noted that when the value of ? is less than 0.3 or greater than 0.6, it does not affect MAPE, however, when it is between 0.3 and 0.6, MAPE changes slightly. In addition, when the value of ? is between 0.3 and 0.6 then several numbers of diverse FARs are generated which slightly affect the MAPE. However, when the selection of ? is less than 0.3, each cluster may  include one FAR; and when the value of ? is greater than 0.6, the cluster may include all FARs.

TABLE VI  THE SENSITIVITY OF MAPE AND ? VALUE OF MINCORR= 0.6 WITH DIVERSED FARS  MAPE Number of diversed FARs ? vlaue 8.1% - 0.1 8.1% - 0.2 8.1% 1 0.3 8.1% 3 0.4 9.9% 4 0.5 9.9% 2 0.6 8.1% - 0.7 8.1% - 0.8 8.1% - 0.9 8.1% - 1   Fig. 6 shows the sensitivity of the MAPE and minCorr for  the brute-force approach (the diversity is employed in all FARs together of different K  (length size of FAR)). The graph shows that when minCorr is 0.49, the minimum MAPE is 11.2%, and it contains rules that cover most cases.

It is noted that as minCorr decreases from 0.49, the MAPE increases. This is explained by producing a large number of rules (decrease in minCorr is accompanied by an increase in the uninteresting FARs to cause noise for the FIS).

Moreover, it is observed that when the correlation value increases beyond 0.49, the MAPE also increases. Again this is explained by producing a small number of FARs, which do not give robust results for the FIS (the increase in minCorr implies a decrease in the number of relevant rules).

Fig 6. The sensitivity of MAPE and minCorr.

Table VII depicts the sensitivity of MAPE over different  numbers of FARs and diverse FARs, where ? 0.3 and minCorr = 0.49, which illustrates the brute-force approach.

This approach produces a good result; its MAPE is acceptable as compared with the employed diversity in FARs with different individual K  (length size of FAR), as shown in Table V.  The diversity is applied in FARs with different K ; they produce 8.1% MAPE and generate a slightly high number of FARs when compared with the brute-force approach, which produces 11.2% MAPE and less numbers of FARs.

0.45 0.46 0.47 0.48 0.49 0.5 0.51 0.52 0.53 0.54 0.55  M A  P E  minCorr         TABLE VII THE SENSITIVITY OF MAPE OVER DIFFERENT  NUMBERS OF FARS AND DIVERSED FARS MAPE Number of diversed FAR Number of FARs 11.2% 0 11 11.2% 1 11 11.2% 2 11 18.3% 3 11   Other criteria measures are applied in this study to  evaluate the predicted accuracy, are as follows [25], [26]:   ?  Mean Absolute Error (MAE)   ? | |                                 (9)   ? Normalized Mean Absolute Error ( )     ? | |? 100%                 (10)  ? Normalized Root Mean Square Error ( )      ? ? 100%        (11)    ? Pearson Product-Moment Correlation Coefficient  (Pearson )    ?? ?                (12)   where  : The predicted output value.

: The real output value.

: Total number of the comparison record.

: The mean of real output.

: The mean of predicted output.

:  Uncorrelated 1 .

These essential measures are concerned with the prediction model. , , ,  and Pearson correlation coefficient (Pearson ) are the most widely used and important measures to evaluate the prediction method [25], [26]. The Pearson r is used to measure the relationship between two variables (the predicted and the real output value). The range of Pearson r  correlation varies from -1 to +1. When r equals 0, the predicted and real output values are uncorrelated. When r equals 1, the predicted and real output values are approximately the same. And when r equals -1, the predicted and real output values are approximately the same with opposite directions.  The values of such criteria are show in Table VIII.

TABLE VIII CALCULATION OF THE EVALUATION CRITERIA  Abalone data Road traffic data Measure Criteria 25.5% 8% 2.78%          32.4% 27.8% 6.7%, 37.2 9.5%, 0.51 0.05   Table VIII shows the impact of using different criteria measurements. It is noted that different criteria yield different values. This is attributed to the different ranges of values in each data set.

The results are compared to those of the integrated Fuzzy C-Means (FCM) and Apriori approach. Prediction quality is assessed using the MAPE in equation (8). The experimental results on the Abalone and road traffic data are summarized in Table IX.

TABLE IX  CALCULATION OF MAPE FCM and DFRB FCM and Apriori  Data set  25.5% 29.4% [5] Abalone 8.1% 9.1% [23] Road traffic   Table IX presents the results from using two different  methodologies: first, it concerns the integrated FCM and Apriori; while, the second deals with FCM and DFRB. In each methodology, the MAPE is calculated, which is the result of the sensitivity improvement of future value predictions by minimizing the MAPE using the proposed DFRB approach. The result was compared with reported work, and it achieved a better result for the DFRB than the results in [5], [22]. It is noted that the result in [5] was generated by two approaches. The first approach applied FCM and Apriori algorithms, its MAPE was equal to 29.4% (its equivalent MAE was 3.77). While the value of MAPE using the proposed DFRB is equal to 25.5% (its equivalent MAE was 2.78). The second approach applied FCM and Apriori algorithms, and then a Genetic Algorithm (GA) was employed in order to optimize and minimize the MAE. The MAE, based on this approach, is equal to 1.77 (it was not mentioned how many runs were experimented for the GA to optimize the MAE in [5]).

The proposed DFRB produces a good result and can be used with a wider data set (even when the data set contains noisy data). This provides more generalized prediction method.

The large differences in MAPE, between the two data sets used in the experiment, refer to the high number of noisy data and high number of attributes existing in the Abalone data set. However, the results are still better than the previous work, shown in Table IX.



V. CONCLUSION This paper proposed the Diverse Fuzzy Rule Base  approach which focused on the Fuzzy Association Rules extraction and effective selection to predict the future values.

The approach concerns both the best and diverse FARs through its capability in filtering them in order to extract the best FARs, thus reflecting an increase in the prediction         accuracy. It generates the FARs, and then calculates the correlation coefficient value for each FAR. After that, it clusters the FARs to determine its diversity while selecting the best FARs (with a higher correlation value) and diverse FARs for prediction using FIS. The proposed approach expresses and maintains the trade-off between both the prediction accuracy and the FARs diversity. The approach was employed for two case studies: real data set concerning the road traffic domain, and the Abalone data set. It is noted that the proposed DFRB approach offers higher prediction accuracy as compared to other approaches reported in the literature. In the future, the associative classification techniques will be investigated to explore further levels of accuracy.

REFERENCES [1] R. Agrawal, T. Imielinski, and A. Swami, "Mining association rules  between sets of items in large databases," In Proceeding of the 1993 Washington, DC, 1993, pp. 207-216.

[2] R. Agrawal and R. Srikant, "Fast algorithms for mining association Large Data Bases, 1994. pp. 487-499.

[3] H. Jiawei, P. Jian, and  Y. Yiwen, "Mining Frequent Patterns Without Candidate Generation," In Proceeding of  the ACM SIGMOD pp. 1-12.

[4] M. Zhang and C. He, "Survey on Association Rules Mining Algorithms," Advancing Computing, Communication, Control and Management, Lecture Notes in Electrical Engineering (LNEE), Springer-Verlag, vol. 56, pp. 111-118, 2010.

[5] J. Lu, B. Xu, and J. Jiang, "A prediction method of fuzzy association Information Reuse and Integration IRI, 2003, pp. 98-103.

[6] M. J. Huang, Y. L. Tsou, and S.C. Lee, "Integrating fuzzy data mining and fuzzy artificial neural networks for discovering implicit knowledge," Knowledge-Based Systems, vol. 19, no. 6, pp. 396-403, 2006.

[7] J. C. Bezdek, Pattern Recognition with Fuzzy Objective Function Algorithms. New York, NY: Plenum Press, 1981.

[8] B. Liu, W. Hsu, and Y. Ma, "Mining association rules with multiple minimum supports," In Proceeding of the fifth ACM SIGKDD 1394 New York, NY, USA, 1999, pp. 337-341.

[9] K. Marzena, "Representative Association Rules," In Proceedings of the Second Pacific-Asia Conference on Research and Development in Knowledge Discovery and Data Mining PAKDD-98, Lecture Notes in Computer Science (LNCS), vol. 1394, Springer-Verlag, pp. 198-209, April 1998.

[10] M. Kryszkiewicz, "Closures of Downward Closed Representations of on Hybrid Artificial Intelligence Systems HAIS 2009, Lecture Notes in Artificial Intelligence (LNAI), vol. 5572, Springer-Verlag, pp. 104- 112, June 2009.

[11] M. Kryszkiewicz and H. Rybinski, "Incomplete database issues for representative association rules," Lecture Notes in Computer science (LNCS), vol. 1609, Springer-Verlag, pp. 583-591, June 1999  [12] T. T. Nguyen Le, H. X. Huynh, and F. Guillet, "Finding the Most Interesting Association Rules by Aggregating Objective Interestingness Measures," Lecture Notes in Artificial Intelligence (LNAI), vol. 5465, Springer-Verlag, pp. 40-49, 2009.

[13] E. Suzuki, "Compression-Based Measures for Mining Interesting Rules," Lecture Notes in Artificial Intelligence (LNAI), vol. 5579, Springer-Verlag, pp. 741-746, 2009.

[14] P. Lenca, P.  Meyer, B. Vaillant, S. Lallich, "On selecting interestingness measures for association rules: User oriented description and multiple criteria decision aid," European Journal of Operational Research, vol. 184, no. 2, pp. 610-626, 2008.

[15] P. Dechan and Q. Xiaolin, "A New Fuzzy Clustering Algorithm on Association Rules for Knowledge Management," Information Technology Journal, vol. 7, no. 1, pp. 119-124, 2008.

[16] F. P. Pach, A. Gyenesei, and J. Abonyi, "Compact fuzzy association rule-based classifier," Expert Systems with Applications, vol. 34, no.

4, pp. 2406-2416, 2008.

[17] M. Steinbach, P. N. Tan, H. Xiong, and and V. Kumar, "Objective measures for association pattern analysis," In Prediction and discovery: AMS-IMS-SIAM Joint Summer Research Conference, Machine and Statistical Learning, Snowbird, Utah: American Mathematical Society, vol. 443, p. 205, 2007.

[18] P. N. Tan, V. Kumar, and J. Srivastava, "Selecting the right objective measure for association analysis," Information Systems, vol. 29, no. 4, pp. 293-313, 2004.

[19] O. R. Zaiane and M.-L. Antonie, "On pruning and tuning rules for associative classifiers," Lecture Notes in Artificial Intelligence (LNAI), vol. 3683, Springer-Verlag, pp. 966-973, 2005.

[20] M. Khan, M. Muyeba, and F. Coenen, "Mining Fuzzy Association Rules from Composite Items,"  Artificial Intelligence in Theory and Practice II, vol. 276, Springer-Verlag, pp. 67-76, 2008.

[21] K. Deb, Multi-objective optimization using evolutionary algorithms.

Chichester, UK: Wiley, 2001.

[22] B. Sowan B., K. P. Dahal, A. M. Hossain, and K. Almejalli, "Knowledge Discovery based on Integrated Fuzzy and Apriori Approach for Prediction,". In Proceeding of the International Conference on Software, Knowledge, Information Management and Applications (SKIMA?2009), Fes, Morocco, 2009, pp. 70-77.

[23] A. Messmer and M. Papageorgiou, "METANET: A macroscopic simulation program for motorway networks," Traffic Engineering and Control, vol 31, no (8/9), pp. 466?-470, 1990.

[24] C. L. Blake and C. J. Merz, UCI Repository of Machine Learning Databases [Online]. Irvine, CA: University of California, Department of Information and Computer Science, 1998.

Available: http://www.ics.uci.edu/~mlearn/MLRepository.html Accessed: August  2009.

[25] S. Han, S. M. Schneider, and R.G. Evans, "Evaluating Cokriging for Improving Soil Nutrient Sampling Efficiency," Transaction-American Society of Agricultural Engineers (ASAE), vol. 46, no. 3, pp. 845- 849, 2003.

[26] Quek, C., M. Pasquier, and B. B. S. Lim, "POP-TRAFFIC: a novel fuzzy neural approach to road traffic analysis and prediction," IEEE Transactions on Intelligent Transportation Systems, vol. 7, no. 2, pp.

133-146, 2006.

