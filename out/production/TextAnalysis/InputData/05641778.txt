Parallel Frequent Patterns Mining Algorithm on GPU

Abstract-Extraction of frequent patterns from a  transactional database is a fundamental task in data mining. Its applications include association rules, time series, etc. The Apriori approach is a commonly used generate-and-test approach to obtain frequent patterns from a database with a  given threshold. Many parallel and distributed methods have been proposed for frequent pattern mining (FPM) to reduce computation time. However, most of them require a Cluster system or Grid system. In this study, a graphic processing unit  (GPU) was used to perform FPM with a GPU-FPM to speed-up the process. Because of GPU hardware delimitations, a compact data structure was designed to store an entire database on GPU.

In addition, MemPack and CLProgram template classes were  also designed. Two datasets with different conditions were used to verify the performance of GPU-FPM. The experimental results showed that the speed-up ratio of GPU-FPM can achieve 14.857 with 16 times of threads.

Keywords-frequent pattern mining, parallel processing, graphic processing unit (GPU), OpenCL

I. INTRODUCTION Both in business and scientific research, there has been a  tremendous growth of data that needs to be processed.

Extracting information from large amount of data is necessary in making correct and effective decisions. Different methods have been developed to determine the characteristics and interrelationships of data. Association rule learning, classification, clustering, and regression commonly need to mine data. Extraction of frequent patterns from a transaction? oriented database is one of the most important of these.

Frequent patterns represent the number of times an itemset appears in a given database. Therefore, if an itemset is frequent it means there are strong relationship between items.

Most frequent patterns mining (FPM) either uses the generate-and-test (A priori-like) [1] or the pattern growth approach (FP-growth) [2]. The core concept of the Apriori-like approach is that if the length k pattern is not frequent in the database, then the super-pattern (length k + 1 )  will not be frequent. It uses a bottom-up approach, extending frequent subsets one item at a time. Since the generated candidates are independent, this approach is suitable for parallelization.

* This work is partially supported by National Science Council. (NSC 98-222I-E-216-023)  t The corresponding author.

Although many Apriori-like methods have been proposed [3-4], the computation time increases significantly when the database contains a large number of transactions. Some studies [5-7] apply parallel and distributed techniques to speed-up the mining processes. However, most of them require a high performance computing system, e.g., a Cluster or Grid System.

In recent years, the graphic processing unit (GPU) has developed from a 3D rendering device for games to a general? purpose computing device [8]. While the GPU can only execute some simple instructions and functions, compared with CPU, it has a large number of computing units. Moreover, using GPU as a high-performance computing device which does not only reduce the deployment cost but also saves on maintenance. GPU programming strategies can be classified according to either graphic APIs or GPU programming language. It is difficult for developers to use the graphic APIs since they need understand the graphic hardware and encode their data to graphic vectors. The most serious problem is the use of previously designed parallel algorithms. Therefore, GPU programming language is currently being used to develop GPU-enabled programs. NVIDIA and ATI have been proposed as GPU programming language by CUDA [9] and Stream [10] respectively. Programs can be written in C programming language (C99) to use the power of GPU. However, CUDA can only be used on NVIDIA's GPU and vice versa. Therefore, OpenCL [11] was proposed in 2009 to deal with this situation.

The program design with OpenCL not only can be executed on different brand GPU devices, but also on multi-core CPUs.

In this study, the GPU-FPM algorithm was used to speed? up the mining processes for FPM when using GPu. Although GPU is a powerful computing device, there are limitations: like memory size, memory latency, etc. Therefore, the data structure has to be re-designed for the FPM algorithm on GPU.

Since the verification time dominates computation time, the main goal of GPU-FPM is to use GPU to verity generated candidates in order to speed-up the FPM processes. Compact Data Structure, MemPack, and CLProgram class were used to achieve this. For verifying the GPU-FPM performance, it was implemented on Microsoft Windows with OpenCL 1.0, in addition, data generated by an IBM Quest Data Generator [12] was used. The proposed algorithm was tested under different conditions, including different transaction lengths, threads,    block sizes, and thresholds. The experimental results showed that GPU-FPM significant reduced the computation time with increasing threads. The speed-up ratio achieved 14.857 with 16 times of threads (in case of the T4011 001 OOK threshold being 1900, and block size 10). Moreover, even in the worst case, GPU used 89.942% of the execution time. This means that GPU-FPM efficiently used the GPU computing power.

The rest of the paper is organized as follows: In section 2, the FPM, GPU, and OpenCL are described. The proposed GPU-FPM is introduced in section 3 and the experimental results are illustrated in section 4. Finally, the conclusions discussed in section 5.



II. PRELIMINARIES  A. Frequent Pattern Mining (FPM) The main concept of FPM is to fmd the number of times a  given pattern appears in a database. FP M is defmed as follows:  Let D be a transactional database consisting of a set of transactions T;, T2, ???,1;': D = {T;, I;, ... , 1',,} . Let I be a set of items ip i2, ? ? ?  , im, a set X = {ip i2, ? ? ?  , ik } <;;;;; I called an itemset or a k -itemset if it consists of k items. The support of an itemset X is the number of transactions containing X .

support(X,D) = I{i I X <;;;;; 7;,X <;;;;; III for i = L.n  An itemset is called frequent if the support is greater than or equal to the given absolute minimal threshold .; . FPM is given a set of items I , a database D ,  and a minimal threshold .; , then fmd FP( D,,;) .

FP(D,,;) = {X <;;;;; I I support(X,D) ?.;} B. Graphic Processing Unit (GPU)  GPU is a parallel-oriented computing device. It always consists of massive processing units to perform mathematical computing. It used to be used as a co-processor CPU for games and 3D design applications. The DirectX 9 proposed in 2005, has taken graphics cards to the next generation because of vertex and pixel shaders being integrated in general-purpose processing units-introducing the universal shader. The mainstream GPU has hundreds to thousands computing units.

Each unit can be regarded as a simplified CPU. Compared with the multicore CPU, the number of processing units has also increased. Consequently, GPU also has a whole new application-general-purpose computing on graphics processing units (GPGPU).

C. OpenCL The GPU programming language can be classified as  graphic APIs (DirectX, OpenGL, etc.), GPU programming language (NVIDIA CUDA [9], ATI Stream [10], OpenCL [11], etc). Previously, GPU programming required developers with in-depth knowledge of graphics programming and hardware. In order to utilize the computation resources on GPU, developers had to encode data to a graphic vector, and then use the DirectX or OpenGL functions to perform rendering. After that,   the rendered data had to be decoded. This procedure not only required graphic programming knowledge, but also depended on different GPUs. Recently, CUDA and Stream have been proposed by NVIDIA and ATI. Both of them provide C interface and allow developers to adapt the hardware, e.g., number of processing units, size of local and global memory.

However, previous frameworks could only be used with the respective GPUs, e.g., CUDA could only be executed on NVIDIA's GPUs.

In order to solve this situation, the Khronnos Group and many industry-leading companies created the OpenCL.

OpenCL is an open and cross-platform parallel heterogeneous programming system. It provides a uniform programming environment for developers to write efficient and portable codes using a diverse mix of multi-core CPUs, GPUs, and other processors.



III. GPU-FPM  The goal of GPU-FPM was using massive processing units on GPU to speed-up the FPM procedures. However, each processing unit on GPU can only perform simple instructions.

Another important issue is memory size and access latency.

Therefore, the algorithm and data structure had to be re? designed for GPUs to fully utilize its computation resources.

Figure 1 illustrates the architecture of GPU-FPM. GPU-FPM has the following features: (1) data handling between CPU and GPU, (2) compact data structure, and (3) highly parallel.

MemPack Pattern Verification I Host20evice ? GPU Oevice2Host  t Candidate Generator I CLProgram ? CPU  Parameter Parser + Kernel Launcher  Figure 1. Architecture of GPU-FPM  A. Compact Data Structure  . . .

. . .

The memory access latency on GPU is very high, and it limits the computational speed-up ratio. Therefore, reducing the number of fetchings of memory improves the performance.

It fetches the memory many times if used directly on a transaction-oriented database. This is because the entire transaction needs to be scanned for verifying each single itemset. Consequently, a transaction identification set (Tidset) was used to directly select transactions instead of scanning whole databases. Tid and Tidset were defined as follows:    Tid(i) = {ij II T,. * 0} for k = l...n  Tidset = {Tid (i) } for j = 1.. .  m  For example, if transactions 1 and 3 contain item i. ,  Tid(i.) = {1,3} , then a whole transaction-oriented database is represented by Tidset. In order to store the Tidset to memory on GPU, TidValue and TidIndex arrays were used to represent Tidset. Figure 2 is an example of TidValue and TidIndex arrays. The TidValue array stored the Tid of each item, e.g., Tid(i.) = {I,3}, Tid(iJ = {I, 2, 5} , Tid(i3) = {2}, etc. (Figure 2 (a)) The boundary of each item on the TidValue array was determined by the TidIndex array. The TidIndex stored each items start and end position, e.g., item i4 ranging from 6 to 10  means six cells were used for i4 in TidValue array and values were stored from TidValue[6] to TidValue[I I]. Therefore, the information required for mining was transformed from database to two arrays.

Tid(i,) Tid(i,) Tid(i3) Tid(i,)  (a) TidValue  o 1 1 214 515 6 111 ? ? 1 i, ;, ;, i,  (b) Tidlndex  Figure 2. Example of Tid Value and TidIndex  B. GPU-FPM  Compared with CPU, GPU is special hardware with massive processing units. GPU processing is in single instruction, multiple data (SIMD) and there is no support recursion on it. Therefore, a compact data structure was designed and implemented to store necessary data for mining on GPU. The FPM could be roughly summarized to the following steps: load database, generate candidate itemset, and verify the candidate itemset frequently or not. Candidate itemset verification usually dominates computing time.

Therefore, in this study, GPU was used to reduce candidate verification time.

GPU-FPM was an Apriori-based mining algorithm and it generated and verified the itemset to produce frequent patterns.

Since memory access between CPU and GPU is a common operation, MemPack was designed to lower GPU programming complexities. MemPack is C++ class template that provided abilities to store different types of data, e.g., int, float, customized structure, class, etc. Two transfer functions: Host2Device and Device2Host and two memory control functions: ReleaseHost and ReleaseDevice were also provided.

Moreover, the CLProgram class was also designed to have the   following abilities: allow arbitrary number of parameters, bind arbitrary of MemPack, launch with arbitrary number of threads, and launch with CPU. The GPU-FPM algorithm follows:  Algorithm GPU-FPM  Input: a transaction database D and a given minimum threshold .;.

Output: a complete set of frequent patterns FP(D,';) .

1. Load D from disk.

2. Generate Tidset via scanning the D and store it on hash  table.

3. Transform hash table to compact array structure?  TidValue and TidIndex.

4. Create MemPacks mpTidValue and mpTidlndex to store  TidValue and TidIndex.

5. Perform Host2Device to copy mpTidValue and  mpTidlndex to GPU.

6 .  Use prefix tree data structure to generated candidate  itemset.

7. Create MemPack mpCandIS to store generated candidates.

8. Perform Host2Device to copy mpCandIS to GPu.

9. Create MemPack mpResults for storing results.

10. Create CLProgram clProg to store related parameters and  bind the mpTidValue, mpTidlndex, mpCandIS, and mpResults.

11. Perform launch kernel of clProg (on GPU) a. Each processing unit (PU) allocated a set of candidate  itemsets (CIs) b. for each CI in CIs  l. PU compute the support of CI according to mpTidValue and mpTidlndex  ii. If support of CI greater than or equal to given threshold .; then set it is frequent on mpResults, else is not frequent.

12. Wait until kernel code executed.

13. Perform Device2Host ofmpResults to store the results.

14. Perform Step 6 until all candidates generated and verified.

IV . EXPERIMENTAL RESULTS In order to evaluate the performance of the proposed  algorithm, GPU-FPM was implemented along with OpenCL library and Visual C++ on Microsoft Windows. Synthesized datasets generated by IBM's Quest Synthetic Data Generator were used to verify the algorithm. The hardware and software configurations are given in Table 1. The algorithm evaluated with different transaction lengths, different threads, different block sizes, and different thresholds. Table 2 gives the details of the dataset testing.

Item  CPU Memory  GPU  os Compiler SDK  Table I. Hardware and Software configuration  Description  AMD Phenom II X4 965 3.4 GHz 8G DDR3 memory ATI Radeon HD 5850 with 1440 stream processing units and I G DDR5 memory Microsoft Windows 7 Microsoft Visual C++ 2008 wi SPI A TI Stream SDK 2.0 wi OpenCL 1.0 support  Table 2. Statistical Characteristic of Datasets  Dataset Avg Trans Avg Len of No of Trans Len Max Pattern  Tl0I4D100K 10 4 100  T40IlODlOOK 40 10 100  A. Various Thread NumberrsQuantities In this section, two datasets with different threads and  thresholds were used to verify the performance of GPU-FPM.

Figure 3 and Figure 4 illustrate the computation time of various thresholds and threads. The computation time of the same threads was affected by the threshold. A smaller threshold refers to a smaller degree of support becoming a frequent pattern. There were 385 and 13,253 frequent itemsets with ; = 1000 and ; = 200 , respectively. The speed-up ratio is depicted in Figure 5 and Figure 6. For 16 times of threads, the best speed-up ratio was 13.066. Even in the worst case, it was 11.037. The average speed-up ratio was 12.576.

B. Various Block Sizes  In this section, GPU-FPM used different block sizes to verify the performance. The block size is the number of candidates that each processing unit on GPU deals with at each kernel launch. A small block size implied that the kernel had to be launched more times. Figure 7 and Figure 8 show the computation time of various block sizes. The Var stands for the block size changing with the number of threads, and the block size (blockSize ) and number of threads (noOjThread) had the  following relationship.

blockSize * noOjThread = 1024  Although a larger block size saved a bit on computation time (block size from 2 to 10, saving 0.826 second in case of Tl 0I4Dl OOK with 1024 threads), it only had a small influence on computation time. In some cases, larger block size even caused more computation time. The speed-up ratio is shown in Figure 9 and Figure 10. The trend of the speed-up ratio could not be observed from the results. According to the experimental results, the block size had no significant effect on the computation time.

C. Computation Time used by CPU and GPU Finally, the computation time used by CPU and GPU is  depicted in Figure 11 and Figure 12. GPU occupied most of the computation time in all cases. This means that the GPU-FPM   algorithm on GPU had the biggest workload. It also pointed out that pattern verification required much computing resources than pattern generation. For 1,024 threads, GPU occupied 93.837% computation time on average.

Computation Time: Various Threshold  TlOl4DlOOK BIO  450 +----'\r------------ ....... 1000- 400 ___ 800 350 +---??---------  U 300 +----?--------- -'-600 ? 250 " +-??--?-------- ""*'"400  +-----= ..... --....300..--------- ...... 200 E 200 i=     64 128 256 512 1024  NUlllberofThreads  Figure 3. Computation Time of Various Thresholds (TlOI4DIOOK, BIO)     --:-  1200 0 ? 1000 " E 800 i=      Computation Time: Various Threshold T40IJODIOOK BIO  +----;:,,---------------- ....... 2000- ___ 1900  +--;??----------?+---.r.?"r---------- -'-1800 +-----"'??"r_--------- ""*'" 1700_ +----??......,-------- ...... 1600 -  64 128 256 512 1024  um berofThreads  Figure 4. Computation Time of Various Thresholds (T4011 OD lOOK, BIO)  Speed-up Ratio: Various Threshold (TIOI4D 100K,B 10)  14 ,--------------------  12 +----------------.?---  .S! 10 +--------------?'""----? :;; or: 8 +-------------1-0- ? 6 +-----------?""----" 0-C/J 4 +-_______ ----:::-'''---___ _  o +---?---?---r_--?--? 64 128 256 512 1024  NumberofThreads  Figure 5. Speed-up Ratio of Various Thresholds (Tl 0I4D lOOK, BIO)    Speed-up Ratio: Various 11lreshold (T40IJOD 100K,B 10)   14 ...... 2000  12 ___ 1900 .9 ;;; 10 ...... 1800 c:<: Q. 8 -++-1700 ::l -b  ..... 1600 " 6 " Q. <J)  o +-------?------?------?------?----? 64 128 256 512 1024  Num berofThreads  Figure 6. Speed-up Ratio of Various Thresholds (T40IlODlOOK, BIO)    ..." 80 u ? 60 " E i=     Computation Time: Various Block Size T lOI4DIOOK,TlOOO  ...... 2 +-?.r-------------------------- ___ 4  +-----??---------------------- ...... 6  +-________ ??------------------ -M-8  ..... 10  ?Var  64 128 256 512 1024  NumberofThreads  Figure 7. Computation Time of Various Block Sizes (TlOI4DIOOK, TlOOO)    ..." 400 u ? 300 " E i=     Computation Time: Various Block Size TI0I4DIOOK T200  +-??-------------------------- ...... 2  ___ 4 +---??------------------------ """6  +-______ ??-------------------- -M-8 ..... 10  +-----------???--------------?Var ---  64 128 256 512 1024  NumberofThreads  Figure 8. Computation Time of Various Block Sizes (Tl0I4DIOOK, T200)   Speed-up Ratio: Various Block Size (TI0I4D 100K,TIOOO)  14 ,---------------------------------------  12 +---------------------------------?t_-- .9 10 +--------------------------------, ?.-=--? ;;; c:<: 8 +---------------------------?aP 0-::l ? 6 +-----------------------???---- " Q. <J) 4 +-----------------???----------  o t-------.-------.-------,-------,- 64 128 256 512  NumberofThreads  Figure 9. Speed-up Ratio of Various Block Sizes (Tl0I4DOIOOK, TlOOO)  Speed-up Ratio: Various Block Size (TI 014D 100K,T200)  14 .---------------------------------------  12 t-------------------------------? .9 10 t------------------------------, ;;; c:<: 0-" ? 6 t-----------------------?? " 0-<J) 4 t-----------------???----------  o t-------.-------.-------,-------,- 64 128 256 512 1024  umberofThreads  Figure 10. Speed-up Ratio of Various Block Sizes (TlOI4DOI00K, T200)  ..." u ?  " E i=   100 ----------------------------- ? GPU - 80 ----------------------------- ? cPU -    NumberofThreads  Figure 11. Computation Time Occupied by GPU and CPU (Tl0I4DlOOK, TlOOO, BIO)    500 ,--___ ---'-'-..:..::..:....:.=:...:..::..::..:..:2..:...=..:=:....:...::.L-_____ _  ,..., 350 g 300 ? 250 .5 200 I- 150   --------------- - opu ?  _______________ -CPU  NumberofThreads  Figure 12. Computation Time Occupied by GPU and CPU (TlOI4DIOOK, T200, BIO)

V. CONCLUSIONS Frequent pattern mining (FPM) is important and  fundamental in data mining. Most FPM methods can be classified as Apriori-like or FP-growth-like. However, the computation time increased significantly when the number of transactions grew. In this study, a GPU based parallel algorithm-GPU-FPM was used to speed-up the mining processes. In order to conform to GPU hardware delimitation, a compact data structure was used to store entire database in GPU. Moreover, two template classes, MemPack and CLProgram were also used. Two datasets with different conditions were used to verify the performance of GPU-FPM.

