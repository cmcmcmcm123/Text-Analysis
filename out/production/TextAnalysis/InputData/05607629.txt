

20IO International Coriference on Educational and Information Technology (ICEIT 2010)  Semantic Approach for Association Rules Extraction  based on Formal Concept Analysis  Ourida Saidi Computer Science department  Higher Institute of Management Tunis, Tunisia  ourida.saidi@isg.rnu.tn  Ahstract-The huge number of generated association rules limits the growth of more appropriate techniques to assist the  decision maker. In this context, based on the theory of Formal  Concept Analysis, we propose to extend the notion of Formal  Concept through the generalization of the notion of itemset in  order to consider the itemset as an intent, its support as the  cardinality of the extent. Accordingly, we propose a new approach to extract interesting itemsets through the concept  coverage. This approach uses a new quality-criteria of a rule:  the relevance bringing a semantic added value to formal  concept analysis approach to discover association rules.

Keywords- association rules, formal concept analysis, quality measure.

1. INTRODUCTION  Given the information density and mass accumulation of data, it was crucial to explore this information in order to extract meaningful knowledge.

The "Concept" is a couple of intent and extent aiming to represent nuggets of knowledge. Recently, researchers have been striving to build theoretical foundations for data-Mining based on Formal Concept Analysis [1,2,3]. Several interesting proposals have appeared, related to association rules [4].

In this paper, we introduce a novel approach of association rules mining based on Formal Concept Analysis.

The remainder of the paper is organized as follows. We outline in Section 2 the association rules derivation problem.

Section 3 introduces the mathematical background of FCA and its connection with the derivation of association rule bases. We present, in Section 4, an heuristic algorithm to calculate the optimal itemsets from rows of data. Section 5 describes the results of the experimental study. Illustrative examples are given throughout the paper. Section 6 concludes this paper and points out future research directions.



II. ASSOCIATION RULES DERIVATION  Commonly, the number of the generated association rules grows exponentially with the number of data rows and attributes. This can reach hundreds' of thousands using only some thousands of data rows. So, their comprehension and their interpretation become a hard task.

To remedy to this problem, several methods were proposed [17].

The commonly millions of rules -  generated thousands and even among which many are redundant  (Bastide et aI., 2000; Stumme et aI., 2001; Zaki, 2004) -[5, 6, 7, 8] encouraged the proposal of more discriminating techniques to reduce the number of reported rules.

This pruning can be based on patterns defined by the user (user-defined templates), on Boolean operators (Meo et aI., 1996; Ng et aI., 1998; Ohsaki et aI., 2004; Srikant et aI., 1997) [9,10,11,12].

The number of rules can be greatly reduced through pruning focusing on additional information namely the taxonomy of items (Han, & Fu, 1995) or on a metric of specific interest (Brin et aI., 1997) (e.g., Pearson's correlation or x2-test) [13, 14]. More advanced techniques that produce only lossless information limited number of the entire set of rules, called generic bases (Bastide et aI., 2000). The generation of such generic bases heavily draws on a battery of results provided by formal concept analysis (FCA) (Ganter & Wille, 1999) [15].

Primitively, the pruning strategy of association rules is based on crucial techniques namely the frequency of the generated pattern through discarding all the itemsets having a support less than MinSup, and the strength of the dependency between premise and conclusion by pruning all the rules having a confidence less than MinCon?  To prune effectively the extracted association rules, some authors [16] introduce another measures. In fact, Bayardo et al propose the conviction measure. Moreover, Cherfi et al [17] suggest five different measures such as the benefit (interest) and the satisfaction. Maddouri et al provide the gain measure [18].

In this paper, we introduce a new measure: the relevance.

Indeed, it is backboned on the Formal Concept Analysis [19, 20]. Assuming that an itemset is completely represented by a formal concept as a couple of intent (the classic itemset) and extent (its support), it combines the support of the rule with the length of the itemset. Thus, we propose to include a semantic aspect on association rules extraction by taking into account the confidence measure during the selection of frequent itemsets during association rules generation.



III. FORMAL BACKGROUND  In the following, we recall some key results from the Galois lattice-based paradigm in FCA and its applications to association rules mining.

2010 International Coriference on Educational and Information Technology (ICEIT 2010)  A. Basic notions  In the rest of the paper, we shall use the theoretical framework presented in [20].

Let ? be a set of objects, P a set of properties and R a binary relation defined between ? and P [19, 20l  TABLE I FORMAL CONTEXT a A B C D  I 01 I I 0 0  02 I I 0 0  03 0 I I 0  04 0 I I I  05 0 0 I I  Definition 1 [19]: A formal context (0, P, R) consists of two sets ? and P and a relation R between ? and P. The elements of ? are called the objects and the elements of P are called the properties of the context. In order to express that an object 0 is in a relation R with a property p, we write oRp or (0, p) E R and read it as "the object 0 has the property p".

Definition 2 [19]: For a set A?O of objects and a set B?P of properties, we define :  The set of properties common to the objects in A : A?={pEP I oRp for all oE A} The set of objects which have all properties in B : B<II ={oEO I oRp for all pE B} The couple of operators ( ?, <II) is a Galois Connection.

Definition 3 [19]: A formal concept of the context (0, P,  R) is a pair (A, B) with A?O, B?P, A ?=B and B<II =A.

We call A the extent and B the intent of the concept (A,  B).

Definition 4 [19]: The set of all concepts of the context  (0, P, R) is denoted by <l> (0, P, R). An ordering relation ?<) is easily defined on this set of concepts by :  (AI, BI)? (A2, B2) ?:> AI?A2 ?:> B2?Bl.

FIGURE I. CONCEPT LATTICE OF THE CONTEXT (0, P, R)  Fe2  FCI 0  ,0  Fe6  In this paragraph, we recall basic theorem for Concept Lattices [19]:  <l> (0, P, R, ?) is a complete lattice. It is called the concept lattice or Galois lattice of (0, P, R), for which infimum and supremum can be described as follow:  SUpj F I (Aj,Bj)=(( U j F I Aj) ? <II, (n j F I BD) In? F I (Aj, Bj)=( n j F I Aj , ( U j F I Bj) <II ?)  Example [18]: table I illustrates the notion of formal context (0, P, R).The latter is composed of five objects {oI, 02, 03, 04, 05} and four properties {A, B, C, D}. The concept lattice of this context is drawn in Figure 1 containing eight formal concepts.

Definition 5 [19]: Let (0, p) be a couple in the context (0, P, R). The pseudo-concept PC containing the couple (0, p) is the union of all the formal concepts containing (o,p).

Definition 6 [20]: A coverage of a context (0, P, R) is defined as a set of formal concepts CV={RE I , RE 2, ... , RE n } in <l> (0, P, R), such that any couple (0, p) in the context (0, P, R) is included in at least one concept of CV.

FIGURE 2. AN EXAMPLE OF PSEUDO-CONCEPT, OPTIMAL CONCEPT, AND NON OPTIMAL CONCEPT CONTAINING THE COUPLE (03,8).

I    a  a   A B C  I I 0  I I 0  0 I I  a. Pseudo-concept of (03,8)  A B C  I I 0  I I 0  0 I I  h. Opllmal concept of (03,8)  A 8 C  1 1 0  1 1 0  0 1 1 c. Non opllmal concept of (03,8)  Example [18]: Considering the formal context (0, P, R) depicted by  table 1, the figure 2.a represents the pseudo-concept containing the couple (03, B) being the union of the concepts FC2 and FCs.

A coverage of the context is formed by the three concepts: {FC4, FCs, FC6} such as:  FC4 is the concept containing the items ({ 0 1, 02}, {A, B});  FCs is the concept containing the items ({ 03, 04}, {B, C});  ? FC6 is the concept containing the items ({ 04, o5}, {C, D}).

The lattice constitutes concept coverage.



IV. DISCOVERY OF OPTIMAL ITEM-SETS  The most expensive step to derive association rules is the computation of the frequent itemsets [4]. Indeed, this step consists of applying, iteratively, some heuristics to calculate candidate itemsets. At the iteration i, we combine the item sets of the iteration i-I. After that, the support  V2-521    2010 International Coriference on Educational and Information Technology (ICEIT 2010)  threshold (MinSup) is used to prune non-frequent candidates. The itemsets of iteration i-I, are also discarded.

We keep the remaining itemsets of the latest iteration n with n is the number of properties in the formal context.

Two characteristics are used in the association rules derivation:  Support: is the cardinality of the set of objects which verify the rule. In Formal Concept Analysis, it refers to the extent of a formal concept.

Cardinality of the Itemset: is the number of properties of the itemset. In Formal Concept Analysis, it refers to the intent of a formal concept.

Assuming that the intent is not sufficient to represent the association rule, the latter is completely related to a formal concept namely both its intent and its extent. Having a support represented by the cardinality of the extent, a highly qualified selection of itemsets must be done according to the intent of the formal concept of the rule.

Moreover, the association rule generated from the formal concept should take into account the quality of the relationship between the head and the body of the rule.

To formalize the new criterions, we give the following definitions.

Definition 7 : Let FCj = (Aj , BD be a formal concept. We define:  Length of a concept FCj: the number of properties in the intent Bj of the concept.

Width of a concept FCj: the number of objects in the extent A j of the concept.

Conf of a concept FCj: the maximum confidence of the set of rules generated from the concept FCj.

Relevance of a concept: is a function of the width the length and the confidence of the concept, given by:  Relevance(FCJ= (length(FCJ+ conf(FCJ) * (length(FCJ+ width(FCJ)  The relevance measure depends on the number of properties. In fact, a less number of properties, a less value of relevance is noted. Having more properties induced to higher relevance. Moreover, if we have a higher number of properties and objects, a higher value of relevance is affected.

Increasing the confidence of the concept induce to higher value of relevance.

Definition 8 : A formal concept FCj = (Aj,Bj) containing a couple (0, p) is said to be optimal if it maximizes the relevance function.

Definition 9 [20]: A coverage CV={ FC1, FCb ... , FCk} of a context (0, P, R) is optimal ifit is composed by optimal concepts.

Example [18]: An illustrative example of the pseudo? concept is sketched by figure 2. b represents the optimal concept FCs containing the couple (03, B). Figure 2.c represents the non optimal concept FC2 containing the couple (03, B).

The optimal coverage of the context (0, P, R) is formed by three optimal concepts: {FC4, FCs , FC6}. FC4 is the concept containing the items ({ 0 1, 02}, {A, B}). FCs is the concept containing the items ({ 03, 04}, {B, C}). FC6 is the concept containing the items ( {04, 05}, {C, D} ).

A. Heuristic Searchingfor Optimal Concept  The pseudo-concept, denoted by PCF, contammg the couple (0, p), is the union of all the concepts containing (0, p). It is computed according to the relation R by the set of objects described by p, then {p} ?, and the set of properties describing the object 0, so {o} ..... Where (?, .... ) is the Galois connection of the context (0, P, R).

When we determinate the pseudo-concept PCF, two cases are considered:  Case 1: PCF forms a formal concept.

If no zero is found in the relation/matrix representing PCF, then, PCF is the optimal concept. So, the algorithm stops.

Case 2: PCF is not a formal concept.

If some zero entries are found in the relation/matrix representing PCF, we will look for more restraint pseudo? concepts within the pseudo-concept PCF.

So, we consider the pseudo-concepts containing the couples like (X, p) or (0, Y). These concepts contain, certainly, the couple (0, p).

The considered heuristic is the optimal concept is certainly  included in the optimal pseudo-concept.

So, we should generate all possible rules from the pseudo? concepts containing the couples like (X, p) or (0, Y).

Then we compute the corresponding confidences and choose the maximum value between them. After that, we calculate the relevance value. Finally, we choose the pseUdo-concept having the greatest value of the Relevance function to be the new PCF.

This heuristic procedure (of case 2) is repeated until PCF becomes a formal concept. To calculate the relevance of a pseUdo-concept, we introduce the general form of the previous function: Definition 10: Let PCFj = (Aj , Bj , Rj) be a pseudo-concept, where Rj is the restriction of the binary relation R, to the subsets Aj and Bj . We define the:  Length of a pseudo-concept PCFj : the number of properties in Bj.

Width of a pseudo-concept PCFj : the number of objects in Aj ?  Confidence of a pseudo-concept PCFj : is the maximum of confidence found when we generate the set of rules extracted from the pseUdo-concept PCFj .

Size of a pseudo-concept PCFj: the number of couples (of values equal to 1) in the pseudo-concept. When PCFj is a formal concept, we have:  Size(PCF)= (length(PCF) * width(PCF)) Relevance of a pseudo-concept is a function of the  width, the length, the size and the confidence given by : Size(PCF)  * Relevance(PCF)= flength(PCF)+ cOn{(PCF/ / (length(PCF)+ width(PCF))- Size(PCF)/  B. Algorithmfor Optimal Coverage  The problem of covering a binary relation by a set of optimal concepts is expressed through covering a binary matrix by a number of its complete sub-matrix. The latter is  V2-522    2010 International Coriference on Educational and Information Technology (ICEIT 2010)  is a matrix having all its entries equal to '1 '. This problem, being NP-Complete problem, has been the subject of several previous works. However, we found out necessary the proposition of an approximate polynomial algorithm called Semantic Based on Formal Concept Analysis Approach SFC2A.

Let R be the binary relation to cover. The proposed solution is to divide R into n packages (subsets): P], ... , Pn' Each package symbolizes one or more couples.

The key idea of SFC2A algorithm is to build incrementally the optimal coverage of R:  (i) The first step, covering the relation Rj =Pj by CVj? (ii) The ith step, let R i-I =P1 U ... U Pi-l and let CVi-1 be  its optimal coverage. Building the optimal coverage CVi of Ri =Ri-l U Pi using the initial coverage CVi_1 and the package Pi.

(iii) The nth step, finally, finding a set of concepts covering the relation R.

Algorithm SFC2A Begin Let R be partitioned to n packages PI, ... , Pn.

Let CVa :=$, FOR i=] to n DO  Sort the couples of Pj by the pertinence of their pseudo-concepts While (PjoF?) Do  Select a couple (a, b) in Pj by the sorted order of the relevance function Search PC : the pseudo-concept containing (a, b) within Rj =CV;-I U Pj Search FC: the optimal concept containing (a,b) within PC  CV; :=(CVj_I -(r ECVj_I / r ?FC}) U{FC}: Delete all the redundant concepts from CV j pj:=pj-{(x,y) E Pj/(X,Y) E FC}  End While End FOR End.

FIGURE 3. INCREMENTATION STEP WHEN ADDING P4  a. Optimal coverage of the context ({ 01,02,03} {A,B,C,D})  ? A B C D   ?  ........ I r 1 1 I 0 III 1 I 0  U ,I ------ -C---? 0 ,1 1  b. Case 1 : Coverage of the context  , ,  ({ 0 1,02,03,04} {A,B,C,D}) A B  " I r 1 1 I  0 ' 1 0 'J __  -----  --- -  C  _Q  L  c. Case 2 : Coverage of the context  ,  --  r-,  D  J __ ,  ({ 01,02,03,04} {A,B,C,D}) Example: Let R be the relation to cover as highlighted  by table 1. R is partitioned into five packages: Pj={ol}x{A, B}, P2={02}x{A, B}, P3={03}x {B, C}, P4={04}x{B, C, D} and Ps={05}x{C, D}.

Initially, R is an empty relation and in each step we add a package.

Figure 3 presents the incrementation step when adding P4.

In this step R3 encloses the four rows P], ... , P3. The  initial optimal coverage CV3 encloses the formal concepts FC3=({01, 02}, {A, B}) and FC4=({03}, {B, C}).

The package P4 encloses only three couples: (03,B), (03,C) and (03,D).

The pseudo concept containing the couple (04, B) and (04,C) is :  Case 1: the union of formal concepts ({03,04}, {B, C}) and ({04},D)  Case 2: the formal concept ({ 04}, {B, C, D}).

The computation of the relevance function induces to a  negative value in the first case and positive value in the second case according to the following formula:  Size(PCF) Relevance(PCF)= f J * length(PCF)+ con{(PCF)  I (length(PCF)+ width(PCF)- Size(PCF)f Hence, the retained formal concept is FC6=({04}, {B, C,  D}).

Thus, the final coverage of R contains the concepts FC3,  FC4 and FC6. Finally, according to our example, we find three Item-sets : {A, B}, {B, C} and {C, D}.



V. EXPERIMENTAL STUDY  We carried out experiments on benchmark datasets, whose characteristics are summarized in table 3.

Experiments were carried out on a Pentium IV PC with a CPU clock rate of 3.06 Ghz and a main memory of 512 MB.

TABLE 2. BENCHMARK DATASET CHARACTERISTICS  Dataset # Transactions #Items  TlOI4D 1000000 100 Mushroom 8124 128 T2016D 1000 9 Tic Tac Toe 958 10  To stress on the performance of our approach, we compare our proposal to the two pionnering methods in the same trend in the litterature namely the Apriori algorithm and IAR approach. The latter is also FCA based approach.

To analyze the data, we choose the following values of parameters: MinSup=0.35 and MinConf=0.75.

V2-523    2010 International Coriference on Educational and Information Technology (ICEIT 2010)  FIGURE 4. RUNTIME COMPARAISON OF SFC2A, IAR AND APRIORI ALGORITHMS  Runtime 120000 -r--=--------_   o  r--____ - IAR  Data sets  Figure 4 sketches the runtime measured in seconds for the three methods. We notice that the three algorithms keep the same behavior overall the data sets.

The Apriori method takes the greater time, since it is based on an exhaustive approach to test all the possible combinations. Our method SFC2A outperforms the two algorithms IAR and Apriori thanks to its semantic selection of the frequent itemsets during the association rules extraction through the use of the relevance measure.



VI. CONLUSION  In this paper, we focused on extraction association rules based on formal concept analysis. In fact, we assume that an itemset is presented by the intent and the extent of a Formal Concept. Thus, we introduce a new approach SFC2A backboned on semantic relationship on the formal concept used for association rule extraction. The carried out experiments of our proposal showed the performance of our method compared to the pionnering approaches in the same trend.

Future works will focus on: (1) the consideration of fuzzy context, (2) the study of the extraction of " generic association rules" inspired from our proposal.

