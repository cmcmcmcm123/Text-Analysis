BitApriori: An Apriori-Based Frequent Itemsets  Mining Using Bit Streams

Abstract? Generating, pruning and counting itemset candidates are important steps in Apriori frequent itemsets mining.

Unfortunately, their computation time is too expensive. In this paper, we propose a new method using Bit Stream to improve their speed. At the beginning, the 1-itemsets are found out and sorted according to the decline of count. By that way, a map of all attributes would be created. After that, each attribute will be presented by 1 bit. At last, the generating and pruning itemset candidates are processed by LOGIC operations which are not cost much of computation time. For experiments we compare our method with some Apriori-based state of the arts.

Keywords-component; formatting; Apriori, Association Rules, Data Mining, Frequent Itemsets Mining (FIM).



I. INTRODUCTION Frequent itemsets mining is a crucial step in association  rule mining. It plays an important role in many data mining tasks including strong rules, correlations and sequential rules.

One of ordinary algorithms is Apriori [1]. It adopts breadth search and finds all frequent itemsets. When the database is sparse and the frequent itemsets are short, Apriori and its improvements give high performance. However, with dense, medium size database, the efficiency of Apriori-based algorithms goes down dramatically. There are some main reasons:  ? In dense database, the frequent itemsets are long.

Therefore, the candidate generating dominates the run time.

? If the longest frequent itemset is n, it means each transaction have to be scanned n times. In other words, the entire database has to be scanned n time.

? Each m-length candidate is generated from 2m-2 extra frequent itemsets. The generation of them costs lot of time.

? The computation cost for counting support of candidates is so high.

In order to solve those shortcomings of Apriori, many improvements had been published. It is useful to store the candidates in a special data structure and save numerous transaction traversals. Firstly, in the ordinary paper [1], hash  tree had been used to store frequent itemsets and candidate frequent itemsets. Only candidate frequent itemsets, whose subsets are all frequent, are generated in each database scan.

Based on the hash tree, candidate frequent itemsets are generated and their subsets are tested. Secondly, the trie-based Apriori [10] were reported. After that, with independent researchs, Borgelt[5], and Bodon [12][14] published the first open-source of Apriori algorithm. And then, a parallel Apriori algorithm for Frequent Itemsets Mining had been proposed [13].

In our research, we propose a method which presents all candidates, frequent itemsets, and transaction in same-length Bit Streams. By that way, the generating candidates, and the support counting will be done by LOGIC operations with low cost of computation. The rest of this proposal will be organized as follow. Section II introduces the description of frequent itemsets mining. Section III presents the Apriori property and Apriori algorithm. In section IV, we present our algorithm, BitApriori.



II. PROBLEM DESCRIPTION Let I = {i1, i2,  ... ,in} be a set of items and D be a multiset of  transactions, where each transaction T is a set of items such that T? I. For any X ? I, we say that a transaction T contains X if X ? T. The set X is called an itemset. The count of an itemset X is the number of transactions in D that contain X. The support of an itemset X is the proportion of transactions in D that contain X. Thus, if the total number of transactions in D is n, then the support of X is the count of X divided by n . 100 percent. An itemset X is called frequent if its support is greater than or equal to some given percentage s, where s is the minimum support.



III. ORIGINALLY APRIORI ALGORITHM Apriori finds frequent itemsets according to a user-defined  minimum support. In the first pass of the algorithm, it constructs the candidate 1-itemsets. Then the algorithm generates the frequent 1-itemsets by pruning some candidate 1-itemsets if their support values are lower than the minimum support. After the algorithm finds out all the frequent 1-itemsets, it joins the frequent 1-itemsets with each other to construct the candidate 2- itemsets and then prunes some infrequent itemsets from the     candidate 2-itemsets to create the frequent 2-itemsets. This process is repeated until no more candidate itemsets can be created. Fig. 1 shows original Apriori pseudo code.

Figure 1. Apriori pseudo code  The apriori-gen function (Fig.  2) takes Lk-1, the set of all large (k-1)-itemsets, as argument. It returns a superset of all k- itemsets. The function is in following order. Firstly, in the join step Lk-1 is joined with itself. Next, in the prune step, all the itemsets c ? Ck that some (k-1)-subset of c are not in Lk-1 are deleted.

Figure 2. Candidate generating  pseudo code  The count function counts support of each itemset in C. If an itemset c ? Ck and with every transaction T contains c,  support of c will be increase 1. Counting process is shown in Fig.  3.

Figure 3. Counting pseudo code  An example on how Apriori discoveries frequent itemsets is shown in Fig. 4. The database in this example denoted D will be used in future examples.

Database D        support = 2  L1 TID Item  Item Support  1 1 3 4 scan {1} 3 2 2 3 5  {2} 4 3 1 2 5  {3} 3 4 1 2 5   {4} 2 5 2 3 4  {5} 3  C2    L2 Itemset   Itemset Support  {1 2}   {1 2} 2 {1 3}   {1 5} 2 {1 4}   {2 3} 2 {1 5}  scan {2 5} 3 {2 3}   {3 4} 2 {2 4} {2 5} {3 4} {3 5} {4 5}  C3    L3 Itemset   Itemset Support {1 2 5}   scan {1 2 5} 2 {1 2 3} {2 3 5} {2 3 4}  Figure 4. An Apriori frequent itemset mining example

IV. BITAPRIORI ALGORITHM  A. BitApiori BitApriori is an approach in which the input file contains  numerical data. If the data in the input file are not numerical,    an index file for all items should to be created. After that, the algorithm will work with this file instead of input file.

All candidates and transactions will be presented by a bit stream with same number of bits (same length). The length (by bit) of a bit stream is n which the number of frequent items is.

To implement bitApriori, we use an array of STL library in C++ bitset<16> container to present each bit stream, the number of elements needs for this array is nE which is the smallest, nearest positive integer and greater than n div 16.

Each bit stream also contains 2 other parameters start and end which indicate the first and the last non-zero element of bit stream. All operations onto every bit stream only work in range (end ? start + 1) element, instead of nE element. The order of bits in a bit stream is presented in Fig. 5.

Figure 5. An array of bitset<16> has nE elements  With n=5 on the above example, we only need nE = 1 for each bit stream, so bit stream has only 1 element, start = end = 0; with n =18, nE = 2.

B. Map of bit stream creation The database will be scannd to create the list of all items.

After that, non-frequent items are deleted and the list of items is sorted by the descent of support count. This list is set of frequent items will be used as a map of bit stream for later processes. This map presents the order of bits in each bit stream.

C. Database conversion to bit streams BitApriori scans the database once more time again. All  transactions are presented by bit streams. If transaction T contain item i which has position p-th in item list, the p-th bit of T?s bit stream will be set 1, otherwise will be set 0.

Assuming that the first transaction {1, 3} contains 2 frequent items 1 and 3 which are respectively the 1-st and the 4-th in the list. Therefore, it will be presented by bit stream 1001, the 1-st bit is the most right one.

D. The 1-length frequent itemset Each frequent item at position p-th in the map will be  shown as a bit stream with p-th bit is 1 and the rest others are 0, then start = end. By that way, L1 is created.

E. Candidate generation In original Apriori [1], Ck is generated by joining Lk-1 with  itself. It leads to many itemsets need to be pruned. There are two kinds of these itemsets:  ? Duplicated itemsets  ? Itemsets have more than k items.

Example L3 = { {1 2 3}, {1 2 4}, {1 2 5},  {1 3 4}, {1 3 5}, {1 4 5}, {2 3 4}}, six pairs of itemsets ({1 2 3}, {1 2 4}), ({1 2 3}, {1 3 4}), ({1 2 3}, {2 3 4}), ({1 2 4}, {1 3 4}), ({1 2 4}, {2 3 4}), and ({1 3 4}, {2 3 4})  generate itemset {1 2 3 4}.

Besides, eight other pairs ({1 2 3}, {1 3 5}), ({1 2 3}, {1 4 5}), ({1 2 4}, {1 3 5}), ({1 2 5}, {1 3 4}), ({1 2 5}, {2 3 4}), ({1 3 4}, {1 4 5}), ({1 3 5}, {2 3 4}), ({1 4 5}, {2 3 4}) create a 5- length itemsets {1 2 3 4 5}. Finding and pruning these spare itemsets cost too much time.

To overcome above shortcomings, we propose an improvement for candidates generating (Fig. 6) in which contains two main rules:  ? In a k-length itemset I = {i1 i2 i3 ?ik}, the item ij (j=1,k) have to be after the item ij-1 in the map of items.

Therefore, an itemset we have index l only join with itemset I1 have index l1>l in Lk-1  ? An k-length itemset is only generated by two itemsets have the same (k-2) first items.

Therefore, in above L3, we join L31 = {{1 2 3}, {1 2 4}, {1 2 5}} and L32 = {{1 3 4}, {1 3 5}} with themselves.

Figure 6. Candidates generating without duplications.

Suppose that subset(I) check whether all (k-1)-length itemsets of itemset I = {i1, i2, ?, ik} are frequent. We see easily that itemset I have k (k-1)-length sub-itemsets. (k-1) of them begin with item i1 and absent one items ij (j=2,k) and the rest one begins with i2, {i2, i3, ?, ik}.

F. Support counting For counting support for all candidate in Ck, bitApriori  algorithms does AND operation between candidate ci and transaction bit stream bj then compares result with candidate.

Because the AND operation only shows the common bits from 2 bit streams, if result bit stream equals to the candidate stream ci, the transaction bi contains ci and ci?s support increases 1. Providing that ci?s support >= minsup, ci wil be inserted into Lk.

The details of support counting process are described in Fig. 7.

Figure 7. Support counting process.

Below is an example which shows how bitApriori finds frequent itemsets for database D in Section III.

Database D     support = 2       Frequent items  TID Item  Item Support 1 1 3 4 1st scan 1 3 2 2 3 5  2 4 3 1 2 5  3 3 4 1 2 5   4 2 5 2 3 4  5 3  Map of bit stream (Sorted frequent items)  Position Item Support 0 2 4  nE = 1 1 1 3  Start = end = 1 2 3 3 3 5 3 4 4 2  With TID = 1, T = {1, 3, 4}, item 1 , item 3 item 4 are at positions 1, 2, 4 respectively in map of bit stream, so bit 1-th, bit 2-th, bit 3-th in bit stream presents for T is 1. bitT = 0000000000010110, start = end = 1.

Because D has only 5 frequent items, so each bit stream presents one itemset (transaction, candidate, frequent itemset) only has 5 value bits. From now, only 5 low bit will be shown for each bit stream of this example.

Database D  Present D by bit streams  TID Item  TID Bit stream 1 1 3 4  1 10110 2 2 3 5  2nd scan 2 01101 3 1 2 5  3 01011 4 1 2 5   4 01011 5 2 3 4  5 10101  Sorted frequent items   L1  Position Item Support  Itemset Support 0 2 4  00001 4 1 1 3  00010 3 2 3 3  00100 3 3 5 3  01000 3 4 4 2  10000 2  C2                  L2  Itemset   Items Support 00011   00011 2 00101   00101 2 01001   01001 3 10001   01010 3 00110   01100 2  C3    L3  Itemset   Items Support 00111   01011 2  Frequent Itemsets  Itemset Items 00001 2 00010 1 00100 3 01000 5 10000 4 00011 2 1 00101 2 3 01001 2 5 01010 1 5 01100 3 5 01011 2 1 5  Figure 8. An example of bitApriori frequent itemset mining.



V. EXPERIMENTAL RESULTS In our experiments, we used four sets of data. Among  them, T10I4D100K, T40I10D100K are synthetic data. They resemble market basket data with short frequent itemsets. The other two datasets, Mushroom and Connect-4 data, are real data which are dense in long frequent itemsets. These data sets were often used in the previous studies of frequent itemsets and asscociation rules mining. We downloaded them from http://fimi.cs.helsinki.fi/testdata.html. Some characteristic of these datasets are shown in table I.

TABLE I. THE DATASETS  Data set #Items Avg. Length #Trans Type Size  T10I4D100K 1000 10 100000 Sparse 3.93 MB  T40I10D100K 1000 40 100000 Sparse 14.8 MB  Mushroom 120 23 8124 Dense 557 KB  Connect-4 130 43 67557 Dense 8.89 MB    Our algorithm has mainly compared with three popular Apriori-based algorithms. Two of them, AprioriTrie [14], depth first search Apriori (dfApriori) [15], were downloaded  from http://fimi.cs.helsinki.fi/src/ . The rest is the newest Borget?s Apriori implementation from http://www.borgelt.net//apriori.html (version 5.8, 2009.11.13).

All experiments were performed on a Intel Core 2 Quad 2.4GHz with 2GB of memory. All times include time for outputting all the frequent itemsets. Tables II through V and figure 9 through 12 present the results.

TABLE II. RUN TIME (S) FOR T10I4D100K DATA  Support (%)  AprioriTri e  Borget's Apriori  Depth Apriori bitApriori  25 2.577 0.5 10.703 0.626 20 2.75 0.51 10.715 0.632  15 2.965 0.515 10.71 0.638 10 3.225 0.558 10.716 0.685  5 4.218 0.672 10.658 0.798         25 20 15 10 5  Support (%)  Ti m  e (s  )  AprioriTrie Borget's Apriori Depth Apriori bitApriori  Figure 9. Run time (s) for T10I4D100K data  Table II and Fig. 9 show the performance comparison of the compared algorithms on T10T4D100K data. AprioriTrie runs fifth faster than Depth Apriori while both bitApriori and Borget?s Apriori make a fair comparison and run twice faster than AprioriTrie.

TABLE III. RUN TIME (S) FOR T40I10D100K DATA  Support (%) AprioriTrie  Borget's Apriori  Depth Apriori bitApriori  25 19.869 1.975 40.231 2.305 20 19.878 2.047 40.032 2.382  15 20 2.198 40.256 2.521 10 20.553 2.605 40.436 2.943  5 20.475 3.438 46.197 4.225     25 20 15 10 5  Support (%)  Ti m  e (s  ) AprioriTrie Borget's Apriori Depth Apriori bitApriori  Figure 10. Run time (s) for T40I10D100K data  The comparison results on T40I10D100K data are presented by Table III and Fig. 11. While AprioriTrie performs twice as Depth Apriori, bitApriori and Borget?s Apriori performance are nearly the same and nine times as AprioriTrie.

TABLE IV. RUN TIME (S) FOR MUSHROOM DATA  Support (%)  AprioriTri e  Borget's Apriori  Depth Apriori bitApriori  25 1.355 0.17 0.656 0.285 20 6.312 0.37 1.576 0.482 15 12.264 0.48 1.86 0.605  10 105.894 4.55 10.34 7.875 5 571.67 40.16 74.01 52.015   25 20 15 10 5 Support (%)  Ti m  e (s  ) AprioriTrie Borget's Apriori Depth Apriori bitApriori  Figure 11. Run time (s) for mushroom data  TABLE V. RUN TIME (S) FOR CONNECT-4 DATA  Support (%) AprioriTrie  Borget's Apriori  Depth Apriori bitApriori  90 13 1.547 1.125 1.672 80 44.798 2.688 35.876 2.802 70 334.485 9.628 255.638 10.171 60 675.695 47.512 585.762 49.205 50 1387.672 189.548 1201.879 192.235             90 80 70 60 50  Support (%)  Ti m  e (s  ) AprioriTrie Borget's Apriori Depth Apriori bitApriori  Figure 12. Run time (s) for connect-4 data

VI. CONCLUSION AND FUTURE WORK In this paper, we have presented a new approach to Apriori  frequent itemset mining, bit Apriori, using bit stream as main data structures to store database and itemsets. Besides, LOGIC operations are used for joining candidates and support counting. By that way, instead of checking one item by one time, our algorithm checks a group of items at once.

Therefore, the performance is considerable improved.

In future, we will improve bitApriori so that it can be fairly compare with other frequent itemsets mining.

