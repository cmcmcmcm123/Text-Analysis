Exploiting Correlation Among Data Items for Cache Replacement in Ad-hoc  Networks

Abstract?Ad-hoc Networks are special types of communication networks that don?t require any prior infrastructure to work. One of the crucial properties of such networks is their disconnected mode of operation. Due to the unpredictable nature of these networks, a node often has to work in offline mode with cached contents. Therefore, it is very vital in ad-hoc environment to determine the particular data to be stored in the cache and the position in the cache where that data has to be stored.  In this paper, we have proposed a novel technique for cache replacement in Ad-hoc Network based on the mining of Association Rules. Using FP-Growth Association Rules Mining, the correlation among data items is computed and is then used as an important heuristics during cache replacement. We have evaluated the proposed technique using the simulator JIST/SWANS. A query routing algorithm for MANET is proposed and a simulation model is developed to analyze the proposed algorithm. The proposed cache replacement technique has been tested on different MANET configurations. The results reflect significant improvement in cache hit ratio with the proposed technique.

Keywords- Ad-hoc Network, Caching, Cache Replacment, Disconnected Operation, MANET

I.  INTRODUCTION Ad-hoc Network has been a vibrant area of research for  last few years.  These networks differ from traditional networks mainly because of their infrastructure-less nature and dynamically changing topology. Hence, solutions proposed for research issues (like power, routing, security and data management etc.) for traditional networks are not sufficient for MANET. A great deal of research work is currently going on to address various issues of MANET.

Caching plays a vital role in data management in MANET due to its unique characteristics.  It allows data items that are expected to be used in near-future to be saved at a location closer to the requester.  Traditionally, most of the caching techniques exploit spatial or temporal properties of data items for cache replacement. These techniques include Least Recently Used (LRU) or Most Frequently Used (MRU) etc. However, these approaches are not very useful for MANET because of their inherent limitations and the dynamic nature of MANET. In this paper, we have proposed a novel cache replacement technique for MANET.

It is based on the assumption that those data items that were accessed together frequently in past are correlated to each other and are anticipated to be used together in future as well.

In order to determine this correlation, we have used association rules mining.

Let D = {d1,d2, ?, dn} be a set of n-item data set. Let Fi = {fj : fj?D ^  1? j?  n } represents a frequent item set i.e. all the elements of Fi are correlated to each other and were used together in past. According to our assumption, all the elements of set Fi are likely to be requested together in future.

The association rule mining algorithm then produces the set F of all frequent item sets:  },...,,{ 21 fFFFF = where, f is the total number of frequent item sets.

Based on the results of association rules mining, a cache  replacement algorithm has been proposed. The algorithm prioritizes the cache locations C={c1,c2, ?, cm} on the basis of their contents and then finds out an appropriate slot k, 0 ? k ? m in the cache where a newly arrived data item di has to be placed. A query routing algorithm has also been proposed and a simulation model is developed to test the proposed scheme. In the sections to follow, we will talk about the proposed technique in detail along with implementation discussions. Rest of the sections of this paper has been organized as follows. First, we will discuss the related work in the area of caching. Then we will discuss the proposed approach that is followed by implementation details. Finally, we conclude the paper with future work.



II. RELATED WROK There has been a significant amount of research going in  the domain of Distributed and Mobile Database Systems to facilitate efficient Information Sharing. Replication schemes like[1] achieve this objective to some extent but are inherently limited by the node mobility and the pre-requisite of knowledge about operating environment. Caching is another way to improve data access. Caching schemes for the mobile and distributed systems comprises of: Simple Caching[2], Hierarchical Caching[3] and Cooperative Caching[4] etc. A Hierarchical Caching Scheme is based on routing cache requests along a hierarchy in a structured manner. Cooperative Caching that is based on cooperation of a number on nodes to perform caching has been an area of extensive research for last few years. [4] has proposed three schemes for cooperative caching based on routing support in MANET that includes: CachePath (caching the path of the data), CacheData (caching the data) and HybridCache (combination of cache path and cache data) scheme. Other cooperative caching strategies include CoCa[5] and  _____________________________________    GroCoCa [6] etc. [7] proposed a cache replacement policy called Least Utility Value(LUV) that is based on several factors like item access probability, item size, coherency, distance between user and the cache node etc. The author also proposed a cooperative caching algorithm ? Zone Cooperative ? that is based on LUV in which 1-hop neighbors nodes forms a zone. [8] presents an On-Demand Cooperative Caching architecture for multimedia objects using soft state signaling. Another related area of caching in which significant research has been carried out is semantic caching i.e. information is cached based on the semantics of the data being cached. [9] presents a semantic caching scheme based on Bayesian probability for image caching.

[10] introduced group coherence as a new coherence criteria for MANET based on the unique features of MANET. To address issues of cache invalidation [11] has proposed a cache invalidation strategy. [12] proposed an approximation algorithm for cache placement in MANET that aims at minimizing the total access cost. The algorithm is greedy in nature and it iteratively selects data items with the maximum benefit and place that in to the cache.



III. AN ASSOCTION RULE-BASED CACHING REPLACMENT SCHEME FOR MANET  Fig 1 shows the proposed approach highlighting the main components along with interactions among them. The Query Manager is responsible for handling all the data item requests generated by users. It first searches for the requested items in the cache and if there is no cache hit, it uses the proposed query routing algorithm (shown in Fig 2) to search for the data items over the network. All the data requests that are issued in one transaction are saved in a log database. We define a transaction as a set of data item requests that are issued simultaneously in one session. A session is a time interval in which the pause between any two data requests is below a certain threshold ?. The Association Rules Mining component utilizes the log database records to discover correlation among the data items. The mining component runs periodically and computes the correlation among the data items based on log database?s transactions. The data structure used for maintaining the log database is circular list.

The computed results of data mining are stored in a list which is then used during cache replacement. In the next subsections, we are going to discuss the proposed query routing algorithm and cache replacement technique in detail.

A. Query Routing Algorithm Fig 2 shows the Query Routing algorithm that we have  used to test the proposed Cache Replacement algorithm in MANET. The query routing algorithm looks for the data item in local cache and if there is no cache hit, it propagates   Figure 1.  Proposed Caching Scheme Based on Association Rules Mining  the request to its adjacent nodes.  If a data item is found in cache, then its reply is generated. Any node receiving the QueryReply, first caches this reply in its local cache and then confirms if this reply is intended for itself or not. If the reply is intended for some other node, query reply is propagated ahead. To avoid network overhead, TTL value of all forwarded message is first checked to confirm if the message has expired or not.

[Query Rout ing Algorithm] /* C represents the Cache Me represents the current  host */  While (running) {  Message m = read(); if(m is QueryRequest) {  if(lookup(m.dataitem,C) { Message res = m.createQueryReply(m); send(res); }else{  forwardT oAdjacentNodes(m); }  }  Else if(m is QueryResponse) {  storeInCache(m.dataItem);  if(m.dest inat ion <> Me) {  forwardT oAdjacentNodes(m);  }  } }     Figure 2.  Proposed Query Routing Algorithm  B. Proposed Cache Replacement Algorithm Let C={c1,c2,c3, ? , cm} represents the set of all cache  entries with ci as individual locations. If we define an individual data items as dj, then the cache replacement problem CR(C, dj) attempts to find out the optimum location k, 0 ? k ? m, in the cache where item di can be placed. The optimality criteria can be based on various factors like the frequency with which data items are accessed, the order in which data items are arrived in the cache etc. Let?s now discuss the proposed cache replacement technique. Let Rk represents the set of all data items that are correlated to dk based on the association rules mining algorithm. Then we define the residual set Sk as:  kk RCS ?= where Sk represents the residual set obtained after  eliminating items related to dk from the set S. Then the particular cache location j to be replaced with item dk can be computed as follows:  )( kSLRUj = where LRU returns the index of the least recently used  item from the set Sk. Fig 3 shows the proposed cache replacement strategy in pseudo code format that tries to allocate a cache entry for a data item d. The algorithm first looks for an empty location in cache. If there is some space available in cache, the algorithm places the item d in that free                              Figure 3.  Proposed Cache Replacement Algorithm  location. If there is no free space, the algorithm then calculate a victim cache location. To do so, the algorithm first constructs a residual set S by eliminating those data items that are related to item d. If the residual set is non- empty, then the algorithm applies Least Recently Used (LRU) algorithm to determine cache location to be replaced with d.

In some rare cases, the residual set might be empty. The algorithm applies LRU algorithm to all the cache contents in that particular case.



IV. SIMULATION DETAILS AND RESULTS The proposed caching strategy has been implemented in  JIST/SWANS network simulation tool. Unless we explicitly mention, all the simulation parameters were kept to default values of JIST/SWANS. The simulation has been performed in a field of 500 ? 500. The nodes were placed randomly.

The routing algorithm we used is Ad hoc On Demand Distance Vector Routing (AODV) protocol. In order to test the proposed scheme, we need to generate some correlated traffic. Hence, a Correlated Data Generator (CDG) was developed in Java. The CDG module generates correlated data item requests periodically based on a correlation matrix M. Using Java Random Generator library, an n ? n correlation matrix M is generated in the following way:  ),(   0.5            1 0.5            0  ),(  for  generatednumber  random a is ]1,0( and    0  and    0 where,  jiM  r r  jiM  ij rnjni  ij  ij  ?<?<?  ? ? ?  ? <  =   Using this correlation matrix M, we generate the set of Candidate Data Item Requests CDR. To generate CDR, we first assign an index i to all the data items. Then, a random data item d is generated. The set CDR is generated in the following way:  { } 1),(| =?== diMdiiCDR The set CDR is generated based on whether the data item  i is related to data item d based on the set CDR. Based on the set CDR, we then generated a request session RS in the following way:  issued  be request to item data a of likelihood  thedetermines  that  value thresholda is   and for  generated  number  random a is ]1,0(  and   i 0 where,  ),(  )(  ?  ?  jiRS p  iCDRRS  ij  p  n i  ?<?  <  = U   In our case the value of ?  is 0.8. There are a number of  Association Rules Mining algorithm i.e. Aprioiri [13], FP- Tree[14]. We have selected FP-Tree algorithm because it is  [Cache R eplacement Algorithm] /* C represents cache memory locations item is the data item to be placed in cache S is  the residual set */  public  int placeItem(Cache C, Item d) { if(C.hasSpace()  { C .add( item); }else{ R  = getR elated(d); S = C F or i = 0 To R.size If S contains R( i) S.remove(R(i)) End End  int j ; If size(S)  <> 0  j = getLRUSlot(S); Else  j = getLRUSlot(C);  C.setT ouchTime(j, currentT ime); C.set( j,d); } }     0.05  0.1  0.15  0.2  0.25  0.3  0.35  Node  H it  Ra tio   a) Simulation Time: 5000s     Nodes: 20        0.05  0.1  0.15  0.2  0.25  0.3  Node  H it  R at  io   b) Simulation Time: 5000s  Nodes: 50  Figure 4.  Results of Proposed Caching Technique  efficient in terms of processing time. The support value for FP-Tree mining algorithm is set to 80%. The capacity of the cache is set to 10 data items of fixed size.  Fig 4 shows the results of the proposed scheme implemented on JIST/SWANS. The graph shows the hit ratio for each of the data item request. The graph compares the results of proposed cache replacement algorithm with LRU. Fig 4a shows the results for 10 nodes with simulation run for 5000s.

As evident from graph, the proposed scheme performs reasonably well in contrast to LRU algorithm. Fig 4b shows the result with 50 nodes, that shows similar trends. In both of the results, there are some data item requests in which the LRU scheme performs better than proposed scheme. This can be because of the fact that the proposed scheme expects related data items to be used in future but in the actual case related items were not used together.



V. CONCLUSION In this paper, we have proposed a contemporary scheme  for Cache Replacement in Mobile Ad hoc Network. The simulation results compared the suggested scheme with LRU cache replacement algorithm. The results show that the proposed scheme gives significant improvement in cache hit ratio as compared to LRU algorithm. However, the proposed  scheme should be tested for various other parameters and configurations i.e. cache size, access time, number of nodes etc. In addition, the algorithm should also be tested when it is used in conjunction with other cache management algorithms i.e. cache consistency algorithms and cache update schemes etc. The proposed Cache Replacement scheme also incites several research areas. Since, the FP-Tree mining algorithm is not computationally good and its memory requirements are high, research should be pursued in extending existing FP-Tree mining algorithms such that it can work well on low-capability devices. A possible solution to this problem is designing approximation algorithms that give association results with reasonable accuracy and  low computational cost.

