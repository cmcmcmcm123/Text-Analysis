Application-aware Resource Allocation for SDN-based Cloud Datacenters

Abstract? In cloud datacenters, since resource requirements change frequently, how to assign and manage resources efficiently while meeting service level agreements (SLAs) of different types of applications is an important research issue.

In this paper, we propose an Application-aware Resource Allocation (App-RA) scheme to predict resource requirements and allocate an appropriate number of virtual machines (VMs) for each application in SDN-based cloud datacenters. To the best of our knowledge, the proposed App-RA is the first application-aware resource allocation scheme that adapts to all types of applications. The App-RA can meet SLAs, allocate resources efficiently, and reduce power consumption for each application in cloud datacenters. The proposed App-RA adopts the neural network based predictor to forecast the requirements of resources (CPU, Memory, GPU, Disk I/O and bandwidth) for an application. In the proposed App-RA, we have designed two algorithms which allocate appropriate numbers of virtual machines and use the VM allocation threshold to avoid SLA violations for five different types of applications. In addition, we adopt an SDN-based OpenFlow network with CICQ switches to appropriately schedule packets for different types of application in the network layer. Finally, simulation results show that the power consumption of the proposed App-RA is only 9.21% higher than that of the best case (oracle) and the power consumption of EAACVA, which is a representative resource allocation method for non-graphic applications, is 104.58% worse than that of App-RA.

Furthermore, the SLA violation rate of the proposed App-RA is less than 4% for all applications.

Keywords - Service level agreement; application-aware; resource allocation; cloud datacenter; software define network.



I.  INTRODUCTION In cloud datacenters, resource requirements changes  frequently. Therefore, dynamic allocating and managing resources to meet the SLA of each application is an important research issue. The objective of dynamic resource allocation is to satisfy the SLA while minimizing the power consumption in cloud datacenters. In order to satisfy the SLA of each application, resource prediction is a fundamental technology. A resource prediction tool is used to predict resource requirements, and then we can allocate resources in advance to avoid SLA violation. In existing resource allocation schemes, most of them adopt a neural network based prediction, which has been proved its prediction accuracy, so we also adopt a neural network based predictor.

There are two types of resource allocation: server-aware resource allocation and application-aware resource  allocation. The server-aware resource allocation, which detects loading of a server and allocates VMs for all applications in the server, cannot assign different SLAs to different applications. In contrast, application-aware resource allocation, which detects loading in an application and allocates VMs to the application, can assign different SLAs to different applications.

In a cloud datacenter, even if we predict and allocate network bandwidth for each application in advance, the network may still congest. In order to resolve this problem, we adopt an SDN-based OpenFlow [1] network with a CICQ switch to schedule packets for different applications in the network layer. OpenFlow is an open standard to allow researchers to run experimental protocols in realistic networks and is currently deployed in large-scale datacenters, like GENI [1].

In this paper, we propose an Application-aware Resource Allocation (App-RA) scheme to predict resource requirements and allocate an appropriate number of VMs for each application in SDN-based cloud datacenters. The rest of the paper is organized as follows. In section II, we review existing resource allocation mechanisms, compare application-aware and server-aware resource allocation schemes for cloud datacenters, and introduce the OpenFlow.

In section III, we describe the proposed App-RA scheme. In section IV, we evaluate our proposed App-RA scheme using CloudSim, and we compare the power consumption of the proposed App-RA with EAACVA, which is the best available related work for non-graphic applications. Finally, we conclude this paper and outline future work.



II. RELATED WORK  A. Resource allocation architecture In order to satisfy the SLA for each application,  researchers have proposed resource allocation schemes used in cloud datacenters. As shown in Figure 1, there are two types of resource allocation: server-aware resource allocation and application-aware resource allocation. In the past, the server-aware resource allocation scheme was used in cloud datacenters. However, it cannot assign a different SLA to each application. Because there are always different applications in cloud datacenters, only setting a single SLA cannot satisfy different requirements of different applications. Thus, it is difficult to satisfy the SLA of each application in cloud datacenters. Nowadays, application- aware resource allocation has become the major scheme in cloud datacenters.

DOI 10.1109/CLOUDCOM-ASIA.2013.44    DOI 10.1109/CLOUDCOM-ASIA.2013.44          Figure 1: Classifications of existing resource allocation methods.

In [2], it presents a scheme which predicts workload using a neural network and adopts server-aware VMs resource allocation, but it mainly focuses on resource prediction. In [3], it introduces a resource prediction scheme using a neural network and uses a resource allocation scheme to save power in cloud datacenters. However, it did not consider an SLA for each application in cloud datacenters.

We first review existing application-aware resource allocation which detects an application?s loading and allocates VMs to the application. Application-aware resource allocation can satisfy different SLAs for different applications. Its prediction is still accurate if an application migrates to another server, and one still can allocate appropriate VMs to the application. To fully utilize the advantage we mentioned above, we adopt application-aware resource allocation for the proposed App-RA. In [4], it proposes an application-aware resource allocation scheme to dynamically manage resources, and it can satisfy the SLA and can allocate resources efficiently for web applications only. In other words, it determines how many VMs should be allocated to satisfy the SLA. However, it only adapts to web applications. In [5], it proposes an application-aware resource allocation scheme with minimum power consumption. It runs benchmarks to measure how many VMs and power required in each application. The resource allocation scheme is based on a benchmark process which takes a lot of time. It cannot dynamically adjust numbers of VMs for different applications. In other words, it is a static scheme rather than a dynamic scheme. In addition, it did not consider graphic applications.

As shown in Table I, the proposed App-RA can adapt to all types of applications, meet different SLAs for different  Table I: Comparison of the proposed App-RA with related work.

Approach EAACVA [5] App-RA(proposed) Suitability for what types of applications  For non-graphic applications All types  Different SLAs for different applications Yes Yes  SLA violation handler No Yes(response time) Bandwidth  provisioning No Yes  Resource prediction No  Yes (neural network based)  applications, adjust resources if an application violates its SLA, adjust bandwidth provisioning in an SDN-based datacenter network for all applications, and provide resource prediction for each application  B. SDN-based datacenter network In recent years, researchers have proposed several SDN-  based datacenter networks which combine with cloud datacenters. In [6], it proposes a practical virtualization cloud datacenter in the SDN network and it defines an APP-ID (a 24 bits label, which can be stored in the IP header) which is used to identify an application in the SDN network. However, it does not consider resource allocation in cloud datacenters.

In [7], it proposes an OpenFlow-based flow level bandwidth provisioning scheme for CICQ switches. Because it schedules packets at flow level, network delay can be decreased by better scheduling for a flow requiring high bandwidth. Based on this observation, the proposed SDN- based cloud datacenter network schedules packets at application level and network delay can be decreased by better scheduling for an application requiring low network response time to meets its SLA.



III. APPLICATION-AWARE RESOURCE ALLOCATION FOR SDN-BASED CLOUD DATACENTERS  A. Application-aware resource prediction In the proposed App-RA, we propose an application-  aware resource prediction to predict resource requirements for each application. In Figure 2, we adopt a neural network to predict the resource requirements (CPU, memory, GPU, hard disk I/O and bandwidth utilization) for each application, and we also use these five types of resource requirements as input factors for the neural network. When the neural network training completes, resource requirements can be predicted. In addition, because the number of users changes all the time in the internet, we also use Time Stamp as an input factor for the neural network to make prediction more accurate. In the following, we introduce the proposed Application-aware Resource Allocation (App-RA) scheme based on application-aware resource prediction to assign an appropriate number of VMs so as to meet the SLA of each applications.

Figure 2: The proposed App-RA resource prediction scheme using a  neural network.

B. Application-aware resource allocation In this section, we introduce the proposed application-  aware resource allocation scheme to allocate an appropriate number of VMs for each application. The objective of the proposed App-RA is to meet SLAs, allocate resources efficiently, reduce power consumption for each application and adapt all types of applications in cloud datacenters.

In a cloud datacenters, we may need to adjust the number of VMs required to meet each application. Algorithm 1 shows how to decide when to power-on or power-off VMs for an application. If the predicted utilization is greater than the VM Allocation Threshold of an application, we power on a VM to support this application. If the current utilization is less than the sum of all VMs? capacity and the reserved resources (maximum utilization ? VM Allocation Threshold) in an application, we power off a VM to save power for this application in the cloud datacenter.

Algorithm 1 Power-on and power-off VMs for an application Xi = the number of VMs currently used by application i Maximum utilization = Xi * 100% Unused resources = Maximum utilization - Predicted utilization If Predicted utilization > VM Allocation Threshold then Xi = Xi + 1; VM Allocation Threshold = VM Allocation Threshold + VM capacity End if If Unused resources > (VM capacity + (Maximum utilization ? VM Allocation Threshold)) then Xi = Xi - 1; VM Allocation Threshold = VM Allocation Threshold ? VM capacity End if   We also need to adjust the VM Allocation Threshold to  meet the SLA of each application. Algorithm 2 shows how to dynamically adjust the VM Allocation Threshold. When the SLA (for example, response time) is violated, the VM Allocation Threshold is decreased according to an SLA weight (WSLA) which is a value between 0 and 1. If WSLA approaches 0, it means more resources are reserved for an application which can result in decreasing the SLA violation of the application, and vice versa.

When the response time is lower than half of the response time specified in the SLA, the VM Allocation Threshold will be increased according to a power consumption weight (WP) which a value between 1 and 2. If WP approaches 2, it represents that very few resources are reserved for an application which can reduce power consumption, and vice versa.

Algorithm 2 Adjustment of VM Allocation Threshold for an application Xi = the number of VMs currently used by application i WSLA = SLA weight (0 < WSLA < 1) WP = Power consumption weight (1< WP < 2) If Xi >= 1 then If Current response time > Response time specified in SLA then VM Allocation Threshold = VM Allocation Threshold * WSLA; Else if Current response time < (Response time specified in SLA / 2) then VM Allocation Threshold = VM Allocation Threshold * WP; End if End if   C. Proposed SDN-based datacenter network design  In cloud datacenters, even if we predict and then allocate network bandwidth for each application in advance, the network may still congest. In order to resolve this problem, we adopt an SDN-based OpenFlow [1] network with CICQ switches to schedule packets from different applications in the network layer. For example, the video streaming application needs more bandwidth, but the search engine application should have a high scheduling priority, so the packets of the search engine application can be sent earlier to avoid increasing network delay. We propose the following scheduling strategy in order to resolve the above problem:  1. The controller maintains a bandwidth provisioning table for different types of applications and sends it to CICQ switches.

2. The switches decide packet scheduling priorities based on the bandwidth provisioning table from the controller.

As shown in Table II, an example bandwidth provisioning table is provided; however, the actual bandwidth provisioning may be based on the charge of each application. First, we need to modify an OpenFlow controller to support our method. We add an APP-ID (24 bits) label of each application to the OpenFlow packet header [6], and thus the controller can identify each application. The controller decides bandwidth provisioning for each application and modify the flow tables in switches. Second, we modify the OpenFlow switches to support our method. In Figure 3, we use a CICQ (Combined-Input-Crosspoint-Queued) switch [7] to handle packet scheduling for each application. The CICQ switch is a kind of crossbar switches with a small exclusive buffer at each crosspoint.

Table II: Bandwidth provisioning for different types of applications.

Type of an applications Bandwidth provisioning  Search engine 10 3D Game 8  Social networking 6 Video 4  Message, Mail 2     Figure 3: Using a CICQ switch to adjust the bandw each application.

As shown in Figure 3, we propose a p method to forward packet for each applicatio  1. In application scheduling, input packets and put them into corr buffers (APPijk?s). Application sc packets with minimum executio sends them to the corresponding bu  2. In input scheduling, packets are buffers (Xij?s) according to the FIF  3. In output scheduling, packets ar port Outj according to the bandwi table.



IV. SIMULATION RESULT  A. Simulation environment We used five different types of applica  the proposed App-RA?s SLA violation consumption using the CloudSim [9] sim capacity is according to [8]. However, sin obtain video traffic data in Table II, APP4 social networking with descending traffic APP3 with ascending traffic. We concurren different types of applications, as shown in IV shows related simulation parameters CloudSim does not provide the functio simulation, we add a network function int environment to evaluate the proposed A APP-ID to identify different applications, an the corresponding buffers.

Table III: Five different types of applica Application name Types of an  APP1 Search APP2 3D g APP3 Social networki  tra APP4 Social netw  descend APP5 W     In1  Inn  APP111  APP112  APP1N1  APP1N2  APPN11  APPN12  APPNN1  APPNN2  X11  XN1  Buffe B11  B1N  BN1  BNN  Out     width provisioning for  packet scheduling on: port Ini receives  responding input cheduling selects on time [7] and uffer (Bij).

e sent to output O order in Bij.

re sent to output idth provisioning  TS  ations to evaluate rate and power  mulator. The VM nce we could not is replaced with c in contrast to  ntly executed five n Table III. Table  setup. Because on for network to our simulation  App-RA. We use nd put packets to  ations.

n application h engine gaming ing with ascending affic working with ding traffic Web   Table IV: Simulation param  Simulator Prediction technique  Prediction tool MA Number of types of applications  Number of servers Maximum number of VMs  Maximum bandwidth WSLA WP  SLA violation threshold   B. Comparison of SLA violation ra As shown in Figure 4, we  applications for 100 minutes. W violation rate for each applicatio resource allocation schemes. EAA resource allocation method for n had many SLA violations in APP2 did not consider GPU in its design.

as the SLA violation threshold. R Engine [10] only guarantees a Mon at least 95%, and Amazon EC2 [1 Uptime Percentage at least 99%. H guarantee the response time specif application. Furthermore, the SLA proposed App-RA is less than 4% applications.

Figure 4: SLA violation rate comparison fo resource allocation sc  C. Comparison of power consumpt We evaluate the power consu  physical servers and VMs under diff three different resource allocation Table V shows that the power cons App-RA is only 9.21% higher tha (oracle) and the power consumpti 104.58% worse than that of App-RA      X1N  XNN  fered crossbar  t1 Outn  meters setup.

CloudSim 3.0  Neural network-based ATLAB 7.11.0 (R2010b)  5 types  40 Mbps 0.9 1.1  100 ms  te executed five types of  We compare the SLA on using three different  ACVA, which is the best non-graphic applications, 2 because EAACVA [5] Note that we set 100 ms  Remind that Google App nthly Uptime Percentage 1] guarantees an Annual However, they could not fied in the SLA for each A violation rate of the % for all five types of   or each application using three chemes.

tion umption of power-on/off ferent loadings [12] using  schemes. Figure 5 and sumption of the proposed an that of the best case ion of EAACVA [5] is  A.

Figure 5: Power consumption comparison for each app different resource allocation scheme   Table V: Comparison of power consumption using thr  allocation schemes.

Application Best case  (Oracle) APP-RA  (proposed) APP1 91.59% 100% APP2 85.66% 100% APP3 91.73% 100% APP4 89.36% 100% APP5 95.60% 100%  Average 90.79% 100%

V. CONCLUSIONS In this paper, we have presented an A  Resource Allocation (App-RA) scheme to requirements and then allocate an approp virtual machines (VMs) for each applicatio cloud datacenters. To the best of our proposed App-RA is the first application allocation scheme that can adapt to all type The proposed App-RA can meet SLAs, a efficiently, and reduce power consumption f of applications in cloud datacenters. It network based predictor to forecast the resources. We have designed two algo proposed App-RA to allocate VMs and dy VM Allocation Threshold to avoid SL different types of applications. In addition presented an SDN-based OpenFlow netw switches to better schedule packets from d applications in the network layer. Finally, s have shown that in terms of power c      plication using three es.

ree different resource  EAACVA [5]  174.59% 264.29% 217.33% 184.79% 181.88% 204.58%  Application-aware predict resource  priate number of on in SDN-based  knowledge, the n-aware resource s of applications.

allocate resources for different types adopts a neural requirements of  orithms for the ynamically adjust  LA violation for n, we have also  work with CICQ different types of simulation results consumption, the  proposed App-RA is only 9.21% h (oracle), and EAACVA, which is th method for non-graphic application App-RA. In addition, the SLA viola App-RA is less than 4% for each app

VI. ACKNOWLED The support by the Inventec unde  by the National Science Council 2221-E-009-090-MY3 is gratefu authors would like to thank Mr. Jon for his valuable comments that imp paper.

REFERENCE [1] N. McKeown, T. Anderson, H. Balakri  J. Rexford, S. Shenker, J. Turner, ?Ope campus networks,? in ACM SIGCOMM 74, Apr. 2008.

[2] Md. T. Imamt, S. F. Miskhatt, R. M. R network and regression based process scaling of Grid and Cloud resources," Information Technology (ICCIT) Conf.

[3] J. Prevost, K. Nagothu, B. Kelley, M.

data center networks loads using stoc Proc. IEEE System of Systems Enginee 27-30 June 2011.

[4] V. Cardellini, E. Casalicchio, F. L. P Resource Management for Applicati Cloud," in Proc. IEEE Network Cloud (NCCA) Conf., pp.20-27, 21-23, Nov. 2  [5] H. Viswanathan, E.K. Lee, I. Rode "Energy-Aware Application-Centric Workloads," in Proc. IEEE Paralle Workshops and Phd Forum (IPDPSW) 2011.

[6] P. Lin, J. Bi, H. Hu, "VCP: A virtuali intra-domain production network," in P (ICNP) Conf., pp.1-2, Oct. 30 2012-No  [7] H. Jin, D. Pan, J. Liu, N. Pissinou, bandwidth provisioning for CICQ INFOCOM Conf., pp.476-480, 10-15 A  [8] ?Amazon EC2,? [Online]. Available: h [9] ?CloudSim,? [Online]. Available: http [10]  ?Google App Engine Service Level A  https://developers.google.com/appengin [11] ?Amazon EC2 Service Level Agre  http://aws.amazon.com/ec2-sla/.

[12] A. Beloglazov, R. Buyya1, Y. Lee, A  Survey of Energy-Efficient Data Ce Systems,? in Proc. IEEE Advances in C  higher than the best case he best resource allocation s, is 104.58% worse than ation rate of the proposed plication.

DGEMENT er Contract 101C179 and  under Grant NSC102- ul acknowledged. The nz Lee from the Inventec proved the quality of this  ES ishnan, G. Parulkar, L. Peterson, enFlow: enabling innovation in M CCR, vol. 38, no. 2, pp. 69-  Rahmant, M. A. Amin, "Neural or load prediction for efficient  " in Proc. IEEE Computer and f , pp.333,338, 22-24 Dec. 2011.

Jamshidi, "Prediction of cloud chastic and neural models," in ering (SoSE) Conf., pp.276-281,  resti, L. Silvestri, "SLA-aware ion Service Providers in the d Computing and Applications 2011.

ro, D. Pompili, M. Parashar,  VM Allocation for HPC l and Distributed Processing Conf., pp.890-897, 16-20 May  zation cloud platform for SDN Proc. IEEE Network Protocols  ov. 2 2012.

"OpenFlow based flow level switches," in Proc. IEEE  April 2011.

http://aws.amazon.com/ec2/.

://www.cloudbus.org/cloudsim/.

Agreement,? [Online]. Available: ne/sla?hl=zh-tw/.

eement,? [Online]. Available:  A. Zomaya, ?A Taxonomy and enters and Cloud Computing Computers Conf., Vol. 82, 2011.

