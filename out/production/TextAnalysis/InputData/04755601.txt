A Theoretical Framework for Assessing Eavesdropping-Resistant Authentication Interfaces  Bogdan Hoanca

Abstract A simple theoretical framework is developed to  evaluate the security and usability of eavesdropping- resistant authentication schemes. Such schemes strive to allow users to authenticate without disclosing the user?s credentials to an eavesdropper, while using only standard computer hardware (monitor, keyboard and mouse). We find that schemes based on shared secrets and standard computer hardware are unable to deliver real security advantages.  For all the schemes reported to date, an attacker can collect all the needed information within ten observations of successful authentications. Shared secret schemes can provide security only if the space of possible shared secrets is extensive enough to prevent an exhaustive search. In turn, this complexity of the shared secrets space is already limited by usability considerations, and cannot be increased further.

Thus, for truly user-friendly interfaces resistant to eavesdropping attacks, shared secrets must be combined with other authentication factors: biometrics or special hardware.

1. Introduction   Most computer authentication interfaces are based on a shared secret: a password that authenticates a given user name. This scheme is inexpensive and widely available because it relies on standard computer hardware: a monitor, a keyboard and a mouse. Despite its advantages, the scheme is also highly vulnerable to eavesdropping attacks.

The vulnerability of the traditional authentication interface arises because the user enters her password in cleartext at the interface. As the User, Ursula, enters her username and password to authenticate to Victor, the Verifier, an Attacker, Anne, might be i) watching over Ursula?s shoulder, ii) using a hardware key logger to monitor her key strokes, iii) using a screen capture program to capture mouse clicks or iv) capturing Ursula?s credentials on a phishing web site (APWG, 2008). Such attacks are known as peeping attacks, shoulder surfing attacks or eavesdropping attacks (Hoanca & Mock, 2007). Once Anne has captured Ursula?s user name and password, she has all the information identifying Ursula as herself.

Aside from capturing user authentication, an attacker can also mount man-in-the-middle attacks by  hijacking a user session, without a need to uncover the user authentication information. Such attacks are more difficult to mount than simple eavesdropping, but they are notoriously difficult to prevent. The theory in this paper is relevant only in the context of eavesdropping attacks that do not hijack a session, but only capture user identifying information.

Given the ease of mounting eavesdropping attacks and the inherent vulnerability of the password scheme, the number of phishing attacks has been rising steadily. This in turn has led several researchers to propose authentication interfaces that use the same basic hardware, yet are better equipped to prevent Anne from carrying out such an attack.

Ideally, such an interface would allow Ursula to authenticate to Victor via a relatively short and cognitively simple process, but would prevent Anne from collecting sufficient information to impersonate Ursula, even after Anne has captured all the user input across several authentication sessions, and even after Anne uses ample computing power over lengthy periods of time processing the user input collected.

There are two ways in which the User?s secret credentials can be protected. One way is to disclose to the Attacker only a portion (ideally zero) of the shared secret, but never the entire information (such schemes are known as zero-knowledge protocols).

The second approach is to make it time consuming to compute the shared secret, even if the Attacker has all the information needed (such an approach relies on large NP-complete problems to construct one-way functions). All the proposed schemes purport to hide the shared secret, but they do not make it clear whether they i) hide part or all of the shared secret, ii) make the shared secret difficult to find or iii) both.

In this paper we show that within a small number of observations all schemes disclose sufficient information for an Attacker to find the shared secret.

A prepared Attacker can gather as much information as the Verifier in any given session. As such, the ability of the User to preserve some shared secret with the Verifier is limited by the complexity of the shared secret and not by the complexity of the information exchanged in any given session. The analysis we present here is applicable to any type of authentication interface, using alphanumeric symbols, graphical interfaces or even complex interfaces involving sounds or video.

We focus in this paper on systems that involve only an input device (mouse or keyboard) and a standard monitor. The User is assumed to be ?nude? in that she does not need to carry around any special devices. The User is also bound by human cognitive and perceptive limitations.

The findings we report in this paper can be seen as the minimum capabilities of an authentication system. Any system involving biometrics or special hardware has the potential to be more secure than the baseline ?nude User? system. Many assistive technologies can lead to interfaces that are highly resistant to eavesdropping attacks, for example using biometrics, authentication tokens (recently including out-of-band signaling devices, e.g. a cell phone (Bedworth & Allison, 2008)) or combinations of these with shared secret authentication. The drawbacks of such authentication systems include higher cost, limited availability and privacy concerns.

In contrast with the ?nude? and cognitively limited User, Anne, the Attacker, is able to use technology extensively, to capture all the information exchanged between Ursula and Victor, to store this information and to correlate information captured across multiple authentication sessions. Anne also has the ability to use significant computing power, over extended periods of time, because she needs not gain access to the User?s credentials in real time.

Victor, the Verifier, is also able to use technology (after all, Victor is in general a computer), but will be limited by the parameters of the user interface.

The next section reviews previous work, then Section 3 presents several definitions including a taxonomy of possible attacks. Section 4 presents the theoretical model. Section 5 applies the theory to published authentication interfaces and summarizes the main findings. Section 6 concludes the paper.

2. Previous work   Authentication in the presence of eavesdropping attackers has already been tackled in numerous published papers. A detailed literature review of several approaches to combat eavesdropping attacks can be found in Tari, Ozok and Holden (2006). While many papers are based on the use of special hardware, including screen filters (Naor and Pinkas, 1997), eye-tracking hardware (Kumar et al, 2007), or trusted browser extensions (Ross et al, 2005), we focus on approaches that are feasible on an untrusted computer, with no special hardware. We assume a monitor and keyboard are generally available.

Matsumoto (1996) presented the first theoretical basis for a Human-Computer Cryptography protocol.

Matsumoto outlines a theoretical framework that can be used to analyze such authentication protocols in a  linear space and presents graphs of the probability of success for the attacker. He notes a tradeoff between the length of the shared secret, the length of the authentication session and the probability of success for the attacker. As practical examples, Matsumoto presents two different types of protocols, but both examples are over nonlinear spaces, and cannot be mapped onto his theory.

Hopper and Blum (2002) also present several ideas of protocols that are highly resistant to eavesdropping attacks. They propose the concept of ?learning parity in the presence of noise? as a way to introduce randomness in the interaction between the User and the Verifier, with the intent of confusing the Attacker. They point out that this is an NP hard problem, although the NP hardness is irrelevant when dealing with problems of a size that is computationally tractable.

More recently, a graphical implementation of a shoulder surfing resistant protocol was first proposed by Sobrado and Birget (2002) and then detailed by Wiedenbeck et al. (2006). Here, the secret shared by Ursula and Victor consists of a series of graphical symbols, and Ursula authenticates by clicking anywhere inside the convex hull defined by the chosen graphical symbols. Anne cannot easily find out which symbols define the hull, because there are multiple possibilities for any given click point. The scheme is easy to understand in principle, but has several weaknesses. First, locating the symbols on the screen can be difficult, because several symbols look similar. Second, to avoid random guesses matching the required entry (false positives) the authentication process needs to be lengthy. Third, even with a lengthy authentication process, the attacker has a relatively high chance of authenticating by randomly guessing at click points1. The paper presents considerations on reducing the success of the Attacker, but not a rigorous analysis of the probabilities of success.

Several more published results approach the shoulder surfing problem by assuming rather arbitrary limitations on the Attacker?s capabilities.

Tari, Ozok and Holden (2006) report on an extensive comparison of perceived and actual shoulder surfing capabilities of text versus graphical passwords, and include both ?strong? and ?weak? passwords in an  1 If an Attacker does not intend to break into one particular account, but rather, in any one of a large number of accounts, the attack may target a large number of accounts in parallel. By trying random password combinations for each of the accounts, such an attack will circumvent the lockout protection and will statistically succeed in breaking into a percentage of the accounts under attack.

experimental evaluation. Their attackers are human participants without any technological aids. As such, visual ability and memory are principal limitations.

The results of the study might have been very different, had the attackers been allowed to video record the authentication sessions or to use key loggers, tools widely available to real attackers. Roth, Richter and Freidinger (2004) present a protocol for entering Personal Identification Numbers (PINs) at Automated Teller Machines in a manner that is resistant against shoulder surfing by unaided human observers. They concede that cameras might be used to enhance the attacker?s capabilities, and evaluate the capabilities of the protocol using the concept of ?shadow numbers? ? the set of PINs that could correspond to a given user input. They identify the same tradeoff between password complexity, length of the authentication session and probability of success for the attacker. Finally, a spy resistant keyboard presented in (Tan, Keyani, and Czerwinski, 2004) is also based on the cognitive limitations of the human observer, but would be easily defeated by an Attacker using a recording device.

Common to all of these protocols is a marked decrease in usability. All protocols require that users perform more complex cognitive tasks than simply remembering and typing a password, as in the familiar authentication approach. All protocols also take significantly longer than typing in a password.

Instead of a few seconds, most protocols take up to a few minutes to enter one?s credentials. The increased complexity is likely to increase error rates, which will further increase the time it takes for users to authenticate. The question we ask (and answer) in this paper is whether the extra efforts are worth the trouble, and whether any of the proposed protocols lead to reasonable robustness to eavesdropping attacks. Do they actually manage to hide some of the information in the shared secret?

3. Definitions   This section describes formally the  authentication interface. We introduce two alphabets: one for the space of shared secrets and another one for the space of interface symbols actually exchanged by the User and the Verifier. We also discuss the mapping between the two spaces (ideally, a one-way or difficult to invert mapping). Finally, we consider possible types of attacks against such an interface.

3.1. Authentication interface   Let A be an alphabet of symbols that define the shared secret on which the authentication scheme is based. The symbols currently used in A are alphanumeric, image tiles, or points on an image. In the future, an authentication interface might involve  Figure 1. Mapping from the space of shared secrets S to the space of interface symbols E. mE is the set of symbols that can be entered at the interface. Among the set mE , there may be multiple symbols that will  correctly authenticate the user in a given session (the set of all the valid responses is mE ). The User can  authenticate correctly by selecting any symbol from mE .  The actual user entered symbol is e . The randomness factor ? ensures that the set mE is different from session to session, to prevent replay attacks.

ES  R  s  e  Em  Em      users responding to sounds, tracking elements in a video or responding to cues in a story.

Let ( )pssss ,,, 21= , pkAsk ,1, =? be the string of symbols making up the secret shared between the User and the Verifier (Fig. 1). Some of the elements of the secret can be repeated (i.e., there might be ji ss =  for some values of i and j, where  pji ,1, = ).

Let p  j  jAAAAAAAS 1=  =?????= be  the set of all possible shared secrets (p is the maximum number of symbols in the shared secret).

Let B be the alphabet of symbols that can be entered at the authentication interface. This needs not be the same as the alphabet forming the space of shared secrets, A. For example, the alphabet A might be a set of images, and the symbols to be entered at the interface might be numbers. The authentication protocol might display nine images from the alphabet A at a time, and might require the user to enter a number indicating how many of the images in the shared secret are currently displayed on the screen, as in the Passfaces approach (Brostoff and Sasse, 2000).

Using symbols from the alphabet B, the User authenticates by selecting an ?entered symbol?  ( )reeee ,,, 21= , with riBei ,...1, =? . The entered symbol is in general an array with r elements in the notation above. Just as for the shared secret, we define the set of all possible sets of entered symbols  as r  j  jBBBBBBBE 1=  =?????= , where r  is the maximum number of elements in the entered symbols the User can select at the interface.

The symbols that can be entered in the authentication process might be the entire set E, or a subset of the interface alphabet EEm ? . mE might vary from session to session, or might be the same.

For graphical interfaces, mE is the set of symbols displayed for the user to select (e.g. faces in PassFaces). For text interfaces, most often EEm = .

In general, there might be several valid symbols a user could select to authenticate at the interface (for example, the user might be able to authenticate by clicking anywhere in a region on the screen). Let  mm EE ?  be the set of all such valid symbols.  The inclusion is strict, otherwise any symbol would be valid and an attacker would be able to authenticate by selecting random symbols at the interface.

In practice, mE must be a small subset of mE  to reduce the probability of a false positive (random guess). If mE is a large subset of mE , an attacker has a  large probability of successfully authenticating by simply choosing a random symbol at the interface. In many types of authentication interfaces, the set mE will contain a single element (i.e., there is one and only one correct entry to authenticate).

Let ? be the mapping between the shared secret and the set of valid symbols  ( ){ }??=?= ,,',' mmm EseEeE  at the interface. The user must apply this mapping to the shared secret to determine the set of valid symbols mE , and then must select the entered symbol from mE . The mapping ? also includes a randomness factor ? , as well as the set of symbols that can be entered at the interface mE .

The mapping depends on the set of symbols in mE , because the user will can only enter a symbol from  mE (i.e., the mapping should not map on a symbol from E that cannot be entered at the interface).

The randomness factor ? must be different from session to session to prevent replay attacks, where the Attacker can simply reenter the same symbols she observed in an earlier session to authenticate in a later session. This randomness factor often consists of displaying the interface symbols mE  in a random and different order every time the user needs to make a selection. In our analysis we assume a uniform distribution of the randomness factor. If the randomness factor is not random or not uniformly distributed, this can give the Attacker additional information, making it easier to carry out the attack.

The mapping ? is described as ?one-way,? although in practice it is just difficult to invert. In many applications requiring one-way mappings, the difficulty to invert is based on the large computational effort required to perform the mapping in a brute force attack. In the type of authentication schemes reviewed earlier in this paper, the cognitive limitations of the human user do not allow for the use of large computational effort requirements. The difficulty in inverting the mapping is simply based on the fact that for any observed entered symbol  ( )reeee ,,, 21= , there is a set mS  of possible values of the shared secret which all map to the same entered symbol (Fig. 2), ( ) mm SsEse ????= ',,,' .

The number of elements in mS  needs only to be large enough that trying all of them is not practical. A lockout mechanism is built into most authentication interfaces and disables the account after a number (3- 5) of unsuccessful attempts to login. This discourages the Attacker from trying out random guesses in hope of finding a match by sheer chance.

3.2. Taxonomy of attack types   There are two types of attacks Anne can mount against the authentication scheme. One type of attack is to guess the shared secret; if successful, this type of attack will give Anne full access to Ursula?s online identity. We refer to this type or attack as ?strong.? The other type of attack is to try to guess the appropriate entered symbol for only a given session.

We refer to this second type of attack as ?weak.? In traditional authentication schemes, the two attacks are entwined: the shared secret and the entered symbols are one and the same. For authentication schemes that are resistant to eavesdropping, the two types of attacks are distinct, although one may be more likely to succeed than the other.

3.2.1 Weak attacks   The protection against weak attacks is based on using the randomness factor. As shown in Fig. 3, two different authentication sessions with two different randomness factors will result in randomly different sets of acceptable authentication symbols, and will most likely result in the User selecting different entered symbols. An Attacker who observed a session will have only a negligible chance of being able to use the same entered symbol to authenticate successfully in a subsequent session (replay attack).

Replay attacks are more likely to succeed if there is a correlation between the mappings of successive authentication sessions, when knowledge of a previous mE  will give the Attacker information about the distribution of a future mE . A critical barrier against guessing attacks is the lockout mechanism  which disables the account after a number of unsuccessful attempts.

3.2.2. Strong attacks based on eavesdropping   A more complex type of attack that is more likely to succeed is to determine the shared secret based on several observations of user input. Having eavesdropped on the entered symbols for two or more successful authentication sessions, the Attacker can record the randomness factors and the entered symbols. She can then calculate offline the sets of possible values for the shared secrets that are consistent with the observed entered symbols. Once the Attacker has sufficient information, she can uniquely determine the shared secret and use it to authenticate in place of the user, without triggering the lockout mechanism. This attack has the highest likelihood of success and will be analyzed in detail in the rest of the paper.

3.2.3. Design tradeoffs   The difficulty of guessing the shared secret  increases with the number of symbols in the secret, p, and with the number of symbols in the alphabet A, in other words with the number of possible shared secrets in the space S.  At the same time, the usability of the authentication scheme decreases with the same factors, as the user needs to remember a longer password composed of a more complex set of symbols. Additionally, the more complex password will likely require a more complex cognitive effort to determine the symbols to be entered at the interface, further reducing the usability of the scheme.

Figure 2. Given an entered symbol e corresponding to a successful authentication, the Attacker is able to determine the set mS of all possible values of the shared secret for that map on the observed entered symbol e .

ES  R  s  e  Sm      The robustness of the authentication interface to brute force attacks depends on the risk that the Attacker would be able to guess the correct set of symbols to be entered to authenticate. The robustness against such attacks increases with the number of symbols to be entered at the interface (r) and with the number of symbols in the set mE . The usability of the scheme decreases with both of these measures, because a larger number of authentication symbols takes longer to enter and also leads to higher error rates. A large number of symbols in mE  also leads to longer authentication times and to higher error rates.

The robustness of the scheme is reduced if the set of valid entered symbols mE  is a large fraction of  mE , because the chance of a random choice from mE to be in mE  increases with the number of elements in  mE .  Conversely, a larger mE  leads to higher usability, because the User is more likely to locate an acceptable symbol if mE  includes more choices.

4. Theoretical framework for assessing robustness to eavesdropping attacks  4.1. Basic assumptions   In this work we make the basic assumption that the security of the authentication scheme is entirely based on the shared secret; there is no ?security through obscurity? (Kerkhoff's Principle). The Attacker knows exactly what the alphabet of symbols (A) is, the maximum length of the shared secret, p, the operation of the authentication process on the Verifier side, and has full access to the User input, ample space to store several authentication sessions,  as well as full access to extensive computing power to process the stored session data. Any interface parameters that the attacker does not already know can be assumed to be part of the shared secret any (for example, in the 2000 Hopper and Blum work, the shared secret would include both secret vectors, the ?secret? and the ?noise generator.?)  We also assume that the Attacker is able to distinguish between successful and unsuccessful authentication sessions. A protocol where a valid User is subject to random false positives and false negatives would greatly complicate the Attacker?s work, but would also confuse and frustrate the User.

Two other important issues have been analyzed extensively elsewhere: whether the User is able to recall the shared secret (Brostoff and Sasse, 2003), and whether the User is able to determine the correct entered symbols (i.e., what is a reasonable cognitive load). We do not make further mention on either of these two issues in the remainder of the paper.

4.2. Formal results   In this section we develop the theoretical framework that quantifies the usability-security tradeoff. We define the false positive error as the probability that an attacker is able to randomly guess the shared secret or the entered symbol successfully.

The term does not imply that the interface will mistake an incorrect entered symbol as correct.

Lemma 1  Given a single session of communication between the User and the Verifier, where the User proves her identity to the Verifier with probability of false positive error not to exceed P; given a known set of all possible shared secrets S; the Attacker is   Figure 3. As an attacker observes two or more authentication sessions, the space of possible shared secrets that could have led to the observed entered symbols shrinks. Eventually, the attacker is able to find out the shared secret as the intersection of all sets of possible shared secret values.

E  e1  S  R1  s  Sm1  Sm2  R2  e2  Em1  Em2      able to narrow down the location of the shared secret to a set with )(SP ?? elements on average ( )(S? denotes the number of elements in the set S).

Proof  The probability of a false positive error in identifying the User is the probability that the User has randomly chosen a symbol from mE  that happens to be in the set of valid symbols, mE , or equivalently a shared secret that happens to map into mE , for a given session with randomness factor ? . The probability of this happening is ( )  ( ) ( ) ( )m  mm  E E  S S  P ? ?  = ?  ? = .

On the other hand, having observed the entered symbol e , the attacker is able to infer that the shared secret is in the set ( ){ }??=?= ,,',' mm EseSsS  of all possible shared secret values that map on the actual entered symbol. The space of possible values for the shared secret is thus reduced from the set S to the subset mS , with )()( SPSm ??=?  elements.

The result of the lemma above is true on average.

In general, the number of elements in the set mS will vary depending on the entered symbol e  (some entered symbols will correspond to more possible values of the shared secret than other entered symbols, e.g. Sobrado and Birget, 2005). For those relations that map each entered symbol to the same number of possible shared secrets, the result of the lemma will be exact, not just on average.

Another important observation is that the proof of the lemma is valid even if the entered symbol includes random user errors, as proposed in Hopper and Blum (2000). If the protocol is such that the authentication allows for up to Z random errors among the elements of the entered symbol e , this will result in a larger set mS . Even if the user actually makes fewer errors in a given session, the set mS  will necessarily include all the possible shared secrets that might match all but Z of the elements of the entered symbol e . At the same time, the Verifier must be ready to accept as valid sessions with up to Z errors, hence the probability of a false positive will also increase. The proof above does not need to assume that all the elements of the entered symbol e are correct, but only that the authentication is successful, hence the lemma holds for any tolerance to errors Z.

Lemma 2  Given k sessions of communication between the User and the Verifier, where the shared secret remains unchanged for all k sessions; given that in  each session the User proves her identity to the Verifier with probability of false positive error not to exceed P; given a set of possible shared secrets S; the Attacker is able to narrow down the location of the shared secret to a subset with )(SPk ?? elements.

Proof  To conduct such an attack, the Attacker needs to capture and store the set of entered symbols je and the randomness factors j? for each authentication session j of the k sessions captured. Let ( ) jmS be the sets that map onto each of the entered symbols je .

The shared secret is in each of the ( ) jmS sets, hence it will also be in the intersection,  ( ) ( )( ){ }kjEseSsS jjmj k  j jm 1,,,','   =???=?= =  . Based on  Lemma 1, the probability that the shared secret is in any given set ( ) jmS  is equal to the false positive probability P. Because the randomness factor is different for each session, the sets ( ) jmS  are independently random distributed, so the probability that the shared secret is in the intersection of ( ) jmS will be the product of the probabilities that that shared secret is in each of the sets, i.e., kP . Hence the intersection set has )(SPk ??  elements.

Theorem 1  To gather sufficient information to uniquely determine the shared secret, the Attacker needs to capture ( )  ( )? ?=  P S  ko log )(log sessions (  is the ceiling  function, returning the smallest integer greater than the argument of the function).

Proof  The proof is trivial when applying Lemma 2.

The average number of possible shared secrets that match all the observed entered symbols over ok captured sessions is 1)( <?? SP ok , hence the actual shared secret can be determined exactly.

The theorem above describes how many sessions the Attacker must capture to collect sufficient information to uniquely determine the shared secret.

It makes no claim about whether the Attacker has sufficient computing power at her disposal to actually determine the shared secret.

Most authentication schemes are based on NP complete or NP hard problems with a search space that is exponential with respect to the length of the shared secret. On the other hand, if the attacker has      collected the needed number of sessions and if she has sufficient computing power to perform an exhaustive search in a reasonable amount of time, the difficulty of solving the problem is irrelevant.

We can now use the framework above to evaluate authentication interfaces proposed in the literature. For any of the proposed interfaces to be secure, they need to exhibit either a sufficient computational complexity or to require the capture of a sufficiently large number of sessions (or both).

5. Application of theory to reported authentication schemes   In this section we analyze a few particular cases of authentication procedures. We first evaluate how much computing power an attacker is likely to have available, then discuss the robustness of the proposed protocols in view of the theory we presented. We consider both the number of observations the scheme is able to withstand, as well as the time required for an exhaustive search of the space of shared secrets.

5.1. What is ?sufficient? computing power?

An attacker having ?sufficient? computing power to conduct exhaustive searches over the shared secret space is able to circumvent the NP hardness of the one-way mapping. Fortunately for the Attacker, the problem of searching for the shared secret values that could have led to a set of observed entered symbols is by its nature highly parallel, and can be farmed out to an army of computers in an efficient manner. The amount of data to be sent to the worker nodes in such an army would include the definition of the alphabets A and B, and the list of observed entered symbols and randomness factors for the 5-10 eavesdropping sessions captured, a very small data set.

Such a brute force attack is greatly aided by technological progress. The computing power of devices is increasing as the cost of computing devices is decreasing. Even more, by using self replicating virus programs to take over unprotected computers  attached to the Internet, Attackers can marshal the resources of armies of computer zombies to carry out nefarious activities for almost no cost to the Attacker.

In 2002 a 64 bit RC5 key was cracked in 1757 days in a distributed manner using donated processing power (equivalent to 32,504 800MHz Apple PowerBook G4) according to Distributed.net (2007).

With a typical CPU speed of 1 GHz, an army of 10,000 zombies, assuming an admittedly optimistic processing speed of one shared secret evaluation per CPU cycle, today?s Attackers would be able to process 1810 shared secrets per day. The next section considers what the implications of this processing power are on several protocols proposed to date.

5.2. Recommendations based on theoretical findings   As discussed in the introduction, the shared secret can be protected either by not disclosing sufficient information about it, or by making the shared secret computationally difficult to find from the disclosed information. Table 1 below summarizes results on the two considerations. To be able to realistically hide the shared secret, the schemes would need to withstand hundreds of repeated observations, for example in the case of daily use over a period of a few months, the standard recommended lifetime of a shared secret. None of the protocols reported to date are able to withstand more than ten observations without disclosing the full information about the shared secret to the Attacker.

Regarding the computational complexity, all but the Hopper and Blum scheme allow the Attacker to conduct a fast search of all the possible shared secrets. Armed with all the information about the shared secret and able to conduct an exhaustive search in less than an hour, the Attacker can uniquely locate the shared secret for all but the Hopper and Blum scheme. For this last scheme, the attacker is still able to capture all the information needed to identify the shared secret, but the complexity of the  Reference or description # of possible shared secrets  Probability of false positive  # of sessions needed to capture shared secret  Time needed for exhaustive search  Strong password**, traditional N=104?1016 1/N 1 0 Matsumoto, 1996 27 1/3 3 0 Sobrado and Birget, 2005 1013 0.001* 5 1 second Strong password**, ideal*** 1016 0.001* 6 15 minutes Hopper and Blum, 2000 1025 0.001* 10 30,000 years * ) No value given: using a conservative P = 0.001 **) A ?strong password? requires at least one digit, one symbol and one upper case letter.

***) Assuming some to be discovered eavesdropping-resistant scheme with excellent user friendly capabilities.

Table 1. Robustness of authentication interfaces to eavesdropping attacks. A scheme is secure if the number of session needed to be captured and the time to perform an exhaustive search exceeds the attacker?s resources.

search space will prevent her from actually locating the shared secret within a reasonable timeframe.

As illustrated in Table 1, the main result of the paper is that the security of the schemes is in the complexity of the space of shared secrets, S, not in information hiding. Information that can be gathered in fewer than ten repeated observations is not well hidden. Regardless of the type of one-way mapping, the User?s credentials can be easily compromised if the Attacker can complete an exhaustive search of the space of shared secrets, S within a reasonable time frame. On the other hand, if S is sufficiently complex to prevent a brute force search in a reasonable amount of time, the Attacker is unable to determine the shared secret even though she may have all the information needed to uniquely identify it.

Another important result is that the amount of information transmitted by the User to the Verifier in any given session has no ultimate implications on the ability of the scheme to withstand repeated observations by the Attacker. A user could be asked to make very simple decisions (binary choices) or to select items among a large number of possibilities.

An interface with increased complexity of choice (in the mE space) will be more resistant to guesses, but will not be more resistant to repeated eavesdropping attacks. The added complexity in mE  leads to a lower probability of false positive, but will also disclose the shared secret in fewer observations. Although, this appears to pose a valuable tradeoff, a closer analysis shows that this tradeoff is very shallow. For example, decreasing the acceptable probability of false positives from 0.001 to 0.0001 in the example above will disclose a ?strong password? in only 4 observations instead of 6. An Attacker who can capture 4 sessions will be equally able to capture 6 sessions if needed. Hence the tradeoff between probability of error and robustness to eavesdropping is not worth making. The best approach is to have the lowest probability of false positives, limited by the usability of the interface (usability introduces a tradeoff that is worth considering, because increased complexity in the mE space leads to exponentially decreasing usability).

With these two conclusions in mind, we propose the following guidelines for devising an interface resistant to eavesdropping:  1. Use a space of possible shared secrets as complex as the user can handle. The space should include at least 2210  possible shared secrets (tens of years of computing time for an exhaustive search).

2. Use a one-way mapping as simple as possible. This mapping does nothing to hide  information from the Attacker, so it can be designed only to maximize usability.

3. Use an interface that requires as much identifying information as possible in one session, limited by the user?s cognitive and speed abilities. The higher the amount of information exchanged, the lower the probability of false positives. The Attacker will receive more information in each captured session, but she will not be able to exhaustively search the space of shared secrets to make use of this information, if the space S is complex enough.

Even by following the guidelines above, it is unlikely that the resulting scheme will be truly user friendly. All of the schemes analyzed above have serious usability issues, because they make the authentication process more complex and significantly more time consuming than the traditional passwords; yet they all provide minimal gains in robustness. To transcend the low usability and the low security a paradigm shift is needed.

There are three ways to allow both robustness to attacks and more user friendly interfaces:  1. Invent a new type of interface that would allow the User to handle a much more complex space of shared secrets, without much more cognitive and memory effort than the current password scheme OR  2. Invent a new type of interface that would prevent the Attacker from using computing power to search the space of shared secrets.

Such schemes intended to prevent automated agents from impersonating human users have been used in other types of applications (see Completely Automated Public Turing Test to Tell Computers and Humans Apart, www.captcha.net/) OR  3. Design interfaces that combine the shared secret with specialized hardware or biometrics. The added computing power that the User can carry in hardware tokens or in out of band authentication devices is a way to counteract the extensive computing power the Attacker has at her disposal. This can include the use of one-time passwords (e.g., transmitted over a cell phone or generated on-the-fly in a smart token).

While we await innovations in 1 and 2 above, the  only feasible solution for now is to focus on combing shared secrets with specialized hardware (tokens, out of band devices or biometrics). As we mentioned before, this has the drawback of higher costs and more limited availability. Based on the theoretical      framework we developed in this paper, the approach of combining only shared secrets and standard hardware is simply unable to deliver both resistance to eavesdropping attacks and reasonable user friendliness at the same time.

6. Conclusion   We presented a theoretical framework that evaluates the robustness of protocols intended to be resistant to eavesdropping attacks. Such protocols can attempt to either not disclose information about the User?s shared secret, or to make it difficult to locate the shared secret, even after collecting sufficient information about it. After reviewing protocols reported in the literature, we conclude that even the most robust protocols (those to the point where usability is a concern) are only able to withstand ten observations before the attacker has sufficient information to uncover the shared secret.

On the other hand, authentication interfaces that use complex shared secrets could be secure even if the Attacker has captured all the needed information to determine the shared secret.  Having collected the required number of sessions, the Attacker will now be limited by computing power, if the space of shared secrets is complex enough. The drawback of complex shared secrets is the exponentially decreasing usability of the resulting interface. As such, interfaces that are both secure and usable can only be devised by combining shared secrets with other authentication technologies (biometrics or specialized hardware) in multiple factor authentication systems.

7. References  APWG. (2008). Phishing Activity Trends, January 2008. Retrieved June 11, 2008, from www.apwg.org/reports/apwg_report_jan_2008.pdf   Bedworth, M. and Allison, C. (2008).  Experiments with a Visual Probabilistic One-Time Password Authentication System.  Proc. SAM 2008.

Brostoff, S., & Sasse, M. (2000):  Are Passfaces more usable than passwords? A field trial investigation. . Proc. HCI 2000, pp. 405-424.

Springer Verlag.

Brostoff, S. and Sasse, M.  (2003): "Ten strikes and you're out": Increasing the number of login attempts can improve password usability. CHI 2003 Workshop on Human-Computer Interact. and Security Systems   Distributed.net. (2007).  Project RC5.  Retrieved Jan.

27, 2008, from http://www.distributed.net/rc5/   Hoanca, B. and Mock, K. (2007). Phishing Attacks and Countermeasures: Implications for Enterprise Information Security, in D. Khadraoui and F.

Herrmann (Eds.) Advances in Enterprise Information Technology Security. IGI, Hershey, PA   Hopper, N. and Blum, M.  (2000). A Secure Human- Computer Authentication Scheme, CMU Tech Report CMU-CS-00-139.

Kumar, M., Garfinkel, T., Boneh, D., and Winograd, T.  (2007). Reducing shoulder-surfing by using gaze- based password entry. Proc. SOUPS?07 vol. 229.

ACM Press, New York, NY, 13-19.

Matsumoto, T. (1996). Human-computer cryptography: An attempt, 3rd ACM CCCS, pp. 68- 75, New Delhi, March 1996.

Naor, M.  and Pinkas, B. (1997). Visual authentication and identification. In Proc. Advances in Cryptology, pp. 322?336.

Ross, B., Jackson, C., Miyake, N., Boneh, D. and Mitchell, J.C. (2005). Stronger Password Authentication Using Browser Extensions, in Proc 14th Usenix Security.

Roth, V., Richter, K., and Freidinger, R. (2004). A PIN-entry method resilient against shoulder surfing.

In Proceedings of the 11th ACM CCS?04,  ACM Press, New York, NY, 236-245.

Sobrado, L. and Birget, J.-C. (2005). Shoulder surfing resistant graphical passwords. Retrieved January 27, 2008, from http://clam.rutgers.edu/~birget/grPssw/srgp.pdf   Sobrado, L. and Birget, J.-C. (2002). Graphical passwords, The Rutgers Scholar, vol 4, 2002.

Retrieved January 25, 2008 at http://rutgersscholar.rutgers.edu/volume04/sobrbirg/s obrbirg.htm  Tan, D. S., Keyani, P., and Czerwinski, M. (2005).

Spy-resistant keyboard: more secure password entry on public touch screen displays. In Proc  19th Series, vol. 122, 1-10   Tari, F., Ozok, A. A., and Holden, S. H. (2006). A comparison of perceived and real shoulder-surfing risks between alphanumeric and graphical passwords.

Proc SOUPS '06, vol. 149. ACM Press, New York, NY, 56-66.

Wiedenbeck, S., Waters, J., Sobrado, L., and Birget, J. (2006). Design and evaluation of a shoulder- surfing resistant graphical password scheme. Proc.

AVI '06. ACM Press, New York, NY, 177-184.

