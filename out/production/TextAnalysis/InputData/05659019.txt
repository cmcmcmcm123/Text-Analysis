An Effective Algorithm Based on Association Graph  and Matrix for Mining Association Rules

Abstract?Association rule mining is a very important research topic in the field of data mining.  Discovering frequent itemsets is the key process in association rule mining. Traditional association rule algorithms adopt an iterative method, which requires very large calculations and a complicated transaction process. FAR (Feature Matrix Based Association Rules) algorithm solves this problem. However, FAR algorithm is not efficient when the value of the minimum support is small or the number of column of the feature matrix is very large. So we proposed a new algorithm (GMA) which based on association graph and matrix pruning to reduce the amount of candidate itemsets. Experimental results show that our algorithm is more efficient for different values of minimum support.

Keywords-medical image; data mining; association rule; relational calculus;   association graph

I.  INTRODUCTION Image mining is more than just an extension of data mining  to image domain but an interdisciplinary endeavor. This domain includes computer vision, image processing, image retrieval, machine learning, artificial intelligence, pattern recognition, database and data mining and so on. Although these areas mentioned above have a relatively mature theories and techniques, but the image mining is still in its infancy, and gradually attended by more and more people. The medical images contain a wealth of hidden useful information that can be exploited by physicians in making correct decision for a patient. However, how to extract this relevant valuable information and use it in medical diagnosis is difficult. Data mining technique is indispensable for researching medical images.

Association rule mining is a very important research topic in the data mining field. Finding association rules is typically done in two steps: discovering frequent itemsets and generating association rules. The second step is rather straightforward, and the first step dominates the processing time, so we focus this paper on the first step.  A number of efficient association rule mining algorithms have been proposed in the last few years.

Among these, the Apriori algorithm by Agrawal, R., Imielinski, T [1][2] has been very influential. Later, many scholars have improved and optimized the Apriori algorithm and have presented new Apriori-like algorithms, [3][4][5]. The Apriori- like algorithms consist of two major procedures: the join procedure and the prune procedure. These algorithms require a  huge calculation and a complicated transaction process during the two procedures. Therefore, the mining efficiency of the Apriori-like algorithms is not very good when transaction database is very large.

L.Jaba Sheela proposed the FAR algorithm [6] in 2009.

This algorithm transforms a transaction database into a Feature matrix stored in bits. Meanwhile it uses the Boolean vector ?relational calculus? method to discover frequent itemsets. This method uses the fast and simple ?and calculus? in the Feature matrix to replace the calculations and complicated transactions that deal with large number of itemsets. But there is a great shortcoming in FAR algorithm. The generating of candidate itemsets relies on the combination of column of feature matrix.

When the number of column of feature matrix is very large, FAR algorithm will cost much time to do useless calculus.

We proposed the GMA (association graph and matrix pruning algorithm) algorithm to solution this problem. GMA algorithm adopts both association graph [7] and matrix pruning to reduce the generation of candidate itemsets. It scans database only once and generates frequent itemsets by the ?and calculus??.

The remaining of the paper is organized as follows. Section ? introduces the pre-processing of medical images. Section ? gives the details of GMA algorithm, pseudo code and an example. Section ? gives the experiment results and analysis.

Section ? concludes our study.



II. MEDICAL IMAGE PREPROCESSING We use the CT images of brain as our research object. First,  we use the adaptive water immersion algorithm [8] to extract the ROI (interest of region) from the CT images of brain (as shown in Fig.1). Second, we need to extract relevant information as the features for each ROI, such as the symmetry, area, location of ROI. Last, we clustered these ROI using simple clustering algorithm. We assume that ROI can be clustered into five categories: A, B, C, D, E. Each CT image can be regarded as a combination of ROI. So the CT images of brain can be expressed into the form of Table?.

(a) (b)   (c) (d)  Figure 1.  Figure (a) and Figure (c) are the two original images of the brain, the dotted line of Figure (b) and Figure (d) are the ROI marked by using the adaptive water immersion algorithm.

TABLE I.  CT IMAGES IMPRESSION IN TRANSACTION DATABASE  Image ID Items IM1 BCD IM2 AC IM3 CDE IM4 BD IM5 ACE ? ?

III. ASSOCIATION GRAPH AND MATRIX ALGORITHM (GMA)  A. Basic Concept Definition 1: Association Rules In general, the I = (I1, I2, ..., Im) is the collection of items,  D is the transaction database, each transaction T is a subset of items(T? I). We say that the T contains the item set X, if X? T. Association rules is logic implication pattern in form of X?Y, in which, X?T, Y?T, and X?Y=?. If the database contains the s% of the X?Y transaction, then we say that association rules X?Y's support is s; If the database contains X transaction, and also s% transaction contains Y, we say that the confidence of association rules X?Y is c.

Definition 2: Association Graph.

For a transaction database D. Let L2 is the set of frequent-  2 itemsets. G is the association graph of D. G is a direct graph which each edge mapped to an itemset of L2. For each itemset {IiIj} of L2, where i<j, there is a direct edge and only one edge from vertex i to vertex j in G.

B. GMA algorithm This paper proposed the GMA algorithm to mine the  association rules from medical images. In this section, we will give the algorithm details. In general, the GMA algorithm consists of four phases as follows:  ? Transforming the medical image transaction database into the ROI matrix and storing it by bit.

? Generating the set of frequent-1 itemsets L1.

? Generating the set of frequent-2 itemsets, constructing the association graph.

? Generating the set of frequent-k itemsets Lk(k>2)  First, GMA algorithm transforms the medical image transaction database into the ROI matrix. Assume that the mined medical image transaction database is D, with D having m images and n categories of ROI. Let T={T1,T2,?,Tm} be the set of transactions and I={I1,I2,?,In}be  the  set of items. So the D can be mapped to a matrix Am*n relative to ROI which has m rows and n columns. Scanning the image transaction database D, if item Ij is in transaction Ti , where 1?j?n,1?i?m, the element value of Aij is ?1?, otherwise the value of Aij is ? 0?.

After transforming, GMA algorithm scans the ROI matrix, computes the supports of all items, and generates the set of frequent-1 itemsets L1 and prunes the matrix. The support number Ij.support of item Ij is the number of ?1? in the jth column of the ROI matrix Am*n. If Ij.support is not smaller than the minimum support, Ij.support?min_sup, Ij will be added to the set of frequent-1 itemsets L1. Otherwise the column of the jth will be deleted from the ROI matrix. For the ROI matrix, the counts of 1 in each row (denote as sum (Ai)) is computed. If sum(Ai) < 2, the ith row of the ROI matrix will be deleted.

Then the set of frequent-2 itemsets is generated to construct the association graph. For each itemset Ii of L1, a node is allocated for item Ii and Ii.link = NULL. For every combination of Ii and Ij (i<j) in L1, the ith and jth column of matrix are two vectors, the ?and? relational calculus Ii?Ij is done. If the sum of element values in the ?and? calculation result is not smaller than the minimum support number min_sup, sum(Ii?Ij) ? min_sup, a directed edge from item Ii to item Ij is constructed and add itemset {IiIj} to the set of frequent-2 itemset L2. So after generating the L2, we can get the association graph.

The most important phase in GMA algorithm is to generate the set of frequent-k itemsets Lk (k>2). In order to find the set of frequent-k (k>2) itemset, GMA algorithm firstly optimizes the matrix. Afterwards it generates the candidate-k itemsets using the information of association graph and matrix pruning.

At last it verifies whether the candidate-k itemset is a frequent- k itemset. The details of above procedures are described as follows.

Pruning the matrix means deleting some rows and columns from it. First, the column of the ROI matrix is pruned. This is described in detail as: Let I? be the set of all items in the frequent set Lk-1, where k>2. Compute all |Lk-1(j)| where j?I?, and delete the column of correspondence item j if |Lk-1(j)| is smaller than k-1. Second recompute the sum of the element values in each row in the ROI matrix. These rows of the ROI matrix whose sum of element values is smaller than k are deleted from this matrix.

In order to generate candidate-k itemsets, we need to consider all itemsets of Lk-1. However, if there is a column of matrix has been deleted by optimizing matrix, we will not consider the itemset of Lk-1 which contains the corresponding of item. Otherwise, for each itemset {I1, I2, ?, Ik-1} of Lk-1, finding edges that from vertex Ik-1 to other vertex in association graph. If there is an edge from vertex Ik-1 to vertex u, the itemset {I1, I2, ?, Ik-1, u} is a candidate-k itemset.

GMA algorithm does the ?and? relational calculus to verify whether the candidate-k itemset is a frequent-k itemset of Lk.

The ?and? relational calculus is for combination of k vectors        which corresponding to the candidate-k itemset {I1, I2, ?, Ik-1, u}. If the sum of element values in the ?and? calculation result is not smaller than the minimum support number min_sup, the k-itemsets corresponding to this combination of k-vectors are the frequent-k itemsets and are added to the set of frequent-k itemsets Lk. Then make k=k+1, do this again to find all frequent-k itemsets.

GMA algorithm is described as follows.

Input: An image transaction database D, the minimum support min_sup.

Output: The set of frequent itemsets Lk.

Transform transaction database into Matrix A;  \*frequent-1 itemsets generation phase *\ L1=?;  if the 1?s counts of the column of Aj (denote as sum(Aj)), sum(Aj) ? min_sup  L1=L1?{Ij}; else delete Aj from A.

for each row Am from A If sum(Am) < 2  delete the row of Am from A.

\* frequent-2 itemsets and association graph construction phase *\  if L1 ? ?  begin allocate a node for each item Ii of L1, and do  item[Ii].link = NULL;  then do produce every 2-vectors Ai, Aj(i?j) combination begin  B=Ai ? Aj for the 1?counts of vector B, if sum(B) ? min_sup do  begin allocate a node p; p.link = Item[Ii].link; p.Item = Item[Ij]; Item[Ii].link = p; L2 = L2 ?{Ii,Ij};  end end  end  \*Frequent ?K(K?3) itemsets generation phase *\ K = 3;  while (|Lk-1| ? k) do begin Lk=?;  OptMatrix( ); for all itemsets {I1, I2, ?, Ik-1}of Lk-1,  if {I1, I2, ?, Ik-1}?Lk-1&& {I1, I2, ?, Ik-1} not contain item Id which the corresponding column of matrix was deleted do begin  pointer =  Item[Ik-1].link; while (pointer ? NULL) do begin  u = pointer.Item; if sum (A1?A2???Ak-1?Au) ? min_sup then  Lk = Lk ? {I1, I2, ?, Ik-1,Iu} pointer = pointer.link;  end  end k= k+1;  end  \*OptMatrix, optmizing the matrix before mining the frequent- k (k>2) itemsets*\  for every column Aj of matrix, compute the |Lk-1(Aj)|, if |Lk-1(Aj)| < k-1;  Delete the column Aj of matrix; for every row of Am of matrix, compute the 1 counts of Am,  if sum(Am) < k; Delete the row Am of matrix;  C. Example for GMA We give a sample execution of the GMA algorithm in this  section. The transaction data of transaction database D are given in Table ?. The itemset of database is the categories of ROI. Assume the minimum support min_sup=2, the m=4 is the number of transactions. There are 5 categories of ROI in medical images transaction database D. Therefore, n = 5 is the number of items. We have given the execution of the GMA algorithm in the following.

TABLE II.  IMAGE TRANSACTION DATABASE  Image ID Itemset IM1 I1,I3,I4 IM2 I2,I3,I5 IM3 I1,I2,I3,I5 IM4 I2,I5  The transaction database D is transformed into the ROI matrix A4*5. We delete the column of the ROI matrix which counts of 1 is smaller than min_sup. Otherwise, add the corresponding item to the set of frequent-1 itemset L1. So we can obtain L1= {I1, I2, I3, I5}.

The fourth column of the matrix A4*5 is deleted because the support number of item I4 is smaller than the min_sup. We then compute the sum of the element values of each row in the matrix and delete all rows where the sum of the element values is smaller than 2.  So, the ROI matrix A4*4 is generated.

10010T 10111T 10110T 01101T IIIII         1010T 1111T 1110T 0101T IIII         A4*5                                                                   A4*4  Then, we mine the set of frequent-2 itemsets L2 and construct the association graph. For each item Ii of L1, allocate a node and make Ii.link=NULL. Next we compute the counts of 1 for all the combination of 2-vectors after doing the ?and? relational calculus. For example, for the combination of itemset {I1I3}, we know that itemset {I1I3} is a frequent-2 itemset of L2 and construct a direct edge from I1 to I3. So we can obtain the L2= {I1I3}, {I2I3}, {I2I5}, {I3I5}} and the association graph as shown in Fig. 2.

We need optimize the matrix before generating the set of frequent-k(k>2) itemset. Next we mine the set of frequent-3 itemset L3. Because we find that |L2(I1)| = 1< 2, we delete the        first column of matrix. Therefore, the itemset {I1I3} of L2 cannot be extended to candidate-3 itemsets. At last, the number of candidate-3 itemsets is only one, {I2I3I5}. We do ?and? relational calculus to verify the candidate-3 itemset and find it is a frequent-3 itemset. Then we make k=k+1 to mine the set of frequent-4 itemset L4. After computing we know |L3|=1 < 4, so we terminate the execution of the GMA algorithm.

Figure 2.  The association graph  In this example, it generates only one candidate-3 itemset both GMA algorithm and FRA algorithm, that is {I2I3I5}. It will generate two candidate-3 itemset {I1I3I5} and {I2I3I5} using DLG algorithm. However, candidate itemsets generated by GMA algorithm is less than FAR algorithm when the number of item is very large. GMA algorithm reduces the generating candidate itemsets by two aspects. One is the information of association graph; the other is the matrix optimizing.



IV. EXPERIMENT AND ANALYSIS In order to appraise the performance of the GMA  algorithm, we conducted an experiment using the DLG algorithm, the FAR algorithm and GMA algorithm. These algorithms were implemented in C and tested on Windows XP SP3 Operating system, Mobile Intel Pentium 4 1.89GHz CPU ?1024MB DDR RAM?VC++6.0 compiler platform. The test database T10I4D100K was generated   synthetically by an algorithm designed by the IBM Quest project. The number of items N is set to 1000; |D| is the number of transactions; |T| is the averages size of transactions, and |I| is the average size of the maximum frequent itemsets. Fig. 3 presents the experimental results for different values of minimum supports.

Figure 3.  The performance comparisons of DLG,FAR and GMA  Experiment shows that, we can get the same set of frequent- k itemset using three algorithms. However, the run_time of the algorithms execution is not same. DLG algorithm is better than FAR algorithm when the min_sup is small. FAR algorithm excels DLG algorithm as the value of min_sup increasing.

Because when the min_sup increase, the efficiency of matrix pruning is better. In general, GMA algorithm is outperform the two algorithms whatever the value of min_sup is.



V. CONCLUSION This paper proposed GMA algorithm by improving the  FAR algorithm. The GMA algorithm draws on the advantages both association graph and matrix pruning to reduce the candidate itemsets generation. In actually, it greatly reduces the candidate itemsets and has improved the efficiency of frequent itemset mining. Experiment shows that GMA algorithm can adapt and adjust better to the change of the value of min_sup.

