Polarity Identification of Sentiment Words based on Emoticons

Abstract?The orientation of sentiment words plays an impor- tant role in the sentiment analysis, but existing methods have difficulty in classifying the orientation of Chinese words, espe- cially for the newly emerged words in Internet. Most approaches are mining the association between sentiment words and seed words using the big corpora and manually labeled seed words with definite orientation. But less work has ever focused on the efficient seed words selection. As we observed, emoticons, which are widely used on social network because of the simplicity and visualization, are good indicators for sentiment orientation.

Thus this paper proposes the sentiment word model based on emoticons, which built orientation model of sentiment words with the orientation of emoticons, and train the model with the SVM classifier. Meanwhile, this work proposes a high efficient way to automatically classify the orientation of emoticons. Experiments show the precision rate of emoticon classification could reach 93.6%, and that of sentiment words classification could be 81.5%.

Keywords-sentiment analysis; emoticon; sentiment words; e- moticon based model; similarity; SVM

I. INTRODUCTION  Sentiment analysis[1] is used to analysis the users? opinions expressed in positive or negative comments. It has become one of the major research topics in the subjective informa- tion processing. Using sentiment analysis, users? opinions could be classified as having positive orientation or negative orientation[2], [3], which benefits to companies and govern- ment to know people?s emotion.

The fact that sentiment words are strong predictors of subjectivity[4] makes them be the important role to sentiment analysis. Sentiment words are words that convey positive or negative sentiment orientation, which could be adjective, adverb and idiom etc. The work[2], [3] category sentiment words as having positive orientation or negative orientation.

There are two main methods to classify the orientation of sentiment words: one is based on corpora[5], [6], [7] and the other is based on dictionary[2], [8], [9]. The one based on corpora is to compare the association of sentiment words with positive seed words and negative seed words, concretely the sentiment words are positive if the sentiment words are more associated with positive seed words, otherwise negative. But this method has a problem: it didn?t tell us the selection of seed words. Whereas, seed words selection is not only inevitable, but also a difficult task in sentiment classification, because different seed words usually yield results of diverse quality.

The other based on dictionary is to use the synonymous and  antonyms of seed sentiment words with definite orientation to predict the polarity of sentiment words. Particularly, the syn- onymous of positive seed words and the antonyms of negative seed words have positive orientation, while the synonymous of negative seed words and the antonyms of positive seed words have negative orientation. However this method could not be used to classify the newly emerged words which didn?t exist in the dictionary. The drawbacks encourage us to seek polarity assignment method which could deal with both the seed words selection problem and new merged words problem.

Emoticons are widely used in the social network, Weibo for instance, to express users? personal emotion, which are a set of dynamic images and are portrayed like people?s expression.

For example: ?Suzhou has an explosion! ?  Obviously, emoticons can convey users? positive and neg- ative sentiment clearly and visually, and the orientation is usually definite, which make them suitable to serve as an- notated seed opinion words. The work[10] also points out that emoticons can convey strong sentiment. They help the users to express their mood when post statuses. The work[11] uses the orientation of emoticons to represent the orientation of statuses. For example, ?Life is wonderful ? is considered as a positive status because ? ? is a positive emoticon while ?Fatso is terrible ? is considered as a negative status because ? ? is a negative emoticon.

As we observed, sentiment words appearing with emoticons have nearly the same orientation of emoticons. For example above, ?Wonderful? and ? ? are both positive, and ?terrible? and ? ? are both negative. The findings inspire us to use emoticons in guiding the recognition of polarities.

Our paper is based on the intuition that the orientation of sentiment words share the same orientation of emoticons when they co-occur. The differences between our work and the previous work are: 1. use the emoticons to build the model for sentiment words. 2. find an effective method to compute the orientation of emoticons. As indicated above, our approach is performed in three steps:  1) Classify the orientation of emotions into positive and negative classes.

2) Construct a dimension-reduced vector space model for emoticon-based word sentiment classification, and prin- ciple component extraction is used to reduce dimensions.

3) Train the classifier with SVM algorithm and optimized the parameters via 10-fold cross validation.

DOI 10.1109/CIS.2013.35    DOI 10.1109/CIS.2013.35    DOI 10.1109/CIS.2013.35    DOI 10.1109/CIS.2013.35    DOI 10.1109/CIS.2013.35    DOI 10.1109/CIS.2013.35

II. RELATED WORK Our work is related to orientation identification for senti-  ment words. The existing work for orientation classification of sentiment words could be categorized into two approaches: corpora-based approaches and dictionary-based approaches.

Our work falls into the category of corpora-based approaches.

The work[6] predicts orientation of sentiment words by detecting pairs of such words conjoined by conjunctions such as ?and?, ?or?, ?but?, in a large document set. The underlying intuition is that the orientation of conjoined sentiment words are subject to some linguistic constraints. Two sentiment words are usually the same orientation when they are conjoined by ?and? while the two sentiment words are the opposite orientation when they are conjoined by ?or?. The weakness of this method is that it relies on the conjunction relations and needs a large amount of manually tagged training data.

In the work[5], the orientation of a sentiment word is calculated as the point mutual information between the given word and the set of manually labelled positive words, minus the point mutual information between the given word and the set of manually labelled negative words. The mutual information is estimated by issuing queries to a search engine and noting the number of hits. If the result is a positive value, then the sentiment word has the positive orientation.

If the result is a negative value, then the sentiment word has the negative orientation. The underlying intuition is that the positive word is more likely to associate with positive words, otherwise, the negative word is more likely to associate with negative words. The weakness of this method is that it is hard to select the proper positive and negative seed words in Chinese. And also their work requires additional access to the Web Search Engine, which is time consuming.

The work[2], [9] takes advantage of WordNet to predict the orientations of sentiment words. The underlying intuition is that in WordNet, the synonymous words have the same orientation, while the antonymous words have the opposite orientations. In the work[8], a words? network is constructed by connecting pairs of synonymous words in WordNet. The orientation of a word is decided by its shortest path to the positive sentiment seed words and the negative sentiment seed words. The work[12] determines the orientation of words based on glosses in an online dictionary. The classifier is trained on glosses of an unknown word to categorize the sentiment words as positive or negative. The weakness of this method is that for dictionary-based methods, they are unable to classify the orientation of sentiment words that are not in the dictionary, for instance, the newly cyberwords.



III. EMOTICON-BASED SENTIMENT WORD MODEL Fig. 1 gives the framework to classify the orientation of  sentiment words. Recall that the task of classifying senti- ment words? orientation is telling whether the orientation of sentiment words is positive or negative, this paper performs this task in three main steps: 1. classifying the orientation of emoticons; 2. constructing the vector space model for sentiment words; 3. training the model with the SVM.

Fig. 1. Proposed Words? Classification Approach by Using Emoticons  A. Classifying the Orientation of Emoticons  To use emoticons in guiding the word sentiment classifica- tion, above all we need to obtain a set of annotated emoticons with known semantic orientation. In this section, this prepro- cess work is done with small proportion of manually labeling and large part of automatic annotation. Before handling the classification of emoticons, we define some symbols first:  Definition 3.1: EOC represents the set of emoticons con- tained in the corpora, and ne is the size of the set EOC.Then EOC = {e1, e2, e3, ? ? ? , ene}, where e1, e2, e3, ? ? ? , ene rep- resents the emoticon.

Definition 3.2: n(ei) represents the count of the emoticon ei occurring in the corpora, i = 1, 2, ? ? ? , ne.

Definition 3.3: n(ei, ej) represents the count of co- occurrence between emoticon ei and ej in the corpora, i, j = 1, 2, ? ? ? , ne. Especially, n(ei, ei) = n(ei)  Definition 3.4: Ve represents the co-occurrence vector of the emoticon e with each emoticon in EOC, then Ve is:  Ve = [n(e, e1), n(e, e2), ? ? ? , n(e, ene)] (1) where e1, e2, ? ? ? , ene ? EOC  Definition 3.5: ind-aff(ei) represents the orientation of emoticon ei. That is:  ind-aff(ei) =  { 1 ei is positive ?1 ei is negative , ei ? EOC (2)  This paper uses a method of both manually tagging and au- tomatically annotation to classify the orientation of emoticons:  1. Manually tagging: The emoticons whose orientation are obvious are easy to label, so we can label them manually.

For the emoticons whose orientation are not that obvious, the automatically annotation is used. We tag positive emoticons with 1 and negative ones with -1, resulting in 116 emoticons.

2. Automatically annotation: For the emoticons whose ori- entation are not obvious to label, we use an unsupervised learning method to label them. We automatically annotated 524 emoticons in this phase.

The intuition of automatically annotation of the emoticon orientation is: if different emoticons appear in the same status, it is the usual case that the emoticons express the same orientation, because the attitude of writers within a short message is usually stable. Suppose the set of emoticons that manually tagged as positive is PE, and the set of negative emoticons is NE. The orientation estimation measure of an unlabelled emoticon could be formulated as (3):  ind-aff(e) = ?  pe?PE S(e, pe)? ind-aff(pe)+  ? ne?NE  S(e, ne)? ind-aff(ne) (3)  ind-aff(e) calculates the orientation difference between e and seed emoticons. S(e1, e2) means the similarity of two emoticons e1 and e2, as formulated in (4), which measures the weight of each seed emoticons in predicting the orientation of a new emoticon. Here, Ve follows the definition in (1).

S(e1, e2) = cos(Ve1 ,Ve2)  = Ve1 ? Ve2  ||Ve1 || ? ||Ve2 || (4)  Experiments in Section IV show that this method can clas- sify the orientation of emoticons with high accuracy. With this method, we can classify the set EOC into positive emoticons EOCp and negative emoticons EOCn, which will be used to build sentiment word model.

B. Construct the Model for Sentiment Words  After classifying the orientation of emoticons, we describe the task of constructing the model for sentiment words. We propose an emoticon-based sentiment word model ECWM. In this model, the orientation of sentiment word is represented by the co-occurrence information of sentiment words with emoticons and the orientation of emoticons. We describe some definitions first:  Definition 3.6: n(sword, ej) means the sentiment word sword and the emoticon ej are co-occurred in n(sword, ej) statuses, j = 1, 2, ? ? ? , ne.

Definition 3.7: Vsword represents the feature vector of the sentiment word sword. The jth vector component of Vsword is the association between the sentiment word and the emoti- con ej , whose value is f(sword, ej), j = 1, 2, ? ? ? , ne, then:  Vsword = [f(sword, e1), ? ? ? , f(sword, ene)] (5) And f(sword, ej) is computed as (6)  f(sword, ej) = n(sword, ej)? ind aff(ej) (6)  In this model, two problems are solved: selecting the features and extracting Vsword?s principal components.

1) Selecting the Features: We use emoticons as features, because their clear and definite orientation make them more appropriate to serve as features than ordinary words. Moreover, its broad usage on the Internet could contribute largely to the coverage of messages. Hence, emoticons are used to construct VSM model of sentiment words.

2) Extracting the Principal Components: There are hun- dreds of thousands of emoticons in a large corpora, which makes the vector Vsword a high dimensional vector. Hence, there is a need to extract the principal components. In fact, some emoticons appear rarely while some are redundant, which increases the computation workload and decrease the accuracy of the model.

Singular value decomposition(SVD) is used to extract the principal components of the model[13]. The method can be depicted as the following four steps.

Firstly, suppose the set of sentiment words is SW , the size of SW is n(SW ), that is SW = {sword1, ? ? ? , swordnw}, and sword1, ? ? ? , swordnw represents the sentiment word.

The feature matrix is constructed for the set SW , which we called A:  A =  ? ?  Vsword1 ...

Vswordnw  ? ? (7)  Secondly, SVD is applied to A, to decompose A into a product of three matrices as follows:  A = U ??? V T (8) where U is nw?nw column orthogonal form, ? is a nw?ne  rectangular diagonal matrix with nonnegative real numbers on the diagonal, and V is ne?ne column orthogonal form. The diagonal entry ?i,i of ? is the singular value of matrix A.

Thirdly, let ?k be the diagonal matrix formed from the top k singular values, where k < ne, and the top k singular values are ?1,1, ?2,2, ? ? ? , ?k,k. Then we define r to be:  r =  ?k i=1  ?i,i?ne j=1  ?j,j (9)  What r means is the rate of information that the top k singular values contain. We make r equal to 99% to let the top k singular values depict 99% information of the original matrix.

Finally, when selecting the top k singular values to form the diagonal matrix ?k, and let Uk and Vk be the matrices produced by selecting the corresponding columns from U and V , then extracting the k principal components from original matrix could be done by following:  Bk = A? Vk (10)  Bk is a nw ? k matrix, and the information rate it contains is r. Remember, the feature num is k, which is much smaller than that of original feature num ne.

C. Train the Vector Space Model of Sentiment Words  The last step is to train the model using the machine learning method. In this paper, SVM is chosen, which is widely used in machine learning and demonstrated effective. We also chose the radial basis function(RBF) kernel as the kernel function.

For training the model, LibSVM[14] is used. LibSVM is an efficient SVM implements package for Java language. There are two parameters we should set manually, and 10-fold cross validation is used to find the best parameters.



IV. EXPERIMENTS AND DISCUSSION  A. Build the Corpora  The Weibo statuses were crawled by Xiaoxin crawler. There are totally 12,543,164 statuses from date time August the 18th, 2009 to December the 27th, 2011. To make sure the quality of statuses, improper statuses are filtered out, including emoticon- free statuses and too short statues(less than 4 words), resulting in 3,921,794 statuses and 640 different kinds of emoticons. In addition, we indexed all filtered statuses to improve efficiency of the approach using Lucene 4.0(http://lucene.apache.org/)  B. The Accuracy of Orientation Classification of Emoticons  To validate accuracy of orientation classification of emoti- cons, the manually labeled emoticons set [11] is used, which contains 121 emoticons. In the set, emoticons are classified into four different sentiment categories, including ?angry?, ?disgusting?, ?joyful? and ?sadness?. The sentiment categories in our paper are positive and negative. So the mapping is built: ?angry?, ?disgusting?, ?sadness? are classified as negative while ?joyful? is classified as positive. After reclassifying, pos- itive emoticons set ET p contains 58 emoticons and negative emoticons set ETn contains 63 emoticons.

The method of validating for (3) is following. The accuracy is used to measure the performance of the algorithm, which is defined as (11)  accuracy = #(num of emoticons classified correctly)  #(num of total tagged emoticons) (11)  To avoid the uneven distribution of emoticons in the corpora, we use different training emoticons and testing emoticons to make multiple trials, and synthesis the average accuracy rate of these trials as the final accuracy rate. We randomly select k positive emoticons ET pk and k negative emoticons ET  n k as the  training set, with remaining emoticons ETrest as the testing set. Here, we run p = 100 times for each separate k. Defining the accuracy rate of each trial for each value k as fki just as (11) says, and we use the average accuracy rate to measure the p trials, which is calculated as (12):  avgk =  ?p i=1 fki p  (12)  Fig.2 shows the average accuracy of the algorithm. To measure the average accuracy, we use different number of seed emoticons. Here, k is in the range [5, 55] with step 5.

From Fig.2, we can see that the average accuracy is high.

When we use 5 seed emoticons, the average accuracy rate is 86.2%, and the average accuracy rate can reach to 90.9% when we use 10 seed emoticons. Moreover, when we use more seed emoticons, the average accuracy is enlarged consequently.

C. Experiment of Classifying Sentiment Words? Orientation  To validate the accuracy of sentiment words? orientation classification, the labeled sentiment words? ontology[15] from the Dalian University of Technology Information Retrieval laboratory are used(http://ir.dlut.edu.cn/). There are 27,466 sentiment words in this ontology. These sentiment words are  Fig. 2. The Average Accuracy with the Number of Seed Emoticons  tagged with three features: the sentiment strength, orientation and part-of-speech.

But not all the words are proper for the experiments. We filter the ontology to get 1500 words. The filter rules are:  1. Filter the noun and verb. Intuitively, most sentiment words are adjective, adverb and prepositional phrase. While lots of the noun and verb sentiment words in the ontology are not exactly sentiment words. So we filter them out.

2. Filter the words with weak sentiment strength and am- biguous meanings. Sentiment words with definitely orientation are considered to be more proper than those weak sentiment ones. So we just keep the sentiment words with sentiment strength value equal to or larger than 5.

3. Filter the words that are not in the corpora. Most words in the ontology are too official to use in the Internet language.

So we only keep the words that are in our crawled corpora.

Suppose Ttest is the set of 1500 sentiment words. All the sentiment words in Ttest are labeled as either positive or negative. Suppose the correctly classified words set is Tcorrect, then the accuracy of this approach fw is Tcorrect/Ttest.

To validate the effectiveness of the algorithm, two baselines are used:  1) PMI+W[5]: PMI+W is short for PMI with word seeds.

This approach is an effective approach to classify the orienta- tion of sentiment words, which uses the point mutual informa- tion to compute the association of two sentiment words. It first tags two seed sets: one set is Pw which contains the positive seed sentiment words, and the other set is Nw which contains the negative seed sentiment words. The orientation of a given word is calculated from the strength of its association with the positive seed words, minus the strength of its association with the negative seed words, just as (13) shows:  PMI(sword) = ? p?Pw  A(sword, p)? ?  n?Nw A(sword, n) (13)  A(word1, word2) is the measure of association between word1 and word2, which is the point mutual information of two words. In [5], 7 positive words and 7 negative words are selected as the seed words. But the author didn?t tell how to select the 14 seed words. The rules we selected are: 1. seed words should appear frequently in the corpora. 2. seed words should have definitely orientation. The selected seed words are listing as Table I.

TABLE I SEED SENTIMENT WORDS USED IN PMI+W  Positive seeds Negative seeds Word n(Word) Word n(word)  ??(joyful) 113,991 ??(poor) 82,401  ??(happy) 83,250 ??(wronged) 36,677  ??(happiness) 54,095 ??(contempt) 27,627  ??(wonderful) 27,894 ??(despair) 25,027  ??(beautiful) 23,362 ??(sad) 14,089  ??(handsome) 20,450 ??(disgusting) 9,629  ??(fine) 18,128 ??(catty) 9,400  TABLE II SEED EMOTICONS USED IN PMI+E  Positive seeds Negative seeds Emoticon n(Emoticon) Emoticon n(Emoticon)  515,559 272,282  271,247 126,016  262,008 92,197  234,699 85,064  162,469 82,401  151,573 72,998  145,506 69,151  TABLE III THE ACCURACY OF DIFFERENT ALGORITHMS  Approaches Accuracy Learning type Feature number PMI+W 68.5% unsupervised 14 words  PMI+E 78.7% unsupervised 14 emoticons  ECWM 81.5% supervised 80  2) PMI+E: PMI+E is short for PMI with emoticon seeds.

It?s similar with PMI+W. But what we select emoticons as the seeds. That means, the orientation of a given word is calculated from the strength of its association with a set of positive emoticons, minus the strength of its association with a set of negative emoticons. The rules that we select the seed emoticons are the same as the approach of the PMI+W. The seed emoticons are listing as Table II.

The overall result is showed as Table III. For the result of ECWM, the feature number of original feature vector Vsword is 640. After the reduction of the features, the feature number of principal components of Vsword is 80, which is much less than the original features. What means that the original vector does have lots of redundant features.

Table III shows that emoticons are better features. The accuracy of PMI+W is just 68.5%, compared to that of PMI+E, which is 10.2% higher, and ECWM is 2.8% higher than that of PMI+E. The seeds play the key role. In fact, the selection of seeds is the process of human intervention, and sentiment words are more widely used in terms of usage. We  have a large range to select the seed sentiment words, but the range of emoticons are much more limited. So the error that selection of emoticons brings is smaller.



V. CONCLUSION This work aims to classify the polarity of sentiment words.

The way we did it is using the emoticons. First we proposed an efficient approach to classify the polarity of emoticons. Based on the polarity of the emoticons, as well as the association between the sentiment word and emoticons, we build the sentiment word?s model through the emoticons, which is called ECWM. Experimental results demonstrate that ECWM was a good model to represent the orientation of sentiment words.

For the future work, more data would be crawled to cap- ture the rich co-occurrence between emoticons and sentiment words. Moreover, the polarity of sentiment words would be used to classify the orientation of statuses in Weibo.

