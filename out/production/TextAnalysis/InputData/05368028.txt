Searching and Clustering on Social Tagging Sites

Abstract.  Social Tagging Site has increasingly become a main avenue for people to share resources online. Users can use simple tools to publish everything from bookmarks to video clips on those sites. However, effective querying of resources in such sites is still a challenging question in industry and academic research. This paper reports a novel algorithm of presenting the web resources query result on the social tagging sites. It adopts a two step clustering approach to organize and rank resources based on their relative similarities with each other. Initial term similarities are computed using user and tag information of the resource. The query results are then organized as a group of concepts represented by a few semantically related terms.  The resources that are related with each concept are rank with respect to the concept. In addition, concepts are also ranked by representing terms and the number of resources associated.

Keywords  Social Tagging, Association Rule Mining, Clustering

I. INTRODUCTION  The Web 2.0 era brings along various tools that enable Internet users to publish all sorts of objects on the Web. It is very easy for any user with Internet connection to publish photos, videos and other non textual object on the web with the help of such tools. Once a photo or video is published, users can make it either private or public. Public resources rely on description text to make them retrievable by other users.  Instead of providing a lengthy description, many users choose to tag their resource with a few keywords. The keywords based tagging activity has gained popularity in websites like flickr, citeULike, youTube and many other sites.

The key feature contributing to its popularity is the uncontrolled vocabulary.  Users may choose any number of terms from any language to describe the object that becomes public or private resource on the web. This feature, on the one hand, encourages people to upload and tag their objects; on the other hand, it presents lots of new challenges for the searching services. Such challenges cannot be addressed by traditional information retrieval techniques for the following reasons.  First, the query target is usually a non-textual web resource.  This is different from a textual webpage containing complete or partial information of a particular query term.

Second, the textual information about the target is highly condensed and limited to, in many cases, only a few terms.

Third, there is no explicit relationship such as hyperlink between resources that can be used for ranking purpose. The  traditional relevance/popularity ranking algorithms do not work very well under these three constraints. Currently, many websites provide alternative ranking mechanisms such as rank by date or rank by subjective measures like interestedness used in flickr. This paper presents a novel way of organizing the object search result on social tagging sites. It adopts a two step clustering approach to group and rank resources based on their relative similarities with each other. The query results are associated with a group of concepts represented by a few semantically related terms.  Resources are ranked by their similarities with respect to those concepts.  In particular, the paper makes the following contributions:  It uses the association rule mining algorithm to obtain an initial similarity measure between popular terms appearing in a result set. The association rule based measure can effectively remove noises generated during the tagging process. Typical noises include relationship generated by single user or non- standard terms used by single user. The set of rules is used to establish a relation graph between terms.

It proposes a two step clustering algorithm to associate resources with related concepts. The algorithm first clusters the terms into semantically related concepts based on the initial similarity measures and term relation graph. It then filters resources into groups associated with particular concepts. Resources are also ranked inside each group.

It proposes new ways to measure resource-cluster similarity, to rank resources in a cluster and to rank clusters in a query result set.

The rest of the paper is organized as follows. Section 2 describes several important related works. Section 3 describes the algorithm of obtaining initial similarity and the design of cluster based measure and the clustering algorithms.  We show the experiments and results in section 4. Section 5 concludes the paper.



II. RELATED WORK  Fonseca et al. [5] uses query log to build concept based on association rule mining technique. Each query is mapped to an item and a set of consecutive queries issued by a same user in a small predefined time frame is mapped to a transaction.

After applying standard association rule mining algorithm, a directed graph is built with each node representing a query and each edge representing a rule between a pair of queries.

Concepts are identified as the minimal cycles in the graph.

DOI 10.1109/SKG.2009.72    DOI 10.1109/SKG.2009.72           Dong et al. [4] presents an association rule/clustering based approach to find concepts in a set of web services. The document is the parameter names of input/output functions of web service operations, such as ?LocalTimeByZipCodeResult?. The terms correspond to words in the parameter names, such as ?Time? and ?Zip?. The problem can be seen as finding term relations in very short documents with no grammatical constraints, which is similar to folksonomy. It adopts the simple ?occurrences as support? approach.

Nie et. Al [6] proposes an object ranking model PopRank to extend the popular PageRank algorithm to object level.

PopRank focuses on building relation between various types of objects and estimating the popularity propagation factor from a predefined partial ranking list. The algorithm is implemented in an academic paper search engine Libra.

PopRank deals with a complex graph consisting of various objects and relationship. Such complexity adds valuable information for computing ranks. The need of a predefined partial ranking list makes PopRank less flexible and reduces its general applicability. On the contrary, our algorithm treats objects of various types as retrievable resources. The minimal requirement is that each resource should have some tags as description. Our algorithm tries to rank resources by examining shared tags among them. It does not require a predefined initial ranking. It can be applied to rank objects of different types as long as they are described by tags.



III. DESIGN  Our ranking algorithm uses a two step approach. We first derive concepts from tags appearing in the result space. Each concept is labeled by its highest ranking tags. All resources are then associated with the concepts and ranked in each cluster. Although tag clusters are mutually exclusive, one resource may appear in multiple clusters. Clusters are also ranked by its internal cohesion and the number of resources it represents.



I. Tag Clustering  In any social tagging system, a tag is defined as a word or a phrase used to describe a uniquely addressed resource on the Internet. The resource could be a webpage, an academic paper, a photo or a video clip. A resource may have more than one tag, for instance: Australian Open and Melbourne , to describe it. Such co-occurrence is an important indicator of possible semantic relationship between tags ([7,11]). Many social tagging sites provide tag based query engine to facilitate resource query. The simplest form of such engine would return all resources containing the query term.

As co-occurrence may happen for various reasons, it is a necessary but not sufficient condition on the existence of semantic relation. Our observation made on several sites shows that a pair of co-occurring tags usually has one of the following five relations:  Inclusive relationship. For example, Australia and Sydney  Expressing one concept in conjunction. For example, Social and Network.

Synonyms, hypernyms and hyponyms. For example, cat and gatto (the Italian word for cat);  Expressing different aspects of the resource. For example, AustralianOpen and 2009.

Non-relevant. There are tags assigned purely for personal use such as toread, or mystuff. These tags almost occur uniformly in the tag space; they may co-occur with any other tags.

We consider the first three as valid and strong relations.

The fourth one may be valid but weak relation in certain cases. This is especially true when all tags involved are popular ones. For instance, party and 2006 may happen to co- occur a lot even though the relation is quite weak  A good similarity measure stronger than co-occurrence should be able to identify and filter out the weak and non- relevant relation. We propose using association rule to compute the relation between a tag pair. Each resource is considered as a transaction and tags used to describe the resource are considered as items. Each association rule has two numbers: support and confidence, to describe the popularity and strength of a particular rule. Following the traditional asocial rule mining approach[1], we can count support as the number of co-occurrence in the whole transaction space. This equals the number of resources having all the tags in a rule. However, in systems like Flickr or Youtube, it is possible and quite often for a user to use a similar set of tags over and over again to describe a collection of pictures or videos. There is high possibility for any pair in that set to become a rule with co-occurrence support measure.

The rule set may include the fourth and fifth relations we described above. We propose using user count instead to measure the support of tag pairs.  Any user may assign a pair of tags multiple times to different resources. The support of that pair is increased by 1 in that case. Confidence computed from user count support can offset the effect of general tags that may be associated with all sorts of other tags. It also provides a normalized measure on the strength of each rule.

We use confidence to measure the strength of tag relation.

Table 1 Comparing two approaches on support  Candidate Rule Co-occurrence  User Count Supp. Conf. Supp. Conf.

WashingtonDC panthera 216 0.6 1 0.02  Bangkok  2004 80 0.75 1 0.06 Taronga  zoo 34 0.92 26 0.9 Deutschland  Germany 28 0.97 11 0.92   Table 1 shows the outcome of the two approaches on a  flickr data set. The co-occurrence approach considers all tag pairs in the table as highly relevant. However, the first two pairs are weakly related. The high co-occurrence numbers are contributed by one user using the pair on hundreds of pictures.

The user count approach with appropriate thresholds can           easily filter these noises out. Spam and non-relevant tags (such as toread, mystuff) can also be filtered out.

Tags and their relations is then expressed in a graph. It is straight forward to generate the tag relation graph from a set of association rules. The tag relation graph ),,( WENG consists of nodes N, directed edges E and a weight matrix W. Each node of the graph corresponds to a tag in an association rule.

If we have two tags p and q, and an association rule qp , there is an edge from node p to node q in the graph. The weight of the edge Wpq  equals the confidence of the association rule.

We take the agglomerative hierarchical clustering approach to organize tags (nodes) into cohesive clusters. The algorithm starts with |N| clusters each containing an individual node. List 1 shows an algorithm CutAvg for tag clustering. It runs iteratively by merging the two clusters that are closest to each other in each iteration until the stop condition is met.

Hierarchical clustering algorithms may use different stop conditions. We adopt the simple and straightforward similarity threshold approach, that is, the algorithm will stop when the highest similarity computed between clusters in a current iteration is lower than a predefined threshold. To achieve this, we need to measure and compute the similarity of clusters.

List 1 Tag Graph Clustering Algorithm  method CutAvg Collection clusters = each node in its own cluster;  Cluster cx,cy; //the two clusters to be merged at a stage maxSim = 0;  //highest similarity so far for each cluster pair {c1, c2} in clusters do  double similarity = calSimilarity(c1, c2); if (similarity > maxSim) maxSim = similarity; cx = c1; cy = c2; end if  end for if  maxSim >= simThreshold  merge (cx, cy);  //merge the two clusters end if  end method  The similarity between two nodes p and q equals Wpq in the  tag graph. Similarity between clusters is computed based on node similarity. Our aim is to develop a non-local measure for cluster similarity. In graph theory, all edges across two subcomponents (clusters) are called ?cut edges?, where ?cut? refers to the partition of these two clusters. Previous work on spectral graph partition [3] suggests that the optimal result occur where the cut of two clusters is minimal, and the cohesion within each cluster is maximized. Intuitively, we may define the cut size of two possible clusters as the sum of weights of all cut edges between them.  At each iteration, the algorithm could always merge the two clusters with the maximum cut size. Cut size defined as such is a local measure. It only includes the edges across two clusters in the computation. It does not consider the size of each cluster or  other edges in the clusters.  To make the measure non-local, we propose to use the size of clusters to normalize the cut between them. The similarity of cluster A and B is thus defined as:  || ),(  || ),(),(  B BAcut  A BAcutBASim   (1)     where |A| represents the number of nodes in cluster A and cut(A,B) is the cut size of cluster A and B defined as:  BvAu uvWBAcut  ,  ),(   (2)

II. Parameter Setting  In our algorithm, support and confidence thresholds are used to control the number of tags and relations in the tag graph. Some initial experiment results indicate that the major clusters and popular tags are always preserved for any threshold values in a reasonable range. We run a test on apple query data with support varying from 5 to 20 and confidence varying from 0.5 to 0.8. The result shows that high support threshold only misses a few less frequent tags and concepts; the clustering result is otherwise quite similar with low support threshold case. High confidence value has a slightly bigger impact as it would ?cut? the tag relation graph into many small pieces. The values we choose for the following experiment are: 5 (users) as minimum support threshold, and 0.5 as minimum confidence threshold.

Similarity threshold as the guard for stop condition is another important parameter that may affect the final results.

Similarity threshold is bounded by confidence threshold.

Similarity value between any two nodes is in a range between [min_conf., 2]. The CutAvg similarity value obtained by formula (1) is in the range [0, 2].

Formula (1) ensures that for any one node cluster, there will be another cluster with whom the similarity is larger than the confidence threshold. We use a simple example to illustrate this feature.  Suppose we are at an iteration with clusters {a}, {b,c,d} and {e,f}. The definition of the tag graph guarantees that each node in the graph would have at least an edge with another node. Suppose a has an edge connecting with b.  The similarity between {a} and {b,c,d} would be  3/baba ConfConf . Regardless of the actual values of the confidence of rule ba , the calculated cluster similarity would always be greater than the confidence threshold. If the similarity threshold is set to equal the confidence threshold, single node cluster {a} would eventually be merged with {b,c,d} to become a big cluster. Error! Reference source not found. clearly illustrates such feature in some example datasets from queries tiger, apple, bridge and Australia. The number of clusters grows rapidly when similarity threshold is greater than 0.5 (the confidence threshold). The observed increase consists largely of single node clusters. On the other side of 0.5 the number of clusters grows much slower with the increase of similarity threshold. This ?knee? or turning point           of a curve is also considered as good choice of number of clusters 6. Hence we take the confidence threshold as similarity bound.

Figure 1. Effects of Similarity Threshold

III. Associating Resources with Concepts  The tag clusters obtained can be viewed as semantically related concepts expressed as a set of tags. The next step is to associate the resources described by a set of tags in the result set with those concepts. There are two simple and intuitive observations we follow to determine the membership and rank of a resource with respect to concepts. They are:  First, any resource whose tags overlap with a concept?s tag set should be considered as a member of that concept.

Second, the strength of the relationship between a resource and a tag cluster concept depends on the portion of tags they share.

Table 2 Simple Example Data, Association Rules and Clusters  Resource Tags r1 t1,t2,t3 r2 t3,t4,t5 r3 t5,t6,t7 r4 t1,t2,t4 r5 t1,t2,t5 r6 t6,t7 r7 t1,t3 r8 t5,t6 2.a  Resources and Tags       The first observation deals with the membership problem  while the second one deals with the rank of resources. Both are quite intuitive and easy to understand. Table 2 shows a simple example of a set of resources and their tags. We assume each resource belongs to a different user and that user assigns all tags for a resource. Under this assumption, the user count is the same as co-occurrence count. Table 2.a shows the resources and their tags. Table 2.b shows rules generated with  support threshold set to 2 and confidence threshold set to 0.5.

Table 2.c shows concept obtained using the clustering techniques described in section 3.2. It also shows the important tags in each cluster. We first examine a few typical pairs of resources where the concept membership and the rank are obvious. One good exam is the pair r1 and r3. They are fully represented by concept C1 and C2 respectively.

Moreover, r1?s tags do not overlap with tags of all other concepts at all. r3 has the same feature.  We can define a similarity function ),( CrSim between a resource and a concept to calculate a similarity value in the range [0,1].

Ideally we should have  1),( 11 CrSim ; 0),( 21 CrSim ; 0),( 12 CrSim  and 1),( 22 CrSim  The second example contains the pair r1 and r7, both of which are clearly members of C1. However, r7 only contains a subset of the C1?s tags. Intuitively, we should have  ),(),( 1711 CrSimCrSim .  A less straight forward case is the pair  r4 and r7, each of which has two tags overlapping with the tags of concept C1.  While r7 has all its tags included in C1 tag set, r4 only has two third of them in it. The similarity measure should give ),(),( 7417 CrSimCrSim .

Based on the above observation of pairs and orderings, we develop a naive object-cluster similarity metric as:  || ||  || ||),(  C Cr  r CrCrSim   (3)     Where || Cr  represents the number of overlapping tags between resource r and concept C; |r| represents the number of tags resource r has and |C| represents the number of tags a concept C has. For the above example, the simple measure will compute  3/2),(;9/4),(;1),( 171411 CrSimCrSimCrSim which satisfies our observation. Several trial experiments with small data sets show that the simple metric performs well for concepts with only a few tags. However, for concepts containing a large number of tags, it is likely that most resources overlap with a small portion of the concept tags. In that case, the na?ve similarity measure cannot avoid certain randomness in ordering. Several resources may end up with a same similarity measure even if they cover different portion of the concept tag set. For instance, in concept C2, resource r6 and r8 would have the same similarity value as 2/3. Without other evidence, r6 and r8 can only be ranked randomly. Such randomness exists because the naive similarity metric treats all tags belonging to a concept as equally representing the concept. Again, it is not a big issue in concepts with a few tags. Yet it is ineffective for general concepts with large number of tags. A more refined measure will first calculate the concept-tag weight and adjust the overlapping portion with  Rule Confidence t1  t2 0.75 t2  t1 1 t1  t3 0.5 t3  t1 0.67 t5  t6 0.5 t6  t5 0.67 t6  t7 0.67 t7  t6 1  2.b  Association rules  Concept Tags C1 t1,t2,t3 C2 t5,t6,t7  2.c Clusters        0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Similarity Threshod  N um  be r o  f C lu  st er  s  apple tiger australia bridge           the respective weightings of tags. This ensures that a resource overlapping with important tags of a concept be ranked higher than a resource overlapping with less important ones. The concept-tag weight denoted as w(t,C) is defined as:  CtifCoupInvcohesion Ctif  Ctweight .*  ),(     (4)  Cv vtWcohesion ,   (5)  Cu utW  CoupInv ,  2.     (6) The cohesion measures the strength of connectivity of a tag  with other tags in the same concept, the Inv.Coup (inverse coupling) measures the strength of connectivity of a tag with other tags not in the same concept. This tag-concept similarity measure is developed based on the classic TFIDF measure in IR field[8]. A tag with lots of internal links should rank higher in this concept than another tag with only a few internal links but many external ones. With the concept-tag weight information, the similarity between a resource and a concept is adjusted to:  rtCt  Crt  rtwCtw  Ctw CrSim  ),(),(  )),(( ),(   )(    (7)     The resource-concept similarity value is also in the range [0,1].   w(t,r) denotes the weight of tags in each resource. It is determined by its weight in the concept it joins. If a tag does not belong to any cluster, its resource-tag weight will be zero.

Ct CtCtw  rtw |0  |),( ),(   (8)  Once resources are associated and ranked in concepts, it is worthwhile to rank the concepts itself. Intuitively, concepts representing large number of resources in the result set should have higher rank. However, we should also evaluate the quality of such big concept. Concepts are ranked by its internal cohesion and the number of resources it represents.

Average tag weight in a concept is a simple way of measuring the quality of internal cohesion of a concept. Formally the ConceptRank is defined as:    N N  C  Ctw R cCtc ||  ),(   (9)  where N denotes the total number of resources in the result set and NC denotes the number of resources in concept C. The first part of formula (9) computes the average tag weight in the concept. The second part normalizes the number of resources in the concept by total result number. Table 3 shows the tag-concept weight, resource-concept similarity and ConceptRank values for the simple example in Table 2. The  new metrics preserve most of the observed orders we described. However, there are a few exceptions. For instance, resource r4 is ranked higher in concept C1 than resource r7.

Such discrepancy is a result of applying tag weights. In this particular example, t2  has higher weight in C1 than t3  has, indicating that  r4 is better represented by C1 than r7 is.  In addition, the new metrics is able to precisely rank resources such as r6 and r8 in concept C2. r6 is ranked higher because it overlaps with more important tags in C2.

Table 3 Similarity measure  C1 C2 weight(t1,C1) = 2.92 weight(t2,C1) = 1.75 weight(t3,C1) = 1.17  weight(t5,C2) = 1.17 weight(t6,C2) = 2.84 weight(t7,C2) = 1.67  Sim(r1,C1)  = 1.00 Sim(r2,C1)  = 0.10 Sim(r4,C1)  = 0.80 Sim(r5,C1)  = 0.64 Sim(r7,C1)  = 0.70  Sim(r2,C2)  = 0.10 Sim(r3, C2)  = 1.00 Sim(r5, C2)  = 0.04 Sim(r6, C2)  = 0.79 Sim(r8, C2)  = 0.71  ConceptRank = 1.22 ConceptRank = 1.83

IV. EXPERIMENT AND RESULTS  The proposed algorithms are evaluated on several data sets obtained from CiteULike (www.citeulike.org). CiteULike is an online bibliography organizer. It allows users to save bibliographic information about published research papers online. Users can tag those papers with keywords. A paper can be retrieved through all tags collectively assigned by various users. We collected several data sets using query terms including ?algorithm?, ?software?, ?web? and so on.

Table 4 shows the clustering results on the data set obtained by query term ?web?. We only show the top concepts whose ConceptRank values are greater than 0.1. For each concept, we list the representing tags in decreasing order of their weights in the concept. We also show the top 5 papers based on resource-concept similarity values. The result clearly distinguishes several research areas related with keyword ?web?. The first and the third concepts are in the area of web information retrieval with different focuses. The first concept has a focus on query log analysis and user behavior study; while the third one represents more traditional approach based on hyperlink analysis. The second concept has a focus on semantic web and web services research. The fourth has a focus on more recent research on web 2.0 and social web.

Table 4 ?web? query result  Concept Members R: 0.92 #t: 20 #r:96   search (24.21), query_log_analysis (14.47), queries(14.47), web_search (13.15), logs (12.81), search_behaviour (12.47) search_engines (12.15), engines (9.64), study (9.43), forsigir2008(6) Searching the Web: the public and their queries (0.79) Vox Populi: the public searching of the Web (0.79) U.S. versus European web searching trends (0.79) Analysis of a very large web search engine query log(0.77) An analysis of web searching by European AlltheWeb.com users (0.72)  R: 0.73 #t: 9 #r: 153   service (8.21), semantic (6.01) ,composition (5.14), choreography(4) coordination (3), ontology (2.73), matching (2.22), discovery (1.71), rdf (1.6) Composition-oriented Service Discovery (0.69) Automated Composition of Semantic Web Services into Executable Processes (0.69) A software framework for matchmaking based on semantic web technology (0.69) Combining RDF and OWL with SOAP for Semantic Web Services (0.67) An ontology-driven framework for data transformation in scientific workflows (0.63)  R: 0.28 #t: 5 #r: 92  information-retrieval (3.0), prodei (1.67), link-analysis(1.67), algorithms (1.0)  SALSA: the stochastic approach for link-structure analysis (1) What is this page known for? Computing Web page reputations (0.92) Enhanced hypertext categorization using hyperlinks (0.92) Measuring index quality using random walks on the Web (0.92) Efficient crawling through URL ordering (0.79)  R: 0.17 #t:7 #r: 57   Folksonomy (4.17), Social (3.83), Eni (3.33), Folksonomies (2) Networks (1.67), Collaboration(1), Tagging (1) Collaborative tagging as a tripartite network (0.82) Social bookmarking in the enterprise (0.71) Referral Web: Combining Social Networks and Collaborative Filtering (0.61) The Tipping Point: How Little Things Can Make a Big Difference (0.55) Collaborative thesaurus tagging the Wikipedia way (0.53 )   Table 5 shows the clustering result on dataset obtained  using query term ?algorithm?. This dataset overlaps partially with the ?web? dataset. They both have papers in the web information retrieval research area. Interestingly, because our algorithm dynamically clusters query results, the papers in the shared part are put into slightly different concepts with relations to the query and to other results. The first concept in ?algorithm? result has similar focus with the third concept in ?web? data set.  Both have ?information-retrieval?, ?web? and ?algorithm? as keywords. The complete sets of keywords are different which reflect slightly different focuses of the groups. The first concept in ?algorithm? data set has ?google? and ?pagerank? as keywords. The original PageRank paper by S.Brin and L. Page is ranked fourth in that concept. This paper has a large number of tags assigned by different users which dilutes the focus and makes it ranked lower than a few other papers with less tags. The third concept in ?web? data set does not include specific words like ?google? or ?pageRank? as its keywords and it focuses on general theme on link based web ranking. The Brin&Page paper belongs to the concept. It is not one of the top 5 results though. The rest of the concepts in ?algorithm?  datasets are about gene analysis, graphic algorithm and social network analysis.



V. CONCLUSION  This paper reported a novel algorithm for presenting the web resource search result on the social tagging sites. It adopts a two step clustering approach to organize and rank resources based on their relative similarities with each other.

Initial similarities are computed using user and tag information. The query results are then organized as a group of concepts represented by a few semantically related terms.

The resources that are related with each concept are rank within the concept. In addition, concepts are also ranked by its representing terms and the number of resources they represent. We run experiment on data sets obtained from an online bibliography organizing sites allowing people to share their favorite academic papers. The results show that our algorithm can effectively distinguish various research areas in query results and associate papers in those areas.

