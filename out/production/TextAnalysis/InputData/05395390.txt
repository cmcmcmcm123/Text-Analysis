Key Issues of Security and Integrity in Third  Party Association Rule Mining

ABSTRACT  Association rule mining discovers interesting association or correlations among a large set of data items. Association rule mining make decision making process easier by providing the important information to the user. The most of the work done in this field is concerned with mining in an isolated form, but it is not only the case and many times more than one parties are involved in this process. Data mining task may be done by third party as a service provider. The database is made available to service provider and he returns the computed association rule to the owner of the database. For example, number of companies dealing in same type of product or services, may work together to identify the current trends in the industry & their customer. The organizations have to share the data & information with their friend or competitor to identify the global trends. There are many situations where more than one parties involve in the data mining process.  In this situation we require security of data so that information stealing by the dishonest party from dataset can be stopped and integrity of result be ensured by stopping dishonest party to corrupt the result or process. In this paper, we have summarized the integrity & security issues related to association rule mining in third  party computation.

Keywords: Privacy Preserving Data Mining (PPDM), Third Party Data Mining, Sensitive Data Security, Association Rule Mining.

1. INTRODUCTION  Association rule mining is one of the most important, frequently used and fundamental technique in data mining which discovers the association and correlation among the itemsets in large database. Now a day?s data collection is huge and omnipresent in social and business  areas. Many organizations are interested in association rule mining in collaborations to achieve joint benefits.

But doing so will leak some sensitive information. This should not happen and for the security of such information, application of privacy preserving association rules mining is compulsory [12],[15]. In Association rule mining databases are transactional database. In transactional database, each transaction represents set of items and these set of items are those items which customers purchase together. By this transactional database, we are interested to find out those set of items, which are purchased by customers frequently. This helps the marketing department to design strategy, mainly to design of display layout with associated items placed together.

The format of an association rule is ?X?Y?, where X & Y are the itemsets. ?X?Y? can be interpreted as presence of X itemset in a particular transaction implies the presence of Y itemset. The extraction of such association rules from transactional database is referred to as association rule mining. Association rule mining is a two step process, in the first step all set of frequent itemsets are identified, while in the second step association rules from the set of frequent itemsets can be extracted. First step is very expensive and has exponential time complexity. An algorithm named Apriori for finding set of frequent itemsets has been suggested by Agrawal and Shrikant [4]. Most of previous researches focus on centralized case of mining, where mining task is performed by the database owner [1]. In this paper we turn our attention from centralized model to distributed model, where mining procedure involves different parties other than the database owner. For association rule mining, the idea of third party mining can      be used. By using this we can take the benefits of other service provider ability & emerging computing paradigm.

This offers technical and financial advantages over the traditional model of computing. A database owner, who uses cloud computing, sends its database to cloud service provider, which in turn returns the association rules for the database owner [14].

There are various third party service providers who run distributed mining algorithms. These providers use the transactional database of different companies.

Suppose there are n malls, located different sites, all are interested to find out the global trends for better management of decision making process. The extraction of association rule in such environment is referred to as global association rule. When multiple parties are sharing their database to find out global association rules, there are few issues that needs to be considered. While sharing statistical information (i) How this can be ensured that nobody has stolen such information. This is sometime referred as security issue in data mining [3],[11]. (ii) How this can be ensured that the mining process is resulting accurate result [8]. This is sometime referred as result integrity issues in mining.

In this paper we have discussed these two issues in next two sections. In first section we discussed security issues in distributed association rule mining and idea to handle dynamic updates securely. In section two integrity of result has been insured. Lastly the paper has been summarized with conclusion & proposed future work.

2. RELATED WORK  In this paper the idea of security has been discussed cryptographically, in which the idea of substitution cipher and poly cipher has been used. Some other approaches of security are k-anonymity [10] and data perturbation [5], [7]. In k-anonymity approach an arrangement of making each individual indistinguishable from a number of other individuals by generalization.

Data perturbation performs random modifications on original data. Both the approaches are not suitable in the sense that they carry loss of information when original data is recovered. Hence correctness in result is not guaranteed. Some task related to authentication between database owner and server side can be performed by using hash trees built on both the sides was proposed by Li et al [9].  The limitation of this work is up to query outputs not for association rule mining.

3. SECURITY ISSUES IN INCREMENTAL ENVIRONMENT  Association rule mining is a two step process finding frequent itemsets and mining strong association rules from frequent itemsets. Cheung et al has proposed the model for distributed association rule mining [2], but they did not given solution for security concern in their work.

In non-distributed environment, a transactional database is required as a input from a single party, while in distributed environment many parties are involved and each party holds a similar type of database. These parties are cooperating together to find out the global association rule. The working of this environment is based on that each party is sharing set of frequent itemsets and then global association rules are mined. If we see this situation in reference to security, the sharing of information of frequent itemsets in this way in distributed environment is problematic. Solution to this problem is suggested by Kantarcioglu et al in his work of Privacy-preserving distributed mining of association rules [6]. The algorithm suggested by him computes the global association rules with the guarantee that each party can only observe its database and mining result but can not observe other sensitive information. The problem of maintenance has not been considered by him. Whenever there are some updations to the database, whole work requires to be repeated and model to handle this problem is suggested by Wong et al [11]. In distributed environment there would be an open welcome to join new parties with there own database, causing updation in the association rules.

Suppose at any instance of time t1, m parties are working in the distributed environment and as a result we get R1 and R2. R1 represents set of globally frequent itemsets and R2 represents sets of supported association rules.

Suppose some new parties join with m parties, causing total n parties to work with, in some next instance of time.

Now R1 and R2 are useless. Joining of new parties require new results say R?1 and R?2 , where R?1  represents set of new globally frequent itemsets and  R?2 represents set of new supported association rules. The support of itemsets are treated as sensitive information and are required to be kept secret from all the parties.

To keep sensitive information secret, requirement of privacy preserving techniques is strongly recommended. R?1  and R?2 can not be achieved easily without the information of old support count , because the old parties has to recompute the supports every time. So we are required to develop a technique which can store     supports of frequent itemsets and finally remembered supports can be used securely and efficiently.

One of the way to store an itemset x securely, is using two parties say pi and pj, pi holds (x + r) mod m and pj hold r, where m is randomly generated. The values that pi and pj hold, can not be distinguished from random number and in this way security of sensitive information is ensured. When we are going to update, the x can be recovered from these two parties. For privacy issue of association rules mining  a secure frequent-pattern tree (FP-tree) based schemes [12], Secure Set Union algorithm can also be used for securing the secret information.[13]. When new parties are going to be added, updation of set of frequent itemsets can be generated in two routines a. If support of some itemset is going to be increased than the updated support count can be calculated from the following formula   Updated support count = old support count + new support count of same itemset.

(b)New itemsets are going to frequent after adding new parties. Cheung has shown in his work that a globally frequent itemset can not be both infrequent in the old parties as well as in the new parties [2]. So, first new itemset is checked in new parties, if it is frequent then it will be checked in old parties and finally overall support is calculated, otherwise itemset can not be in final result.

While performing Updation, new parties learn the old result, needs to be hidden. Two routing of updation can be described by applying some sequence of steps. First of all we define some atomic steps;  1. Computation of supports in new parties 2. Computation of overall support 3. Compare support to threshold 4. Compute supports in old parties routine (1) can be defined as 1?2?3 and routine (2)  as 1?3?4?2?3. 4?2?3 is done only in old parties, nothing is performed by new parties.

So both the procedure can be represented in single procedure by 1?2?3?4?2?3.

Hence updates can be performed without using the sensitive information in its original form[14].

4. THIRD PARTY COMPUTATION  When the issue of mining association rules via third party i.e. service provider comes, then privacy of parties become great concerns. Two common issues are automatically reflected a. Stealing the information (data security problem) b. Do not performing the mining tasks  properly (result integrity problem). Although, if these two are not the cases with third party service providers, then this offers the database owners the benefits of cost relief and use of minimal resources. Following we discuss these two issues in detail.

4.1 Security Issues in Third Party Computation  The information can be stolen by third parties, when it looks for him to be interested. As we know that input for algorithm is transactional database. If transactional database is using actual names of items, for example, say a transaction ti = {bread, butter}, then the necessary information can be understood by third parties and can be stolen by them. Beside this if we use encrypted codes for such items then the securities of information can be achieved up to a certain extent. For example, a transaction {bread, butter} for database owner, can be {I55, I63} for third party. Here bread item is replaced by I55 and butter is replaced by I63. We call this idea to replace an item by a unique symbol as one-to-one mapping. This is similar to the principle of substitution cipher, in which each letter of text is replaced by another character. By the drawback of this scheme is known to be vulnerable to frequency analysis. Similarly the one-to-one mapping of items vulnerable to frequency analysis. If the supports of itemsets are given, we are able to recover the original database. Also one to one mapping leaks statistical information, like the number of frequent itemsets. So we needs to develop a more secure scheme. One idea is one- to-n mapping, in this, say item milk can be mapped to {I51, I88, I96, I101}, doing so will affect the frequency outputs of itemsets. Mapping of item names to unique symbol in this process is referred to as encryption.

Decryption, mapping of symbols to their names, should be performed unambiguously and for this item must associated with one unique symbol has suggested by Wong et al [3]. Item codes are for third parties, while names are for database owners. Besides this transformation, some fake items can also be used in transformed database, to make security tight.

4.2 Integrity Issues in Third Party Computation  The problem of integrity can be solved by the idea of using audit environment suggested by Wong et al [8].

Basically an audit environment consists of two parts. Part 1, consists a set of transformational methods, through which original database is transformed and sent to the service providers. The output from service provider is the     mined result say R. While part 2 consists again two parts (i) a set of verification methods (ii) auxiliary data that consist the process of verification. Here it should be noted that audit environment is in itself a complete system.

The techniques of database transformation and verification are referred to as artificial itemset planning (AIP). This is the AIP, through which it is guaranteed that incorrect or incomplete mining results have been returned by service providers. Correctness guarantee can be achieved by the logic described below.

i) suppose some set of itemsets are given say FI?. Through AIP an artificial database T? is constructed, such that all itemsets in FI? are frequent and their exact supports are known.

ii) Besides just sending T? as input to third party service provider, we send T+T? as input.

T+T? can be performed by just appending the transaction of T? with T, called it W.

iii) Service provider now mines W and generates an output say R. This R consists FI +FI?.

iv) As we know FI? earlier, then FI? generated by miner is checked with FI? known earlier.

v) If FI? generated by miner is incorrect or incomplete, and then there is a high guarantee of being FI, incomplete or incorrect.

So just by verifying FI?, we are able to guarantee, whether the integrity of result is enforced or not.

5. CONCLUSION AND FUTURE WORK  In this paper an abstract idea of security and integrity issues, while working in distributed environment has been demonstrated. In future different techniques and algorithm will be our interest to discuss. Similar idea will be discussed for some other major technique of data mining like clustering, etc. How authentication will be achieved between database owner and third party will also be a work of future interest.

