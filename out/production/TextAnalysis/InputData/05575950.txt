Efficient Algorithm for Discovering Potential Interesting Patterns with

Abstract   A pattern discovered from a collection of data is usual- ly considered potentially interesting if its information content can assist the user in their decision making process. To that end, we have defined the potential interestingness of a pattern based on whether it pro- vides statistical knowledge that is able to affect one?s belief system. In previous work, we proposed two novel algorithms, Discovering All Potentially Interesting Patterns (DAPIP) and All-Confidence Discovery of Potentially Interesting Patterns (ACDPIP), designed to discover potentially interesting patterns from a collec- tion of data. Results of experimental investigations show that the application of these two algorithms is limited to non-dense datasets.

In response, we propose a new algorithm, referred to as ACDPIP-Closed, designed to discover potential interesting patterns from dense datasets. We show em- pirically that ACDPIP-Closed is able to effectively and efficiently discover potentially interesting patterns from dense datasets. Additional contributions provided by the paper include a definition of a frequent closed itemset based on an all-confidence threshold and a theorem stating that, under the assumption of a partic- ular ordering of items, an itemset is support based closed if and only if it is all-confidence based closed.

1. Introduction   We previously proposed two algorithms, Discovering  All Potentially Interesting Patterns (DAPIP) and All-  Confidence Discovery of Potentially Interesting Pat-  terns (ACDPIP) which are designed to discover two  types of potentially interesting patterns from a collec-  tion of data [7]. These two types of patterns, referred to  as positive and negative patterns, provide statistical  knowledge that is able to affect one?s belief system  [9].In other words, if a pattern changes a user?s belief  system, then it has the potential to guide the user into  acting differently in the future. The DAPIP algorithm is  a non-heuristic search algorithm that ensures the dis-  covery of all positive and negative patterns satisfying a  given set of constraints. Its application requires the  specification of relatively small support thresholds for  generating itemsets and therefore its use is limited to  small, non-dense datasets. The ACDPIP algorithm,  unlike DAPIP, generates itemsets based on an all-  confidence threshold instead of a support threshold.

The all-confidence value of an itemset, I, represents the minimum confidence of a rule (pattern) that can be  generated from the itemsets in I [5]. This measure has the desirable anti-monotonic property: if an itemset I does not satisfy a given all-confidence threshold, then  no super itemset of I will satisfy the threshold. Results of experimental investigations show that ACDPIP sig-  nificantly outperforms DAPIP in terms of execution  time and provides adequate levels of coverage with  respect to the discovery of positive and negative pat-  terns. Unfortunately, the investigations also showed  that its application is limited to non-dense datasets. For  example, when applied to the dense datasets such as  mushroom and breast cancer its performance is unac-  ceptable in terms of execution time and completeness  of positive and negative patterns discovered.

The current state of the art in discovering positive  and negative patterns parallels the early history of as-  sociation rule mining in which the discovery process  was limited to non-dense datasets. More recently pro-  posed association rule mining algorithms have over-  come this limitation, in part, through the developed  concepts of frequent maximal and closed itemsets.

In this paper, we propose an alternative form of the  ACDPIP algorithm, referred to as ACDPIP-Closed that  generates non-redundant positive and negative patterns  from a set of frequent closed itemsets. We show empir-  ically that ACDPIP-Closed can successfully discover  positive and negative patterns from dense datasets.

Additional contributions of the work include a defini-  tion of a frequent closed itemset based on an all-   http://archive.ics.uci.edu/ml/datasets.html   DOI 10.1109/GrC.2010.55     confidence threshold and a theorem stating that, under  the assumption of a particular ordering of items, an  itemset is support based closed if and only if it is all-  confidence based closed. The rest of this paper is orga-  nized as follows. Section 2 highlights the unique con-  tributions of our work by comparing it to related work.

Section 3 develops the theoretical foundation that faci-  litates the discovery of non-redundant positive and  negative patterns. Section 4 presents the details of the  ACDPIP-Closed algorithm and Section 5 presents the  results of experiments conducted to assess its perfor-  mance. Finally, Section 6 provides a summary of the  work.

2. Related Work   In [9] we have considered the problem of discovering  potentially interesting patterns (rules) from a dataset D  consisting of N transactions {t1, t2, ?, tN}, where each  transaction ti ? I and I is a set of items {i1, i2, ?, ik} over which the transactions are defined. We assume the  standard definition for the support (supp) of an itemset  and for the confidence (conf) of a rule.

We define a binary relation ? on I, such that for any pair of itemsets Qi, Qj ? I, we have Qi ? Qj ? Qi,= Qj ^ i, where i ? I. The itemset Qi is referred to as the parent of Qj whenever Qi ? Qj. Finally, given a rule Q?A where Q, A? I, the quantity supp(Q) = n is referred to as the noise controller.

Definition 2.1 Potentially Interesting Pattern Let Q ? I, A ? I and Q ? A = ?.

A rule Q?A is called a positive pattern if one of the following two conditions holds:  1. conf(Q ?A) ? supp(A) ? s, given: Q ? I, |Q| > n, and 0 ? s ? 1.

2. conf(Q?A) ? max1?i?j [conf(Pi ?A)] ? s, given: Q ? I, |Q| > n, itemsets P1, P2, ?, Pj are all the parent itemsets of Q, and 0 ? s ? 1    A rule Q?A is called a negative pattern if one of the following two conditions holds:  1. supp(A) - conf(Q?A) ? s, given: Q? I, |Q| = n, and 0 ? s ? 1.

2. min[conf(Pi ?A)] ? conf(Q ? A) ? s, given: Q ? I, |Q| > n, itemsets P1, P2, ?, Pj are all the parent itemsets of Q, and 0 ? s ? 1.

The parameter s is called the significance controller and it intuitively represents the minimum degree of statistical change that a pattern must provide in order for it to be classified as potentially interesting. Both positive and negative patterns represent potentially interesting information. For example, a pattern with  confidence of 30% will typically be deemed uninterest- ing. However, consider the following situation: the conf(B?A) is 1% or 80% and conf(B^C?A) is 30%, where A is some kind of disease; B denotes some popu- lation and B^C is a subpopulation of B. Now one may conclude that the latter pattern is potentially useful.

The work by Bayardo et al. [3] on the concept of a  minimum improvement constraint is very similar to the  notion of a positive pattern. However, their proposed  algorithm requires the consequent of a rule to be speci-  fied in advance. The existing algorithms DAPIP and  ACDPIP and the proposed algorithm ACDPIP-Closed  do not have this constraint.

Several published papers have reported on work re-  lated to the discovery of potentially interesting, de-  scriptive rules from a collection of data. The previous  work most closely related to the work presented in this  paper includes the notion of exception rules [4, 8] and  peculiarity rules [10]. Specifically, the definition of a  positive pattern includes peculiarity rules, but also in-  cludes other potentially interesting patterns that are not  instances of such a rule. Likewise, the definition of a  negative pattern can be viewed as a generalization of  an exception rule.

The use of frequent closed itemsets to generate asso-  ciation rules has been studied by a number of research-  ers [2, 6]. The primary focus of their work has been to  use frequent closed itemsets to produce generating sets  of association rules. A generating set represents a non-  redundant collection of interesting association rules  from which all other interesting rules can be derived. In  the next section, we present a formal framework that  provides the basis for the discovery of non-redundant  positive and negative patterns. Generally speaking, a  positive (or negative) pattern will be considered non-  redundant if its confidence is sufficiently larger (or  smaller) than the confidence of patterns (rules) belong-  ing to a corresponding reference set.

3. Problem Formulation   Researchers have improved the efficiency of discover-  ing association rules through the use of frequent closed  itemsets. Unfortunately, the discovery of positive and  negative patterns is limited when itemsets are generated  based on a support threshold. This fact has lead to the  design of the ACDPIP algorithm which generates item-  sets based on a given all-confidence threshold. Hence,  an interesting research question is the following: Can the efficiency of ACDPIP be improved, without sacri- ficing its effectiveness, through the use closed item- sets? The answer to this question is yes and the expla- nation is provided in the remaining sections. To that  end, we present a set of formal definitions, an impor-     tant theorem, and the design of an efficient algorithm  that discovers positive and negative patterns through  the generation of all-confidence based frequent closed  itemsets.

Definition 3.1 Parent rule If  X ^ Y ? Z is an interesting rule then  X ? Z and Y ? Z are parent rules of X ^ Y ? Z.

Definition 3.2 Frequent Closed Itemset (Support- Based) An itemset X is called a closed itemset if there exists no itemset X? such that  1. X? is a proper superset of X, and 2. sup(X?) = sup(X).

If condition (1) and (2) hold for X?, then X? can be a closed itemset. A closed itemset X is a closed frequent itemset (CFI) if it is frequent; that is, if sup(X) ? supp, the minimum support threshold.

We now define a novel approach to generate closed  itemsets. We defined a new approach to generate fre-  quent itemset with all-confidence [7]. Similarly we can  generate closed itemsets.

Definition 3.3 All-confidence based Frequent Closed Itemset An itemset X is called a closed itemset if there exists no itemset X? such that  1. X? is a proper superset of X, and 2. all-conf(X?) = all-conf(X).

If condition (1) and (2) hold for X?, then X? can be a closed itemset. A closed itemset X is an all-confidence closed frequent itemset (ACFI) if it is frequent accord-  ing to minimum all-confidence threshold; that is, if all-  conf(X) ? all-conf-supp.

Definition 3.4 Redundant rule A rule or a pattern is considered redundant if its confi-  dence is not sufficiently different (by having a confi-  dence value that is different by the significance thre-  shold value, s) from that of its parent rule(s).

Definition 3.5 Positive LHS redundancy  A pattern P1 is positive LHS redundant if the differ-  ence of its confidence from the MAX of its parent  rules? confidences is <= s.

Example 3.1 Given frequent itemsets {A,B,C,D},  {A,E,C,D}, and {B,E,C,D} that are not closed, sup-  pose that there is a frequent closed super-itemset  {A,B,C,D,E}.

Compare the confidence (s) of the following pat-  terns.

a. (A^B) ?  (C^D)      (generated from {A,B,C,D})  b. (A^E) ? (C^D)       (generated from {A,E,C,D})  c. (B^E) ? (C^D)       (generated from {B,E,C,D})  d. (A^B^E) ? (C^D)  (generated from  {A,B,C,D,E})  From definition 2.1, pattern P1 (d) is a positive pat-  tern if: [C^D | A^B^E] ? MAX ([C^D | A^B], [C^D |  A^E], [C^D | B^E]) > s.

Hence, the use of closed itemset generates a positive  rule P1 having sufficiently larger confidence with re-  spect to rules whose LHS are parents of itemset  {A,B,E}. In particular, if Support({A,B,C,D} =  Sup-  port({A,B,C,D,E}, then the increase  in confidence is  0, which is < s. In this case, if only closed frequent  itemsets are kept at the itemset generation stage, then  itemset {A, B, C, D} will not get generated. However,  the rule (A^B) ?  (C^D) will be generated from the  closed frequent itemset {A,B,C,D,E} during the rule  generation step.

Definition 3.6 Cegative LHS redundancy  A pattern P2 is negative LHS redundant if the differ-  ence of its confidence from the MIN of its parent rules?  confidences is < = s.

Example 3.2 Given frequent itemsets {A,B,C,D},  {A,B,C,E}, and {A,B,E,D} that are not closed, sup-  pose that there is a frequent closed super-itemset  {A,B,C,D,E}.

Compare the confidence (s) of the following patterns.

a. (A^B) ?  (C^D)      (generated from {A,B,C,D})  b. (A^E) ? (C^D)       (generated from {A,E,C,D})  c. (B^E ) ? (C^D)      (generated from {B,E,C,D})  d. (A^B^E) ? (C^D)  (generated from  {A,B,C,D,E})  From definition 2.1, pattern P2 (d) is a negative pat-  tern if:  MIN ([C^D | A^B], [C^D | A^E], [C^D | B^E]) ? [C^D  | A^B^E] > s.

Hence, the use of closed itemsets generates negative  rule P2 having sufficiently smaller confidences with  respect to rules with LHS are parents of itemset {A, B,  E}. In particular, if Support({A,B,C,D} =  Sup-  port({A,B,C,D,E}, then the decrease  in confidence of  P2 (from its parents) is 0, which is < s. In this case, if  only closed frequent itemsets are kept at the itemset  generation stage, then itemset {A, B, C, D} will not get  generated. A potential negative pattern that will be  generated from the closed frequent itemset  {A,B,C,D,E} is {A,B} ? {C,D,E}, provided its confi-     dence is not smaller than that of the pattern {A,B} ?  {C,D} by more than s.

We now present a theorem that establishes an equi-  valence relationship between support based closed  itemsets and all-confidence based closed itemsets.

Theorem 3.1  Suppose that the items in ? are ordered such that Sup-  port ( ji ) ?  Support ( ki ), for nkj ???1 . Then, an  itemset is all-confidence based closed iff it is support based closed.

Proof: Let T is a transaction table with C transactions.

Only If-part  Let X = {i1, i2? ij} be a all-confidence based frequent itemset and there exist a all-confidence based closed frequent itemset X? = {i1, i2? ik}, where 1< j < k.

We know from definition 3.3, if X? all-confidence based closed then,  all-confidence (X?) = all-confidence (X)        -- (1) and X? is proper superset of X         -- (2)  Now from all-confidence definition[5],  all-confidence(X) = }|)({  )(  XiiSupportMAX  XSupport  jj ?? -- (3)  all-confidence(X?)= }'|)({  )'(  XiiSupportMAX  XSupport  kk ??  -- (4)  From the fact that MAX is monotonically non- decreasing function, with the addition of another item,  it must be true that,  MAX{|{i1}|, |{i2}|, ?, |{ij}|} ?  MAX{|{i1}|, |{i2}|, ?, |{ik}|}.

From (1) & (2), we obtain Support (X) has to ? Sup- port (X?) and that the all-confidence values are equal, which imply that,  MAX{|{i1}|, |{i2}|, ?, |{ij}|} ?  MAX{|{i1}|, |{i2}|, ?, |{ik}|}.

Therefore, we can conclude that,  MAX{|{i1}|, |{i2}|, ?, |{ij}|} = MAX{|{i1}|, |{i2}|, ?, |{ik}|}.

Thus,  Support(X) = Support (X?)                                -- (5)  (2) and (5) satisfies the definition 3.2 and thus X? is support based closed.

If-Part  From the fact that MAX is monotonically non- decreasing function, with the addition of another item,  it must be true that,  MAX{|{i1}|, |{i2}|, ?, |{ij}|} ?  MAX{|{i1}|, |{i2}|, ?, |{ik}|}.

From the assumption that items in ? are ordered in non-increasing value of their supports, we conclude,  MAX{|{i1}|, |{i2}|, ?, |{ij}|} ?  MAX{|{i1}|, |{i2}|, ?, |{ik}|},  implying that the denominators in (3) & (4) are equal.

Since we are given Support(X) = Support (X?), we con- clude that,  }|)({  )(  XiiSupportMAX  XSupport  jj ??  = }'|)({  )'(  XiiSupportMAX  XSupport  kk ??    Thus, we conclude that,  all-confidence (X?) = all-confidence (X).         ?  Based on the above theorem redundant positive and  negative patterns can be eliminated through the genera-  tion of all-confidence based frequently closed itemsets.

4. Algorithm   We have extended the ACDPIP algorithm to discover  non-redundant LHS positive and negative patterns from  all-confidence based frequent closed itemsets. The re-  sulting algorithm, called ACDPIP-Closed, is shown in  Figure 4.1.

Algorithm ACDPIP-Closed: Algorithm generates  closed frequent itemsets using an all-confidence thre-  shold with algorithm in figure 4.2 and positive and  negative patterns with closed itemsets.

Input: dataset D; significant controller s, noise control- ler n, all-confidence threshold t.

Output: set of positive patterns PP and the set of nega-  tive patterns ?P.

[1] Generate closed frequent itemsets CFI with  all_confidence > t with modified apriori algorithm.

[2] for each itemset fin ?CFI generate all possible rules from fin and place in AP [3]     for each Pai ?  AP  //When P is an atomic concept [4]        if (conf (Q?A) ? supp(Q) ? s) [5]             add Pai  to PP [6]       else  [7]       if (supp(Q)?conf(P?Q) ? s) and(supp(P)? n) [8]             add Pai to ?P  //When P is a composite concept [9]  if (conf (Q?A) ? max1?i?j [conf (Pi?A)]), ?Pi?parents (P) [10]           add Pai  to PP [11]    else if (min1?i?j [conf (Pi?A)] ? conf (Q?A)),  ?Pi ? parents(P) and [parent(Pai)] ? n [12]         add Pai to ?P.

Figure 4.1: Algorithm ACDPIP-Closed    The steps of the algorithm are as follows:     ? Generate all frequent closed itemsets FCI from a given dataset D using a minimum all-confidence > t.

? For each frequent closed itemset, generate all possi-  ble association rules.

? For each association rule determine if it represents  either a positive or negative pattern. In particular, if a  rule satisfies the definition of a positive pattern then  evaluate the next rule. If it does not then determine if  the rule represents a negative pattern.

We have modified the Apriori algorithm [1] to gen-  erate all-confidence based frequent closed itemsets  from a dataset D. Specifically, the algorithm finds fre- quent closed itemsets using a bottom-up procedure in  which candidate itemsets of size k are generated by  joining the frequent itemsets of size k-1. If any superset  of an itemset I has an all-confidence equal to the all- confidence of I then it is not returned as part of the result set. The algorithm terminates when the frequent  closed itemsets of a given size is equal to zero.

5. Experiments   We compared the performance of ACDPIP and ACD-  PIP-Closed. The specific objectives were to compare  the coverage level and execution time of both algo-  rithms.

5.1 Experimental Setup   The experiments were performed on a PC with Intel(R)  Core(TM) Duo CPU, E6750 @ 2.66GHz, and 3 GB of  RAM. The noise control threshold, n, and the signific- ance threshold, s, used in all experiments were .02, and 0.1, respectively. Three real-life dense datasets, chess,  mushroom, and adult were used in the experimental  investigation. These datasets were obtained from the  UCI ML repository .

5.2 Experimental Results   The experimental results show that ACDPIP-Closed  out performed ACDPIP on the selected datasets. Spe-  cifically, ACDPIP-Closed outperformed ACDPIP with  respect to the number of generated itemsets, the num-  ber of generated redundant patterns, and the execution  time.

Figure 5.1 shows the number of itemsets generated  by ACDPIP and ACDPIP-Closed with an all-  confidence threshold value equal to 0.06  The reduc-  tion obtained by ACDPIP-Closed for the chess dataset   http://archive.ics.uci.edu/ml/datasets.html  was approximately 27%, for the mushroom dataset it  was 48%, and approximately 33% for the adult dataset.

Figure 5.1: Redundant itemset reduction with closed  itemsets    Figures 5.2 - 5.4 provide a comparison of the number  of patterns discovered by ACDPIP and ACDPIP-  Closed with respect to the chess, mushroom, and adult  datasets, respectively. The additional patterns discov-  ered by ACDPIP represent LHS redundant positive or  negative patterns.  The level of redundancy in the con-  text of the chess datasets is approximately13%, 37% in  the context of the mushroom dataset, and 28% in the  context of the adult dataset.

Figure 5.2: Redundant patterns reduction with closed  itemsets for Chess dataset.

Figure 5.3: Redundant patterns reduction with closed  itemsets for Mushroom dataset.

Figure 5.4: Redundant patterns reduction with closed  itemsets for Adult dataset.

Figure 5.5: Percent execution time improvement with  closed itemsets    Figure 5.5 shows the execution time for ACDPIP and  ACDPIP-Closed for all three datasets with all-  confidence threshold value equal to 0.06. The results  shown in this figure clearly illustrate that ACDPIP-  Closed outperformed ACDPIP with respect to all three  datasets.

6. Conclusion   In our previous work we show with the help of experi-  mental results that when dataset is dense, the number of  frequent itemsets generated is very large. This affects  the performance of the interesting patterns discovery  algorithms. We improved the performance by using all-  confidence measure. Even though all-confidence based  algorithm outperformed the support based algorithm  we discover that there is still need for further improve-  ment. In this paper we show that the performance can  be improved with the help of closed itemsets by reduc-  ing redundant itemsets. We propose changes to ACD-  PIP algorithm by introducing closed itemset generation  and we refer it ACDPIP-Closed. Experimental results  show that we are able to improve the performance of  ACDPIP with closed itemsets. ACDPIP-Closed outper-  forms ACDPIP in terms of redundant itemset reduc-  tion, redundant patterns reduction, and improved ex-  ecution time.

7. References   [1] Agrawal, R, and Srikant, R. ?Fast Algorithms for Min-  ing Association Rules.? In Proceedings of 20th Int?l Conf. on Very Large Databases, 1994.

[2] Bastide, Y, Pasquier, N, Taouil, R, Stumme, G, and  Lakhal, L. ?Mining Minimal Non-Redundant Associa-  tion Rules Using Frequent Closed Itemsets.? In Pro- ceedings of 1st Int?l Conf. on Computational Logic, 2000.

[3] Bayardeo, R, Agrawal, R, and Gunopulos, D. ?Con-  straint-Based Rule Mining in Large, Dense Databases.?  In Proceedings of 15th Int?l Conf. on Data Engineering, 1999.

[4] Hussain, F., Liu, H., Suzuki, E., and Lu, H. ?Exception  Rule Mining with a Relative Interestingness Measure?.

In Proceedings of PAKDD, 2000.

[5] Omiecinski E. ?Alternative interest measures for  mining associations.? IEEE Trans. Knowledge and Data Engineering, vol.15, no. 1, pp. 57 - 69, 2003.

[6] Pasquier, N, Bastide, Y, Taouil, R, and Lakhal, L.

?Closed Set Based Discovery of Small Covers for  Association Rules.? Cetworking and Information Systems Journal, vol. 3, no. 2, 2000.

[7] Singh, R, Johnsten, T, Raghavan, V, and Xie, Y. ?An  Efficient Algorithm for Discovering Positive and Nega-  tive Patterns.? In Proceedings of IEEE Int. Conf. on Granular Computing, Nanchang, China, 2009.

[8] Suzuki, E. Undirected Discovery of Interesting Excep- tion Rules. Int. Journal of Pattern Recognition and Ar- tificial Intl.16:1065-1086, 2002.

[9] Xie, Y, Johnsten, T, Raghavan, V.V, and Ramachan-  dran, K. ?On Discovering ?Potentially Useful? Patterns  from Databases.? In Proceedings of IEEE Int. Conf. on Granular Computing, 2006.

[10] Zhong, N, Yao, Y.Y., Ohshima, M. Peculiarity Oriented Multidatabase Mining. IEEE Trans. On Knowledge and Data Engineering, 15:952-960, 2003.

