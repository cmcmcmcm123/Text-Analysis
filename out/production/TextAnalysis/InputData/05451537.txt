

Abstract? with the enormous amount of data stored in files, databases, and other repositories, it is increasingly important, to develop powerful means for analysis and perhaps interpretation of such data and for the extraction of interesting knowledge that could help in decision-making. Data Mining, also popularly known as Knowledge Discovery in Databases (KDD), refers to the nontrivial extraction of implicit, previously unknown and potentially useful information from data in databases. Thus data mining is the process of automated extraction of hidden, predictive information from large databases. Data mining includes: extract, transform, and load transaction data onto the data warehouse system.

Neural networks have been successfully applied in a wide range of supervised and unsupervised learning applications. Neural-network methods are not commonly used for data-mining tasks, because they may have complex structure, long training time, and uneasily understandable representation of results & often produce incomprehensible models. However, neural networks have high acceptance ability for noisy data and high accuracy and are preferable in data mining. In this paper, investigation is made to explore application of Artificial Neural Network in Data mining techniques, the key technology and ways to achieve the data mining based on neural networks are also researched. Given the current state of the art, neural-network deserves a place in the tool boxes of data-mining specialists.

Keywords-Data mining,KDD,SOM,Data mining process

I.  INTRODUCTION Data mining, the extraction of hidden predictive  information from large databases, is a powerful new technology with great potential to help companies focus on the most important information in their data warehouses.

Data mining tools predict future trends and behaviors, allowing businesses to make proactive, knowledge-driven decisions. The automated, prospective analyses offered by data mining move beyond the analyses of past events provided by retrospective tools typical of decision support systems. Data mining tools can answer business questions that traditionally were too time consuming to resolve. They  search databases for hidden patterns, finding predictive information that experts may miss because it lies outside their expectations. Different types of data mining tools are available in the marketplace, each with their own strengths and weaknesses. Internal auditors need to be aware of the different kinds of data mining tools available and recommend the purchase of a tool that matches the organization's current detective needs. This should be considered as early as possible in the project's lifecycle, perhaps even in the feasibility study.

Data mining commonly involves four classes of tasks.[1] Classification - Arranges the data into predefined groups.

For example an email program might attempt to classify an email as legitimate or spam. Common algorithms include Decision Tree Learning, Nearest neighbor, naive Bayesian classification and Neural network.

Clustering - Is like classification but the groups are not predefined, so the algorithm will try to group similar items together.

Regression - Attempts to find a function which models the data with the least error.

Association rule learning - Searches for relationships between variables. For example a supermarket might gather data on customer purchasing habits. Using association rule learning, the supermarket can determine which products are frequently bought together and use this information for marketing purposes. This is sometimes referred to as "market basket analysis".

Artificial Neural Network is a system loosely modeled based on the human brain. The field goes by many names, such as connectionism, parallel distributed processing, neuro-computing, natural intelligent systems, machine learning algorithms, and artificial neural networks. It has ability to account for any functional dependency. The network discovers (learns, models) the nature of the dependency without needing to be prompted. Initially the application of data mining is not being used because of Complex structure, long training time, and poor interoperability. But as neural networks is a powerful technique to solve many real world problems. They have the ability to learn from experience in order to improve their performance and to adapt themselves to changes in the environment. In addition to that they are able to deal with incomplete information or noisy data and can be very  Volumn 2  978-1-4244-5586-7/10/$26.00      2010 IEEEC     effective especially in situations where it is not possible to define the rules or steps that lead to the solution of a problem.



II. DATA MINING TECHNIQUES Data mining techniques can be implemented rapidly on  existing software and hardware platforms to enhance the value of existing information resources, and can be integrated with new products and systems as they are brought on-line. When implemented on high performance client/server or parallel processing computers, data mining tools can analyze massive databases to deliver answers to questions such as, "Which clients are most likely to respond to my next promotional mailing, and why?" As shown in Fig1, Data mining process consist of three main phases:-  1. Data preprocessing  2. Applying data mining techniques  3. Interpretation of Results    Fig1: General Data mining Process  This section provides an introduction to the basic techniques of data mining. The most commonly used techniques in data mining are:  ? Artificial neural networks: Non-linear predictive models that learn through training and resemble biological neural networks in structure.

? Decision trees: Tree-shaped structures that represent sets of decisions. These decisions generate rules for the classification of a dataset.

Specific decision tree methods include Classification and Regression Trees (CART) and Chi Square Automatic Interaction Detection (CHAID).

? Genetic algorithms: Optimization techniques that use process such as genetic combination, mutation, and natural selection in a design based on the concepts of evolution.

? Nearest neighbor method: A technique that classifies each record in a dataset based on a combination of the classes of the k record(s) most similar to it in a historical dataset . Sometimes called the k-nearest neighbor technique.

? Rule induction: The extraction of useful if-then rules from data based on statistical significance.



III. ANN APPLICATION IN DATA MINING As discussed in the previous section, we can use various  techniques in data mining. This section will focus on how artificial neural networks are appropriate for data mining.

There are two main types of neural network models: supervised neural networks such as the multi-layer perceptron or radial basis functions, and unsupervised neural networks such as Kohonen feature maps. A supervised neural network uses training and testing data to build a model. The data involves historical data sets containing input variables, or data fields, which correspond to an output. The training data is what the neural network uses to ?learn? how to predict the known output, and the testing data is used for validation. The aim is for the neural networks to predict the output for any record given the input variables only.

Fig2: Example of a simple feed forward neural network   One of the simplest feed forward neural networks (FFNN), such as the one in Fig2, consists of three layers: an input layer, hidden layer and output layer. In each layer there are one or more processing elements (PEs). PEs are meant to simulate the neurons in the brain and this is why they are often referred to as neurons or nodes. A PE receives inputs from either the outside world or the previous layer. There are connections between the PEs in each layer that have a weight (parameter) associated with them. This weight is adjusted during training. Information only travels in the forward direction through the network - there are no feedback loops.

Volumn 2      Why Neural Networks   High Accuracy: Neural networks are able to approximate complex non-linear mappings.

Noise Tolerance:  Neural networks are very flexible with respect to incomplete, missing and noisy data.

Independence from prior assumptions: Neural networks can be updated with fresh data, making them useful for dynamic environments. Hidden nodes, in supervised neural networks can be regarded as latent variables. Neural networks can be implemented in parallel hardware

IV. TRADITIONAL APPROACHES TO INFORMATION PROCESSING VS. NEURAL NETWORKS  In this section comparison is made between traditional methods & neural Network for information processing.

A) Foundation: Logic vs. Brain Traditional Approach: - Simulate and formalize human reasoning and logic process. TA treats the brain as a black box. TA focuses on how the elements are related to each other and how to give the machine the same capabilities.

Neural Networks:- Simulate the intelligence functions of the brain. NN focus on modeling the brain structure. NN attempts to create a system that functions like the brain because it has a structure similar to the structure of the brain B). Processing Techniques: Sequential vs. Parallel Traditional Approach: The processing method of TA is inherently sequential.

Neural Networks: The processing method of NN is inherently parallel. Each neuron in a neural network system functions in parallel with others C ) Learning: Static and External vs. Dynamic and Internal Traditional Approach: Learning takes place outside of the system. The knowledge is obtained outside the system and then coded into the system.

Neural Networks: Learning is an integral part of the system and its design. Knowledge is stored as the strength of the connections among the neurons and it is the job of NN to learn these weights from a data set presented to it.

D) Reasoning Method: Deductive vs. Inductive Traditional Approach: Is deductive in nature. The use of the system involves a deductive reasoning process, applying the generalized knowledge to a given case.

Neural Networks: Is inductive in nature. It constructs an internal knowledge base from the data presented to it. It generalizes from the data, such that when it is presented a new set of data, it can make a decision based on the generalized internal knowledge.

E) Knowledge Representation: Explicit vs. Implicit  Traditional Approach: It represents knowledge in an explicit form. Rules and relationships can be inspected and altered.

Neural Networks: The knowledge is stored in the form of interconnections strengths among neurons. Nowhere in the system, can one pick up a piece of computer code or a numerical value as a discernible piece of knowledge.



V. DATA MINING BASED ON NEURAL NETWORK A  Data mining based on Self-Organizing Maps (SOM)  The self-organizing maps (SOM) introduced by Teuvo Kohonen [11]are deemed as being highly effective as a sophisticated visualization tool for visualizing high dimensional, complex data with inherent relationships between the various features comprising the data. The SOM?s output emphasizes the salient features of the data and subsequently leads to the automatic formation of clusters of similar data items. This particular characteristic of SOMs alone qualifies them as a potential candidate for data mining tasks that involve classification and clustering of data items.

A ?learnt? SOM can be used as an important visualization aid as it gives a complete picture of the data; similar data items are automatically grouped together.

The Self-Organizing Map (SOM) has proven to be one of the most powerful algorithms in data visualization and exploration. Application areas include various fields of science and technology, e.g., complex industrial processes, telecommunications systems, document and image databases, and even financial applications. The SOM maps the high- dimensional input vectors onto a two-dimensional grid of prototype vectors and orders them. For a human interpreter, the ordered prototype vectors are easier to visualize and explore than the original data. The SOM has been widely implemented in various software tools and libraries.

Fig3: Applying SOM in Data mining   As shown in fig3, Post-processing the SOM extracts  qualitative or quantitative information of the data.

Visualization and clustering provide qualitative information, while modeling and monitoring give quantitative information resulting in deeper understanding of the system behavior B  Data mining based on Neuro-Fuzzy  Volumn 2     A neuro-fuzzy system is based on a fuzzy system which is trained by a learning algorithm derived from neural network theory. The learning procedure operates on local information, and causes only local modifications in the underlying fuzzy system.

A neuro-fuzzy system can be viewed as a 3-layer feed forward neural network. The first layer represents input variables, the middle (hidden) layer represents fuzzy rules and the third layer represents output variables. Fuzzy sets are encoded as (fuzzy) connection weights. It is not necessary to represent a fuzzy system like this to apply a learning algorithm to it. However, it can be convenient, because it represents the data flow of input processing and learning within the model. Sometimes 5-layer architecture is used, where the fuzzy sets are represented in the units of the second and fourth layer. A neuro-fuzzy system can be always interpreted as a system of fuzzy rules. It is also possible to create the system out of training data from scratch, as it is possible to initialize it by prior knowledge in form of fuzzy rules. The learning procedure of a neuro-fuzzy system takes the semantically properties of the underlying fuzzy system into account. This results in constraints on the possible modifications applicable to the system parameters.

Neural networks achieve high accuracy in classification, prediction and many others applications as suggested in the literature. But this system is unable to explain the knowledge embedded in trained neural networks is one of the major drawbacks of this technology. Much of attention has been paid to solve this problem by extracting rules from trained neural networks.Fig.4 shows data mining process based on neuro-fuzzy system.

The first step is to build neural network forecasting model by the neural network construction system. The mechanism of the subsystem is like an Expert System Shell.

The second step is to extract rules from trained the neural networks. Neural network architecture and weight space are used to mine the business rules that govern the forecasting by the rule extraction mechanism.

In the third step hidden forecasting rules extracted in the previous step are incorporated to the network generated by neural network construction system to form a descriptive neural network, DNN. Most of researchers extract if-then type association rules, as they are more understandable for humans than other representations.

Fig 4: Data mining process using Descriptive Neural Network  C Data mining based on ART2 Clustering analysis is an important research topic in data  mining field, and it is one of main task of data mining.

Adaptive Resonance Theory (ART) neural network is an effective method to realize clustering. But the classical ART2 network has some shortcoming and insufficiency in data clustering application. The classical ART2 network must designate p alert parameters before the network training; the configuration of this parameter has a direct impact on the network clustering result. The classical ART2 uses the "winner takes all" competition rule, in general only considers winning neuron information, but neglects other useful neuron information in the output layer. The classical ART2 network output is essentially one-dimension structure is unable to manifest the whole relation to entire input mode space. By improving the structure of ART2, ample considering amplitude information of mining object, which can decrease the requirement of vigilance parameter and earn cluster result with administrative level structure .we can apply ART2 Neural network in data mining for browsing patterns in web log data.

D Data mining based on Back propagation Some situations where a BP NN might be a good idea:  1. A large amount of input/output data is available, but you're not sure how to relate it to the output.

2. The problem appears to have overwhelming complexity, but there is clearly a solution.

3. It is easy to create a number of examples of the correct behavior. Outputs can be "fuzzy", or non-numeric.

Back propagation algorithm can be used for classification problems.



VI. CONCLUSION & DISCUSSION In this paper, we have reviewed how to apply Artificial  Neural Network in Data mining techniques. Neural network itself is very suitable for solving the problems of data mining because of its characteristics of good robustness, self- organizing adaptive, parallel processing, distributed storage and high degree of fault tolerance. This overall benefit that ANN offer makes it a powerful & exciting tool to be applied in the field of Data mining to enhance capabilities of  Data mining process.The outcome from such a combined tool would provide valuable insights& intellegance for planning & decision making in all spheres. Further, Particle swarm optimization, Ant colony optimization can be integrated with artificial neural network to further enhance the performance of ANN in Data mining.

