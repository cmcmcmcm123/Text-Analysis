THE APPLICATION OF DATA MINING IN ONLINE BOOKSTORE

Abstract: With the rapid development of Internet technology in  recent years, Electronic Commerce has been an inevitable product of the economy, the science and the technology. This paper takes an online bookstore platform as a background, introduces the definition, functions, process and common analytical techniques of data mining. In the end, the experiment on association rules mining from the order data of online bookstore is completed by Apriori algorithm.

Keywords: Online bookstore; Data mining; Association rule; Apriori  Algorithm  1. Introduction  Along with the development of the computer and the database technology, all trades and professions start to adopt the computer and corresponding information technology to carry on the management and the operation.

It has greatly improved the ability of producing, collecting, storing and processing data. Under such a background, people urgently need new computing technology and tools to excavate the knowledge contained in database, which guides technological decision and strengthens the competitiveness of enterprises.

Data mining has emerged as a means for identifying patterns and trends from a large amount of data [1]. The major reason that data mining has attracted a great deal of attention in the information industry in recent years is due to the wide availability of huge amounts of data and the imminent need for turning such data into useful information and knowledge. Data mining can be viewed as a result of the natural evolution of information technology.

The paper is organized as follows. The definition, process and techniques of data mining are introduced in section 2. The design and implement of online bookstore is introduced in section 3. In section 4, association rules mining and Apriori Algorithm is introduced and experiments are conducted. The conclusions are discussed in Section 5.

2. Data Mining Theory  2.1. Definition of Data Mining  Simply stated, data mining refers to extracting or ?mining? knowledge from large amounts of data [1]. Data mining is the process of discovering actionable information from large sets of data. It uses mathematical analysis to derive patterns and trends that exist in data. Typically, these patterns cannot be discovered by traditional data exploration because the relationships are too complex or because there is too much data.

These patterns and trends can be collected and defined as a data mining model. Mining models can be applied to specific business scenarios, such as: ? Forecasting sales.

? Targeting mailings toward specific customers.

? Determining which products are likely to be sold  together.

2.2. Data Mining Process  Building a mining model is part of a larger process that includes everything from asking questions about the data and creating a model to answer those questions, to deploying the model into a working environment. This process can be defined by using the following six basic steps.

? Defining the Problem ? Preparing Data ? Exploring Data ? Building Models ? Exploring and Validating Models ? Deploying and Updating Models  The following Figure 1 describes the relationships between each step in the process, and the technologies in Microsoft SQL Server that can be used to complete each step.

Although the process illustrated in the diagram is circular, each step does not necessarily lead directly to the next step. Creating a data mining model is a dynamic and iterative process. After exploring the data, one may find that the data is insufficient to create the appropriate mining models, and that one therefore have to look for more data.

Alternatively, you may build several models and then realize that the models do not adequately answer the problem you defined, and that you therefore must redefine the problem. You may have to update the models after they have been deployed because more data has become available. Each step in the process might need to be repeated many times in order to create a good model.

Figure 1. Relationships between six steps  2.3. Data Mining Techniques  1) Classification: discovery of a predictive learning function that classifies a data item into one of several predefined classes. The typical method is fuzzy decision tree [5], [6], [7].

2) Regression: discovery of a predictive learning function, which maps a data item to a real-value prediction variable [8].

3) Clustering: a common descriptive task in which one seeks to identify a finite set of categories or clusters to describe the data.

4) Summarization: an additional descriptive task that involves methods for finding a compact description for a set (or subset) of data.

5) Dependency Modeling: finding a local model that describes significant dependencies between variables or between the values of a feature in a data set or in a part of a data set.

6) Change and Deviation Detection:  discovering the most significant changes in the data set.

2.4. Data warehouses  The data warehouse is a collection of integrated, subject-oriented databases designed to support the decision-support functions (DSF), where each unit of data is relevant to some moment in time. The function of the data warehouse is to store the historical data of an organization in an integrated manner that reflects the various facets of the organization and business.

A three-stage data-warehousing development process is summarized through the following basic steps:  1) Modeling: In simple terms, to take the time to understand business processes, the information requirements of these processes, and the decisions that are currently made within processes.

2) Building: To establish requirements for tools that suit the types of decision support necessary for the targeted business process; to create a data model that helps further define information requirements; to decompose problems into data specifications and the actual data store, which will, in its final form, represent either a data mart or a more comprehensive data warehouse.

3) Deploying: To implement, relatively early in the overall process, the nature of the data to be warehoused and the various business intelligence tools to be employed; to begin by training users. The deploy stage explicitly contains a time during which users explore both the repository (to understand data that are and should be available) and early versions of the actual data warehouse. This can lead to an evolution of the data warehouse, which involves adding more data, extending historical periods, or returning to the build stage to expand the scope of the data warehouse through a data model.

3. Design and Implement of Online Bookstore Based on ASP.Net  An online bookstore is formed by the front and back business subsystem. The website is built by Dreamweaver, ASP.net, Microsoft SQL Server, etc. Visitors can  log in the online bookstore and choose books to buy. The whole shopping flowchart is as the following Figure 2.

4. The application of data mining in online bookstore  As the running of online bookstore, it will produce a large number of order lists which contain customer's shopping information on the net. It is very important to find  Defining the Problem  Preparing Data  Exploring Data  Validating models  Deploying and updating models  Building Models          valuable information or knowledge from all lists.

Figure 2. System overall design flowchart  4.1. Association Rules Mining  Association rules, first introduced in [2], are used to identify relationships among a set of items in a database.

These relationships are not based on inherent properties of the data themselves (as with functional dependencies), but rather based on co-occurrence of the data items [10].

Definition 1: Let I ={I1, I2, ? , Im} be a set of m distinct attributes, also called literals. Let D be a database, where each record T has a unique identifier, and contains a set of items such that T ? I An association rule is an implication of the form X? Y, where X, Y ? I, are sets of items called itemsets, and X Y? = ? . Here, X is called antecedent, and Y consequent.

Two important measures for association rules, support (S) and confidence (C), can be defined as follows.

Definition 2: The support (S) of an association rule is  the ratio (in percent) of the records that contain X Y?  to the total number of records in the database.

( ) ( ) X Y  S X Y P X Y D  ? ? = ? =        (1)  Therefore, if we say that the support of a rule is 5% then it means that 5% of the total records contain X ? Y.

Support is the statistical significance of an association rule.

Grocery store managers probably would not be concerned about how peanut butter and bread are related if less than 5% of store transactions have this combination of purchases.

While a high support is often desirable for association rules, this is not always the case. For example, if we were using association rules to predict the failure of telecommunications switching nodes based on what set of events occur prior to failure, even if these events do not occur very frequently association rules showing this relationship would still be important.

Definition 3: For a given number of records, confidence (C) is the ratio (in percent) of the number of records that contain X ? Y to the number of records that contain X.

( ) ( | ) X Y  C X Y P Y X X  ? ? = =       (2)  Thus, if we say that a rule has a confidence of 85%, it means that 85% of the records containing X also contain Y.

The confidence of a rule indicates the degree of correlation in the dataset between X and Y. Confidence is a measure of a rule?s strength. Often a large confidence is required for association rules. If a set of events occur a small percentage of the time before a switch failure or if a product is purchased only very rarely with peanut butter, these relationships may not be of much use for management.

Definition 4: The form of mining rule is: ( : , ) ( , ) ( , )[sup , ]P X customer W Q X Y buys X Z port confidence? ?  In above form, X  is the keyword of relationship ?customer?, P and Q are predicate variables, W , Y and Z are Object variables and their values are in the range of customer  X .

For example, a rule of age(X, ?20?29?) income(X, ?40000?50000?) ? buys(X ?economic books?)[2 60%] can tell us that a customer who is 20 years old and has a revenue between 40,000 to 50,000 most probably chooses economic books (confidence is 60%).

4.2. Apriori Algorithm  The Apriori algorithm developed by [3] is a great achievement in the history of mining association rules [4].

It is by far the most well-known association rule algorithm.

Yes  Registered users?

Index page  To pick out and purchase  Put selected goods into shopping cart  To confirm quantity  Go to cash desk  To register  To Log in  Confirm the order and submit  Fill in personal detailed information  Finish shopping  No          The Apriori algorithm has two steps, During the first step, Lk-1 is joined with itself to obtain Ck. In the second step, apriori_gen() deletes all itemsets from the join result, which have some (k-1)-subset that is not in Lk-1. Then, it returns the remaining large k-itemsets [11].

Algorithm : Apriori // To search all frequent itemsets Input: Database, D, of transactions; minimum support  threshold, min_sup.

Output: L, frequent itemsets in D.

Method: 1) L1={largel-itemsets}; 2) FOR{k=2; Lk-1 ?? ; k++} DO BEGIN 3) Ck=apriori-gen ( Lk-1, min_sup );  // Ck is the candidate set of k elements 4)    FOR all transactions t D DO BEGIN  //scan D for counts 5)      Ct=subset( Ck, t );  // get the subsets of t that are candidates 6)      FOR all candidates c Ct DO 7)       c. count++; 8)    END 9)    Lk={c Ck |c.count?min_sup} 10)  END 11) Answer=UkLk; Procedure apriori-gen( Lk-1 ) // generate candidate sets 1) FOR all itemset p Lk-1 DO BEGIN 2) FOR all itemset q Lk-1 DO BEGIN 3) IF p.item1= q.item1, ...,p.itemk-2= q.itemk-2,  p.itemk-1<q.itemk-1 THEN BEGIN 4) c=p?q; //join step: generate candidates 5) IF has_infrequent_subset(c, Lk-1) THEN 6) delete c; //prune step: remove unfruitful  //candidate 7) ELSE add c to Ck; 8) END 9) Return Ck Procedure has_infrequent_subset(c, Lk-1)  //use prior knowledge 1) FOR all (k-1)-subset s of c DO 2) IF s?  Lk-1 THEN 3) Return TURE; 4) Return FALSE;  4.3. Experiments  The experiment on association rules mining from the order data of online bookstore is completed by Apriori algorithm.  We set 623 sales records in database as the data source and set up the following four tables to support the algorithm.

1) Table BookName: To store book ID and book name.

TABLE 1. BOOKNAME  Column Name Data Type Length ID int 4  Name nvarchar 255  2) Table OrderList: To store book order lists  TABLE 2.  ORDERLIST  Column Name Data Type Length ID int 4  Orders nvarchar 255  3) Table RealItemList: To store frequent itemsets and  their supports TABLE 3. REALITEMLIST  Column Name Data Type Length ID int 4  ListNumber int 4 RealOrders nvarchar 255  Support int 4   4) Table ConfidenceDegreeList: To store all items above confidence  TABLE 4. CONFIDENCEDEGREELIST  Column Name Data Type Length ID int 4  NowBooks nvarchar 255 MoreBooks nvarchar 255  ConfidenceDegree float 8  Rule support and confidence respectively reflect the  usefulness and certainty of discovered rules. In our experiment, The parameter support is set to 2%  and confidence is taken to be 60%. We set 623 items in the data source of customers? orders table and get 286 association rules. Finally, part of frequent itemsets is as the figure 3 and part of  association rules is as the figure 4.

5. Conclusions  In this paper, an online bookstore was created based on Asp.net. Then an experiment analyzes customer buying habits by finding associations between the order items in database. The discovery of such associations can help retailers develop marketing strategies by gaining insight into which items are frequently purchased together by          customers. The information from the experiment can lead to increased sales by helping retailers do selective marketing and plan the bookshop space.

Figure 3. frequent itemsets   Figure 4. association rules  Acknowledgements  This paper is supported by the Project of Hebei Education Department under Grant No. 2008417.

