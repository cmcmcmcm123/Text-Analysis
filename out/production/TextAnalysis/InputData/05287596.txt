An Efficient Close Frequent Pattern Mining Algorithm

Abstract?Efficient algorithms for mining frequent itemsets are crucial for mining association rules and for other data mining tasks.  FP-growth algorithm has been implemented using a prefix-tree structure,   known as a FP-tree,   for storing compressed frequency information.  Numerous experimental results have demonstrated that the algorithm perform extremely well.  But In FP-growth algorithm,   two traversals of FP-tree are needed for constructing the new conditional FP- tree.   In this paper we present a novel FP-array technique that greatly reduces the need to traverse FP-trees,   thus obtaining significantly improved performance for FP-tree based algorithms.  We then present a very effective closed frequent pattern   algorithm which uses a variation of the FP-tree data structure in combination with the FP-array technique efficiently.  In the algorithm,   an efficient closeness-testing approach is also given for mining closed frequent itemsets.

Experimental results show that the new algorithm outperform other algorithm in not only the speed of algorithms,   but also their scalability.

Keywords- Closed FP-growth algorithm;  Closed FP-tree; sparse datasets;  FP-array

I. PREFACE The core of mining association rules is mining frequent  itemsets efficiently.  An important property of frequent itemset is ?anti-monotonicity?,   which means any subset of a frequent itemset is frequent.  When a transaction database is very dense,   i.e. when the database contains large number of long frequent itemsets,   mining all frequent itemsets might not be a good idea.  For example,   if there is a frequent itemset with size L, then all 2L nonempty subsets of the itemset have to be generated.  For overcome the difficult, scholars put forward the concept of closed frequent itemsets.

The closed frequent itemsets not only is less several orders of magnitude   than   frequent   itemsets,   but also contains complete information.  So it is widely used. Some representative research results are made.  for example  This paper proposes an effective closed frequent pattern mining algorithm at the basis of frequent itemsets mining algorithm FP-growth .  A novel FP-array technology is proposed in the algorithm,   a variation of the FP-tree data structure is used which is in combination with the FP-array.  Experimental results show that the new algorithm has very good performance.



II. CLOSED FREQUENT ITEMSETS CONCEPT Mining association rules is divided into two steps.  Fist  step:  find all frequent itemsets;   Second step:  generate strong association rules.  The second step costs much lower than first step,   so the performance of mining association rules is decided by the first step.  For reduce the number of frequent itemsets,   we give the concept of maximal frequent itemset.

Definition 1:  A frequent itemset X is called maximal if there does not   exist a   frequent itemest Y such that X?Y.

Sometimes we only want to know whether an itemset is frequent or not.  Then it is sufficient to discover only all the maximal frequent itemsets (MFI).  Many existing algorithms only mine maximal frequent itemsets (MFI). However, mining only MFI?s has the following deficiency.  From a MFI and its support,   we know that all its subsets are frequent and the support of any of its subset is not less than MFI?,   but we do not know the exact value of the support.

For generating association rules,   we do need support of all frequent itemsets.  To solve this problem,   another type of a frequent itemset,   the Closed Frequent Itemset (CFI) was proposed.

Definition 2:  A frequent itemset X is called closed if the support of all its supersets is less than the support of X.

So,   the first step of mining association rules is changed to find all closed frequent itemsets.  Mining closed frequent itemsets is divided two steps. (1) find frequent itemsets;   (2) verify that the new frequent itemset is closed.



III. CLOSED FREQUENT PATTERN MINING ALGORITHM  A. Closed  FP-tree construction We proposed an effective closed frequent pattern mining  algorithm based on FP-growth,   which is named,   closed FP-growth.  In the algorithm,   a variation of the FP-tree is used,   named Closed FP-tree.  In a Closed FP-tree,   each node in the subtree has four fields: item-name, count,   node- link and level.  Level is used for closed frequent itemset testing.

An example is used to illustrate the construction of the Closed FP-tree.  a transaction dataset is shown in table 1.  the minimum support is supposed to be 20%.  figure 1 shows FP-tree which contains all frequent itemset;   table 2 shows that each item of FP-tree?s conditional pattern base and conditional FP-tree.  the constructed Closed   FP-tree is   DOI 10.1109/ICICTA.2009.134    DOI 10.1109/ICICTA.2009.134    DOI 10.1109/ICICTA.2009.134    DOI 10.1109/ICICTA.2009.134    DOI 10.1109/ICICTA.2009.134    DOI 10.1109/ICICTA.2009.134     shown in figure 2 which contains all closed frequent itemsets.

A node x: l: c means that the node is for item x,   its level is l and its count is c.  The header table in the CFP-tree is the same as that of the FP-tree.

Start from the first FP-tree T in figure 1.  Since T contains more than one path,   a bottom-up search has to be done.  First,   because item g?conditional FP-tree contains only one path,   we get the first frequent itemset {a, g}.

Obviously it is closed,   so it is inserted into the Closed FP- tree directly.  Similarly,   for item b and e,   we can get closed frequent itemsets {d, b} and {a, c, e}.  For item f, construct f?conditional FP-tree (Tf),   because Tf contains more than one path, Closed FP-growth is recursively called, we get closed frequent itemsets {a, d, f},   {a, f}.  Similarly, we deal with item d until item a.  Finally,   we get Closed FP-tree as shown   in   figure2.

TABLE I.    A TRANSACTION SET            TABLE II.  CONDITONAL FP-TREE                   Figure 1.  FP-tree          Figure 2.  Closed  FP-tree    B. FP-array technique The core of Closed FP-growth algorithm is traversing  Closed   FP-trees and constructing new conditional Closed FP-tree after the first Closed   FP-tree is constructed   from the original database.  From a great deal of experiments we found out that about 80% of the CPU time was used for traversing Closed   FP-trees.  Therefore, the question is,   can we reduce the traversal time so that the method can be sped up?

The traversal time can be reduced by using a simple additional data structure.  For each item i in the header of a conditional FP-tree TX,   two traversals of TX are needed for constructing the new conditional FP-tree TX  {i}.  The first traversal finds all frequent items in the conditional pattern base of X {i},  and initializes the FP-tree T X {i} by constructing its header table,  The second traversal constructs the new tree T X {i}.  We can omit the first scan of TX by constructing a frequent pair array AX while building TX.  TX is initialized with an attribute AX.

Definition: Suppose the T is a conditional FP-tree, I= {i1, i2?im} is the set of items in the header table of T.  A frequent pair array of T is a (m-1)*(m-1) matrix,   where each element of the matrix corresponds the counter of an ordered pair of items in I.  Obviously, there is no need to set a counter for both item pair (ij,   ik) and item pair (ik, ij).

Therefore we only set the counters for all pairs (ij, ik) (j<k).

We explain the construction of the FP-array based on datasets shown in table 1.  After the first scan of the original database,   we get frequent items as a:5,  c:5,  d:5,  f:4,  e:2, b:2, g:2.  During the second scan of the database we will construct FP-tree T and a FP-array A.  The FP-array will save the counts of all pairs of items,   each cell is a counter of a pair of items,   and   All cells in the FP-array are initialized as 0. For example,   A [a, b] is the counter for itemset {a, b}.

During the second scan,   for each transaction,   first all frequent items in the transaction are extracted.  Suppose these items form itemset I.  To insert I into T,   the items in I are sorted according to the order in header table of T.  When we insert I into T,   at the same time A [i, j] is incremented by 1.  if {i, j} is contained in I.  For example,   for the fourth transaction, {a, c, e, f} is extracted (item h is infrequent  )  Tid Transactions 1 cdb 2 acde 3 acg 4 acefh 5 cdfk 6 adfgi 7 adfbj  item Conditional pattern base Conditional FP-tree g {(fda:1),  (ca:1)} {(a:2)} b {(fda:1),  (dc:1)} {(d:2)} e {(dca:1),  (fca:1)} ((c:2, a:2)) f ((da:2),  (ca:1),  (dc:1)) {(a:3, (d:2, c:2)), (d:1,  c:1)) d {(a:2),  (ca:1),  (c:2)} (((c:3, a:1), a:2)) c {(a:3)} {(a:3)} a Null set Null set     This itemset is inserted into T as usual,  and at the same time, A[a, c], A[a, e], A[a, f], A[c, e], A[c, f], A[e, f] are all incremented by 1.  After the second scan, FP-array A contains the counts of all pairs of frequent items as shown in table 3.

Next,   the FP-growth method is recursively called to mine frequent itemsets for each item in header table of T.

However,  now for each item i,  instead of traversing T along the linked list starting at i to get all frequent items in i?s conditional pattern base,  A gives all frequent items for i. For example, by checking the third line in the table for A, frequent items a; c; d for the conditional pattern base of f can be obtained.  Therefore,   for each item i in T the FP-array A makes the first traversal of T  unnecessary,   and T {i} can be initialized directly from A.

For the same reason,  from a conditional FP-tree TX, when we construct a new conditional FP-tree for X {i},  for an item i,  a new FP-array AX {i} is calculated.  During the construction of the new FP-tree T X {i},  the FP-array A X {i} is filled. For example,  if the conditional FP-tree T{f} is constructed, the cells of its FP-array A{f} will be the table 4.

This FP-array is constructed as follows.  From the FP-array A,  we know that the frequent items in the conditional pattern base of {f} are,  in order, a, d, c.  By following the linked list of f,  from the first node we get {a, d }:1,  so it is inserted into the new FP-tree T{f}. At the same time, A{f}[a, d] is incremented by 1.  From the second node in the linked list, {c,  d}:1 is extracted,  and it is inserted  into T{f}.  At the same time,  A{f}[c, d] is incremented by 1.  From the third node in the linked list,  {a, b}:2 is extracted,  and it is inserted into T{f}. At the same time, A{f}[a, b] is incremented by 2. Since there are no other nodes in the linked list,  the construction of T{f} is finished, and FP-array A{f} is ready to be used for construction of FP-tree in next level of recursion.

The construction of FP-arrays and FP-trees continues until the FP-growth method terminates.

TABLE III.  A           TABLE IV.  A{F}

IV. ALGORITHM  DISCRIPSION According to the FP-array technique, we present an  improved FP-growth algorithm (FP-growth# ).  T means an FP-tree, its attribute contains base, header and FP-array.

T.base contains the itemsets X,  while T is X?s a conditional FP-tree,  T.FP-array contains FP-array AX.  The algorithm detail is described as follows:  Procedure Closed  FP-growth (T,C) Input: A conditional FP-tree: T The Closed FP-tree for T.base: C Output: updated C Method: 1. If  T is single path P 2.        generate all Closed FP-tree?s from P 3.    for each Closed FP X 4.           if   not closed_checking (X,C) 5.                insert X into C 6.          else for each I in T.header { 7.                       set Y=t.base {i}; 8.                       if  not closed_checking (Y,C) 9.                           if  T.FP-array is not NULL 10.                           construct the header of Y? conditional  FP-tree from  T.FP-array 11.                         else 12.                               scan T to construct the header 13.            construct the FP-tree TY and its FP-array AY; 14.            initialize Y?s conditional Closed FP-tree CY; 15.            call Closed  FP-growth(TY,CY); 16.            merge CY with C 17.  end In the algorithm,   FP-array technology is used from line  9 to line 12.  Function closed_checking (Y, C) is called to test if Y is closed frequent itemset in line 4 and line 8.  if it is, function returns true.  Y?conditional frequent pattern tree and closed frequent pattern tree are constructed in line 14 and line 15. Closed  FP-growth is called recursively.



V. EXPERIMENT ANALYSIS We implemented Closed FP-growth and CLOSET+ by  running them on a virtual dataset.  The virtual dataset is downloaded from the website of research center of IBM [7], which contains 100, 000 transactions and 1000 items. The average transaction length is 40, and the average frequent pattern length is 10. it is a sparse dataset. The experiments were performed on a Lenevo computer with Intel 2.8 GHz Processor, and 1 GB of memory. The  operating system was Windows 2003 Server.  The algorithm is developed by VC++.  Source codes of CLOSET+ algorithm is download from [8].

Figure 3 shows that respective runtime of two algorithms.

Because of the usage of FP-array technique,  For a sparse dataset, Closed FP-growth turns out to be faster than CLOSET+.  But when the minimum support is very low, the FP-tree contains good compressibility,   thus the FP-array has no too great advantage,  Consequently, as showed in Figure 3,  for very low minimum support,  Closed FP-growth and CLOSET+ have almost the same runtime.

c 3 d 3 3 f 3 2 3 e 2 2 1 1 b 1 1 2 1 0 g 2 1 1 1 0 0 a c d f e b  d 2 c 1 1 c a        Figure 3.  Compare on sparse dataset

VI. CONCLUSIONS In this paper, we combine FP-tree with FP-array  efficiently and present an  improved closed frequent pattern mining algorithm. Experiment result indicates,   for the sparse database,  that the algorithm has more excellent performance than the FP-growth algorithm. How to apply FP-array technique to mine the data streams based on frequent itemsets,   it need further research.

