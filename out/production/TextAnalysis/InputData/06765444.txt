Big Data Approach in an ICT Agriculture Project

Abstract? The advent of Big Data analytics is changing some of the current knowledge paradigms in Science as well in Industry. Although, the term and some of the core methodologies have been around for many years, the continuous price reduction of hardware and some services (e.g. cloud computing) are making more affordable the application of these methodologies to almost any Research Area being developed in Academic Institutions or Company Research Centers. This growing popularity is also raising some concerns regarding some of its core concepts and the way Data is treated through the analysis process. It is the aim of this paper to address these concerns because big Data Methodologies will be extensively use in the new ICT Agriculture project granted by NEDO, in order to improve the efficiency and accuracy of the proposed system, therefore it is necessary to establish a common background for all the project members in which Sojo University plays a fundamental role in the improvement of the general performance of the proposed system.

Keywords?Big Data; Computer Science; Data Systems; Data Analysis

I. INTRODUCTION Big Data is currently an emerging topic among different  researchers like: computer scientists, economists, mathematicians, political scientists, bio-informaticists, sociologists and many others who are claiming that the results of Big Data analysis are richer results than standard analysis so far done in their areas. [1]  The concept behind Big Data can be simplified as the analysis of a wide variety of data volume towards the intention to find a regular pattern or data behavior that will allow making decisions in a faster and more accurate way [2].

Although, some authors consider the term Big Data poor, the term is used in science to refer to data sets large enough to require supercomputers for their analysis, even though currently, vast sets of data can be analyzed on powerful but affordable, desktop computers with standard open software tools [6]. We believe and agree that data intensive applications represent a challenge for Big Data, like the LCH (Large Hadron Collider), but for most organizations processing large volumes or wide varieties of data remains merely a technological solution unless it is tied to business/research goals and objectives [2, 3, 4].

Furthermore, Big Data is important because it refers to the analytical phenomenon that is a current trend in academia and  industry. It is the phenomenon around Big Data what we want to address [5]. There are several issues around Big Data but in this paper we will focus on: Data availability, Security, Ethics, Big Data Results? Interpretation, Data set equivalence, and Big Data main applications scenarios.

In particular for the objective of the application of Big Data in our research, it is necessary to define our research spectrum towards Big Data since the data set in which we will apply its concepts and analysis methodologies will be taken from a new project that is being implemented by NEDO in Japan in which Sojo University is an active research member in the group.

The main target of this paper is to discuss the biggest Big Data issues not only from the technological point of view, but how the decisions made using this complex group of methodologies could affect our concept of knowledge. We will apply in the best possible manner the concepts shown in this paper to our project in order to accomplish the best results but at the same time ensuring the user confidence in our system through a strong ethical behavior.



II. MAIN BI G DATA CONCERNS  A. Data Availanilty Today we use social networking for almost all of our daily  activities i.e. Google, Facebook, Twitter, Flickr, etc. These sites generate large amount of Data everyday in which it could be included our personal information (depending on the Security privacy measures we have taken on our own accounts); which generates  a problem we address later; among other information related to our activities, opinions, posts, activities, etc. This information could be retrieved using different APIs (Application Program Interface) provided by these sites in order to allow any researcher or any person to retrieve specific data from the large data set this companies have. But, the amount and the quality of the retrieved information is not the expected since these APIs are under control of the previous mentioned companies. In avergae ony 1% of the public twitts are available through these APIs [7].

Above of all, these sample data is only available to some companies and startups, but only few researchers have access to this information. The same behavior is observed in the rest of the so called ?big? companies in the Internet, making the data not representative of the Universe which it belongs.

B. Security Security is a general underestimated area in almost all  Information Technology areas, reactive could be the closest word to describe the kind of behavior companies have towards security threats all around the world. In the particular case of Big Data, Security is strongly related to the protection of user?s privacy. Private user information in the Universe of the Social Media and its relation with other accounts the users have in other sites could generate a ?pattern? or ?behavior? [6].

In the recent decade the number of attacks related to steal user?s information increased dramatically and it will continue growing since the social engineering methodologies are becoming more aggressive and companies do not change their behavior towards information security.

C. Ethics While Big Data is an emerging trend, there is a little  understanding about the ethical implications on the research being done. A very good example is the case of a research done in Harvard in 2006, in which a collection of colleagues? Facebook profiles were used to make a study of how was their friendships and interests over time [9].  The collected data was publicly released to other researches to conduct experiments on that, but they realized it was possible to de-anonymize part of the data set.

It is important that scholars reflect on the importance of accountability in order to act in ethical manner. Regarding Big Data, accountability is strongly related to their research field as well as to their research subjects.

Being accountable for a specific action will entitle to specific set of rules that must be kept in mind in any step done towards the realization of the research specific goals and objectives [2, 4]. Those characteristics make accountability a broader concept than privacy [6].

D. Big Data Results? Interpretation ?As a large mass of information, Big Data is not self  explanatory. And yet the specific methodologies for interpreting the data are open to sort of technological and philosophical debate. Can the data represent an ?objective truth? or is any interpretation necessarily biased by some subjective filter or the way the data is ?cleaned? [11]?  All researchers are interpreters of data [12, 13]. We could observe every organization has its own non-standardize way to figure data and they way this must be represented. From the technological point of view, Big Data performs its analysis using tools that are freely available in the internet such us: R, Hadoop, Pig, etc, together with some statistical analysis that could shape the date the ways the researcher want it. Big Data?s result interpretation must be done with the less possible bias in order to keep an ethical behavior towards them.

E. Data Set Equivalence Some researchers have the assumption that analytical  methodologies done in small data sets can be applied in the same manner to Big Data, which in some specific scenarios can be done, but following the general knowledge of Big Data  those analysis can not be applied. We could describe this issue in two parts:  ?Cleaning? Process of collected Data.

Once Data is collected there are plenty of  ?no interesting? data that must be ?cleaned?, but preserving the integrity of the useful Data. [8].

Metadata Generation.

Assuming that the former point was successfully accomplished, the next step is the generation of the best descriptive metadata possible. The most important points that metadata must describe are how it is recorded and measured.

Since every single research topic have its own particularities regarding to data collection, an agreement regarding which data format will be used (or if this must be created) must be decided prior to the metadata generation or, if possible, to the data collection.

Having different research scientific topics and its relation with industry, makes even more difficult the decision of the format to be used for the metadata generation. An important issue here is data provenance. It is necessary to know where the data was generated in order to trace forward and backwards its accountability [6]. Having different metadata from different sources and trying to find its correspondence with another data set represent a big challenge due to the lack of standardization showed before, and trying to find a correlation between two different data set formats could affect the granularity needed to get the best results of the applied analysis.



III. BIG DATA APPLICATIONS At present, Big Data methodologies are being applied in  very different science and industry applications, from computer science to Marketing and Industrial Management. Elsevier?s ?Research Trends? 2012 publication shows the different publications statistics found under the ?Big Data? keyword see Figure 1. We could observe that regarding scientific papers the biggest number of publications correspond to Computer Science and the least Art and Humanities [1].

Regarding industry, the most common applications of Big Data are: Supply Chain Management, Security and Access Control, Work in Process Tracking, Consumer Applications, Asset Management, Environmental Applications, Finance, Smart Grid, etc. Due to the wide range that is possible to be applied, Big Data is becoming a recurrent name in the biggest business areas in the world. A consequence of that recent popularity is the new born term ?Data Scientist? [14].



IV. CURRENT SCOPE OF ICT AGRICULTURE IN JAPAN ICT Agriculture was born in the ?Tunis Agenda for the  Information Society", and since, Japan has been playing an active role towards the design and implementation of the required technologies to be applied in ICT Agriculture [15].

Academia, as well as Company Research Centers, has been actively working on this topic due to its importance in Japan.

Researchers in Academia focus their approach towards the design of custom systems, which will allow them [16]:     0 20 40 60 80 100 120 140 160 180  Arts and Humanities  Multidisciplinary  Decision Sciences  Medicine  Materials Science  Social Sciences  Biochemistry, Genetics and Molecular Biology  Physics and Astronomy  Business Management and Accounting  Mathematics  Engineering  Computer Science  Papers    Fig. 1. Subject areas researching Big Data, Elsevier?s Research Trends  1. Field monitoring (numerical data acquisition, detailed image-capturing system)  2. Construction of a Data Acquisition System  These custom made systems, will later be linked to the Japan Meteorological Agency for further crosscheck analysis.

These are based on the farmer?s expertise, which will give the core information the system designer or integrator, which will decide the different sensors, networks and data format. Further, the generated data will be stored in Data Bases for further analysis, in which case different visualization software packages could be used.

In the case of Company Research Centers they decided to pursue a wider approach in which not only the technical approach was tackled but also the Management Area as well as the business concerns from the producer point of view and the market point of view. In this case, retailers are considered the market, and other problems are shown as well, as the increasing elderly population that affects agriculture because there is no person to transmit the accumulated know-how [17, 18].

Although, both approaches could use the advantages of Big Data methodologies, there are some issues regarding its application:  1. In the case of Academic Institutions, the need of a multidisciplinary team could increase the cost and complexity of the project, in which case, a re-engineering could be necessary in order to define specific research objectives the working group could work on, not focusing their efforts only in the ICT Agriculture but in different Big Data applications related to society  2. In the case of Company Research Institutions, although they could have much more resources than Academic Institutions, their cost is still high for a market such Agriculture  in which the instability of their yearly production, that could be affected by external factors, could badly affect their budget projections making this Company based Big Data application not affordable. Moreover, the investment made, if it?s made, must be comprehensible for the farmer or farmer community; also the farmer must understand completely the scenario in which its information will work and how it will work, something that could be difficult to achieve due to the unique characteristics of the target group.



V. THE NEDO PROJECT NEDO (New Energy and Industrial Technology  Development Organization) in Japan is the Governmental Organization in charge of the promotion of addressing energy and global environmental problems, and the enhancement of Japan?s Industrial competitiveness, through research and development, not only in Japanese territory but also abroad.

Currently, NEDO is the largest Research and Development organization in Japan that invested in different research and development projects, from Energy to the resolution of various issues [19].

In the case of this project, the main target is to create a system that could provide healthy food suggestions to the user and, if the user decides, provide as well the food he/she will require for their daily needs.

The system is a conglomerate of farmers, transportation companies and restaurants that will generate a considerable amount of data. The objective is to use Big Data analysis methodologies in order find specific patterns that could improve the efficiency and accuracy of the food suggestion system. Due to the work group in which this project is being done, each active member of the group has a different and specific task.

Therefore, the cost included for this project could be less compared to research initiatives in Academia and Company Research Institutions. So far the project is in its beginning, and we are foreseeing all the necessary details for its correct development.



VI. CONCLUSIONS AND FUTURE WORK Since the project is in its beginning stage it must consider  every Big Data aspect as well as its issues and trends.

Big Data, being a relative new trend, must be used according to the highest ethical behavior in order to ensure the user confidence towards any Big Data Application  We must ensure the privacy and data protection towards the end user to strength the link between the different actors of the NEDO Big Data project  The different data sets that will be used in the project must be standardized in order to avoid loosing granularity  The results of the analysis must be just a part of the global and multidisciplinary analysis towards the improvement of the general recommendation made by the system.

ICT Agriculture in Japan (usually consider  under the ?Sensor Networks? research) has been a trend topic due to the     diverse factors that could affect harvest and the supply chain between producers and retailers. The developed initiatives, academic and company research based ones, have common objectives towards the improvement of the quality of the harvest as well to improve the profit the producer could make if all external factors could be predicted and avoided.

Research being done in Academic centers and Companies are facing specific problems regarding to their particular characteristics. In the case of Academic research the need of multidisciplinary team and the temporal characteristic of the projects could jeopardize the continuity of their projects. In the case of Research done in Companies, their main disadvantage is the cost that the farmer must pay in order to use the service.

Farmers have been facing some difficulties regarding their business because of the weather change, price instability and constant financial problems due to foreign competition.

Therefore, an expensive service like this could be only available to big producers in which case, markets are completely ensured for a long period of time.

The current NEDO project involves different specialized members that could improve drastically the output of the mentioned system without increasing its cost or causing external issues to the farmer or to the restaurants involved.

Therefore, the NEDO project have a competitive advantage if compared to current academic or company based research.

Handling the user?s Data with the highest ethical behavior will ensure the user?s confidence on the system and it will create a reliable environment towards the success of the project.

The next step in the project is the creation of the common platform as well as the algorithm design and analysis strategy.

ACKNOWLEDGEMENTS This work was supported by New Energy and Industrial  Technology Development Organization (NEDO) in ?IT Integration-based New Social System Development and Demonstration Projects?, Grant No. 12102069.

