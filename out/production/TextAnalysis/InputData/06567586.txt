FPGA-Based HPC Application Design for Non-Experts

Abstract?In the current era of big-data computing, most non-engineer domain experts lack the skills needed to design FPGA-based hardware accelerators to address big-data problems.

This work presents bFlow, a development environment that facilitates the assembly of such accelerators, specifically those targeting FPGA-based hybrid computing platforms, such as the Convey HC series. This framework attempts to address the above problem by making use of an abstracted, graphical front-end more friendly to users without computer engineering backgrounds than traditional tools, as well as by accelerating bitstream compilation by means of incremental implementation techniques. bFlow?s performance, usability, and application to big-data life-science problems was tested by participants of an NSF-funded Summer Institute organized by the Virginia Bioinformatics Institute (VBI). In about one week, a group of four non-engineering participants made significant modifications to a reference Smith-Waterman implementation, adding functionality and scaling theoretical throughput by a factor of 32.



I. INTRODUCTION  Today?s world is one of ?information everywhere,? in which the size and availability of valuable data sets is rising rapidly, especially in the life sciences. Consider the genome of a single human individual?processing this data set involves the analysis of three billion DNA base pairs. This fact is extremely relevant given the expectation that in the near future next- generation sequencing machines will produce whole human genomes in a matter of hours [1]. This flood of information creates the need for exceptional computing performance in order to process such data sets within tolerable times.

At the forefront of big-data analysis efforts are domain experts, e.g. bioinformaticians who explore genome hypothe- ses by analyzing large quantities of genome data [2]. Such domain experts may be skilled programmers; however, their productivity?hypothesis discovery and verification rate?is lim- ited by the performance capacity of available computing re- sources. For example, the architecture of data-center class com- puting platforms is designed for speed over a general mix of problems, and efficiently applying such platforms to domain- specific data structures and algorithms such as DNA/protein sequence alignment is often not straightforward [3]. Heteroge- neous computing machines like the Convey Hybrid-Core (HC) servers have potential to address this gap, since they enable the creation of application-specific, FPGA- based accelerators tightly coupled with general-purpose processing resources (i.e.

CPUs). This tight coupling is achieved through the use of custom instructions and cache-coherent, shared memory space [4]. Unfortunately, development flows for such accelerators require extensive computer engineering and digital design expertise, rendering the use of these platforms impractical for most experts in the life sciences community.

In this work a development flow targeting hybrid-core systems such as the Convey HC servers is proposed with the purpose of aiding non-engineering domain experts in the assembly of big-data hardware accelerators. Such a flow should help such experts address ?-omics? problems on an unprecedented computational scale [2]. Since graphical design environments often provide a simpler, more intuitive mapping to parallel hardware than text-based languages, a graphical design entry tool, namely DataIO?s Azido, was selected as the flow?s front-end. Accelerators are described in Azido using a graphical, algorithmic language built on simple, canonincal primitives, and the tool facilitates development for heteroge- neous platforms within a single environment [5]. In this work, an Azido System Description (SD) was prepared to target the Convey HC architecture. This description acts as a plugin to Azido, encapsulating specifications of the HC platform organization and interface details. Most of these interfaces are abstracted to simpler, higher level structures within Azido to ease development. All abstractions are complemented with software helper routines (C/C++) that abstract the co-processor API into a framework more intuitive to the big-data user.



II. BACKGROUND  Design productivity for FPGA-based computing has suf- fered from the contemporary ASIC ?design productivity gap? and has unique needs and opportunities not adequately ad- dressed by existing FPGA design tools. In [6] Nelson et al. proposed a productivity model that exposes three key contributors to high design productivity: multi-level design reuse, high-level design abstractions, and a more interactive verification environment that increases the number of devel- opment turns per day. All of these are necessary to improving design productivity, e.g. the use of high level (above HDL) languages would significantly reduce functional simulation time, thereby increasing turns per day. Also, describing designs in a hierarchical, high level language can promote reuse by making designs more portable.

High-level synthesis is a very active area of research, and many high level design tools and approaches exist (e.g.

ImpulseC, AutoESL, SysGen, catapultC). The primary focus of these tools is to reduce time to solution for designers who have considerable computer engineering expertise. While working from a high level of abstraction and guaranteeing functionally correct output, they require design input (e.g.

pragma statements) concerning low-level hardware detail in order to produce efficient RTL output. Hence, such languages are generally inappropriate for use by those in the life- sciences community, which is comprised primarily of software programmers with no hardware design experience.

A. Convey hybrid-core architecture and design flow  The use of heterogeneous computing architectures like the Convey HC platform (CPU + FPGA) for fixed- point [7] and Nebula (CPU + GPU) for floating point algorithms [8], con- stitutes one approach to meeting big-data processing demands.

The Convey HC-1 system, which is considered in this work, consists of a commodity Intel Xeon host server extended with a custom co- processor board. This board contains four large FPGAs (Xilinx part XC5VLX330) called Application Engines (AE), each augmented with cache-coherent, high bandwidth memory access (8 memory controllers per AE). Each config- uration of the Convey co-processor is called a ?personality,? and makes application-specific functions available to the host server processor as custom instructions [9].

Convey provides a Personality Development Kit (PDK) to enable the creation of custom personalities [10]. The PDK includes a comprehensive simulation environment with bus- functional models of all interfaces, enabling verification of the complete system?host CPU software with the four co- processor FPGAs?prior to bitstream compilation. The PDK supports HDL and synthesized netlists (e.g. EDIF) as design entry formats. Final personality compilation is performed by the Xilinx FPGA design flow, while software routines for the host CPU are compiled using Convey?s cnyCC compiler. The personality can execute on up to all four FPGAs, providing significant computational capability; however, the PDK does not address the needs and skills of big-data users, most of whom have little FPGA development experience.

? Local Machine  ? Remote Shadow fax  Com pute  Cluster  Azido Desktop Environment  -Convey Hybrid Core Platform  Algorithm Design  Synthesis (HC) Simulation (x86)  Personality Compilation  System Simulation  Compilation (cnyCC)  Host Executable  EDIF to Verilog Conversion  Verilog Netlist  Run  Verilog Wrap Logic  Run-Time Interaction  Host C/C++ Application  Host Application Development  EDIF Netlist  Personality Release (cae_fpga.tgz)  Fig. 1. Movement of data within bFlow.

B. Azido hardware design environment  Azido is a graphical, object-oriented design environment based on the Implementation Independent Algorithm Descrip- tion Language (I2ADL). The tool abstracts low-level com- plexities of digital hardware design to intuitive, algorithmic objects built on its implementation-independent primitive li- brary, the CoreLib. Bitstream implementation is accomplished with Azido System Descriptions (SDs), which are script-based ?plugins? to Azido. Among several existing graphical design environments, Azido was selected for three reasons: 1) it provides a flexible design environment and core library capable of servicing many application domains at multiple levels of abstraction, 2) the System Description-based implementation framework facilitates extention of the tool to many target platforms, and 3) beyond standard schematic-capture abilities, Azido provides some dynamic features, such as automatic data typing and graphical polymorphism. These characteristics distinguish Azido from tools such as LabVIEW [11] and Simulink [12]. The former was not considered because of its constraint to specific target platforms. The latter, though capable of producing platform independent HDL, lacks most of the dynamic features mentioned above.

C. bFlow contributions  This work presents bFlow, an approach that provides a simplified and portable accelerator development flow that supports rapid prototyping of big-data algorithms in hardware by non- engineers. Design productivity is improved with a high-level graphical front-end (i.e. Azido) and an accelerated compilation process employing incremental implementation strategies facilitated by qFlow [13] and Xilinx Hierarchical Design Flow [14]. Futhermore, this framework supports the growth of the third-party ?personalities ecosystem? through the distribution of open- source accelerator implementations.

Thus, no user is limited to closed-source personalities provided by the system vendor.



III. RAPID BIO-ACCELERATOR DEVELOPMENT FLOW  This approach is divided into three efforts: 1) configuring Azido to target the Convey HC-1 platform, 2) the acceleration of the back-end compilation process, and 3) a hands-on test of the complete flow. The full design framework is shown in Figure 1. The accelerator is designed and synthesized within Azido on the user?s local machine, compiled and packaged as a HC-1 personality on VBI?s Shadowfax cluster [15], and simulated and ultimately executed on the HC server. Local simulation of individual logical blocks may be performed using Azido?s built-in x86 system description, and very rough system simulation can also be done locally by instantiating custom Component Object Model (COM) objects in place of HC memory abstractions (e.g. stream characters from a file on the desktop instead of co-processor memory). Of course, cycle- accurate system simulation is possible on the HC server.

A. HC-1 system description and software helper routines  The Azido System Description (SD) for the HC platforms can be divided into three components: 1) a communication implementer for the transfer of probe results and stimuli between Azido and the personality at run-time, 2) an abstracted     view of the co-processor dispatch interface, and 3) streaming abstractions for the memory interface.

1) Azido communication implementer: The first component is invisible to the designer, and handles communication be- tween the Azido environment and a running personality in order to enable diagnostic probing and stimuli. This is achieved using a COM object within the Azido HC-1 SD, an SSH tunnel, and several utilities on the HC platform itself. The Convey HC management ring interface is used to probe and stimulate the design in a non-obtrusive manner.

Fig. 2. Collection of Convey dispatch interface objects in Azido (left) and example usage (stream inverter) of the streaming memory abstractions (right).

2) Convey dispatch interface abstraction: The second con- sists of the Azido abstraction of the AE dispatch interface (Figure 2). Logic external to the Azido-generated netlist de- codes incoming dispatch instructions and presents a simplified interface to the Azido designer. The AE general registers are exposed as simple read/write blocks in Azido, and the co- processor custom instructions are exposed as blocks with a ?Start? output.

3) Memory streaming abstraction: Lastly, to conceal the complexities of random memory access and address arith- metic, bFlow contains a simplified streaming abstraction of the memory controllers available to each AE. These ?streamers? are comprised of ?source? and ?sink? modules, to be used to stream memory blocks in and out of memory (see Figure 2).

In addition to the SD objects available to the designer within Azido, several software routines were developed to simplify the configuration and execution of a custom personal- ity. This is done by wrapping the Convey-provided, low-level assembly routines in higher-level, C/C++ routines contained in a C++ class.

B. Extension of Smith-Waterman reference implementation  To verify the usability and productivity that bFlow attempts to realize, it was placed in the hands of four non-engineering participants of the NSF-funded Summer Institute organized by VBI. The students were asked to review [16] and gain a basic understanding of the systolic array approach to implementing the Smith-Waterman (SW) local sequence alignment algorithm [17]. The students were then given a reference SW accelerator in Azido and tasked with accelerating the design and extending its functionality. As in [16], this accelerator consisted of a large systolic array to store the short (50-200 bases) query sequence and compute the scoring matrix values as the reference (mil- lions of bases) is streamed through. The output is the value and location of the highest-scoring cell.

C. Partial implementation flows with qFlow and Partitions  Acceleration of the bitstream compilation process is achieved by two methods, Xilinx Hierarchical Design Par- titions flow [14] and qFlow [13], both incremental, partial implementation frameworks that reduce build times through high-level management of the Xilinx ISE implementation process. Both methods exploit the Convey AE architecture, which contains static, unchanging interface logic that con- sumes roughly 25% of each AE, and is reimplemented on every run of Convey?s standard compilation flow.

1) Partitions flow: The first approach taken makes use of the Xilinx Hierarchical Design Partitions flow [14]. Two par- titions were selected for this flow: (1) top partition containing the entire FPGA design and (2) the Azido-generated logic.

The first is preserved while the second is constantly updated by the Azido designer. The implementation of this flow is very simple, consisting of some Makefile extensions and a couple constraint files (*.ucf).

2) qFlow: This second utilizes a subset of the qFlow framework, a tool for acceleration back-end compilation. The tool assumes a hierarchical design methodology similar to that which the Convey PDK encourages. That is, the use of inter- face logic that is designed and configured once, experiencing few evolutions throughout the entire design process, during which the core, computational logic that is the focus of the design undergoes many evolutions. Compared to the partitions- based approach discussed above, qFlow provided generally faster compilations, but was unable to fit some of the larger designs that the partitions framework was able to.



IV. RESULTS  The participants were successful in their attempt to im- prove the performance and functionality of the reference SW implementation. Modifications included logic to maintain the index of the highest scoring alignment, and a transition from a single cell array to multiple arrays, in order to search multiple partitions of the reference sequence in parallel. The first mod- ification was simple, and included the use of Azido?s counter, maximum, multiplexer, and register objects; however, the sec- ond involved significant change to the high-level structure of the implementation. This resulted in a realized 4x bandwidth increase from 150 million to 600 million bases per second (bps), with a feasible speedup of 32x to 4.8 billion bps, given enough parallel cell arrays. These reported throughput rates are for co-processor performance only, and assume that the reference sequence(s) are available in co-processor memory.

One difficulty experienced by the students during their use of the flow was synchronous design? especially synchronizing multiple flows of data. Azido?s CoreLib contains objects to ad- dress these difficulties; however, they lack elegance, consume excessive FPGA resources, and are visually ?messy.? Another complication of the design process was timing closure. Under the standard parameterization, the Convey PDK enforces a clock rate of 150 MHz. Such a tight constraint is easily and often broken by long chains of asynchronous operations, since Azido neither analyses the design nor enforces any timing restrictions at compile time.

The performance of the alternative build flows is given in Table IV and visualized in Figure 3. Each Smith-Waterman     TABLE I. BUILD TIMES (MEAN OF THREE RUNS) FOR CONVEY?S STANDARD FLOW, THE PARTITIONS FLOW, AND QFLOW. THE SPEEDUP  OVER STANDARD FLOW IS GIVEN IN PARENTHESES. NOTE: DEVICE UTILIZATION LISTED IS THE UTILIZATION DUE ONLY TO USER LOGIC.

Design Cells Device Util. (%) Mean Build Time (min)  LUTs FFs Standard Partitions qFlow  sw 1x8 8 1.83 2.16 89.10 65.60 (1.36) 26.58 (3.35) sw 1x12 12 2.43 2.44 89.90 54.16 (1.66) 26.12 (3.44) sw 1x16 16 3.02 2.73 104.09 57.92 (1.80) 32.94 (3.16) sw 1x24 24 4.22 3.30 98.80 76.85 (1.29) 34.75 (2.84) sw 1x32 32 5.41 3.87 102.20 72.89 (1.40) 38.27 (2.67) sw 4x8 32 5.62 4.10 96.90 61.58 (1.57) 39.20 (2.47) sw 1x48 48 7.79 5.01 128.50 82.95 (1.55) 43.02 (2.99) sw 1x64 64 10.18 6.15 129.73 87.92 (1.48) 53.75 (2.41) sw 4x16 64 10.36 6.34 130.08 84.74 (1.54) 53.94 (2.41) sw 4x32 128 19.85 10.81 165.99 173.62 (0.96) 97.33 (1.71) sw 4x48 192 29.34 15.29 173.22 sw 4x64 256 38.83 19.76 208.89  ? ? ? ? ? ?  ? ? ?  ? ?  ?  ? ? ?  ? ? ?  ? ? ?  ?  ? ? ? ? ? ? ?  ? ?  ?  1x8 1x12 1x16 1x24 1x32 4x8 1x48 1x64 4x16 4x32 4x48 4x64       Bu ild  Ti m e Hmin L ? qFlow  ? Partitions  ? Standard  Fig. 3. Build times for Convey?s standard flow, the Partitions-based flow, and qFlow for twelve different variations of the Smith-Waterman Azido implementation.

configuration is named with convention sw MxN, where M is the number of parallel systolic arrays and N is the length of each array. The median speedup over the standard, Convey- provided flow for the partitions-based approach 1.51, while that of qFlow was 2.76. The last two configurations tested, 4?48 and 4?64, could not be placed into the dynamic region? the same dynamic region constraints were used for both flows.

Note the jump in build time from configuration 4?16 to 4?32 due to the increased utilization of the dynamic region.



V. CONCLUSIONS AND FUTURE WORK  This work presents bFlow, an FPGA-based big-data ac- celerator development environment significantly more usable by non-engineers than traditional design tools. Design pro- ductivity is increased by promoting object reuse, providing an high-level, abstracted graphical design environment, and reducing bitstream compile times. The framework was applied to the Convey HC-1 platform, and its usability and produc- tivity tested by participants of the NSF-funded bioinformatics Summer Institute at the Virginia Bioinformatics Institute. In a week, the participants successfully extended and accelerated a reference Smith-Waterman FPGA accelerator designed in Azido, achieving a theoretical throughput speedup of 32x and additional functionality. However, significant deficiencies in Azido?s graphical syntax, specifically the poor synchronization abstractions, proved to be major barriers to the participants? creation of complex logic.

Future research efforts include the consideration of other design front-ends, such as LabVIEW [11], exploration of memory abstractions other than simple streaming objects, and gaining an understanding of the influence of domain-specificity on the usability and performance of accelerator design flows.

