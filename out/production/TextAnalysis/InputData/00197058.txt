V4.17  Computationally efficient tracking of multiple targets by

Abstract The joint probabilistic data association (JPDA) algorithm  has been previously reported to be suitable for the problem of tracking multiple targets in the presence of clutter. Although it make few assumptions and can handle many targets, the com- plexity of this algorithm increases rapidly with the number of targets and returns. An approximation of the JPDA has been suggested in this paper. The proposed algorithm uses an analog computational network to solve the data association problem.

The problem is viewed as that of optimizing a suitably chosen objective function. Simple neural network structures for the ap- proximate minimization of such functions have been proposed by other researchers. The analog network used here offers a signifi- cant degree of parallelism and thus can compute the association probabilities more rapidly. Computer simulations indicate the ability of the algorithm to track many targets simultaneously in the presence of moderate density clutter.

1. Introduction The problem of tracking multiple targets in the presence of  clutter has derived considerable attention in recent years. The probabilistic data association (PDA) approach reduces the com- plexity of more sophisticated algorithms by focusing on the few most likely hypotheses [Bar-Shalom 19781. This is done by form- ing a validation gate around the predicted position of each tar- get and selecting only the returns inside the gate for association with the target. The algorithm assigns a probability, called the association probability, to  every hypothesis associating a return to  a target. A weighted average of the state estimates under all the hypotheses associating different returns to a particular target serves as the PDA estimate of the state of that target. The associ- ation probabilities are used as weights. Assuming the true return from a given target to be a Gaussian random vector with mean and covariance given by the predicted state vector and covari- ance matrix, the likelihood function can be evaluated under every hypothesis associating different returns to  that target. The as- sociation probabilities are computed from these likelihoods. The simplest of the PDA methods computes the association probabil- ities taking one target a t  a time, regardless of how close the other targets may be. For this reason the ordinary PDA tracker per- forms poorly while tracking crossing targets or when the targets are close to each other. This difficulty is alleviated by the joint probabilistic data association (JPDA) algorithm which computes the association probabilities from the joint likelihood functions corresponding to the joint hypotheses associating all the returns  * This work was sponsored in part by the SDIO/IST program managed by the Office of Naval Research under contract no.

N00014-85-K-0551.

to different permutations of targets and clutter points [Fortmann et a1 19831. However the increase of complexity in the computa- tion of the association probabilities may prove significant for a number of targets in moderate density clutter. There have been efforts to  approach the performance of the JPDA by imitating its properties via ad hoc association rules [Fitzgerald 19861. How- ever the effectiveness of these approximations in tracking many targets in the presence of clutter is not guaranteed.

This paper suggests the use of an analog computational net- work for computing the association probabilities. The task of finding these probabilities is viewed as a constrained optimiza- tion problem. The constraints are obtained by a careful evalu- ation of the properties of the JPDA association rule. Some of these constraints are analogous to those of the classical ?Trav- eling salesman problem? (TSP) and hence the neural network solution of this problem suggested by Hopfield and Tank [1985] is used as a reference.

2. Problem description and the PDA solution  sidered.

T dynamic systems of the following familiar form are con-  zt(k + 1) = F t ( k ) z t ( k )  + wt(k ) ,  t 5 T (1) where z is the plant or target state vector, F is a known matrix describing the dynamics of the target and w is a vector of zero- mean Gaussian noise uncorrelated to  any such noise vector a t  a different instant of time. The superscript t corresponds to the tth target and k is the index of time. The plant noise vectors w t ( k )  for different targets are assumed to be uncorrelated with each other at all instants of time k .  The measurement model is  z ( k )  = H ( k ) z t ( k )  + u ( k )  (2) where z is the measurement vector, H is a known matrix and U is a zerc-mean Gaussian noise vector independent of wt. The vectors U at different time instants are assumed to be independent of each other. The covariance matrices Q t ( k )  and R(k)  of wt(k ) and u(k), respectively, are known. The initial state of the target t ,  t = 1 , 2 , . . . , T  is assumed to  be Gaussian with known mean vector kt(O1O) and known covariance matrix Pt(O1O).

The PDA approach considers only a subset of measurements which are validated by an appropriate gate. The Zth return zr(k) is validated for the tth target if its Mahalanobis distance from the predicted location kt(klk - 1) of the tth target is less than a threshold, i .e. ,  r;(k)? = [ q ( k ) - H ( k ) k t ( k l k  - l)]%?*(k)-? . [ z l (k)  - H(k)??(klk - l)] 5 7? (3)  where W y k )  = H ( k ) P t ( k / k  - l )H(k)?+  R(k)  (4)   CH2561-9/88/0000-2152 $1.00 0 1988 IEEE    Pt(klk - 1) is the predicted error covariance for the t th tar- get and the threshold 7 is selected to produce a predetermined probability of erroneous rejection of the correct return. It is as- sumed for simplicity that the true return is a Gaussian random vector with mean H(k)?t(klk - 1) and covariance Pt(klk - 1).

A validation matrix may be formed by using (3) in the following way.

0 otherwise  if the Zth return belongs to Gt(k) [W4ll,t = { (5)  where G'(k) is the validation region of the t th target. n(k) has dimension m(k) x T where m(k) is the total number of validated returns a t  the kth instant and Z indexes the set of these returns.

The PDA state estimate is given by a weighted combination of all the estimates under different hypotheses.

m(k)  et(klk) = Bf(k)&:(klk) (6) I=O  where &f(klk) is the state estimate under the hypothesis that  the Zth validated return came from the t th target. The weight @(k) corresponds to the probability that the lth return came from the tth target. The overall covariance update is  m(k)  Pt(klk) = P,t(W,t(klk) (7) 1=0  where P:(klk) is the covariance matrix corresponding to &f(klk).

The various PDA techniques differ only in the ways they  compute the association probabilities aj(k) which must satisfy  m(k1  Bj(k) = 1, t =  1,2, . . . ,T l=O  The ordinary PDA focuses only on the returns in one validation region at  a time. If the probability of detecting the correct re- turn is PD and the probability of validating a detected return is Pa then it can be shown that [Fortmann et aZ 19831 the PDA association probabilities are  where  otherwise . I  Computation of the JPDA association probabilities is more com- plicated. Define a feasible hypothesis of joint events x(n, k) as a permutation of targets and clutter points which allows at  most one target to be associated with a given return and at  most one return to be associated with a given target. It was shown by Fortmann et a1 [1983] that the JPDA association probabilities are  t=l  1 < r < T, 0 5 I <  m(k) (11)  where j r  is the return to which the r th  target is associated under a given hypothesis and the sum is over all feasible hypotheses which allow the Zth return to be associated with the t th target.

In the above equation pf is as described in (10) except for a minor difference in the case of p: which is given by X ( l  - PD). c is a normalizing constant. (11) reflects the fact that the JPDA uses the joint likelihoods of all the returns while (9) shows that the ordinary PDA effectively uses a normalized version of the simple likelihood functions as the association probabilities.

It is useful to examine the properties of #(k) which are ex- clusive to the JPDA. I t  is unlikely that @(k) will be large if B[(k) for some r # t is also large. Furthermore, a close exami- nation of (11) reveals that @(k) is large if, in addition to pf(k) being large, there is a highly likely combination of the remain- ing targets { r  : 1 < r < T, r # t} and the remaining returns {j : 1 5. j < m(k), j # I } .  A highly likely combination is indi- cated by a large value of the product of the corresponding pf(k)s.

This property of the JPDA association probabilities was not con- sidered in the following ad hoc formula for the /3:(k)s proposed by Fitzgerald [1986].

The additional term Et p;(k) in the denominator (compare (9)) is introduced in order to reduce the chances of #(k) and P[(k), r # t being large at  the same time. The arbitrary constant po is expected to improve the performance in the presence of clutter. Another PDA scheme, called the nearest neighbor PDA (NNPDA), picks the joint hypothesis which best explains the ordinary PDA association probabilities described by (9). The resulting matrix of B(k)s consists only of 1s and Os. The task of choosing the nearest hypothesis may require an exhaustive search over all feasible hypotheses. All of the above PDA techniques can track two targets satisfactorily. However their performance in tracking more targets in the presence of moderate density clutter may be inadequate.

The complexity of the JPDA is overwhelming for relatively large T and m(k), and yet a computationally efficient substitute based on a careful understanding of its properties is lacking. The next section develops a method which is expected to serve as an effective alternative to the JPDA tracking scheme.

3. The traveling salesman problem and the JPDA The traveling salesman problem (TSP) is a well-known con-  strained multidimensional optimization problem. Given a set of n cities and the distance between each pair of them, the task is to design a closed tour for a traveling salesmhn. The length of the tour should be minimized subject to the constraints that no city should be excluded or visited twice. For an n-city TSP, there are n!/2n distinct valid tours out of which the shortest has to be chosen. Hopfield and Tank [1985] proposed a neural network solution to the TSP by using n2 interconnected neurons. They formulated the problem as that of minimizing an objective (or energy) function of the form  over all V;. They also designed an analog circuit which approxi- mately minimizes the above energy function. T;, represents the strength of connection from the output of the j t h  neuron to the     input of the i th neuron while 1, represents the externally supplied input current to the i th neuron. The evolution of the circuit is described by the differential equation  where s is the index of time, so is a time constant and U, is the input to the i th neuron. The output V, of the neuron is related to its input by a monotonically nondecreasing function g with domain (-00, CO) and range [0,1]. Although the circuit operates over the N-dimensional hypercube defined by 0 5 V, 5 1, the minima of (13) occur only at  the corners of the hypercube, pro- vided the connections are symmetric (T,J = T3,) .  In the case of TSP a propel: choice of a few design parameters causes the net- work to converge to a stable state or minimum which corresponds to one of the best few solutions.

The problem of finding the association probabilities ,B:(k) from the likelihoods p : ( k )  described in the previous section has features similar to the TSP. If the output voltages of an (m(k)  + 1) x T array of neurons are defined to be the association proba- bilities, then the columns would represent targets and the rows would indicate returns. The zeroth row would correspond to no return from a given target. The constraints of the data associ- ation problem (DAP) are as follows. Each column sum of the voltages must be unity so that (8) is satisfied. At most one large entry may be favored in every row and column in accordance with the assumptions that no two returns can come from the same tar- get and no return can come from two targets. @(k) should be large if p:(k)  is large and there is a combination of the remaining targets and returns which result in a large product of the cor- responding likelihoods. All these requirements are accomplished by minimizing the energy function  where pf is a normalized version of the p:(k)s ,  pf. is roughly the PDA association probability for the lth return and t th target (compare (9)). The ,Bi(k)s are obtained as the output 1 = O,l , .  . . , m(k),  t = 1 , 2 , - .  . ,T.  The index k is dropped for convenience. The first term achieves its minimum value of 0 when there is at most one large entry in each row.

Similarly the second term inhibits more than one return to be strongly associated with a given target. The third term biases the final solution towards a normalized set of numbers. The fourth term favors associations which have a high likelihood and the fifth term favors a highly likely combination of the remaining targets and returns. Minimizing (15) can be shown to be equivalent to minimizing the energy function  where  and I; = C + (D + E)pf + E(T - 1 - C p I )  (19)  Here 6,j is the usual Kronecker delta function. Equation (17) is equivalent to (13) except that each neuron is identified by a superscript as well as a'subscript. I t  may be observed that the strengths of connection T:; given by (18) do not depend on p : .

Thus a new network need not be designed every time a new set of likelihood functions are available. Instead, the input currents 1; as described by (19) can be easily controlled by these functions.

The equations of motion for this circuit are  r  Kt = g ( 4  (20a)  - [D + E(T - l)]qt + (D + E)pt  The coefficients A, B ,  C, D and E can be adjusted to control the emphasis on different constraints and properties. A large value of D will produce close to pf which are approximately the ordinary PDA association probabilities. A larger emphasis on A, B and C will produce the nearest neighbor solution (as in the TSP). This special case offers an attractive method of deter- mining the nearest hypothesis without explicitly examining all the hypotheses. Finally, a balanced combination of all five terms will lead to the most complete emulation of all the properties of the JPDA. A larger number of targets will only require a larger array of interconnected neurons instead of an increased load on any sequential software to compute the association probabilities.

Figure 1 shows the block diagram of a tracker which uses the p r e posed analog network to compute the association probabilities.

4. Simulation of performance The performance of the neural network PDA (NPDA) was  simulated along with those of the Fitzgerald's simplified PDA (SPDA) and JPDA. Four targets were chosen with nearly con- stant velocities in a two dimensional plane. The discretized state equation for each target is given by (1) where  2(k) = (z i: y '  y)' (21)  (22)  1 A O O  P ( k ) =  (: ; ; :) V t ,  V k 0 0 0 1  using Cartesian coordinates in two dimensions. The quantities in the right hand side of (21) indicate the position and velocity a t  time k and target t .  The sampling interval (A) was assumed to be 0.5 second. The plant noise wt(k )  is assumed to be of the form [Fortmann 19831     where (wL(k) wi(k))?  is a vector of independent Gaussian ve- locity noises with associated variances (~:(k))~ = ( ~ i ( k ) ) ~  = 0.0009 km?s-? V t ,  V k which correspond to a standard devia- tion of a t  least .04 times the mean velocity. These uncertainties allow for small changes of the target velocity. It was assumed that only position measurements are available so that  1 0 0 0 H ( k ) = ( o  0 1 0)  for all k. The measurement noise covariance matrix is  R(k) = diag(.0225, .09)  assuming all the measurement noise to  be uncorrelated. The probability of validation Pc and the probability of detection Po were both assumed to  be 0.95. The corresponding threshold of the Mahalanobis distance, as obtained from the table of xi dis- tribution is 7 = m. This determines the size of the validation gate. A uniform clutter density? of about 0.05 km-2 was chosen.

This produced on the average 0.35 clutter point per validation gate.

Equations (20a) and (20b) represent the evolution of the states of the analog circuit for the neural network solution of the DAP. The function g(u:) in (20a) was defined to be [Hopfield and Tank 19851  Y t  = g(u;) = 1 (1 + tanh 2) 2 (23)  In order to avoid bias to any particular set of stable states, the initial states were chosen to  be such that they approximately produce cE_bk) Yt  = 1 V t initially. It is known [Hopfield and Tank 19851 that the addition of a random noise to the initial values enhances convergence. Accordingly the initial states were chosen to be  where Suf is a random variable having uniform distribution over [-O.lu,, O.lu,]. The constant U,, was chosen to  be 0.02 to pro- duce a moderate rate of convergence. The differential equation (20b) was approximated by a difference equation with stepsize 0.0005 s. so was selected to be 1 s. An experimentally deter- mined limit of 100 iterations was imposed on the recursive dif- ference equation. The 100th iterates xt(l0O), 15 m(k), t 5 T are expected to  be close to the steady state solutions of (20b).

These values were normalized for each t to  ensure strict compli- ance with the constraint (8). The constants A, B, C, D and E were also chosen experimentally to produce a stable operating point. The values A = 1, B = 40, C = 1000, D = 30 and E = 5 appeared to be suitable for two to four targets.

Figure 2 shows the ability of the NPDA and the failure of the SPDA to track four targets in the presence of moderate density clutter. The SPDA association probabilities were computed from (12) with po = 0. No non-zero value of po appeared to improve its performance. The performance of the NPDA is equivalent to that of the JPDA in terms of rms position and velocity errors [Sengupta and Iltis 19871.

5. Conclusion Computation of the association probabilities by an analog  network appears to be a viable alternative to the JPDA. I t  out- performs the SPDA by accurately emulating all the properties  of the JPDA. The coefficients of the function E D A ~  have to  be chosen suitably for a given number of targets and returns. Com- puter simulations indicate that a suitable operating point may be obtained for a range of complexity of the problem. The ana- log network is structurally simple and there is a high degree of parallelism inherent in it. A DAP of higher complexity will only require a larger array of neurons instead of increased burden on a sequential algorithm such as the JPDA. In spite of the necessity of D/A and A/D conversions, these attractive features may ren- der the NPDA useful for tracking a reasonable number of targets in the presence of moderate density clutter.

