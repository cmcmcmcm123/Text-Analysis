Maintaining High Utility Pattern Trees in Dynamic Databases

Abstract?We have previously proposed the high utility pattern (HUP) tree for utility mining. In this paper, we further handle the problem of maintaining the HUP tree in dynamic databases.

A HUP maintenance algorithm has thus been proposed for efficiently handling new transactions. The proposed algorithm can reduce the cost of re-constructing the HUP tree when new transactions are inserted. Experimental results also show that it indeed executes faster than the batch maintenance algorithm and generates nearly the same tree structure as the batch one.

The proposed maintenance algorithm can thus achieve a good trade-off between execution time and tree complexity.

Keywords: utility mining; maintenance; HUP tree; high utility pattern.



I.  INTRODUCTION Mining frequent itemsets from a transaction database is a  fundamental task for knowledge discovery. In the past, numerous methods were proposed to discover frequent itemsets [1][2][3][4]. The approaches could be divided into two categories: level-wise approaches and pattern-growth approaches. The Aprori algorithm [1] was first proposed to mine association rules based on a level-wise processing way.

The FP-growth algorithm was then proposed to construct a compressed tree structure and to mine rules based on it [9].

In the above approaches, it treats all the items in a database as binary variables. In this case, frequent itemsets just reveal the occurrence importance of the itemsets in the transactions, but do not reflect any other implicit factors, such as prices or profits.

Utility mining [12][13] was thus proposed to partially solve the above problem. It may be thought of as an extension of frequent-itemset mining with sold quantities and item profits considered. Liu et al. presented the two-phase algorithm for fast discovering all high utility itemsets [10] based on the downward-closure property. Lin et al. proposed an HUP-tree structure to construct a tight tree structure and keep related mining information, such that the database scan time can be greatly reduced. The HUP tree is a little like the FP-tree structure except that each node has been attached an array (quan_Ary) to keep the quantities of its prefix items in the path for later mining process. The HUP-growth mining  algorithm was proposed to derive high utility itemsets from the HUP-tree structure.

In the HUP-tree approach, all transactions are processed in a batch way. The previously constructed HUP-tree structure may not be valid when the new transactions are inserted into the database incrementally. In this paper, an incrementally updated HUP (abbreviated as iHUP) maintenance algorithm is thus proposed. It modifies the batch procedure of constructing the HUP-tree structure for incrementally mining, which makes the tree update easier.

Experimental results also show that the proposed iHUP maintenance algorithm has a better performance than the batch HUP algorithm.



II. RELATED WORKS In this section, some related researches are briefly  reviewed. They are the FUP (fast updated) algorithm and the HUP-tree (high utility pattern tree) algorithm.

A. The FUP algorithm One common type of data mining is to derive association  rules from transaction data, such that the presence of certain items in a transaction will imply the presence of some other items [1][2][3]. In real-world applications, transaction databases usually grow over time and the association rules mined from them must be re-evaluated. Considering an original database and some new inserted transactions, the following four cases illustrated in Figure 1 may arise [6][7]:    Original database  New transactions  Large Itemsets  Small Itemsets  Large Itemsets  Small Itemsets  Case 1 Case 2  Case 3 Case 4   Figure 1.  Four cases when new transactions are inserted into an existing database.

DOI 10.1109/ICCEA.2010.67     Since itemsets in Case 1 are frequent (large) in both the original database and the new transactions, they will still be frequent (large) after the weighted average of the counts.

Similarly, itemsets in Case 4 will still be non-frequent (small) after the new transactions are inserted. Thus Cases 1 and 4 will not affect the final frequent (large) itemsets. Case 2 may remove existing frequent (large) itemsets, and Case 3 may add new frequent (large) itemsets. Based on the FUP approach, the cases 1, 2 and 4 are more efficiently handled than conventional batch mining algorithms.

B. The HUP-tree algorithm In association-rule mining, only binary itemsets are  considered in a database. In real-world applications, however, frequent itemsets just reveal the occurrence of itemsets in transactions, but do not reflect any other important factors, such as prices or profits. High profitable products but with low frequencies may thus not be found in traditional association-rule mining. Yao et al. proposed the utility model by considering both quantities and profits of items [12][13].

Chan et al. proposed the topic of utility mining to discover high utility itemsets [5]. Liu et al. then presented a two-phase algorithm for fast discovering high utility itemsets by adopting the downward-closure property [10] and named his approach as the transaction-weighted-utilization (TWU) model. Lin et al. proposed a high utility pattern tree (HUP- tree) algorithm [11], which extended from the FP-growth approach, to mine the high utility itemsets from a tight tree structure. It integrated the two-phase approach [10] and the FP-tree concept [9] to efficiently and effectively find high utility patterns. As an example, the quantitative database in Table 1 is used to show how to construct the HUP tree. It consists of 10 transactions and 6 items, denoted A to F.

TABLE I.  THE QUANTITATIVE DATABASE  TID A B C D E F 1 3 2 0 3 0 0 2 2 0 0 4 2 0 3 3 0 5 0 0 3 4 1 0 3 0 1 2 5 1 0 0 3 2 0 6 1 2 0 4 0 0 7 2 3 2 0 1 1 8 0 0 0 0 0 2 9 0 0 3 3 0 0 10 3 0 0 4 0 0   Assume the minimum high utility threshold is set at 35%.

Also assume that the predefined profit values for the items are defined in a utility table shown in Table 2.

In the HUP mining algorithm, it first calculates the transaction utility of each transaction to find the high transaction-weighted 1-itemsets. The algorithm then keeps only the high transaction-weighted 1-itemsets in the transactions and sorts them according to their transaction frequencies. The updated transactions are then used to build the HUP tree tuple by tuple. For the above example, the high  transaction-weighted 1-itemsets with their value are found as {A:2725, B:1540, D:2080, E:1483}, each of which has its transaction-weighted utilization larger than or equal to the minimum high utility value 1022.35. Each transaction in the quantitative database is then updated to remove the items which are not the high transaction-weighted 1-itemsets. After that, the updated transactions are used to construct the high utility pattern tree (HUP tree) tuple by tuple. The final results of the above example are then shown in Figure 2.

TABLE II.  THE UTILITY TABLE  Item Profit ($) A 3 B 150 C 1 D 50 E 100 F 20     {root}  A:2728  D:1930  A  B:962  Header_Table Item twu  A 2728  D 2083  E 1483  B 1540  A D  A 4 D 7 B 4  E:759 A 3 D 7 E 4  E:724 A 3 E 2  B:578 A 2 E 1 B 3  D:153 D16     Figure 2.  The final constructed HUP tree.

In the HUP tree, each node has to store the transaction- weighted-utilization of the item as well as the quantities of its preceding items (including itself) in the path. An array called quan_Ary is then attached to a node to keep those values. After the final HUP-tree is constructed, the HUP- growth mining approach is then executed to derive the high utility itemsets from the tree [11].



III. THE PROPOSED INCREMENTAL UPDATED HUP MAINTENANCE ALGORITHM  To process the incrementally updated HUP (abbreviated as iHUP) maintenance algorithm, an HUP tree must be built in advance from the original quantitative database before new transactions come. When new transactions are inserted, the proposed maintenance algorithm will then process them to maintain the HUP tree. The proposed approach first partitions the items into four parts according to whether they are high transaction-weighted (indicated as large) 1-itemsets or non-high transaction-weighted (indicated as small) 1- itemsets in the original database and in the new transactions.

Each part is then processed by its own procedure. The Header_Table and the HUP tree are correspondingly updated whenever necessary. The details of the proposed iHUP maintenance algorithm are described below.

The incrementally updated HUP maintenance algorithm: INPUT: An old database D, an already built HUP tree with  its corresponding Header_Table, a minimum high utility threshold ? , an already calculated total transaction utility in the original database, and a set of d new transactions.

OUTPUT: A new HUP tree for the updated database.

STEP 1: Calculate the utility value ujk of each item ij in  each new transaction tk as ujk = qjk*pj, where qjk is the quantity of ij in tk and pj is the profit of ij.

Accumulate the utility values of all the items in each transaction tk as the transaction utility tuk for tk. That is:  , ?  =  = m  j jkk utu  where m is the number of items.

STEP 2: While executing the above step, also find the  occurrence frequency f(ij) of each item ij in the new transactions.

STEP 3: Calculate the transaction-weighted utilization (abbreviated as Sd(ij)) of each item ij as the summation of the utilities of the new transactions which include ij. That is:  .)( ? ?  = kj ti  kj d tuiS  STEP 4: Check whether the value of Sd(ij) is larger than or equal to the minimum high utility value  ? ?dt  k k  tu*?  in the new transaction database.

STEP 5: For each item ij which is large both in the new transactions and in the original database (appearing in the Header_Table), do the following substeps (Case 1): Substep 5-1: Set the updated transaction- weighted utilization SU(ij) of item ij in the entire updated database as:  SU(ij) = SD(ij) + Sd(ij),  where SD(ij) is the transaction-weighted utilization of item ij in the Header_Table (appearing in the original database) and Sd(ij) is the transaction- weighted utilization of item ij in the new transactions.

Substep 5-2: Update the value of ij in the Header_Table as SU(ij).

Substep 5-3: Put ij in the set of Insert_Items, which will be further processed in STEP 10.

STEP 6: For each item ij which is small in the new transactions but large in the original database (appearing in the Header_Table), do the following substeps (Case 2):  Substep 6-1: Set the updated transaction- weighted utilization SU(ij) of item ij in the entire updated database as:  SU(ij) = SD(ij) + Sd(ij).

Substep 6-2: Check whether the value SU(ij) of item ij satisfies the following condition:  ?? ??  +? dt  k DT  kj U  kk  tutuiS )(*)( ? ,  where Tk and tk mean the k-th transaction in the original database and in the new transactions, respectively. If item ij satisfies the above condition, it will still be large after the database is updated; then update the value of ij in the Header_Table as SU(ij) and add ij to the set of Insert_Items; Otherwise, item ij will become small after the database is updated; remove ij from the Header_Table and from the HUP tree, connect each parent node of ij directly to the corresponding child node of ij, and update its corresponding child node of ij in the path to remove ij of its attached array quan_Ary.

STEP 7: For each item ij which is large in the new transactions but small in the original database (not appearing in the Header_Table), do the following substeps (Case 3): Substep 7-1: Rescan the original database to find out each transaction utility of item ij in the original database, calculate the transaction- weighted-utilization of item ij and set it as SD(ij).

Substep 7-2: Set the updated transaction- weighted utilization SU(ij) of item ij in the entire updated database as:  SU(ij) = SD(ij) + Sd(ij).

Substep 7-3: Check whether the value SU(ij) of item ij satisfies the following condition:  ?? ??  +? dt  k DT  kj U  kk  tutuiS )(*)( ? ,  where Tk and tk mean the k-th transaction in the original database and in the new transactions, respectively. If item ij satisfies the above condition, it will be large after the database is updated; add item ij both in the set of Insert_Items and in the set of Rescan_Items.

STEP 8: Sort the items in the Rescan_Items in the descending order of their transaction frequencies f(ij) and sequentially insert them with their SU(ij) values to the end of the Header_Table.

STEP 9: For each original transaction with an item ij existing in the Rescan_Items, do the following substeps: Substep 9-1: If an item ij in the currently processed k-th transaction has appeared at the     corresponding path of the HUP tree, add the transaction utility tuk (calculated in Substep 7-1) to the node ij as its accumulated value. Besides, add the quantities of the prefix items of ij to the corresponding elements of the quan_Ary array in the node, which stores the accumulated quantities of the prefix items of ij.

Substep 9-2: Otherwise, add a node with ij to the end of the corresponding path and set the utility value tuk in the k-th transaction as its value in the node. Besides, set the quantities of the prefix items of ij in the transaction to the corresponding elements of the array (quan_Ary) in the node. At last, insert a link from the node of ij in the last branch to the current node. If there is no such branch, insert a link from the entry of ij in the Header_Table to the current node.

STEP 10:For each new transaction with an item ij existing in the Insert_Items, do the following substeps: Substep 10-1: If an item ij in the currently processed k-th transaction has appeared at the corresponding path of the HUP tree, add the transaction utility tuk to the node with ij in the path as its accumulated value. Besides, add the quantities of the prefix items of ij to the corresponding elements of the quan_Ary array in the node, which stores the accumulated quantities of the prefix items of ij.

Substep 10-2: Otherwise, add a node with ij to the end of the corresponding path and set the utility value tuk in the k-th transaction as its value in the node. Besides, set the quantities of the prefix items of ij in the transaction to the corresponding elements of the array (quan_Ary) in the node. At last, insert a link from the node of ij in the last branch to the current node. If there is no such branch, insert a link from the entry of ij in the Header_Table to the current node.

After STEP 10, the final updated HUP tree is then  constructed. Note in STEP 9, a corresponding path means a path in the tree which corresponds to the items to be processed in a transaction according to the order of items appearing in the Header_Table. Besides, STEPs 9 and 10 can be simultaneously done in a database scan. Below, an example is given to illustrate the proposed iHUP maintenance algorithm when new transactions are inserted.



IV. AN EXAMPLE In this session, an example is given to illustrate the  proposed incrementally updated HUP (iHUP) maintenance algorithm when new transactions are inserted. The original database and its already constructed HUP tree are shown in Table 1 and Figure 2, respectively. Table 3 shows the new transactions to be inserted to the original database in Table 1.

There are 5 new transactions. The items are the same as those in Table 1.

TABLE III.  FIVE NEW INSERTED TRANSACTIONS  TID A B C D E F 11 3 0 4 8 0 0 12 3 0 3 7 0 0 13 3 0 2 6 0 0 14 1 0 0 0 1 1 15 4 3 0 0 0 0   Assume the minimum high utility threshold is also set at  35%. The minimum high utility value was calculated as (2921*0.35) (= 1022.35). The utility value of each item occurring in each new transaction in Table 3 is calculated.

The transaction-weighted utilizations of each item in the transactions are summed together. After that, all the items are then divided into four cases and are then processed in their individual ways. The final updated HUP tree is thus shown in Figure 3.

{root}  A:4399  D:3016  A  B:962  Header_Table Item twu  A 4399 D 3169 B 2002 C 2037  A D  A 4 D 7 B 4  B:1040 A 6 B 6  D:153 D30    C:220  C:578  C:153  A 2  C 2 B 3  A 4 C 8  D 3 C 3  C:1086 A 9 D C 9    Figure 3.  The final updated iHUP tree.



V. EXPERIMENTAL RESULTS A real dataset called chess was used in the experiments  [8]. The values of quantity and utility were assigned to each purchased item in the database. The range was set at from 1 to 20 for quantity, and from 1 to 200 for utility, respectively, in uniform distribution. Experiments were then made to show the execution time of the batch HUP algorithm and the proposed iHUP maintenance algorithm, which included the tree-construction phase and the mining phase. The first 3,000 transactions were extracted from the chess database to construct an initial HUP-tree structure. The value of the minimum support thresholds were set at 70% to 90% for the two algorithms, with 5% increment each time. The next 1% of the first transactions, which was 30, was then used in incremental mining. The results for the execution time of the two algorithms are shown in Figure 4.

From Figure 4, it is obvious to see that the proposed iHUP maintenance algorithm has a better performance than the batch HUP mining algorithm in five different minimum utility thresholds. Besides, the number of tree nodes for the HUP-tree and iHUP-tree is also compared. The results are shown in Figure 5.

From Figure 5, it can be seen that the two algorithms generated nearly the same size of trees. The effectiveness of the iHUP maintenance algorithm is thus acceptable.

Figure 4.  The comparsion of execution time.

Figure 5.  The comparsion of node numbers.



VI. CONCLUSION In this paper, an incrementally updated HUP  maintenance algorithm is proposed to efficiently and effectively handle incremental mining. When new transactions are added, the proposed iHUP maintenance algorithm processes them to maintain the HUP tree.

Experimental results show that the proposed algorithm executes faster than the batch HUP mining algorithm.

Besides, the number of tree nodes is also evaluated to show that the proposed algorithm generates nearly the same tree  structure as the HUP tree. The proposed approach can thus achieve a good trade-off between execution time and tree complexity.

