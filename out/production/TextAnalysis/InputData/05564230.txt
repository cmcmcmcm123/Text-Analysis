

Abstract?Existing algorithms for support-based association rule mining (ARM) can not discover the itemsets which are scarce but have high utility values, while utility-based association rule mining (UBARM) can not discover the itemsets whose utility values are not high but the product of the support and utility of the same itemset (defined as motivation) is very large. This paper proposes motivation-based association rule and a down-top algorithm called HM-miner to discover all high motivation item-sets efficiently. By integrating the advantages of support and utility, the new measure, i.e., motivation can measure both the statistical and semantic significance of an itemset. HM-miner adopts a new pruning strategy, which is based on the motivation upper bound property, to cut down the search space.



I. INTRODUCTION Upport-based association rule [1]-[3] supposes that users are interested only in the frequent itemsets. It uses support to measure the importance of itemsets, and thus can not  find the itemsets with a low support but a high utility. On the other hand, the utility-based association rule [4]-[6] supposes that users are interested only in the itemsets which can bring about high utility. it uses utility to measure the importance of itemsets and aims at discovering all high-utility itemsets, ignoring all of the low-utility but high support itemsets.

Although the itemsets are not of high utility, the product of the support and utility are high enough to cause users? interest, and the rules generated by the itemset may contain a very attractive decision scheme. Therefore, a motivation-based association rule and a bottom-up mining algorithm are proposed.

The expectancy theory [7] holds that motivation is a kind of evaluating and selecting process. The motive force (i.e.

motivation) for one to perform an action depends on their assessment of the value (i.e. valence) resulting from the action and the estimation (i.e. expectancy) of the possibility to achieve the expected target. In other words, the amount of motivation depends on the product of valence and expectancy, namely,  expectancy   valence motivation ?=                  ?1? According to the above theory, only those itemsets whose  support (i.e. expectancy) and utility (i.e valence) are simultaneously at high levels can produce a powerful motivation. The motivation-based association rule employs motivation (the product of support and utility) to measure the   Xianshan Zhou is with the College of computer science and technology,  Yangtzeu University ,Jingzhou, China (e-mail:xszhou@yangtzeu.edu.cn).

Liang Wang is with the Information Certer of Jingzhou Municipal Bureau  of Environmental Protection,Jingzhou,China (e-mail: wyh_0209@126.com ).

Guangzhu Yu is with the College of Information Science and Technology, Donghua University,Shanghai, China (e-mail: ygz@mail.dhu.edu.cn).

importance of itemsets, and its major task is to discover all high-motivation itemsets.



II. THE THEORETICAL BACKGROUND  A. Concepts and definitions Suppose that I={i1, i2, ?, im} is the set of items and T={t1,  t2, ?, tn} is the transaction database. Every transaction tq ( Ttq ? ) has its only number Tid, all the items contained in tq constitute one subset of I, denoted as Itq ? . Suppose S is a subset of I, if qtS ? , we say that tq contains S.

Definition 1: The transaction-set of itemset S, denoted as Ts, is the set of all transactions containing S, namely,  },|{ TttStT qqqs ??=                                      (2) Definition 2: The transaction-utility of item ip, denoted  as )t,i(u qp , is the utility (i.e. efficiency) provided for users by item ip when transaction tq happens. This paper supposes that the utility in question is the economic utility. In the transaction database, the transaction-utility of the item is the product of its unit profit and sales volume.

Definition 3: The utility of item ip in itemset S, denoted as u (ip,S), is the sum of all the transaction-utility of item ip, namely,  ? ?  = sq Tt  qpp )t,u(iS),u(i                                          (3)  Definition 4: The utility of itemset S, denoted as )S(u , is the sum of all the utilities of items in itemset S, namely,  )S,i(u)S(u Si  p p  ? ?  =                                           (4)  Definition 5: If utilmin)S(u ? , then S is a high utility itemset. Otherwise, S is a low utility itemset. Minutil is the threshold specified by users.The utility-based associaiton rule mining is to discover all high utility itemsets.

Definiton 6: The motivation of itemset S, denoted as )S(m , is the product of the support )S(s  and utility of the  itemset, namely, )S(u)S(s)S(m ?=                                                (5)  Definition 7: A motivation-based association rule is an implication form like ?X?Y?, which satisfies the following conditions at the same time:  1. The support of the association rule ?X?Y? is greater than or equal to threshold minsup specified by users, namely,  supmin)YX(s ??                                            (6) 2. The confidence of the association rule ?X?Y? is greater  than or equal to threshold minconf, namely,  Motivation-based Association Rule Mining Xianshan Zhou, Liang Wang and Guangzhu Yu  S  August 13-15, 2010 - Dalian, China          confmin )X(Support  )YX(Supportconf ?= ?               (7)  3. The utility of itemset ?X?Y?, denoted as u(X?Y), is greater than or equal to threshold minutil, namely,  utilmin)YX(u ??                                            (8) 4. The motivation of itemset ?X?Y? is greater than or  equal to the threshold minmotivation, namely, motivationmin)YX(m ??                           (9)  The item sets satisfying the conditions 1, 3 and 4 are called high motivation itemsets.

B. The relevant research Support and utility are interesting measures. Support  reflects the statistic feature of a itemset and it is a kind of objective measure. Its weakness is its being unable to reflect the itemset?s semantic feature. On the contrary, utility reflects the itemset?s semantic feature and it is a kind of subjective measure [8].What determines one?s interest is always a combination of subjective and objective factors. Therefore, the association rule mining model depending either on support or on utility to measure the importance of itemsets is inadequate to the expression of one?s interest.

Reference [3] formulates a target-oriented and utility-based associaition rule mining model labelled as Model OOA. OOA employs support and utility at the same time to measure the importance of itemsets and thus it can discover high utility frequent itemsets in the database.

However, the model and its OOApriori algorithm formulated by the author are different from our research target in the following aspects: 1) The OOA association rule does not require that the motivation of itemsets is greater than a certain threshold; 2) the support threshold of the OOA model must be set as relatively great, otherwise too many frequent itemsets will be produced. Therefore, the OOA model will lose some models whose support is not high but whose motivation is strong. As for the motivation-based associaition rule mining, the support threshold minsup and utility threshold minutil are often small. Minor rules are removed mainly by the motivation threshold minmotivation. The purpose for setting up minsup and minutil is to filter some useless models which are highly frequent but of low utility or those which are of high utility but accidental.

The ninth reference of this paper employs ?general utility? to measure the importance of itemsets [9]. In definition, the general utility )S(gu  of the itemset S is equal to the weighted sum of its support and utility, namely,  )S(u)1()S(s)S(gu ??+?= . ?General utility? reflects the itemset?s semantic and statistic features but the determination of the weight ?  is relatively random. The meaning of the concept is not as straightforward as that of motivation. Based on probability and management, motivation is easier to understand.

The fourth reference of this paper formulates Umining, a utility-based association rule mining algorithm, which provides the basis for my research.



III. A BOTTOM-UP MINING ALGORITHM  A. The features of motivation constraint The fourth reference indicates that utility constraint is not  of montone and anti-montone, nor convertible and succinct.

According to the definition of motivation, motivation constraint is not of montone and anti-montone, nor convertible and succinct.

Definition 8: Suppose that Sk is a k-itemset (S contains k items). And then all the subset of Sk whose length is (k-1) constituting a set }SS|S{L k1k1k1k ?= ??? . Obviously,  k|L| 1k =? .

Defintion 9: All Sk-1 containing ip forms a new set  }LS,Si|S{L 1k1k1kp 1k1k  ip ????? ??= . Obviously,  1k|L| 1kip ?= ? .

For example, a 4-itemset is S4=ABCD. According to the definition, L3={ACD ? ABD ? ABC ? BCD}, and  ABC} ,ABD ,{ACDL3A = .

Theorem 1 (motivation?s upper bound feature):  Suppose that )S(m k  is the motivation of k-itemset Sk, then the following formula is tenable:  1-k )m(S  )m(S 1-k1-k LS 1-k  k ? ??                            (10) Prove: suppose that )S(u k  is the utility of the k-itemset  Sk. According to the second theorem (i.e. utility?s upper bound feature) of the fourth reference, the following formula is obtained:  1-k )u(S  )u(S 1-k1-k LS 1-k  k ? ??                  (11) both sides of Formula (11) are multiplied by the support  s(Sk), then the following formula is derived:  1-k )u(S  *)s(S)u(S*)s(S 1-k1-k LS 1-k  kkk ? ??      (12) According to s(Sk) ?s(Sk-1), the above formula can be  written as:    1-k )m(S  1-k )S(s)u(S    1-k )u(S  *)s(S)m(S  1-k1-k1-k1-k  1-k1-k  LS 1-k1-k  LS 1-k  LS 1-k  kk  ??  ?  ??  ?  =?  ? (13)  The end.

Definition 10: The candidate set of Sk is denoted as Ck-1,  which is the set of the (k-1)-subset of Sk, namely, 1k1k LC ?? ? .

Defintion 11: The motivation upper bound of Sk, denoted as )S(b km ,is defined as:  1|C| )S(m  )S(b 1k CS  1k k  m 1k1k  ? = ?  ? ?? ??                             (14)          Where C k-1 in Formula (14) is the candidate itemset of Sk and |Ck-1| is the cardinal number of Ck-1.

Theorem 2 (pruning strategy): If every (k-1)-itemset )CL(S 1k1k1k ??? ??  is a low-motivation itemset and  motivationmin)S(b km ? , then Sk is of low motivation, namely, motivationmin)S(m k ? .

Prove: Since every )CL(S 1k1k1k ??? ??  is a low-motivation itemset, there is the following formula:  ?? ?????? ????  ?  )CL(S)CL(S  1k  1k1k1k1k1k1k  motivationmin)S(m ?        (15)  According to Theorem 1, namely Formula (10), the following formulas can be obtained:  1-k ation1)minmotivk(  ionminmotivat)(S       //b   1-k  ionminmotivat|)C|k(e1)minmotiv|C(| 1-k  ionminmotivat|)C|k()1)b(S|C(| 41Formula  tocording       //a   1-k  ionminmotivat|CL|)(S1)b|C(| 1-k  ionminmotivat|CL|)m(S 51Formula  toccording       //a   1-k  ionminmotivat)m(S 1-k  )m(S)m(S 1-k  )m(S  1-k )m(S  )m(S  k m  1k1-k  1kk1-k  1k1kk m  1-k  1k1k S  1-k  S )L(S 1-k  S )L(S 1-k1-k  ))L((S 1-k  LS 1-k  k  11-k  11-k 11-k1-k  11-k 11-k1-k  11-k11-k1-k1-k  ??  ?+??  ?+?=  ?+? ?  ?+ ?  + ?  + =  =?  ?  ?  ??  ?? ?  ? ??  ? ??  ???  ?  ? ?  ? ?  ??  ?  ? ?  ? ?  ??  ?  ?  ??  ??  k  k k  k k  kk  C  C C  C C  CC    Therefore, ionminmotivat)S(m k ? . The solution has been completed.

B. The algorithm Based on the above pruning strategy, we have formulated  an algorithm like Umining which is labelled HM-Miner (i.e.

high motivation itemset miner). The HM-Miner algorithm adopts a bottom-up search strategy, generating the k-itemset from the (k-1)-itemset repeatedly and calculating the support, utility and motivation of the candidate set.

With Inputs as Database T,Threshold minsup, minutil, minmotivation and outputs as the set of high motivation itemsets, i.e., HM, the procedure can be described as below:  HM-Miner(Database T,Threshold minsup, minutil, minmotivation)  {  I=scan(T); C1=I; k =1; Ck=CalculateAndStore(Ck,T) H=Discover(Ck, minsup,minutil,minmotivation); While (|Ck|?0) { k=k+1; Ck=Generate(Ck-1,I); Ck =Prune(Ck, Ck-1, minsup,minutil,minmotivation); Ck = CalculateAndStore(Ck,T); HM=HM?Discover(Ck, minsup,minutil,minmotivation); } Return HM; }  The function Scan scans Database T to find the set I of all  items; function CalculateAndStore calculates the support, utility and motivation of every k-itemset in Ck and store them in the corresponding data structures; function Dicover finds the high-motivation itemsets in Ck which satisfy the conditions; function Generate generates the potential candidate k-itemsets from (k-1)-itemsets in Ck-1; and function Prune calculates motivation upper bound of every k-itemset in Ck, and determine whether it is pruned out or not according to the motivation value, support and utilit. If the motivation upper bound of kCc?  is less than the threshold minmotivation, then it is pruned off from Ck. Only the candidate itemsets remaining in Ck require a precise calculation of motivation. Different from Umining, HM-miner makes use of the downward closure property of frequent itemsets, utility?s upper bound property and motivation?s upper bound pruning property at the same time.



IV. THE EXPERIMENT AND ANALYSIS The experiment has been conducted on the Tidings server  XEON. The main frequency of the CPU is 2.4G; the memory is 2G; Windows 2003 runs; the program is coded with Delphi 7. The dataset used by the experiment is T20.I6.D100Ok, generated by the IBM data generator. the number of items is 1k. There are only 0 and 1 in the dataset, respectively standing for whether a certain item appears in transaction and has no utility value Therefore, the random Delphi function ?RandG? is used to generate random values (Gaussian distribution) to simulate the unit utility of the items in transactions. Module 100 of transaction number TID (TID mode 100) is used to express the sales volume. In this way, the utility of a certain item in a certain transaction is equal to the item?s sales volume multiplied by its unit utility. Obviously, the transaction utility of items is random, which determines that every mining has a different result.

Figure 1 shows the effect of the change of transaction number on the algorithm performance. HM-Miner requires many times? scannig of the database. When transactions increase, the time for scanning becomes longer, the candidate sets may increase in number and the runing time of HM-Miner becomes long.

In Figure 2, minsup and minutil are set as 0.2% and then minmotivation changes from 2?10-6 to 40?10-6. When 2? 10-6?minmotivation?4?10-6, minmotivation?minsup? minutil is tenable. The itemset satisfying the support constraint (the support is no less than minsup) and utility constraint (the utility is no less than minutil) must satisfy the  motivation constraint (the motivation is no less than minmotivation). The pruning effect has nothing to do with minmotivation. When minmotivation?4?10-6, the pruning effeciency of algorithm becomes more dependent on motivation constraint. The greater the minmotivation, the more obvious the pruning effect of motivation constraint.

minsup=minutil=0.25%, minmotivation=25(millionth)        0.1 0.2 0.4 0.6 0.8 1  transaction number(million)  r u nn i n g  ti m e ( s )   Fig.1 The effect of the change of transaction number on algorithm performance  minsup=minutil=0.2%       2 4 6 8 10 20 40  motivation threshold Motivation(millionth)  r un n in g  ti m e( s )   Fig.2 The effect of the change of motivation on algorithm performance

V.  CONCLUSION The paper makes an analysis of the weakness of  support-based association rule and utility-based association rule, and puts forward the problems on the motivation-based association rule mining. As a new kind of interest measurement, motivation combines the strengths of support and utility, reflects the semantic and statistic features of itemsets in a better way and can provide better services for decision-making. The paper also analyzes the nature of motivation constraint, proves the existence of motivation?s upper bound property and conducts pruning in the HM-Miner algorithm by means of the property. The experiment has proved the correctness and validity of the algorithm.

