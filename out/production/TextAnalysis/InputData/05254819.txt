5-7 August 2009, Selangor, Malaysia

ABSTRACT  Association rules mining (ARM) algorithms have been extensively  researched in the last decade. Therefore, numerous algorithms  were proposed to discover frequent itemsets and then mine  association rules. This paper will present an efficient ARM  algorithm by proposing a new technique to generate association  rules from a huge set of items, which depends on the concepts of  clustering and graph data structure, this new algorithm will be  named clustering and graph-based rule mining (CGAR). The  CGAR method is to create a cluster table by scanning the database  only once, and then clustering the transactions into clusters  according to their length. The frequent 1-itemsets will be extracted  directly by scanning the cluster table. To obtain frequent k-  itemsets, where k ? 2, we build directed graphs for each cluster in  the case of very huge amount of transactions. This approach  reduces main memory requirement since it considers only a small  cluster at a time and hence it is scalable for any large size of the  database. Experiments show that our algorithm outperforms other  rule mining algorithms.

1. INTRODUCTION  Data mining is a tool that supports research and allows new  assertions to be made by disclosing previously undisclosed  details in large amounts of data [11]. One of the most  challenges in database mining is developing fast and efficient  algorithms that can deal with large volume of data because  most mining algorithms perform computation over the entire  database and mostly the databases are very large.

Association rules mining is one of the most well studied  data mining tasks. It discovers relationships among attributes in  different types of databases, producing if-then statements  concerning attribute-values [2]. It was firstly introduced in [1]  to discover association rules between items over basket data, an  association rule describes the associations among items in  which when some items are purchased in a transaction, the  others are purchased, too. In order to find association rules, we  need to discover all large or frequent itemsets from a large  database of customer transactions. A large itemset is a set of  items which appear often enough within the same transactions.

In this paper, we introduce an algorithm called CGAR,  which is fundamentally different from all the previous  algorithms in the following points:  i. It reads the database of transaction only once to  generate frequent 1-itemsets.

ii. It is scalable with all types of databases  regardless to their size.

iii. It is as efficient as it requires less memory and  CPU time to generate strong rules from the  transaction database.

iv. It is easy to implement as it uses simple cluster  table and a robust graph data structure.

The rest of the paper is organized as follows. In  Section 2, we provide a general definition of the problem of  rule mining, in section 3, a concise explanation of rule mining  algorithms and the relative researches of association rules are  given, and then, in Section 4, we offer our algorithm, which we  have called CGAR, and give an example of CGAR in Section  5. Section 6 contains the design of our experiments and the  results returned; finally, in Section 7, we present our  conclusions.

2. Association Rule Problem  Association rules, first introduced in 1993, are used to  identify relationships among a set of items in a database, it was  used in the sale transaction databases domain, and so there  should be a set of [m] distinct items I = {I1, I2, ? , Im}, and a  database of  transactions D,  where each transaction T has a  unique identifier TID, and contains a set of items such that T?I.

An association rule is an implication of the form  X?Y, where X and Y are subsets of I, and they are disjoint,  that is, X?Y =?. X and Y are sets of items called itemsets. The  rule X ?Y holds in the database D with confidence c, if c% of  transactions in D that contain X also contain Y. The rule X ?Y  has support s in the transaction set D, if s% of transactions in D  contain X ?Y. Given the database D, the problem of mining  association rules involves the generation of all association rules  that have support and confidence greater than or equal to the  user-specified minimum support and minimum confidence.

3. Background  Previous studies in data mining have presented  efficient algorithms for discovering association rules. But the  main problem in the first algorithms is the need to do multiple  passes over the datasets to generate frequent itemsets. The  Apriori association rule algorithm proposed by Agrawal and  Srikant [2] can discover meaningful itemsets and build  association rules within large databases, but a large number of  the candidate itemsets are generated from single itemsets and  this method also needs to perform contrasts against the whole  database, level by level, in the process of creating association  rules. Performance is severely affected, as the database is  repeatedly scanned to contrast each candidate itemset with the  database. After Agrawal et al. [1994] proposed the Apriori  association rule, most association rules researchers have used  Apriori-like candidate generated approaches, all of these  methods focus on reducing the number of candidate itemsets,  and therefore reducing the number of database scans.

Different strategies were developed after that to  improve the process of generation association rules, as in FP-  Growth [8], which outperforms all candidate-set-generation-  and- test algorithms as it mines frequent patterns without  candidate generation, but it still have problems in the case of no  common prefixes within the data items. Another technique is  the sampling algorithm which reduces the number of database  scans to a single scan, but still wastes considerable time on  candidate itemsets [5].  A third algorithm is the dynamic  itemset count (DIC) algorithm [6] for finding large itemsets,  which uses fewer passes over the data than classic algorithms,  and yet uses fewer candidate itemsets than methods based on  sampling [5]. In addition, the column-wise apriori algorithm  [10] and the tree-based association rule algorithm [4],  transformed the storage structure of the data, to reduce the time  needed for database scans, improving overall efficiency.

Finally, the partition algorithm [7]  to further improve  efficiency, it does so by effectively reducing the number of  database scans, however, considerable time is still wasted           scanning infrequent candidate itemsets. Pork et al. proposed an  effective algorithm DHP (direct hashing and pruning) [3] for  the initial candidate set generation. This method efficiently  controls the number of candidate 2-itemsets, pruning the size of  database [8].

4. Clustering and Graph-based Association Rule (CGAR)  Although, the Cluster-based Association Rule (CBAR)  algorithm [1] outperforms Apriori algorithm as it scans the  database only once, but the opportunity to enhance cluster-  based algorithms still available by providing an efficient graph  data structure to simplify the process of generating frequent k-  itemsets, where k ? 2.

In this paper, we present a new algorithm called  clustering and graph-based association rule (CGAR), for  efficient association rules mining, which overcome the  drawbacks of the previous algorithms.

The items should be given sequential numbers to  simplify the process of building the graph; this must be taken in  consideration as an important action before applying our  proposed algorithm. CGAR scans the database of transactions  only once to build the clustering table as a two-dimensional  array where the columns represent items and the rows  represent transactions? IDs (TIDs). The contents of the table  consist of 0 or 1 to indicate the absence or presence of an item  in a transaction, respectively. After that, the bit vectors for  each item will be ready and it is an easy process to determine  the frequent 1-itemsets by counting the number of 1s in each  transaction, if it isn?t less than the minimum support  threshold, it is considered as a frequent itemset and then be  used in building the graph, otherwise, it will be discarded  from further discussion as it is infrequent item. The second  phase starts by reordering frequent 1-itemsets by providing  each one with a sequential number to facilitate the process of  constructing the graph, which is constructed by doing logical  and operation between each pair of consecutive frequent 1-  itemsets <itemi, itemj> | i < j, if the number of 1s in the result  is greater than or equal to minimum support threshold, a  directed edge is drawn from itemi to itemj, this operation is  repeated for all frequent 1-itemsets. As the graph is completed,  the set of frequent 2-itemsets are generated, and it will be direct  from the graph traversing to generate frequent k-itemsets, such  as k ? 3. CGAR will deal with only one type of ARs, that is,  Boolean ARs.

5. An Example of CGAR  We provide an example to give an extra explanation to  our proposed algorithm; the minimum support threshold is  45%. There are 18 transactions and 5 different items in the  database. We assume ? as in most of sequential rule mining  algorithms ? that the items are in lexicographical order. A  transaction database example is shown in Table 1; we represent  the items by letters rather than numbers to deal some worst  cases, where the numbering step is required  TID Items  TID Items TID Items  T1 A, B, C T7 C, E T13 A, B, C, E  T2 B, C T8 B, C, E T14 C, D  T3 A, E T9 A, B, C, D T15 B, C, D  T4 A, C, D, E T10 A, D T16 A, D, E  T5 A, C T11 A, B, D T17 B, D, E  T6 A, C, E T12 C, E T18 A, C, D  Table 1: an example of database of transactions           The first step, as we said, is scanning the database to  determine the length of each transaction, the length means the  number of items in a transaction, and at the same time,  assigning numbers to the items, item A will be given the  number 1, item B the number 2 and so on. This will help us in  both constructing the cluster table and building the graph, after  that we don?t need to rescan the database, as we will move to  deal with the clustering table that can be easily resided in the  main memory.

In our example, the maximum transaction length is 4,  and so, there will be at most four clusters. Since there are no  transactions of length 1, the total number of clusters is 3 as  shown in Table 2, the table contents are 0s or 1s to denote  absence or existence of an item in a transaction, after  constructing the table, each column is the bit vector for the  corresponding item, and so, no need to make further contrasts  with the cluster table. These bit vectors are used in building the  graph and determining the frequent 1-itemsets.

The bit vectors for the items are:  BV1 = 011010011010101111  BV2 = 100000010111010011  BV3 = 101101111101001111  BV4 = 000010100011111110  BV5 = 010101001100110101      By counting the number of 1s in each bit vector, we  determine the support for each candidate itemset of length 1, as  the following: support ({1}) = 55%, support ({2}) = 40%,  support ({3}) = 45%, support ({4}) = 65%, and support ({5}) =  0.45.Thus the frequent 1-itemsets are: {{1}, {3}, {4}, {5}} as  their supports are not less than 45%.

The second step is started by making logical and (?)  between each pair of frequent 1-itemsets, as we mentioned  earlier in this paper, and by assigning 30% as a new value to  the minimum support threshold, we found that the frequent 2-  itemsets will be: {{1, 3}, {1, 4}, {3, 5}}, and the graph is  constructed by drawing an edge between each pair of frequent  items, as in Figure 1.

Figure 1: a simple directed graph to display frequent k-itemsets, k ? 2  To determine frequent 3-itemsets, we traverse the  graph as if there is a path among three nodes {i , j} and {j, k}  then the set {i, j, k} will be frequent 3-itemset. Here, in this  example, {{1, 3, 5}} is the only frequent 3-itemsets. As there  are no extra edges, the algorithm terminates.

In the standard situation, as the database contains  hundreds of thousands of transactions and different items,  constructing only one graph is not practical, and so we  suggested to construct different graphs for each cluster and find  from this graph all frequent itemsets, then combine the subsets  of frequent itemsets together to get the whole set of frequent  itemsets, and this technique is scalable with all transactions  databases of different sizes.

6. Experimental Results  To assess the efficiency of the proposed technique, we  have implemented the CGAR, along with Apriori algorithm,  using Java programming language on a Pentium IV 1700 MHz  PC with 512MB of available physical memory. The test  databases are the standard datasets available to evaluate rule  mining algorithms, they are: T10I4D100K and T40I10D100K.

We execute both algorithms, Apriori and CGAR, at  various values of minimum support thresholds, as the number  of frequent itemsets generated inversely proportional with the  value of the minimum support. Figure 2 displays the average  execution time in seconds to generate all frequent itemsets  using CGAR and Apriori algorithm.

Figure 2: a comparison between Apriori and CGAR  The experimental results in Figure 2 show that the  CGAR algorithm has better performance than Apriori in terms  of the execution time. When there is an increase in the number  and size of frequent itemsets discovered, i.e. reduction in the  minimum support threshold, the performance gap between  these algorithms is displayed in greater clearance.

7. Conclusion  In this paper we propose a new framework, which is  scalable and efficient.  The entire database is divided into      Time (Seconds)    Minimum Support %           partitions of variable sizes, each partition will be called a  cluster.  Each cluster is considered one at a time by loading the  first cluster into memory and calculating large itemsets and the  corresponding support counts. Then the second cluster is  considered similarly and the cumulative support count is  calculated for the cumulative large itemsets. This process is  continued for the entire set of clusters and finally we have the  whole large itemsets and the corresponding cumulative support  counts.  This approach reduces main memory requirement since  it considers only a small cluster at a time and hence it is  scalable for any large size of the database.

Experiments using two of the standard transaction  databases available on the Internet, T10I4D100K and  T40I10D100K, show that CGAR outperforms Apriori, a  familiar and widely used association rule mining algorithm.

When there is a reduction in the value of the minimum support  threshold, the performance gap between the algorithms  becomes more evident.

