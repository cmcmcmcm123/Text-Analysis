Super-sequence Frequent Pattern Mining on Sequential Dataset

Abstract?Due to the importance of Frequent Pattern Mining (FPM) in bioinformatics, web mining, social networks and so on, researchers have been paying significant attention to FPM and its various forms. In this study, we introduce a new form that we call super-sequence pattern mining. In contrast to frequent sub-sequence pattern mining studied significantly in the literature, frequent super-sequence mining requires to identify super-sequences that may contain sequential parts from different sequences and that have the total support larger than a given threshold. In essence, finding frequent super-sequence patterns turns out to be related to the well-known NP-hard longest path problem in graphs. Accordingly, we transform a given sequential dataset into a sequence graph and formulate the problem as k- hop longest path problem. We then propose a heuristic algorithm using dynamic programming techniques. The running time of our solution is depending on the number of different items in the sequence set but not on the size of the dataset. Through experiments, we demonstrate the effectiveness of the proposed solution. We also illustrate its use on an actual web log dataset and find out some interesting facts based on the identified frequent super-sequences on the web log dataset.



I. INTRODUCTION  Frequent Pattern Mining (FPM) is to seek frequently oc- curring patterns or relationships in a large database. It was first introduced by Agrawal et al [1] to analyze the item sets that appear frequently in the customers? shopping baskets. As we review in the next section, researchers have proposed many algorithms to this problem and investigated various other forms of FPM. In this paper, we focus on sequential datasets and investigate a new form of sequential pattern mining.

A sequential dataset is a collection of sequences of or- dered elements or events [2]. Traditional sequential pattern mining tries to determine the frequently occurring ordered (sub)sequences as patterns. As an example, let us consider web log sessions in Table I. Each web session is an ordered sequence of web clicks, i.e., two consecutive pages AB means that a user first visited page A and then page B. In this exam- ple, traditional algorithms (e.g., Apriori, downward closure) would identify AB and CD as the most frequent sub-sequence patterns as they appear three times in the dataset. Finding such frequent sub-sequences can be helpful for analyzing the web site structure and improving the performance. For example, by analyzing the traversal patterns in a web server?s log, one can gather important information such as web users? browsing  TABLE I AN EXAMPLE OF SEQUENTIAL DATASET CONSISTING OF WEB LOG  SESSIONS.

Session Id Session sequence 1 ABEB 2 BED 3 AB 4 AB 5 BCD 6 CD 7 CD  behaviors, most popular pages and which pages are likely to be visited together [3].

Extracting the frequent sub-sequences can help in analyzing the common structure existing in each of the elements in a database. On the other hand, the underlying general structure in a database is also important in analyzing the database.

In this paper, we study a different form that we call super- sequence frequent pattern mining (SS-FPM). In contrast to sub-sequences, super-sequences may contain several parts from different sequences. For example, in the above example, the most frequent super-sequence pattern with sequence length 4 would be ABCD because the total number of occurring times of AB, BC, and CD is 7, which is higher than that of any other super-sequences with sequence length 4.

Extracting super-sequences in a sequential dataset is impor- tant to analyzing the characteristics of a dataset and predicting the underlying patterns in it. It can be used in various areas and applications, e.g., in web page design and construction, system call analysis, bioinformatics, social networks, etc. For example, biologists can better understand the relationships be- tween gene structures and functional elements by determining the frequent super-sequences in the DNA sequences [4] of closely related species. Another example would be malware detection [5], where researchers analyze the sequence of sys- tem calls [6] [7]. With our technique, researchers can identify frequent super-sequence system call patterns from many pro- grams and use this information to determine unusual sequence of calls that might be invoked by malicious programs. Super- sequence patterns can also help in predicting longer patterns from shorter sequences available. For example, suppose an operating system allows only k system calls to finish a session      in the above system call sequences example. Through the super-sequence patterns, we can predict what are the possible patterns if the system allows l system calls for a session, where l > k.

The SS-FPM problem is related to the longest path problem in graphs, which is known to be NP-hard [8]. We first transform the given sequential dataset into a sequence graph, and then represent it in a matrix. Searching the most frequent super-sequence becomes the problem to search the longest path.

In our problem, however, we are interested in finding all the k-hop paths ((k+1)-length super-sequence frequent patterns) that have a larger weight than a given threshold. Note that k- hop longest path is the same as (k+1)-length super-sequence frequent pattern (SS-FP).

In response to solving this new form of the longest path problem, we propose a heuristic method that uses Dynamic Programming techniques to gradually compute k-hop paths from the initial one-step sequence matrix and the (k? 1)-hop paths computed in previous iteration.

As we discuss later in detail, the overall worst-case com- plexity of the proposed heuristic will be O(kn4). However, in practice, since the sequence graphs are sparse, we will see in Section V that the running time is reasonable based on the experiments on the web log dataset.

The remaining part of the paper is organized as follows.

In Section II we give related work in frequent pattern mining area. We formally define super-sequence frequent pattern min- ing (SS-FPM) problem and give the graph model in Section III.

In Section IV we present our proposed heuristic method using dynamic programming for solving the SS-FPM problem.

We then evaluate the performance of our solution through experiments on actual web log dataset in Section V. Finally, we conclude this paper and point out some issues for future research in Section VI.



II. RELATED WORK  Frequent Pattern Mining (FPM) plays an important role in data mining research area. It deals with extracting pat- terns from large databases representing complex relationships among various entities.

After the Apriori algorithm was first proposed, many new algorithms and improvements were introduced. For exam- ple, researchers have tried to improve Apriori using vari- ous techniques including hashing technique [9], partitioning technique [10], sampling approach [11], dynamic itemset counting [12], incremental mining [13], parallel and dis- tributed mining [9] [14] [13] and so on [15]. People have also developed new algorithms for the FPM problem such as FP-growth [16], which uses FP-tree to store the itemset association information, and Eclat [17], which uses an Equiv- alence CLASS Transformation method. Moreover, researchers have been studying various other types of FPM problem including multilevel and multidimensional association rules mining [18], closed frequent pattern mining [19], colossal  pattern mining [20], sequential pattern mining [21], graphs, trees and lattices mining [15].

Our work is mostly related to sequential mining, where the frequent itemsets mining is extended with the consideration of ordered items. Specifically, sequential mining tries to find the set of frequent subsequences in a given sequential dataset.

One of the first solutions to this problem was AprioriAll [21], which extends the similar techniques in Apriori [1] to find frequent patterns in transactions of the customers. It generates candidate sequences by measuring the support of them in passing over the database. Some of the well-known sequential mining algorithms are Apriori-based GSP (Generalized Se- quential Patterns) [22], Pattern-growth based FreeSpan [23] and PrefixSpan [24], Vertical format-based SPADE [25] and Constraint-based SPIRIT [26]. All of the above works mainly focus on the sub-sequence mining, which is to find the common part of all the sequences in a dataset. In our problem, we are looking for a general structure, the super-sequence.

The most frequent super-sequence is the one with the largest total support of each consecutive length two sequence in it.

Although part of the most frequent super-sequence may be the most frequent sub-sequence, this is not necessary.

The longest path problem is known to be NP-hard [8].

Accordingly, authors have proposed various approximation algorithms or developed exact algorithms for specific classes of graphs. Karger et. al proposed an approximation method for the longest path in a graph using greedy algorithm [27].

Murat et. al proposed probabilistic longest path problem [28].

And there are other solutions on specific type of graphs.

For example, researchers proposed longest path problems on interval graphs [29], on co-comparability graphs [30], on ptolemaic graphs [31] and so on. Most of these studies tries to find the longest path starting from a source without any constraints. In our case, however, we are interested in any k- hop longest path whose weight is greater than a threshold.



III. FORMAL DEFINITION AND GRAPH MODEL  In this section we introduce the notation used in this paper and formally define SS-FPM problem.

We assume that a sequential dataset denoted by S = {S1, S2, ..., SN} is given, where Si = {w1, w2, ..., wli} is a sequence of ordered elements or events (e.g., sequences of web pages in Table I). Let W = {w1, w2, ..., wn} be the complete set of all elements or events (i.e., W =  ?N i=1 Si).

Let p = {w1, w2, ..., wk} be a super-sequence pattern with path length of (k ? 1). Note that p is not a set but an array, which means we consider the order of the elements occurring in the pattern. In contrast to sub-sequence patterns, super-sequence patterns may contain different parts of multiple sequences in the sequential dataset. For example, the super- sequence pattern ABCD identified from the dataset in Table I contains parts from most of the sequences in the table.

Let support(wxwy) be the total number of occurrences of the sequence wxwy in S. Similarly, we can define the support     for a pattern p as follows:  support(p) = k?1? i=1  support(wiwi+1)  We say p is k-length frequent if support(p) is greater than a given threshold ?. We can now formally define SS-FPM problem as follows:  Definition 1: Given a sequential dataset S, a sequence length k, and a threshold ?, the Super-Sequence Frequent Pattern Mining (SS-FPM) problem is to find the set P = {p1, p2, ...pr}, where each pattern pj = {w1, w2, ..., wk} satisfies the following condition  support(pj) = k?1? i=1  support(wiwi+1) > ?.

SS-FPM problem is actually related to the longest path problem in a graph. So we transform a given sequential dataset S into a sequence graph, which can be defined as follows.

Definition 2: A Sequence Graph is a directed weighted graph G = (V,E), where V = {w1, w2, ....wn} and E = {e1, e2, ..., em}. Each edge ei connects wa and wb iff there is a consecutive sequence wawb in any sequence in S. The weight of edge ei is set to support(wawb), which is the total number of occurrences of consecutive sequence wawb in all sequences in S.

According to this definition, we can easily construct the sequence graph for a given sequential dataset. For example, the sequence graph for the sequential dataset in Table I would be as shown in Fig. 1. We use the adjacency matrix, which   ???? ???? ???? ???? ???? ???? ????  ???? ???? ???? ???? ???? ???? ??????????????????  A B  C D  E  1 3  3 2  Fig. 1. The sequence graph for the sequential dataset in Table I.

we call the initial one-step sequence matrix, to represent the sequence graph. Since there are n elements in the set of all sequences, the sequence matrix would be n?n. For example, the sequence matrix for the above graph would be as in Fig. 2.

M1 =  ? ?????  A B C D E  A 0 3 0 0 0 B 0 0 1 0 2 C 0 0 0 3 0 D 0 0 0 0 0 E 0 1 0 1 0  ? ?????  Fig. 2. The sequence matrix for the sequence graph in Fig. 1.

The sequence matrix denoted by M1 can directly be com- puted from the given sequential dataset S. For this, we first  set M1[wi][wj ] to 0 for every wiwj . We then go through each sequence Si and add one to M1[wx][wy] for each wxwy in Si.

The reason for using the notation M1 is to indicate that M1[wi][wj ] actually represents the support of 1-hop path (2- length sequence) from wi to wj . In the rest of the paper, we will continue to generalize this notation as Mk to store the supports of the k-hop longest path ((k + 1)-length most frequent super-sequence). Note that Mk[wi][wj ] will show the support of the k-hop longest path starting with wiwj , not the path from wi to wj . The actual k-hop paths will be stored in a hash table, as we discuss later in detail.

In this paper, we are looking for simple paths (e.g., se- quential patterns without duplications). The dataset may have duplicates such as the first entry in table I. But when we search for a frequent super-sequences, we do not consider loops since the path may not be able to get out of the loop. So the frequent super-sequences got from the sequence graph is a directed acyclic graph(DAG).



IV. PROPOSED SOLUTION FOR SUPER-SEQUENCE FREQUENT PATTERN MINING  To determine the (k + 1)-length most frequent super- sequence patterns, we actually try to compute all the k-hop longest paths whose total weights are greater than a given threshold. For this, we mainly use Dynamic Programming to gradually compute the matrix Mk from M1 and Mk?1. As we discussed in last section, M1[i][j] is the support of the 1-hop longest path (direct link) from node i to node j. On the other hand, for k > 1, Mk[i][j] is the support of the k-hop longest path starting with sequence ij rather then being the weight of a path from i to j. Along with Mk, we maintain a hash table Hk that stores k-hop longest paths ((k+1)-length frequent super- sequences) starting with ij. So the keys in Hk are [ij] for all the non-zero elements in Mk while the values are the k-hop longest paths starting with the corresponding ij. Here there can be multiple paths starting with the sequence ij that have the same weights. In this paper, we only consider the situation that links on the sequence graph all have different numbers of weights since in large real world dataset, e.g., web log dataset, the numbers of visitings are large and have a large probability that they are different. More general cases can be extended easily based on our solution. We will first illustrate the details of the proposed calculation method through an example. We then give its pseudo code and computational complexity.

Let us now consider the sequence graph in Fig. 1 and illustrate the process of getting k-hop longest paths ((k + 1)- length frequent super-sequence patterns) when k is 3. So, we need to gradually calculate M3 and H3.

First, let us generate H1. This can easily be done by using the non-zero elements from the original one-step sequence matrix M1. Resulting keys and 1-hop paths in H1 will be as shown below:     H1 =  ???????? ???????  key : value AB : ?AB?, BC : ?BC?, BE : ?BE?, CD : ?CD?, ED : ?ED?  ???????? ???????  We then compute M2 by using M1 twice as follows. For each i and j, we first search the largest value in row j of M1 and identify its column index as maxC. We then simply compute M2[i][j] by taking the summation of M1[i][j] and M1[j][maxC]. If M1[i][j] is 0, we keep it 0 in M2[i][j]. Also, if the maximum in row j of M1 is 0, we again set M2[i][j] to 0.

The reasons behind the these two checks can be explained as follows. When M1[i][j] is zero, there is no visits on page j after page i. Thus, there is no need to calculate the super- sequence path starting with ij in the sequence. Similarly, when the largest value on row j is zero, there is either no outlet in the (k?1)-sequence matrix for page j or they could generate a circle if we keep adding pages in the path. Thus, we set the corresponding Mk[i][j] to zero. In summary, if either one of these conditions is true, then we cannot find a k-hop path starting with ij; thus, we set Mk[i][j] to 0. Accordingly, the resulting M2 will be as shown in Fig. 3.

M2 =  ? ?????  A B C D E  A 0 5 0 0 0 B 0 0 4 0 3 C 0 0 0 0 0 D 0 0 0 0 0 E 0 2 0 0 0  ? ?????  Fig. 3. The 2-sequence matrix from the sessions in Table I.

While computing M2, we can generate the corresponding hash table H2 and make sure that the paths in hash table will not have loops. After computing M2[i][j], we check if is is 0 or not. If it is not 0, then we copy the value of the key [jmaxC] in H1 to [ij]?s value in H1 after the first element. For example, the new value in H2 for key [AB] will be ?ABE? . This is obtained by copying ?BE? to ?AB? after A since M1[B][E] has the largest value on row B. Accordingly, the resulting H2 will be as follows:  H2 =  ?????? ?????  key : value AB : ?ABE?, BC : ?BCD?, BE : ?BED?, EB : ?EBC?  ?????? ?????  This shows that 3-length super-sequence patterns are ABC, BCD, BED and EBC with the supports of 5, 4, 3 and 2, respectively. Note that we did not choose EBE as a 2-hop path since it has a loop. We keep track of the paths and check if there is a loop when a path is extended with a the new node.

If so, we ignore that node and consider the next node.

Finally, let us compute M3 by using M1 and M2 as follows.

For each i and j, we first search the largest value in row j of M2 and identify its column index as maxC. We then simply compute M3[i][j] by taking the summation of M1[i][j] and M2[j][maxC]. Accordingly, the resulting M3 will be as shown in Fig. 4.

M3 =  ? ?????  A B C D E  A 0 7 0 0 0 B 0 0 0 0 0 C 0 0 0 0 0 D 0 0 0 0 0 E 0 5 0 0 0  ? ?????  Fig. 4. The 3-sequence matrix from the sessions in Table I.

For H3, since M2[B][C] has the largest value on row B, we copy the value of [BC] : ?BCD? to the value of [AB] : ?ABE?, starting from the second element. Consequently, we obtain ?ABCD? and save it in H3 with the key value of [AB].

Using the same process, we also obtain ?EBCD?. As a result, H3 will be as follows:  H3 =  ?? ?  key : value AB : ?ABCD?, EB : ?EBCD?  ?? ?  In summary, we computed ABE as the 2-hop longest path (3-length most frequent sequence) by combining 1-hop longest paths AB and BE from M1 in Fig. 1. Since AB has the support of 3 and BE has the support of 2, the support of ABE will be 5. Continuing this way, we determined ABCD as the 3-hop longest path (4-length most frequent super-sequence) with the support of 7. We can now present the above steps in a pseudo code form, as shown in Fig. 5.

As we mentioned at the beginning of this section, our solution can find the most frequent super-sequence with length k starting from ij only when the weight on each link is different from each other. When there are the same weights links, our solution will miss some super-sequences, e.g., if there are 2 most frequent super-sequences starting from ij, we will only get one of them. This can also mislead the most frequent length k+1 super-sequence. To get a better solution, we need another hash table to store all the possible paths that can give a most frequent super-sequence and this would be a good extension for our future work.

Let us now consider the computational complexity of the heuristic algorithm in Fig. 5. In essence, it computes the n?n matrix Mk by performing the above mentioned operations on two n? n matrices, namely M1 and Mk?1. The actual paths are stored in a hash table Hk by extending the paths in Hk?1 while making sure that there will be no loops in them. To compute each element Mk[i][j], the heuristic algorithm finds the maximum in row j of Mk?1, which costs O(n), and checks if the new path starting with ij would have a loop, which costs O(k). If there is a loop, the heuristic algorithm ignores that path and finds another maximum until it finds a path without     Heuristic Algorithm Computing k-hop Longest Path Input: M1, Mk?1, and Hk?1 Output: Mk and Hk  for 1 ? i ? n do for 1 ? j ? n do  if M1[i][j] ?= 0 then Find maxC such that Mk?1[j][maxC] ?Mk?1[j][l] for 1 ? l ? n while there is a loop in the new path do Mk?1[j][maxC] = 0, Find maxC such that Mk?1[j][maxC] ?Mk?1[j][l] for 1 ? l ? n  end while if Mk?1[j][maxC]! = 0 then Mk[i][j] = M1[i][j] +Mk?1[j][maxC], update hash table Hk  else Mk[i][j] = 0  end if end if  end for end for  Fig. 5. The pseudo code of the heuristic algorithm proposed for SS-FPM.

a loop. In the worst case, the heuristic algorithm may end up checking all the elements in row j, which costs O(n). So, for each element ij, the heuristic algorithm would perform O(n(n + k)) operations, resulting in overall complexity of O(n4+kn3). Since we are interested in simple paths, k will be less than n and thus the worst-case complexity of the heuristic algorithm for a given k will be O(n4). However, since our overall solution gradually computes Mk by calling the heuristic algorithm k times, the overall worst-case complexity of our solution will be O(kn4). However, in practice, since the sequence graphs are sparse and the matrix Mk storing the weights of the longest k-hop paths gets more and more zero elements as the k increases, we would not need to find maximum or search for loops in paths for every elements in the matrix. This results in reasonable average case complexity, as we demonstrate through experiments in the next section.



V. EXPERIMENTS AND RESULTS  In our experiments, we have two parts. In the first part, we analyze the actual running time of computing the matrix Mk in search of the (k+1)-longest super-sequence. In the second part, we use the actual web log dataset called BMS-WebView- 11 to find some interesting facts by analyzing supper-sequence patterns in that dataset. BMS-WebView-1 contains several months of clicking stream data from an E-commerce website.

As discussed in Section I, the web log data is transformed into a set of sequences. Each sequence is a session showing a  1BMS-WebView-1 has been used as datasets in KDDCup 2000 competition and can be downloaded from The Data Mining Forum (http://forum.ai- directory.com).

sequence of web pages visited by a user. The details on web log pre-processing are out of the scope of this paper and the details can be found [32] [33] [34]. In BMS-WebView-1, there are 59602 sessions and 497 web pages in it. For simplicity, we give each web page an ID starting from 0 to 496.

A. Running Time Analysis  To analyze the running time under different number of nodes in the sequence graph, we generated random dataset similar to web log dataset BMS-WebView-1 with ten thousand sessions and by changing the number of web pages from 50 to 200.

The length of the super-sequences that are going to be searched ranges from 3 to 7, (since the smallest pattern has two pages and the initial sequence matrix shows any length 2 super- sequence weight). The steps for generating the random dataset is as shown below: ? Randomly pick a number iter between 3-7.

? Repeat iter times to randomly pick a number between 0  to size (size is the session size which is set to 50, 100, 150 and 200 in different experiment groups). This gives a sequence in the session.

? Repeat last step for 10,000 times and we get a ten thousand session dataset with size web pages.

All of the experiments are run on 2.26 GHz Intel Core processor with 4GB memory. Fig. 6 shows the actual running.

Fig. 6. Running time for searching longest super-sequence on randomly generated web log data.

From Fig. 6, we can see that the actual running time grows more like a quadratic function of the number of nodes rather than quartic function as in the worst-case complexity. This is a good indication that the proposed heuristic algorithm would be practical for modest size datsets. However, we still need to improve its performance for very large datasets as we plan to do in our future work.

B. Super-sequence pattern analysis  Before analyzing the super-sequence patterns in the actual web log dataset, we would like to show that our heuristic algorithm gives almost the same longest path that a brute- force algorithm can find. Due to the exponential complexity of a brute-force algorithm, we try a small number of nodes (web pages) and randomly generated 10000 sessions. Each session     can have less than 10 pages. By using brute force means that if we are looking for length k super-sequence in the dataset, we to generate all the permutations of a k pages out of the 10 pages, that is also why we only have 10 pages, since large number of pages can be time consuming to do permutations.

In Fig. 7 we compare the average weight of the longest super-  Fig. 7. The total weight of the super-sequence found using brute force and our algorithm  sequences that we found using our algorithm to the ones found using brute force method. We did five groups of experiments with super-sequence lengths from 3 to 7. We use letter A and B to for our Algorithm and Brute force, respectively. We can see that our algorithm give almost the correct longest super- sequences with minor offset.

We will now use our heuristic algorithm on the actual web log dataset to find some interesting facts. In Fig. 8, we show the number of sequences (paths) that we found with visiting numbers (total weight) from 2000 to 5000 and the sequence length (k) varies from 5 to 10. Similarly, Fig. 9 shows the number of sequences that have visiting numbers from 5000 to 8000 and the sequence length goes from 12 to 20. Both  Fig. 8. Number of paths found for different lengths(5-10) with different visiting numbers  figures confirms that, as expected, our algorithm finds more paths under the same visiting numbers as the sequence length increases. This is due to the fact that the total weight of a path increases as the sequence length increases. Also from  Fig. 9. Number of paths found for different lengths(12-20) with different visiting numbers.

comparing the two figures, we can see that there are a lot of paths (e.g., close to 30000) when path length is relatively long and visiting threshold is relatively small. Instead of such commonly appearing many paths, it would be useful to focus on the small number of paths having a relatively large weight (number of visiting). For example, in this data set, one should closely analyze the 6-length paths with visiting numbers larger than 2200, or the 10-length paths with visiting numbers larger than 4000.

For example, let us consider such distinguished paths to investigate if there is any weakest link, which has significantly small number of visitings compared to other links in a frequent super-sequence pattern. If there are any such links, web designers can delete or regroup them. To identify such links, we calculated the deviations of the distinguished paths with length 3, 4 and 5. From Table II, III and IV we can see that the number of paths significantly decreases as the visiting threshold increases. Accordingly, we pick the visiting numbers of 1000, 1500, and 2000 to get 30, 21, and 26 distinguished paths, respectively.

TABLE II THE NUMBER OF PATHS WITH LENGTH 3  number of total visitings number of paths found >900 394  >1000 30 >1100 10 >1200 7 >1300 2 >1400 0  Fig. 10 shows the ordered standard deviation for the 30 paths found in Table II. We can see that there are 4 paths with deviation less than 200 and 7 paths with standard deviation larger than 600. The rest of the paths have standard deviation between 200 and 600. After checking the path that has the smallest standard deviation, we found that the path has the web page sequence ?164, 0, 1?. The visitings for page 0 after visiting page 164 is 590 and then visitings to page 1 is 621.

The largest deviation exists in path ?265, 281, 277?, where     TABLE III THE NUMBER OF PATHS WITH LENGTH 4  number of total visitings number of paths found >1400 106 >1500 21 >1600 14 >1700 8 >1800 6 >1900 1 >2000 0  TABLE IV THE NUMBER OF PATHS WITH LENGTH 5  number of total visitings number of paths found >1900 144 >2000 26 >2100 15 >2200 8 >2300 7 >2400 1 >2500 0  the visitings are 48 and 953, respectively. Fig. 11 shows the ordered standard deviation for the 21 paths found in Table

III. The smallest deviation exists at the path with web page sequence ?164, 0, 1, 97?. We can see that it is the same path before but extended with web page 97 and the visitings after page 1 to page 97 is 771. The largest deviation exists in path ?277, 281, 2, 45? and the visitings are 953, 8, 877, respectively. Fig. 12 shows the ordered standard deviation for the 26 paths found in Table IV. We found that the path that has the largest standard deviation has the web page sequence ?44, 45, 2, 277, 281? and the visitings are 290, 877, 10, 953, respectively. This means that visitings on web page 277 after users visiting page 2 has only 10 times occurring in the dataset.

This is very few compared to other visitings in this super- sequence. So the designer might want to remove page 277 or combine its content with page 281.

Fig. 10. Visiting numbers standard deviation for length 3 paths with total visitings larger than 1000

VI. CONCLUSION AND FUTURE WORK  In this paper, we formulated a new form of sequen- tial pattern mining, namely frequent super-sequence pattern mining. We proposed an heuristic algorithm using dynamic  Fig. 11. Visiting numbers standard deviation for length 4 paths with total visitings larger than 1500  Fig. 12. Visiting numbers standard deviation for length 5 paths with total visitings larger than 2000  programming techniques.We also looked into frequent super- sequence patterns in an actual web log dataset from a different perspective. Through experiments, we demonstrated that its practical running time is reasonable. But there is a significant room for improving its quartic worst-case complexity which we leave it for our future work.

In the future, we would like to scale up our method on large datsets, e.g., parallel algorithms on frequent super- sequence mining. We also would like to apply our method on other areas, e.g., bioinformatics dataset, to discover interesting characteristics based on the frequent super-sequences found.

