

Abstract?Since the sole focus can?t capture the high-quality image of multi-association plastic gear tooth profile?s flaw detail on different end surface, these flaws couldn?t be detected simultaneously. When it comes to the two images focused on different gear ends, the highly detailed image is required due to the large quantity and complex profile of gear teeth. In view of the subject above, some fusion rules of multi-focus image, which adopt big high-frequency coefficient and mean value of low-frequency coefficient, are proposed in this paper based on wavelet transformation. Then suitable wavelet coefficient and decomposition layers are adopted to fuse the multi-focus image.

Experimental results show that the fusion image has a high quality as well as low calculation and the tooth profile is greatly different from the background. So the proposed method shows great foreground in real time detection.



I. INTRODUCTION NJECTION molding of small plastic gears more often appear together with collapse teeth, missing teeth and overflow edges and other defects. At present,  manufacturers usually detect the flaw by using manual methods. But due to the great quantity and variety of product with small size, the detection efficiency is very low, and the reliability can not be guaranteed[1],[2]. Automatic detection using computer vision, based on digital image processing technology, can improve the efficiency and accuracy of detection considerably. In order to reflect fully and clearly the multi-gear tooth flaws in different sections, it is necessary to focus and collect two individual images from big and small gears respectively, shown in Fig.1. (a), (b). And then two individual tests are carried out for big and small gears respectively. The above method can achieve automatic detecting, but it has a low efficiency. In this paper, using image fusion based on wavelet transform, to fuse two pictures with different focuses, to reconstruct large and small gear teeth are to meet the testing requirements feature an image for a gear defect detection can improve the efficiency of follow-up testing.

Manuscript received April 8, 2010. This work was supported in part by The Natural Science Foundation of Ningbo under Grant (2009A610098).

Yong-qing Chen is with the School of Mechanical Engineering, Ningbo University of Technology, Ningbo 315016, China (phone: 15967803420; fax: 0574-87080136; e-mail:arching@163.com).

Lian-qing Chen is with the School of Mechanical Engineering, Ningbo University of Technology, Ningbo 315016, China (e-mail:clq@nbut.cn).

Hong-jie Gu, is with the School of Mechanical Engineering, Jilin University,Changchun 130025, China (e-mail: 604183168@qq.com).

Kun Wang is with the School of Mechanical Engineering, Jilin University,Changchun 130025, China (e-mail: 327713874@qq.com).

(a) Focus large gear                         (b) Focus small gear  Fig.1.Plastic gear source image

II. PLASTIC GEAR BASED ON WAVELET TRANSFORM IMAGE FUSION RULES  Image fusion based on wavelet transform method lies in determining how to choose the fusion rules and the decomposition level of wavelet transform [3]. Fig.1. (a), (b) to be integrated in the two source images, F is the fused image, based on wavelet transform image fusion of plastic gear basic steps: 1) The registration of the source image has A and B  respectively wavelet decomposition, the equivalent of using a set of high and low pass filter for filtering, separating the high frequency and low frequency information;  2)  Decomposition of each layer by high frequency information and low frequency characteristics based on the information received, adopt a different fusion rules, in their respective transform domain feature information extraction, were fused;  3) Using 1) the wavelet transform reconstruction algorithm on the processed wavelet coefficients inverse transform reconstructed image, you can get the fused image. The flow chart shown in Fig. 2.

Plastic gear source image obtained by wavelet decomposition of the low-frequency sub-band transform values are positive, reflecting the Gears in the resolution of the general picture, does not reflect the edge of the details of gear teeth; the high frequency sub-band corresponding to the edge of the image detail, reflecting gear tooth profile, high-frequency components of fuzzy regions modulus smaller, clear high-frequency components of the regional model is bigger.

1)     The low-frequency sub-band of the fusion rule  Low-frequency wavelet coefficients of fused image desirable two source images the mean low-frequency wavelet coefficients, it can take a source image of the low frequency wavelet coefficients, depending on the  Technology for Multi-focus Image Fusion Based on Wavelet Transform  Yong-qing Chen, Lian-qing Chen, Hong-jie Gu, and Kun Wang  I   Third International Workshop on Advanced Computational Intelligence August 25-27, 2010 - Suzhou, Jiangsu, China  978-1-4244-6337-4/10/$26.00 @2010 IEEE         image and purpose to be.

2)      High frequency sub-band of fusion rules High  frequency sub-band of fusion rules can be divided into two categories [4]: based on a single pixel and region-based fusion method. Here on this article chosen integration method based on a single pixel for description:  Fusion method based on a single pixel is to try to model the value of high frequency wavelet coefficients larger image wavelet coefficients as a fusion, including the maximum wavelet coefficient selection method, the weighted average method. Select the method to be the maximum first pieces of image fusion using wavelet decomposition, respectively, and then compare each band corresponding absolute value of wavelet coefficients, wavelet coefficients of large absolute value as the integration of the wavelet coefficients in a new wavelet coefficient map, through the inverse wavelet transform to get the final fused image, fusion formula is:  ? ? ?  ? ?  = ),(),(),( ),(),(),(  ),( yxByxAyxB yxByxAyxA  yxF    (1)  Where, A (x, y) wavelet coefficients for image A, B (x, y) for the image B of the wavelet coefficients, F (x, y) for the integration of the wavelet  coefficients.

Weighted average of the integration formula is: ),(),(),( yxbByxaAyxF +=     (2)  here a + b = 1 Maximum value selection method for high-frequency  components than the rich, bright, high contrast source images, fusion images to retain the basic characteristics of the source image, the image contrast and the same source image.

Weighted average weight adjustable, wide application and can remove some noise, low source image information loss, but will cause a decline in image contrast.

Wavelet transform theory shows that the high-frequency coefficients of a clear image are much larger than those of a blurred image. But the low-frequency coefficients are roughly equal [5]. As more small plastic gear, more complex tooth profiles, on the details of the higher, therefore, adopt high frequency coefficient is large, low-frequency coefficient of the average fusion rule, the concrete in three steps.

1)  using two-dimensional wavelet transform of Mallat  algorithm, the image is decomposed gear. Set Hr, Hc array{ }lkC , ? ( ) 2, Zlk ? , respectively, on the role of rows and columns of operator H, the Gr and Gc, respectively, acting on the array of rows and columns of Operator G. D Mallat decomposition algorithm:  Jj  CGGD CHGD CGHD CHHC  jcrj  jcrj  jcrj  jcrj  ,,1,0      =  ? ? ?  ? ? ?  ?  = = = =  +  +  +  +  (3)  2)      Compare two images in the corresponding position of the high frequency wavelet coefficients to retain a large factor. Comparing two images is the wavelet  coefficients of 1jD ? jD ?  jD to retain the greater  value. Seeking two images and the average low-frequency wavelet coefficients as a new low-frequency  wavelet coefficients Cj.

3)   Two-dimensional inverse wavelet transform of Mallat algorithm, image reconstruction gear. D Mallat reconstruction algorithm is:  JjDGG  DGGDHHCHHC  jcr  jcrjcrjcrj  ,...,1,0~~  ~~~~~~     =+  ++=  +  +++ (4)          Fig.2. Image Fusion Based on Wavelet Transform

III. PLASTIC GEAR IMAGE FUSION EVALUATION Integration of image quality evaluation of the main  objective from the subjective and qualitative analysis and quantitative analysis of two aspects. Subjective qualitative analysis is a comparative analysis from the visual, mainly based on visual resolution and spectral characteristics of knowledge to a simple assessment of fusion results; objective and quantitative analysis based primarily on quantitative analysis of several commonly used formula to calculate the corresponding image or source image fusion targets data, comparative analysis [6-9]. Small plastic gears on the effect of image fusion evaluation, taking into account the evaluation of the typical parameters and complexity of the algorithm can select the information entropy and the average gradient as the result of objective evaluation of integrated indicators.

1)    The information entropy  If the fused image entropy the greater the entropy of the image that the more integrated the information contained in the image richer, better integration of quality. For a single image, that the gray value of its elements are independent of the sample, then this image of the gray distribution of { }ni PPPPP ,,,, 21= , gray value Pi is equal to the number of pixels i and the image ratio of the total number of pixels , L is the total number of gray level.

Image entropy is:  ? ?  =  ?=  2log  L  i ii PpE                               (5)  2)     The average gradient The average gradient reflects the image of the small details of the contrast, texture variation, and image clarity, which is defined as:  ? ? = =  ?+? ?  =? M  i  N  j yx IINM  g 1 1  22 2/)(1             (6)  Fusion rules  Decom positio  Decom positioImage A  Image B  Inverse wavelet transform  Image F          Where, z and b, respectively xI?  and yI?  direction of the difference. NM ?  is the image size (unit: pixels). In general, if the average gradient is larger, the more the image level, the higher the image resolution, integration will be effective in improving image clarity. Therefore, the fused image can be used to evaluate the expression in the small details and differences.



IV. EXPERIMENTAL RESULTS AND EVALUATION OF IMAGE FUSION  Currently based on wavelet transform of multi-focus image fusion in wavelet and decomposition level on the choice of no uniform standard, which two elements of fusion will have a huge impact [10-12].

A. Selection of Wavelet The most commonly used image processing wavelet are  Haar, Daubechies orthogonal wavelet bases, Cioflet wavelet, Symlets Biorthgonal wavelet and biorthogonal wavelet bases.

Fused image using Haar wavelet has a relatively small average gradient and poor clarity of image detail, though with the shortest processing time. DbN series of wavelet entropy close to that with the increase in the length of compact support, the processing time in turn increase; SymN series on all aspects of wavelet parameters are close; CoifN series of wavelet, compactly supported length with the increase of entropy increases, the processing time required to gradually increase; biorthogonal wavelet comprehensive performance comparison good. Biorthogonal wavelet bases can be selected on the plastic gear images for fusion. The experimental data shown in Table I.

TABLE I RESULTS OF DIFFERENT WAVELET FUSION  Wavelet Image entropy Average gradient  Processing time (s)  bior2.2 6.1538 3.225 4.656  bior2.4 6.1513 3.2215 4.753  bior4.4 6.1442 3.2114 4.813  bior5.5 6.1414 3.21 5.031  bior6.8 6.1466 3.2072 5.719  Can see from the table, Bior2.2 Wavelet entropy and the average gradient value of large, good clarity of image detail, less time required for fusion, general properties.

B. Determination of wavelet decomposition level Determine the best decomposition level, need to consider  the details of the comprehensive, operational time and loss and other factors. As the decomposition level increases, the fused image entropy increased. This is because the more layers of wavelet decomposition, the more extensive integration of the frequency range, the more extensive details, fused image contains the greater amount of information.

Decomposition level, but more top-level integration will be greater the amount of information loss, and such losses can not be restored by inverse transform. Select Bior2.2 wavelet,  respectively, for 1 to 8 layer decomposition of the integration of different decomposition level of the integration effect. The objective indicators entropy, average gradient and the time evaluation are shown in Table II. The fusion result image is shown in Fig. 3.

TABLE II RESULTS OF DIFFERENT DECOMPOSITION LEVEL OF INTEGRATION OF THE  OBJECTIVE INDICATORS OF EVALUATION FORM Decomposition  level Image entropy  Average gradient  Processing time (s)  bior2.2-1 5.9487 2.8182 3.594  bior2.2-2 6.0288 3.1125 4.391  bior2.2-3 6.0684 3.2118 4.516  bior2.2-4 6.1165 3.2234 4.594  bior2.2-5 6.1538 3.225 4.656  bior2.2-6 6.2516 3.2248 4.703  bior2.2-7 6.3171 3.2249 4.766  bior2.2-8 6.4463 3.222 4.828      (a) first                               (b) second    (c) third                               (d) forth    (e) fifth                                (f) sixth    (g) seventh                            (k) eigth Fig. 3. Bior2.2 wavelet decomposition level of the fusion of different The 5 layers of decomposition level is a critical point. The  average gradient is 5 level decomposition of the fused image big, rich details, good sharpness of the image. While continuing to increase as the decomposition level, entropy          and spatial frequency is still increasing, but also increasing computation, processing time increases. Tiny plastic gear handle on the results of a comprehensive analysis of the above indicators, based on Bior2.2 5 Wavelet decomposition level image fusion, image-rich detail, clearer images, all aspects of general properties. Therefore, in automatic detection of computer vision, a wavelet decomposition of 5 layers Bior2.2 is applied for image fusion of small plastic gears, as shown in Fig. 3 (e).



V. CONCLUSION Based on the Focus small multi-joint plastic gear tooth end  collection of different source images, made high-frequency coefficient is large, low-frequency coefficient of the average fusion rule, select the appropriate wavelet and decomposition level determined to carry out a wavelet transform Multi-focus image fusion research, deficiencies in the performance characteristics, image quality and processing time to achieve satisfactory results, for the realization of computer vision, automatic detection of a large and small face gear to provide a defect in the male.

