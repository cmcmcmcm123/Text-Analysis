Foundation item:  Supported by the National Natural Science Foundation of China (NO.70861001) and Natural Science  Foundation of Guangxi (Guangxi Science 0991027).

Abstract?It is very time-consuming to discover association rules from the mass of data, but not all the rules are interesting to the user, a lot of irrelevant information to the user?s requirements may be generated when traditional mining methods are applied. In addition, most of the existing algorithms are for discovering one-dimensional association rules. Therefore, this paper defines a mining language which allows users to specify items of interest to the association rules, as well as the criteria (for example, support, confidence, etc.), and proposes a method based on rough set theory for multi- dimensional association rule mining methods, dynamically generate frequent item sets and multi-dimensional association rules, which can reduce the search space to generate frequent itemsets. Finally, an example is used to illustrate the algorithm and verify its feasibility and effectiveness.

Keywords: association rule; multi-dimensional association rule; frequent itemsets; rough set

I.  INTRODUCTION An association rule describes the interesting association  or relevant connection among items in the large amount of data [1]. Association rules have been widely applied in many areas, such as e-commerce, association analysis of the link between the web documents and so on. With the accumulation of data, many industry and researchers are increasingly interested in mining association rules, which makes the research and application of association rule mining is still constantly developing.

However, the size of the transaction database can be very large. It is very time consuming to find all the association rules from a large database and users may be only interested in some information. Moreover, the criteria of the discovered association rules may not be the same. Many uninteresting information for the user requirements can be generated when traditional mining methods are applied. Hence, a data mining language needs to be provided such that users can query only interesting knowledge to them from a large database of customer transactions. In this paper, a data mining language is presented in which users can specify the interested items and the criteria of the association rules or sequential patterns to be discovered.

Literature discussion: Association rule mining problem and Apriori algorithm were proposed firstly by Agrawal etc.

[2]. Initial research was largely motivated by the analysis of market basket data, the results of which allowed companies to more fully understand purchasing behavior and, as a result, better target market audiences. Some have also made  optimization of Apriori algorithm, see as reference [3,4].

However, Apriori-like methods may produce a large number of frequent item sets. It is time-consuming and costly to compute frequent itemsets. In response to this inherent defect, J. Han etc. [5] introduced a FP-growth, which doesn't produce frequent itemsets. After the first scanning, put the frequent itemsets in the database into a compressed Frequent Pattern Tree (FP-tree), meanwhile, keep the key information, and then, divide the FP-tree into certain condition bases, each is relevant to 1-lenth frequent itemsets, thus mining association rules on these condition base can be performed respectively. So it can reduce the search costs and improve efficiency. However, it is unrealistic to build FP-tree based on memory when the database is large. Besides, many constraint-based mining methods have been proposed. Pei and Han [5] developed pattern-growth methods for constrained frequent pattern mining and sequential pattern mining. An item constraint specifies what is the particular individual or group of items that should or should not be presented in the pattern. In paper[6],the author categorized all the constraints into five classes, proposed and studied one class of constraints called convertible constraints, which can be nicely integrated into the existing framework of frequent pattern mining, moreover, developed a new constrained frequent pattern mining method, called constrained frequent pattern mining CFG. But all the above approaches cannot discover the associations among certain items and all the other items.

Meo R etc. proposed a SQL-like operator for extracting association rules [7]. However, SQL-like operator cannot completely express the associations among certain items and all the other items. Furthermore, the SQL-like operator performs have little efficiency. Yen, S.J [8] proposed a data mining language for mining interesting association rules.

The approach constructs an association graph and generates all the frequent itemsets by traveling the association graph.

However, it needs to take a lot of memory space to record the related information.

To date, most of algorithms aim at mining 2-value attributes database or one-dimensional association rules mining, but multi-value attributes and multi-dimensional rules are more general. Although a number of one- dimensional association rules can be extended to multi- dimensional association rule mining, but there are lots of problem such as low efficiency when they are applied to large database [9].

DOI 10.1109/FSKD.2009.163    DOI 10.1109/FSKD.2009.163     In response to these issues above: Constraint-based approach to improve efficiency; allows users personalized requirements to mining process, obtain association rules in multi-dimensional case. This paper defines a mining language allows users to specify interesting items and criteria(such as support, confidence, etc. moreover, propose a novel multi-dimensional association rules mining technology based on rough set, which can reduce the generation of frequent itemsets search space and improve the efficiency.



II. BASIC CONCEPTS AND PROBLEM IN MULTI- DIMENSIONAL ASSOCIATION RULE MINING  2.1 The basic concepts [1,10] Definition 1 Let  1 2{ , , , }mAI I I I= be the set of all of items, in which ( 1, 2, , )kI k m=  is called item. An itemset of length k  is called an k ? itemset.

Definition 2 A transaction ,T TID I=< > is a tuple, whereTID is the identifier of transaction, and I AI? .

A transaction database TDB is the set of transactions, { 1, 2, }TDB T T Tn= . Let X be an itemset, i.e.

,T TID I=< > support (also can be said as contain) X  if and if X T? . The support number of X  is the number of transactions which contain itemset X , then the support of X is the support number divided by the total number of transactions inTDB .

Definition 3 If the support for an itemset X satisfies the user-specified minimum support threshold minsup ( 1 minsup TDB? ? ), then X  is called a frequent itemset, simply as a large itemset.

Definition 4 A rule has the form ,X Y?  in which X and Y  are two sets of items. , ,X T Y T X Y? ? = ?? and .

The support of a rule X Y?  is defined as the support for the itemsets X Y? . That is,  { ( ) } ( ) ( )  T T TDB X Y T  TDB support X Y P X Y  ? ? ? ? =? = ?  The confidence of a rule X Y? is defined as the ratio of the support for the itemsets X Y? to the support for the itemset X . That is,  { ( ) }  { }  ( ) / ( ) .

( ) T T TDB X Y T T T TDB X T  support X Y support X  confidence X Y ? ? ? ? ? ? ?  =  ? =  ?   If itemset X Y?  is a frequent itemset and the confidence of X Y?  is no less than the user-specified minimum confidence, then the rule X Y?  is an association rule.

An multidimensional association rule has the form ,X Y? in which ,X Y are called the antecedent and  consequent of the rule respectively, refer to logic formula composed by conjunctive normal form, X Y = ?? .

If a rule only described the items appears in certain case or not, then it is a single-dimensional boolean association rule, for example, buy milk ? buy bread [support = 2%, confidence= 60%]. If a rule concern two or more  dimensional, such as age, income, occupation, buy computer or not and so on, then it is a multidimensional association rule. For example, age( x ,?30?34? )?income( x ,?42K? 48K?) ? buy ( x ,?computer?), in which x refer to customer.

2.2 Multi-dimensional association mining Given a transaction database TDB (see as table 1),  support threshold is minsup , confidence threshold is minconf .Mining multidimensional association rules is a task to find those rules whose support is no less than minsup and confidence is no less than minconf .Usually, the task can be divided to two part processes: (1) the identification of sets of items or itemsets within the dataset;(2) the subsequent derivation of inferences from these itemsets.

TABLE I.  A TRANSACTION DATABASE OF BASKET DATA FROM A SUPERMARKET [11]  TID ME G income age beer fish  39808 CH M 27000 46 F F  63762 CA F 30000 28 F T  10872 CA M 13200 36 T F  26748 CA F 12200 26 T T  91609 CH M 11000 24 F F

III. ROUGH SET THEORY Rough Set theory, initially proposed by the Polish  mathematician Z. Pawlak in 1982 [12], is a powerful tool to deal with uncertainty and ambiguity of the data. To date, the theory has received an increasing attention from number of scholars all over the world [13-16], and it has been widely used in many fields, such as decision-making analysis, artificial intelligence, expert systems, pattern recognition, machine learning, knowledge discovery and so on.

Definition 5  Information system , , ,S U A V f=< > , where U is a non-empty finite set of n objects,  1 2{ , , , }nu u u ,called the universe of discourse, and  1 2{ , , , }mA a a a= is a non-empty finite set of m attributes, f is an information function, such that ( , ) : af u a U A V? ? ,  for any ,a A?  i.e., ( ) ,aa x V x U? ? ? . aV  is called the domain of attribute a .Especially, if ,A C D C D= = ?? ? , then , , ,S U A V f=< > is named a decision system (or decision table), where D  is a decision attribute set, and C is termed the conditional attribute set. We can treat the decision attribute as a kind of classifier on the universe of objects given by an expert or a decision-maker.

Definition 6 For an information system , , ,S U A V f=< > , one can describe relationships between objects through their attribute values. With respect to an attribute subset B A? , a binary equivalence relation BR  may be defined as  , , ( , ) ( ) ( )Bx y U x y R a x a y a B? ? ? = ? ?  BR  is referred to the relation with respect to B derived from information system S .With relation B , two objects are considered to be indiscernible if and only if they have the same value on each a B? , in other words, the indiscernibility relation of B  is defined by:  ( ) {( , ) , ( , ) ( , )}ind B x y U U a B f x a f y a= ? ? ? ? = Obviously, ( )ind B  is also a equivalence relation,  inducing a partition onU , denoted as / ( )U ind B , or simply as /U B . Each element in /U B  is equivalence class of ( )ind B , called as elementary set or elementary concept.

Definition 7 Let B A? , call B is a reduction of A , if: (1) ( ) ( );ind B ind A=  (2) there exist no 'B B? such  that '( ) ( )ind B ind A= .



IV. APPROACH BASED ON ROUGH SET FOR MULTIDIMENSIONAL ASSOCIATION RULE MINING  4.1 Analysis of rough set for multidimensional association rule mining  Based on rough set, we can have that , , ,TDB T I V f=< > Definition 8 Indiscernibility relation *( )ind I induces a  partition on T : /U I ? , I I? ? . Let [ ]X  be a equivalence  class in it, if I k? = , I k? = ? 1 1{ , , , },kI I I I ? = then  [ ]X  is called as k ? elementary set, denoted as [ ]kX ,  ' '1 1 [ ] { ( , ) ( , ) }k i i i k kX T f T I i f T I i= = ? ? = , Here,  kX  referred to k ? description ' '1 1( ) ( ) k  k k X I a I a= = ? ? = ,  where each normal form 't tI i=  is termed as description  clause, ' ( )tti V I? . For distinguish, we call the elementary set appear in the antecedent of the rule as feature class, and those elementary sets appear in the consequent of the rule as concepts.

Definition 9 The support of k ? elementary set is ([ ]) ([ ]) / ( ).k ksup_count X card X card T= , where ( )card X  means the cardinal of set X ,i.e., X . Let minsup be support  threshold, then [ ]kX  is called k ? frequent elementary set, if ([ ])ksup_count X minsup? . Denote kC  as the family of all  k ? elementary sets, kL as the family of all k ? frequent elementary sets.

Formally, use ,i jX Y  to represent the item in the antecedent and consequent of the rule, respectively.

According to ' '1 1( ) ( )k kX x X x= ? ? =  and  ' '1 1 ( ) ( )k kY y Y y= ? ? =  one can derive an association rule  X Y? between itemset X Yand , whose support and confidence as below, respectively,  ' ' ' '1 11 1 ([( ) ( )] [( ) ( )])  % 100% ( )  k kk k card X x X x Y x Y x  s cardU  = ? = = ? = = ?  ? ,  ' ' ' '1 11 1 ([( ) ( )] [( ) ( )])  % 100% ([ ])  k kk k card X x X x Y x Y x  c card X  = ? = = ? = = ?  ?   Based on the attribute reduction in RS, redundant rule can be defined as below.

Definition 10 If 1 2,X Y X Y? ?  are two rules inducing the same concept description, where  ' 1 1 2 2( ) ( ) ( ),k kX X x X x X x= = ? = ? ? = ,  '' 1 1 2 2 1 1( ) ( ) ( ) ( ) ( )k k k k k m k mX X x X x X x X x X x+ + + += = ? = ? ? = ? = ? =  i.e. 2 1 1 1( ) ( )k k k m k mX X X x X x+ + + += ? = ? = , then ''X Y?  is a redundant rule.

According to Apriori, a subset of any frequent itemset is  still a frequent itemset, any superset of a non-frequent itemset is still a non-frequent itemset, then we can have that:  Theorem 1 The necessary condition of a k ? elementary set to be k ? frequent elementary set is that all of the j ? elementary set including in the k ? elementary set is a  frequent elementary set. 1 1j k? ? ? .

To conclude, the rough set approach for  multidimensional association rule mining is composed of two major operations:  (1) According to Theorem 1, generate 1kC +  from kL  via the conjunction operator of elementary sets as follows: obtain kC , then choose those feature classes whose support is no less than support threshold to form kL . And then make conjunction by the feature classes of kL  and 1L , to produce 1kC + .

(2) Delete: According to the principle of Theorem 1, check all k ? description of 1[ ]kX +  in 1kC + , if there exist [ ]kX  doesn?t appear in kL , then delete [ ]kX  from kC .

Extract rules whose support is no less than support threshold via computing  ' ' ' '1 11 1 ([( ) ( )] [( ) ( )])  % 100% ([ ])  k kk k card X x X x Y x Y x  c card X  = ? = = ? = = ?  ?   in kL , and delete the elementary sets corresponding to the rules, in order to avoid redundant rules.

4.2 Data mining language expressing the users' personalization needs (Personalized Data Mining Language, PDML)  The data mining language for interesting multidimensio- nal association rules is defined as follows. Users can query association rules by specifying the related parameters in the data mining language.

Ming<interesting items> From<Transaction DB> with minsup s% and minconf c%  Where <interesting items>specify the items of interest, <Transaction DB> is used to specify the database to which users query the association rules, and minsup followed by     the user-specified minimum support s%, minconf followed by the user-specified minimum confidence c%.

4.3 An algorithm for mining interesting multidimensional association rules based on RS and PDML  In this section, we focus on mining interesting association rules according to proposed data mining language. We divide the query into two cases. Case 1: there are items in the antecedent and consequent of the discovered rules specified. Case 2: there are items in the consequent of the discovered rules specified, but the item in the antecedent is not specified, which can be any items. Suppose that the itemset specified in the antecedent of the discovered rules in Case 1 is 1{ , , }tX X X= , and the itemset specified in the consequent of the discovered rules is 1{ , , }Y Y Ys= . We propose an efficient algorithm named MIMAR-RS (Mining Interesting Multi-dimensional Association Rules based on Rough Set) to find all the interesting association rules according to the user requirements, which is described as follows:  Input: transaction data base TDB  , minimum support minsup , minimum confidence minconf  Output: multidimensional association rules sets that satisfy the user requirements RL  Process: Step1: Initialization RL= ? ; Step 2:Scan TDB ,find all 1-item feature classes, to form  the set 1C of 1-elementary sets, and compare these elementary sets? support to minsup TDB? , then find all the frequent 1-itemsets, generating 1L ;.

Step3: Obtain elementary sets containing the itemset specified and their support ( ' ' ' '1 11 1[( ) ( ) ( ) ( )]t st sX x X x Y y Y y= ? = ? = ? = for case 1; ' '1 1( ) ( )]s sY y Y y= ? =  for case 2), If there is no elementary set satisfy support threshold, then the algorithm end; else all elementary sets no less than minsup  compose  kL , where k is referred to the length of itemset that user specified ( k s t= +  for case 1; k s= for case 2). Then, for case 2, go to step 5;  ' ' ' '1 11 1 [( ) ( ) ( ) ( )]t st sX x X x Y y Y y= ? = ? = ? =  Or  ' '1 1 ( ) ( )]s sY y Y y= ? =  can be obtained by intersecting  '[ ]iX x=  and '[ ]jY y=  with elementary sets in 1L .

Step 4: For case 1, try to derive association rules that satisfy user-specified requirements. If there exists ' ' ' '1 11 1[( ) ( ) ( ) ( )]t st sX x X x Y y Y y= ? = ? = ? = , such that its confidence no less than minconf , then add it into RL, and delete ' ' '1 11 1[( ) ( ) ( )t tX x X x Y y= ? = ? = ?  '( )]s sY y= ,which is corresponding with the rule; else go to step 5;  Step 5: Generate candidate ( 1)k + -itemset 1kC +  as follows: join kL  and 1L  by intersecting their elementary sets.

And then 1kL +  can be obtained from 1kC + ;  Step 6: Similar to step 4, try to extract association rules that satisfy user-specified requirements in 1kL + , If there exists, then put it into RL and delete the normal form corresponding to it; else repeat these steps until the n iteration such that k nL + = ? , then stop the calculation, output RL.

Time complexity analysis of the algorithm: Suppose that there are n  records in transaction data base, m 1-item, and each 1-item can has t  discrete value. The time complexity of computing support of one elementary set is O(n) .If the length of itemset Y  that user-specified in consequent is L , i.e. Y L= , corresponding to h  concepts, then there are  1 2 2 2 m L m L m L m LK C t C t C t  ? ? ? ?= ? + ? + + ?  feature classes. In  the worst case, it needs computing K  support to performing the rules for one concept, and discreting the values for 1-item needs logn n ,so the time for the algorithm is  ( log )h Kn n n? + , since , ,m t h n , hence, the time complexity of the algorithm is ( log )O n n . Besides, in this algorithm, after obtaining frequent k -itemsets, if some rules can be derived, then the elementary sets corresponding to the rule will be deleted, thus avoid redundant rules, at the same time, reduce performing intersection for frequent ( 1)k + - itemsets, thus the efficiency of the algorithm can be improved.



V. AN EXAMPLE Suppose there is a transaction database TDB  (see as  table 2), there are 10 transactions in which, i.e. TDB =10.

If a user want to correlation between B  and E :  consider E as consequent itemset, discover the effect of B  to E , besides, minimum support is 30%minsup = , and minimum confidence 70%minconf = .

Firstly, we turn this requirement to PDML, that is: Mining ( B ), ( E ) From TDB  with 30%minsup =  and  70%minconf = .

According to the algorithm developed, the performing  process as follow: Scan TDB , obtain 1-elementary sets.

1 {[ 0],[ 1],[ 2],[ 1],[ 2],[ 0],  [ 1],[ 3],[ 0],[ 1],[ 2],[ 0],[ 1]}.

C A A A B B C  C C D D D E E  = = = = = = =  = = = = = = =   Obtain frequent 1-elementary sets. For example, ([ 0]) { 1, 2, 3, 8} 4 minsupSup_count A T T T T TDB= = = > ?  Analogously, the support of other 1-elementary sets can be computed. Then,  1 {[ 0] ,[ 1],[ 1] ,[ 2], [ 3],[ 1],[ 0],[ 1]} L A A B B C D E E  = = = = = = = = =    Find 2L  that contains B  and E , that is 2 {[ 1 1],[ 2 1]}L B E B E= = ? = = ? =     Try to derive association rules containing the itemsets that use-specified in 1L  as follow:  The confidence of 1 1B E= ? =  is : ([ 1] [ 1])( 1 1)  ([ 1]) { 1, 3, 5}  60% .

{ 1, 3, 5, 9, 10}  card B Econf B E card B  T T T minconf  T T T T T  = == ? = = =  = = <  ?    Analogously, the confidence of 2 1B E= ? =  is also 60% minconf< , So, both of the rules can?t be add into rule sets RL.

Generate frequent 3- elementary sets contain B and E  to form 3L  by performing intersection operation between elementary sets in 2L  and 1L .

For example, [ 1 1] [ 3] [ 1 3B E C B C= ? = = = = ? = ?? 1]E = can be put into 3C , as the support of which is  { 1, 3, 5} 3T T T minsup TDB= = = ? .

The result is 3 {[ 1 3 1],[ 2 1L B C E B D E= = ? = ? = = ? = ?  1]}= Try to derive association rules containing the itemsets  that use-specified in 3L as follow: 1 3 1B C E= ? = ? = , the confidence is 75%> minconf ; 2 1 1B D E= ? = ? = , the confidence is75%> minconf  Then, add these two rules into RL , and delete [ 1 3 1],B C E= ? = ? = [ 2 1 1]B D E= ? = ? =  from 3L .

Now, 3L become empty, so output the rules in RL , end.

TABLE II.  AN  EXAMPLE  TID A  B  C  D  E T1 0 1 3 1 1 T2 0 2 0 1 1 T3 0 1 3 0 1 T4 1 2 3 1 1 T5 2 1 3 2 1 T6 1 2 1 1 1 T7 1 2 3 2 0 T8 0 2 0 1 0 T9 1 1 1 1 0 T10 2 1 3 1 0

VI. CONCLUSIONS In this paper, on the basis of the literature research, we  introduce a data mining language. From the data mining language, users can specify the interested items or the  sequences, and the minimum support and the minimum confidence threshold to discover interesting multi- dimensional association rules. And then according to Rough set theory, we transform multi-dimensional association rules to elementary sets description, antecedents corresponding with feature classes, consequent corresponding with concept in RS, and then propose the efficient data mining algorithm MIMAR-RS to process the user requirements, combined with the idea of generating frequent itemsets dynamically, thus reducing the search space to produce frequent itemsets, reducing the time complexity. Furthermore, it can avoid redundant rules.

