Distributed Mining of Association Rules Based on  Privacy-Preserved Method

Abstract?With the rapid development of social information, the application of distributed database system is increasing.

Distributed data mining will play an important role in data mining. As one of the well-known distributed association rules mining algorithm, the FDM algorithm is very fast and efficient, however, the cost of this algorithm is very great because it is designed under the condition of non-shared resource.

Moreover, the important information at every site is exposed to other sites, which is not accord to the nowadays trend of attaching importance to privacy preserving increasingly. In this paper, we propose an improved algorithm based on the FDM algorithm. In the process, it computes the total support count with the privacy-preserved method, meanwhile ensures the source of every local large item-set and local support count is covered, so it reduces the time spent on communication and preserves the privacy of the data distributed at each site. The experimental evaluations show that the proposed algorithm is efficient and rather suitable for the practical application fields.

FDM; privacy preserving; association rules; data mining

I.  INTRODUCTION Association rules mining is an important research area in  data mining, which indicates relations among item sets in database, With the accumulation of the data, association rule mining in large data set attracts more and more attention, distributed mining algorithms are effective methods to solve this problem. At present, researchers have proposed some distributed algorithms to mining association rules such as PDM, CD, FDM, DMA, FPM, DDDM, Grid based method and parallel FP-Growth et al. Among these algorithms, FDM[1] is classical which is proposed by Cheung D.W. based on the CD[2] algorithm. The time cost of each iteration can be reduced by decreasing the communicating cost and the number of candidates in each site.

In each site, the FDM algorithm finds the local support counts and prunes all infrequent local candidate sets. After completing local pruning, each site broadcasts messages containing all the remaining candidate sets to all other sites to request for their support counts. It then decides whether large item sets are globally frequent and generates the candidate item sets from those globally frequent item sets.

This process continues until no globally frequent item sets is generated or no candidate set is produced.

To reduce message communication, it uses polling site method. In this method every itemset is assign to one local site and this site must calculate support count of it. So if a site need support count of any itemset, ask from its polling site. This idea reduces communications between processes.

FDM?s main advantage over CD is that it reduces the communication overhead.

However, the FDM algorithm was designed under the condition of non-shared-resource. In the paper[3], the network condition of topology is formed between all sites and local large candidate item sets are broadcasted to all sites that results into the exposure of important information of every site in the distributed system and unable to privacy preserving.

Therefore, based on the FDM algorithm, an improved algorithm which named PPFDM is proposed. In the process, it computes the total support count with the privacy- preserved method, meanwhile ensures the source of every local large item-set and local support count is covered. The experimental result shows that it reduces the time spent on communication and preserves the privacy of data distributed on each site.



II. PROBLEM  DESCRIPTION With the increasing development of information  technology, people appeal to privacy preserving urgently. In the paper[4], singularly high privacy preserving is required in some fields of data mining, especially in the field of finance, medical treatment etc. For example, to analyze the incidence of one disease, it needs for several hospitals to integrate and analyze the information held by their own, but in practice, the hospitals are unwilling to share the information for the reason of protecting privacy of patients or for other reasons. Thus, in some fields, privacy preserving becomes the important factor to evaluate the performance of distributed data mining. In the paper[5], As far as the defect of FDM algorithm concerned, since it was designed under the condition of non-shared-resource, the topology of network causes one site to expose its own information to other sites. Consequently, we improve the classical FDM  Third International Symposium on Information Science and Engineering  DOI 10.1109/ISISE.2010.125   Third International Symposium on Information Science and Engineering  DOI 10.1109/ISISE.2010.125   Third International Symposium on Information Science and Engineering  DOI 10.1109/ISISE.2010.125     algorithm in order to prevent revealing important data and improve the performance of the algorithm.

Distributed mining of association rules can be classified into two kinds: horizontally partitioned and vertically partitioned. In [6-8] , Accordingly FDM algorithm is on the base of horizontally partitioned data and correspondingly the theory of privacy preserving in horizontally partitioned data mining is to ensure local candidate item-sets are accessible to local sites but inaccessible to other sites. Hereby the motive of introducing privacy preserving in this paper, namely the problems need to be solved is as follows:  1) Ensuring that the local large itemset and local support count is covered to other sites.

2) Computing the global support count.

Firstly, secure set union is proposed to adopt by means of  encrypting, re-encrypting and permuting encrypted items at every site, so that the local large item-set and local support count could be transferred between sites and the tracing of source of original data could be prevented well.

Secondly, secure sum could be adopted to solve the second problem. In detail, we set up a site called home site, then it is proposed to compute a certain function from the home site to other sites with the privacy input into this function, return the ultimate function value to the home site, decrypt the returned function value at the home site according to the original privacy input, and obtain the secure sum finally, that is global support count.



III.  PRIVACY-PRESERVED METHOD As is known that in classical FDM algorithm, the local  large item sets need to be broadcasted to other sites after the local pruning so that the global support count of these local large item-sets could be computed. In order to ensure the information of local site such as local large item-sets and local support count could not be aware to other sites, we introduce the secure set union here.

Secure set union is a method of privacy preserving in data mining, through which the information of local site such as rules, local large item-sets etc. can be broadcasted in the distribution system, but owners of broadcasted information can?t be exposed. Theoretically, secure set union executes its function basing on the thought of permuting encrypt item.

Figure 1 shows the principle to set up secure set union.

))(( 32 CEE  ))(( 32 DEE                             )(1 CE   C )(3 CE                  D  )(3 DE   )))((( 132 CEEE                                                               ))(( 13 CEE     Figure 1.  Determining the union of itemsets  If given key 1,... nK K K? , for any permutation ,i j , the following two equations hold:  1 1 (... ( )...) (... ( )...)  i in j jnK K K K E E M E E M=                (1)  1 2 1 2, ,M M M M M? ? ? , given arbitrary 1, 2kk ? < , s.t  1 11 2 ( (... ( )...) (... ( )...))  i in j jnr K K K K P E E M E E M ?= <       (2)  By introducing the secure set union, each site encrypts  the local data and transfers it to other sites, then each site reencrypt data received from other sites. Accordingly to equation 1 and equation 2, duplicates in the original items will be duplicated in the encrypted items, and can be deleted.

In addition, the decryption can occur in any order. Thus, by permuting the encrypted items, it is prevented that each site tracks the source item-sets.

Obviously, through this method of secure set union, each site could transfer the information of local large itemsets and local support count etc., without revealing that information from which site. However during the process of transferring data, the number of local large item-sets is revealed which exist in two sites. For example, if K site have a local large item-set, it will be duplicated k times.

Although the item-set itself is not revealed, the true secure computation could not reveal this information. In practice, allowing innocuous information leakage in an algorithm means lower cost than the algorithm with fully secure computation.

On the other hand, we would like to compute the global support counts and ensure the local supports of each site could not revealed to other sites as well. This can be easily fulfilled by the method of secure sum.

If given sites1, 2,...s , first a home site(site No.1) must to be determined; and site No.1 randomly produces a randomR which ranges in [1, ]n  and will be added the local support count of site No.1, then transfers 1 modR v n+  to site  No.2; asR is a random ranging in[1, ]n , site No.2 could not obtain the real value of 1v  after receiving the information of  1 modR v n+ ; similar mode to compute the function will be set up in remainder sites No. l  ( 2... 1l s= ? ) and now the  received function value in site No. l  is  mod  l  j j  V R v n ?  = = + ?  ,  which will be added R  (that  is  mod ( ) mod l  j j j  R v n v V n =  + = +? ) and transferred to site  No. 1l + ; ?; similarly the last site (site No. s ) computes the function and returns the function value to site No.1 where decryption will be implemented according to the value of cryptically R , global support count will be acquired and local support counts of other sites can?t be revealed. Figure 2 shows the principle to compute secure sum.

Obviously, the method of secure sum will be confronted with problem if sites collude. For instance, site No. 1l ?  and site No. 1l +  could collude, then could confirm the real  D  C  C      712 +     !219 =? R   17=R   517 ?   0+R  Figure 2. The principle to compute secure sum  value of lv  by comparing the function values that they sent out and received. However one site could be threatened on privacy secure, unless all the other sites colluded. This makes it possible for secure sum to be used in our proposed method.



IV. EXPERIMENTAL  EVALUATION The proposed improved algorithm (PPFDM) is evaluated  on some UCI datasets[9], and the distributed system in the experiment is made of four computers which are deployed with the following hardware and software: CPU: Pentium(R) D CPU 2.60GHZ; Memory: 1024MB; Operation System: Windows XP. Java was adopted as the programming language in the experiment.

The front 1400 records of dataset named Contraceptive Method Choice in UCI datasets are used in the experiment.

We first discretize an attribute named Wife's age, the original values of which are integers and range in [20, 50] (the value of other attributes is discretized originally and need not be scattered). We suppose the data distributes symmetrically in each computer, namely the numbers of the data distributed in each site are approximately equal. Our scheme is described as: symmetrically distributing 1400 discrete records to each site, just 350 records per site. Table I describes some samples with records.

Among the above attributes, firstly, attribute A denotes wife?s age: 2 for 20~29 years old, 3 for 30~39 years old, 4 for 40~49 years old; secondly, attribute B denotes wife?s education level which ranges from low to high as: 1, 2, 3, 4; thirdly, attribute C denotes husband?s education level which ranges from low to high as: 1, 2, 3, 4; and attribute D is the statistic of number of children ever born; attribute E shows wife?s religion: 0 for non-Islam and 1 for Islam; attribute F figures whether wife is now working: 0 for working and 1 for not working; attribute G denotes husband?s occupation level which ranges from low to high as: 1, 2, 3, 4; in addition, attribute H denotes standard of living index which ranges from low to high as: 1, 2, 3, 4; and attribute I shows media exposure: 0 for good and 1 for not good. Finally, attribute J shows way to contracept: 1 for never use, 2 for long-time use and 3 for short-time use.

Given min_sup=20%, min_conf=70%. In the testing on effectiveness, we got the average time of 10 times tested on experimented dataset respectively by classic FDM algorithm  and improved algorithm, and the experimental results are showed in Table II.

TABLE I.  SOME SAMPLES  Code of attribute   No. of  record Name of  attribute  ? ? ? ? ?  A Wife?s age 2 4 4 4 3  B Wife?s  education 2 1 2 3 3  C Husband?s education 3 3 3 2 3  D Number of  children ever born  3 10 7 9 8  E Wife?s religion 1 1 1 1 1  F Wife?s now working? 1 1 1 1 1  G Husband?s occupation 2 3 3 3 3  H Standard of living index 3 4 4 3 2  I Media exposure 0 0 0 0 0  J Contraceptive method used 1 1 1 1 1  TABLE II.  EXPERIMENTAL RESULTS ON EFFECTIVENESS TESTING  FDM Algorithm PPFDM Algorithm  the Result of Large  Association Rules  301,111 JIEJFE ????  301,111 JIEJFE ????  Time Spent 2246ms 2019ms   As is shown that in Table II the proposed improved  PPFDM algorithm is more effective than the FDM algorithm, At the same time, we have got the same large association rules by the improved algorithm. Furthermore, we have compared the efficiency of the improved algorithm with the classical one. The proposed algorithm reduces the computation time because secure sum has been used in the improved strategy and the new communication mode has decreased the time which spent on communication with the set up of home site. Besides, privacy of each site has been also preserved well.



V. CONCLUSIONS In this study, we propose an improved algorithm  (PPFDM) based on the FDM algorithm and the computation method of privacy preserving. In the process, this algorithm computes the total support count with the privacy-preserved method, meanwhile ensures the source of every local large item-set and local support count is covered, so it reduces the time which spent on communication and preserves the privacy of the data distributed at each site. The experimental evaluation proves that the improved algorithm is efficient and rather suitable for the practical application fields,  Site No.3  Site No.2 -5  Site No.1     particularly those fields which require preserving privacy in the mining process.

