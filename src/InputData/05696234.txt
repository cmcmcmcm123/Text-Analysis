A novel GEP-based multiple-layers association rule mining algorithm  CAI Hong-guo            YUAN Chang-an         LUO Jin-Guang        HUANG Jin-de

Abstract?to mine popular accessed Web pages items and find out their association rule from the Web server Log database  for junior users providing recommendation service. A novel  GEP-based algorithm for mining multiple-layers association  rules was presented. Firstly, takes generalizing technology as a  way to value fitness function in GEP (Gene Expression  Programming). Then, relying on the significant self-search  function of GEP, the most optional species was evolved. The  frequent items and association rules in the next deeper layers  can be mined by using traditional support-confidence method  in sub-database. The algorithm improves on the frame of  traditional association rule mining and uses a new evolutionary  algorithm for mining association rules. Finally, the validity and  efficiency of the method are presented by the application in the  paper.

Keywords-GEP; Multiple-layers association rule;Web Usage Mining;Generalizing;Data mining;Abstract Frequency Items.

i. Introduction  The WUM (Web Usage Mining) mines the characteristics and performance of the behavioral patterns of users when the users access to Web which interact with server [1]. An important application of the current WUM is a personalized Web services for personalized recommendation system [2]. It is an important research in personalized recommendation method for mining popular accessed Web pages items and find out their association rule from the Web server Log database for junior users. The literature [3] [4] proposed some algorithms and recommendation system from mining frequent association rules. In recent years, the evolutionary  algorithm is used for mining association rules, which becomes hot topic. The literature [5] discussed how to apply genetic algorithm to the process of mining association rules in a large database. The literature [6] proposed how to use PAGEP (mining Predicate Association by GEP) algorithm for mining generalized association rules. These methods can solve for mining association rules in the same layer in the WUM of multilevel association rule, but the capabilities for mining association rules between layers in multi-layer association rules seem inadequate. This is because of: (1) the above methods encode simply with a single character encoding to the items, but not address code of the item in different layers and not make coding a good explanation. (2) Some of the above algorithms generate any individual by scanning database, so a large time and space overhead. The literature [7] proposed that you can tap into the frequent item-sets after the abstract by generalizing a large transaction databases. After getting a sufficient degree if abstraction to support frequent items, the GEP-based multiple-layers association rule mining algorithm, which is used to split the database and find out the common characteristics in sub -database, and then mining the lower frequent item-sets. Gene Expression Programming (Gene Expression Programming, GEP) is the development of new concept combines the advantages of both based on genetic algorithm (Genetic Algorithms, GAs) and Genetic Programming (Genetic Programming, GP), more flexible than the genetic algorithm codes, have a stronger ability to solve problems [8][9]. The literature [7] combined with the generalization technique to the GEP, we can guide the direction of the evolution of GEP individuals to generate   DOI 10.1109/CIS.2010.22    DOI 10.1109/CIS.2010.22    DOI 10.1109/CIS.2010.22     more optimum individual and then scan sub-database which greatly reduce the time and space overhead and improve the capacity of mining association rules between layers.

ii.  Related works  A. The multiple-level association rule mining Association rules, also known as association models,  association rule mining found an interesting correlation or related relationship between item-sets in large data. Mining algorithms first is put forward and research by the Agrawal, the pruning algorithm based on frequent item-sets is put forward by Agrawal et , which is divided into two stages, first , identify all the frequent item-sets, and then frequent item-sets generated the strong association rules, these rules must satisfy the minimum support S (support) and minimum confidence C(confidence). Mining association rules problem is generated over S and C were given by the user's minimum support and minimum confidence of association rules that is to produce strong rules. However, for many applications, the strong association rules between data items in the lower or the original abstraction layer is difficult to find. Mining association rules between multiple layers have enough sufficient flexibility is an important area of data mining Data. Association rules mining in a number of layers called multi-level association rules [7]. Multilevel association rules in accordance with the rules involved level can be divided into the same level association rules and association rules between layers. At present, the mining of multilevel association rules basically follow the "support - confidence" framework and concentrated on the same layer associated mining, this mining association rules method apply to the mining between layers, capacity of what is clearly insufficient. This method in the paper can improve the traditional multi-level association rule mining framework.

B. Based on the abstract generalization frequent item-sets  mining Definition 1 (Abstract Frequency Items, AFItems) The  items in the item-sets of the library is a database property value, property value in data processing can be carried out along dimension for the generalization, after a  generalization to the top, the top-level item-sets is frequent, and we call these frequent item-sets of the top to AFItems.

This step of generalization, with such as DB2, SQL Server and other database tools, can be most easily completed in the algorithm, we say that this step is generalizing (TS). The experiment in this paper Uses Microsoft SQL Server 2005 Analysis Services deal with the generalization process. Microsoft SQL Server 2005 Analysis Services provide the tools that analysis data warehouse and data mart stored data, SQL Server 2005 Data Transformation Services (DTS) is a Microsoft SQL Server 2005 Analysis Services for developing components, data conversion services support to extract data from a data source, and carry out complex data conversion from time to time and store conversion of data have been summarized in another data source. It can generalize and aggregate in multiple dimensions of database.

Generalization play an important role in the complex database, usually indiscriminate mining in large databases could lead to a large number of "rules", but actually the number of rules are not interested in a particular user, if there is a clear depicts before the excavation, it is said that we hope that the abstract frequent item-sets, they can cover most of the transaction. The benefits of which is: develop the road map in the macro and provide the basis for a large search space, reduce blindness of searcher, at the same , the lower frequent item-sets that is not belong the abstract frequent item sets will be pruned off, this would be similar to the Agrawal?s pruning algorithm based on frequent item-sets.

iii.  Algorithms for mining multilevel association rules  A.  The fitness measure function The fitness value of GEP is used to measure each  individual of populations in the optimization calculation, which may meet or help to find the fine level of the optimal solution. The MAGGEP(mining Multiple-layers Association rule using Generalizing- based GEP) algorithm used the following definition measure individual adaptability.

Definition 2 Evaluation (T) by generalizing (TS): set a     transaction T = (I1, I2 ... ... .. Im, In), generalizing (TS) mine the General Mining frequent item-sets that is called AFItems, if the In of T can be generalized to AFItems, and In ? Im, then , fitness (T) = fitness (T) +U  (U is a constant value, indicating a weight)     (1) B. Algorithm thinking depicts Step1: generalizing?TS?,referencing the literature [7] with the generalization Method based on the planning database mining, then obtaining AFItems; Step2: randomly generate initial population; Step3: evolve by GEP to the optimal population , get some better individuals; Step4: Every one of the population individuals will be scanned in the sub-database based on the basic framework of "support - confidence". The frequent items of individuals and association rules to meet the conditions can be outputted.

Algorithm: MAGGEP (mining Multiple-layers Association rule using Generalizing-based GEP) algorithm  Input ?transaction TS, support s, confidence c Output: frequent items, some set of Multiple-layers  Association Rule.

Steps: 1) Create Initial population;   // randomly  generated initial population.

2) nGeneration = 0; 3) WHILE true 4)     Evaluation(T) by generalizing?TS?; //  Adaptive measurement of individual.

5)     KeepBest() ; // Selection operation.

6)     IF nGeneration>=nMaxGeneration THEN 7)   break; 8)     END IF 9)     FOR i=0 to nPopulationSize/2 DO 10)   select two individual p1, p2 from current  population; 11)      Crossover on p1, p2, get new individuals s1,  s2; // several recombinant operation.

12)     Do mutation on p1, p2; // mutation  operation.

13)      append to next generation; 14)     END FOR 15) nGeneration++? 16) END WHILE   // Obtain optimum population F 17) FOR each T in F DO 18) FItem=?; F?=?; 19)   FOR each Item in T DO 20)   Scan TS with Item get support s?; 21)   IF s? ?s 22)   FItem=FItem+Item; 23) END FOR 24) RETURN FItem;  // Obtain the frequent  item-sets 25) IF FItem is not in F? THEN 26)   add FItem to F?;  // F? is the set of all frequent  item sets 27) END FOR 28) FOR each FItem in F?? 29) Scan TS with? array: FItem[m-1] ?element:  FItem[m]?, get  confidence c?? 30) IF c? ?c 31) RETURN  array: FItem[m-1] ?element:  FItem[m]? // Output association rules to meet the conditions  32) END FOR Comparison the MAGGEP algorithm with the genetic  association rules algorithm in the literature [5] is easy to find: the MAGGEP is expert in expression domain of the attributes space and more extensive explanation; At the same time,  the MAGGEP algorithm compared with the genetic algorithm and the PAGEP algorithm[6], because there is a road map of searcher space by a generalization way and then reuse support - confidence framework, the time and space complexity of the MAGGEP algorithm significantly reduces greatly. If the number of generation of traditional genetic algorithm is N, then the scanning frequency number of the MAGGEP algorithm is the algorithm in the literature [9] 1 / N in scanning sub-database .Comparing the MAGGEP algorithm with the classical pruning algorithm, the scanning frequency and the number of transactions of the database reduce greatly. The     MAGGEP algorithm is more suitable for mining multilevel association rules between different layers.

iv. WUM experiment  In my experiment, each layer of the site is divided into 10 themes and the association rules tap into the third layer .Then more than 10 * 10 * 10 pages were dig to find frequently visited pages and found to be associated. A larger  web site can tap into a deeper layer. For understanding easily, the experiment taps to the third level only as a simple example.

Through mongering and squashing similar transactions, then setting the value of S and C, We can easily tap into a relational based on generalizing (TS) as (2): Admissions Employment\ academic departments Remote   Support = 60%, Confident = 67.5%   (2) This abstract frequent item-set illustrates that during this period external users access Admissions Employment and academic departments frequently under the home page.

A. Main parameters of GEP  Multiple genes encoding of GEP: each gene is called as a one-dimensional array of constant length, a gene represents an item, the two- dimensional array of fixed length form each chromosome, and the whole two-dimensional array represents a transaction. After specific operators transform item-sets element and transaction, and then form the search space. All the Chromosome encoding and decoding methods of  individuals see in the literature [6] [8] [9] and so on. In a visit to transaction, home should be washed as noise; a web page was visited again in the same transaction that represents only one gene. Each page in a transaction can be encoded and decode at different levels, for example.1 (Fig 1) as follows: academic departments - the Faculty of Arts - Master and teacher  (b-ba - bac) can be represented (& ~ bdf & baeg & & bac). e.g.Fig1.

Population size (M): algorithm uses the strategy of generalizing and partition in the database .The strategy can be generalized the Web log data of 10 days to AFItems and mine the Web log data of 1 day with GEP.

Initial population generated randomly. It?s dissatisfied to set the too small initial population.

Genetic recombination (crossover) rate: this case is to mainly extract specific frequent item sets; the main genetic operator is mutation and Genetic recombination. In all of the genetic operation, the variation operation is better than the other operation, and the variation operation in performance is the best.

B. Analysis of experimental results Through the experiment, set the different S values and the operating parameters (e.g. table1), some statistically significant and obvious correlation between the frequent item-sets was extracted and analyzed. The results can be show in table2. Note, the experimental results used in the page and decoding: ?1 enrollment and employment?b??2 academic departments?d??3  Graduate Admissions?ba? ?4  Graduate jobs?bf??5  swap Notice?bae??6  &  b a  &  b d  & c  & a  b  + +  Fig 1: Example.1 encoding and decoding  &~bdf&baeg&&bac  ?Example. 1? Table1 experiment Parameters.

Times of run 50  evolution algebra 50  Function set &,~  Terminal set a, b, c, d, e, f, g, h, I, g  Number of gene 10  Head length 2  copy the rate 0.4  mutation rate 0.05  2-point cross rate 0.1  1-point cross rate 0.1     Department of Information Technology?def??7  Graduate teacher Instructors?bac??8  Resources and Environmental Sciences?dd?.

Table 2: experiment performance analysis Table2 shows that: the three experiments all could better find frequent item-sets; test1 is the strongest in extracting association rules; The value of confidence in test2 and test3 declines and decreases slope, indicating that the capability of association rules mining declines; as the same time, we observe a two-layers associate themes in the test1 and a three-layers associate themes in the test2 and test3.The levels of the layers are more abstract, the ability of association rules mined is the stronger by the algorithm. In accordance with characteristics of multi-level association rule mining .The experiment also demonstrated the limitations of the algorithm.

v.   Conclusions  Through a combination of database generalization technology, the MAGGEP algorithm for association rule mining applied to multi-layers. Next, this application will be integrated into real-time system model to recommend for junior users in Web Intelligence .Meanwhile, the GEP algorithm combined with the generalizing technology applies to sequential pattern mining also has research value.

This article focuses on introducing this method, on such issues; the more the parameters setting of the GEP and comparative analysis of performance of the algorithm will be discussed in a separate paper.

ACKNOWLEDGE  This work is supported by the National Science Foundation of China Grant #60763012, the National Science  Foundation of Guangxi Grant #0731028 and the foundation of Guangxi Educational Committee Grant #2008C064.

