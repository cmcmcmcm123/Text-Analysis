Scaling Concurrency of Personalized Semantic Search over Large RDF Data

Abstract?Recent keyword search techniques on Semantic Web are moving away from shallow, information retrieval-style ap- proaches that merely find ?keyword matches? towards more interpretive approaches that attempt to induce structure from keyword queries. The process of query interpretation is usually guided by structures in data, and schema and is often supported by a graph exploration procedure. However, graph exploration- based interpretive techniques are impractical for multi-tenant scenarios for large databases because separate expensive graph exploration states need to be maintained for different user queries. This leads to significant memory overhead in situations of large numbers of concurrent requests. This limitation could negatively impact the possibility of achieving the ultimate goal of personalizing search. In this paper, we propose a light- weight interpretation approach that employs indexing to improve throughput and concurrency with much less memory overhead.

It is also more amenable to distributed or partitioned execution.

The approach is implemented in a system called ?SKI? and an experimental evaluation of SKI?s performance on the DBPedia and Billion Triple Challenge datasets shows orders-of-magnitude performance improvement over existing techniques.

Keywords?Scalability; Concurrency; Keyword Query Interpreta- tion; Personalization; Big RDF data; Semantic Web;

I. INTRODUCTION  There is increasing interest in exploiting the growing amount of structured, semantic data on the Web to improve the quality of keyword search. The idea is to be able to better identify a user?s intended semantics for a query so as to provide the appropriate set of results. To achieve this, techniques must go beyond the IR or ?meaning as match? interpretation styles used by traditional search engines. Most techniques proposed for keyword queries over structured/semi-structured data are also based on such interpretation styles with relational databases ([1], [2], [3], [4], [5], [6]) and XML databases ([7], [8]). The limitation of these approaches are well known: i) result lists that are semantically incongruent so that users have to manu- ally filter out results that are irrelevant to the user?s querying context; ii) inability to deal with moderately complex queries.

One example is the class of ?list queries? that describes a set of entities rather than a specific entity. For example, the query ?patents big data management? is likely intended to return a list of patents on topics related to big data management. For example, a query for ?patent big data management? may miss patents that do not contain the phrase ?big data management? but contain keywords like ?scalable?, ?MapReduce? and so on.

Processing such queries with current IR techniques presents challenges due to the length of such queries. In addition, some keywords in the queries are descriptive, which should not be  considered as data explicitly associated with relevant results but as metadata.

To address this limitation, semantic search techniques have been proposed ([9], [10], [11]) where an ?interpretation? phase is inserted prior to query evaluation. The goal of interpretation is to map a keyword query to a structured query, thereby giving the query a fixed semantics for which semantically congruent results can then be computed. However, identifying a unique semantics is often difficult because the terse nature of keyword queries makes them ambiguous. Consequently, most techniques address this as a top-K problem producing a list of K structured queries representing the K most likely intended se- mantics for a given keyword query. The structurization process involves computing connected subgraphs of keyword hits on a summarized representation of schema and data graphs. These graphs are mapped to structured queries by distinguishing the roles of keywords in a query i.e. metadata keywords vs. data keywords. For example, for the query ?conferences tutorial big data? depending on the roles assigned to the word ?conferences?, the interpretation could be ?the list of conferences with tutorials on big data? or could be the ?list of tutorials at conferences on big data?.

Heuristics for ranking connected subgraphs typically assign the intended semantics of a query to the probability of the query, defined in terms of the frequency or occurrence of subgraph structures. This is similar in spirit to search engines determining most relevant results based on click patterns in query and click-through logs. However, such techniques are impersonal and fail to customize interpretation of a query to an individual user?s needs. As an example, while the most frequent intention associated with the query ?magic sets? may be toys because the shopping context is very general and has a large population of users. However, the same query could be intended to mean the query optimization technique which is well known but in a much smaller community. Unfortunately, such a relatively unpopular context would not be considered even if intended. It is important to note that this is not simply a question of profiling users and determining interests of a user because users have different interests and interact with the Web in different contexts. For example, a database researcher issuing the query ?magic sets? may intend the context of toys when shopping for some gifts. Another example is ?Jaguar Speed?; a computer science researcher may be investigating the supercomputer, then at a different time be buying a car, and yet another time be helping a middle school child with a science homework. Therefore, the ideal situation is to personalize query interpretation by identifying the intended interpretation for a specific user at a specific time.

In our previous work ([9], [10]), we addressed the problem of ?personalizing? keyword query interpretation by capturing and exploiting a user?s ?ambient? query context in terms of the queries preceding a query being considered. The underlying hypothesis is that users often pose multiple queries related to a specific need or task so that earlier queries can provide some contextual basis for future queries. The approach proposed modeled this context-aware query interpretation as computing top-K connected subgraphs over a context-aware summary graph. The context-aware summary graph was modeled as a dynamic weighted graph model in which keywords in a query ascribe weights transfer summary graph and the impact. The result is that for a given query being issued at a given time, connection subgraphs involving concepts and relationships with lower costs (higher weights) are ranked higher in the top- K list (decay model). A key challenge addressed in previous work is the indexing and management of the dynamic weight graph model and efficient algorithm for computing the Steiner Trees.

Motivation. Like the non-personalized techniques for query interpretation, our earlier proposed context-aware interpreta- tion technique is heavy-weight because it is based on graph exploration on memory resident summary graphs. For big data, the number of hits per keywords and the degree of connectivity between nodes rises, increasing the exploration search space for connection subgraphs and thus memory requirements. For example, the keyword ?conference? has 19 occurrences in DBPedia 3.61, which includes 272 concept nodes and around 3000 properties (edges). Further, it has 1785 hits in the Billion Triple Challenge datasets (BTC 2009)2, which contains 150232 class nodes and around 1.3 million edges (BTC is a superset of DBpedia). In personalized query interpretation, each user has a different dynamic weighted graph because of differences in their query contexts. This could imply a separate graph exploration process for each user. For example, the memory requirements for interpreting a single query on the BTC dataset is around 500MB, which leads that a server with 8GB RAM can handle only 17 user queries concurrently. Consequently, we are faced with the limitation of only being able to meet the goal of personalized and contextual search under low concurrency/throughput, which is impractical for real multiuser search environments.

Contributions and Scope. In this paper, we focus on in- creasing the practicability of personalized semantic search in big data contexts by introducing lightweight interpretation techniques. Specifically, we propose an approach called ?SKI that uses a dual indexing scheme to maximize the concurrency and throughput of the query interpretation process while min- imizing the latency. SKI indexes user-specific query context information separately from the more general user-independent information about concepts and their relationships. The former is captured in an index ? personalized query context map (PCM) and the latter in dense path index (DPI) ? an index of subgraph structures. The data-specific indexes inform a graph exploration-free interpretation algorithm?s (GeFree) decisions about which substructures to prune and how to assemble substructures into complete interpretations. GeFree avoids the need for graph exploration and is fast and memory-efficient reducing both latency and memory requirements of query  1http://blog.dbpedia.org/2011/01/17/dbpedia-36-released/ 2http://km.aifb.kit.edu/projects/btc-2009/  interpretation.

Impact. We posit that integrating our proposed scalable query interpretation approach with many ongoing-efforts on scalable query-answering techniques, will result in scalable Semantic Web search architectures.

The rest of the paper is organized as follows: Section 2 includes the preliminaries of the keyword query interpretations and the problem definition. Section 3 describes the overview of the SKI architecture. Section 4 discusses the details of the index structures and algorithms used in the SKI. Section 5 and 6 present performance evaluation results and related work.



II. PROBLEM DEFINITION  Let ? be a universe of words. An RDF schema graph is a labeled graph GS = (VS , ES , ?S) where the nodes represents classes and edges represent properties. ?S is a labeling function that maps a graph element (node or edge) to l ? ? that contains words that make up the label of the class or property. An RDF data graph is also a labeled graph GD = (VD, ED, ?D, ?D) that has VD, ED and ?D are similarly defined with ?D mapping a graph element to set of words contained in the string literal associated with that element. ?D maps each data graph element (node or edge) gD to a set of schema graph elements: those to which gD is connected by a ?rdf:type? relation.

Given a schema graph GS and data graph GD, an annotated schema graph GA is a tuple (GS , ?A) where ?A maps each graph element gS such that ?A(gS) = { ?S(gS) ? ?D(gD) |gS ? ?D (gD)}. In other words, the function ?A lifts labels on elements of data graph to the schema elements that they are instances of, thereby annotating the schema graph with keywords from the data graph.

A keyword query Q is a set of words {k1, k2, ..., k|Q|} from the universe ?. An element gi of an annotated schema graph GA is called a hit for keyword k if k ? ?A(gi). The set of all hits for a keyword k is denoted as hit(k). An interpretation [[Q]] of a keyword query Q is a subtree of GA, that contains one hit for each keyword in Q. Since there are potentially multiple interpretations of a keyword query (due to different possible combinations of hits for all keywords), we focus on a specific (top) interpretation for Q which we denote [[Q]]?, but ignore for now, how to choose [[Q]]? from the set of alternatives for Q.

DEFINITION 2.1: A context-aware annotated graph or CAG for short, associates weights with an annotated schema graph based on the sequence of queries that have been posed on that graph. A sequence of queries Q1, ..., Qm produces a sequence of weighted graphs G0 ? G1 ... ? Gm where Gt (0 ? t ? m) is the weighted annotated schema graph produced after Qt.

Gt is defined as (GA, ?t) where ?t ? W , W is a family of weighting functions s.t:  ? ?0 ? W is an init. function that assigns weights to all elements of the annotated schema graph prior to Q1;  ? ?t ? W is defined s.t. for g ? [[Qt]]?, i.e. in the top interpretation for Qt, ?t(g) = ?(?t?1(g))).

In other words, after Qt, the weights of a graph elements in the top interpretation of Qt, is a function of their weights after     Fig. 1. An example context-aware annotated graph (CAG) and its interpretation processes. The example CAG contains the two possible interpretations on the the keyword query ?Mississippi River Bank?: the bank of the Missippippi River (a financial institute) or the Missippippi River (a large natural stream of water).

Qt?1. This leads to the definition of an annotated schema graph as a dynamically weighted graph whose elements? weights change with queries.

As mentioned earlier, the details of how to select [[Q]]? ? the top interpretation for a keyword query Q, are omitted.

However, this can be thought of as the lowest weighted interpretation when the weights of all graph elements in that interpretation are combined. The combination cost function and ? are discussed in [9], but we illustrate the concept of a CAG with an example.

Context-Aware Interpretation Example Fig. 1(a) shows the example CAG with some classes and literal nodes which are annotated with literals from the data graph. Given a keyword ?Mississippi River Bank?, we find matches in this graph and select the ?highest? weighted connecting subtree as the ?top? interpretation. In Fig. 1(a), the graph has been initialized with some weights, e.g., the class nodes ?Mississippi River Bank? and ?Bank? are initialized with the weight 1.0 and 2.0 respectively. For example, the green subtree involving the class nodes Mississippi River Bank and Bank represents the interpretation of the query as the bank of the Missippippi River while the purple subtree involving nodes Mississippi River and River represent the interpretation the Missippippi River.

However, based on the weight assignment, it is difficult to determine which interpretation should be selected as a highest weighted one since the total weight of subgraphs are the same, i.e. 3.0 and 3.0 for both subtrees. Note that the method for computing the initial weights can vary and is not our primary concern here. We calculate the total weights as the sum of the weights of nodes and edges, not the sum of the weights of all paths represented in the subgraph.

Fig. 1(b-d) show how context-aware interpretations are pro- cessed with two paths originating from the initial graph. Each path represents a sequence of queries performed by a user: the top path (Q1 and Q2) by the user X and the bottom path (Q3 and Q4) by the user Y . In the top path, Fig. 1(b) shows that the keyword query Q1 ?Mortgage Rate? results in increasing the weight of the nodes Mortgage Loan and Rate  from 1.0 to 2.0, and the weight of its neighboring node Bank from 2.0 to 2.5. These changes make the top interpretation of the keyword query Q2 becomes the subtree consisting of the nodes Mississippi River Bank and Bank in Fig. 1(c) because the sum of the weights of those nodes are the highest one, i.e.

2.5+1.0 = 3.5. Similarly, in the bottom path, the weight of the node River is increased from 1.0 to 1.5 because of the keyword query Q3 ?Fishing Activity? in Fig. 1(d). This increment leads to the subtree with the nodes Mississippi River, River, and River Bank as the top interpretation of the subsequent query Q4 because its weight now becomes the highest one, i.e., 1.0 + 1.5 + 1.0 = 3.5. Note that Q2 from the user X and Q4 from the user Y are the same queries but produce different top interpretations.

Although our example illustrates the changes in weights as increasing weights, the real situation is the inverse (higher weight leads to lower cost). Since we are solving this as a translation of the Steiner Tree problem which is a minimization problem, the ?top? interpretations should actually be the small- est weighted ones. Consequently, our concept of increasing weights in example to reflect importance, is actually done as decreasing weights.

The problem we address in this paper is supporting personal- ized CAGs, i.e. for two users X and Y with query sequences QSX and QSY resp., CAGX and CAGY are two (possibly different) CAGs associated with X and Y resp. The conceptual model of CAGs extends very naturally to multiple users.

However, the key challenge is how to scale up the number of concurrent users, since a different CAG has to be managed for each user? Particularly, in the presence of big annotated schema graphs. The following section discusses our approach.



III. THE SKI APPROACH  A. Architecture Overview  In this section, we present the SKI strategy for scalable personalized query interpretation that consists of three main components:     1) a distributed master-slave architecture for scalability 2) an index for user query-context information called a per-  sonalized query context map (PCM), which is separate from a more heavy-weight index of user-independent information about graph structures, i.e., concepts and relationships in the schema graph 3 captured in a couple of other indexes. After each query has been interpreted, PCM is updated to reflect this new information about query context i.e. ?Uit ? ?Uit+1 for user Ui. To avoid the overhead of maintaining all dynamic weighted graphs for supporting multiple concurrent interpretations, PCM maintains only node-weight maps for each user.

3) an algorithm GeFree for computing top-k connection subgraphs for each user query in which user-independent indexes (i.e., dense path index, DPI) are shared across interpretation instances for each user and are then com- bined with their user-specific context information in the PCM. GeFree is graph exploration free making it more ef- ficient and allowing higher throughput and the sharing of user-independent indexes minimizes amount of memory required for interpretation to allow increased concurrency.

4) form the query interpretation layer which is interfaced with the query answering layer that uses standard RDF query processing engines such as SESAME.

In this paper, we focus on the interpretation layer. The slave nodes are grouped into clusters, or interpretation clusters for and the master node is responsible for scheduling user query requests to interpretation clusters and exchanging information such as resulting interpretations and query answers between users and interpretation clusters. Each interpretation cluster is responsible for processing a specific group of users? query requests. Indexes are replicated across all slave nodes with one exception where, a partitioning of PCM in an interpretation cluster contains only the context map for the group of users maintained by this cluster, it is replicated across slave nodes within this cluster. Each slave node in an interpretation cluster runs a separate thread for each interpretation instance. Each interpretation instance has 3 key steps depicted in Fig. 2:  1) Step 1.1 Initialize Keywords Hits: by looking up the KS-Map (inverted index) that maps keywords to schema graph elements;  2) Step 1.2 Identify Candidate Roots: identifies all possible roots of candidate connecting trees linking at least one keyword hit for all keywords in a query. This process is supported by Rabit Index: a group reachability index for rapid identification of root nodes of connecting trees;  3) Step 1.3 Top-K Graph Patterns Generation: uses the GeFree algorithm to assemble and generate top-K graph patterns representing top-K interpretations based on can- didate roots computed in 1.2. GeFree is a ?graph explo- ration free? algorithm that uses DPI for fast construction of interpretations. It uses materialized path information stored in DPI and Rabit to enable rapid assembly of the top-K minimum connecting trees representing the top-k interpretations. To personalize the interpretation process, it uses the user?s information in the PCM partition as- signed to that slave node.

3In the rest of the paper, when we say ?schema graph?, we actually mean ?annotated schema graph?  Fig. 2. Architecture and workflow for a single slave node  After the personalized top-K candidate graph patterns are generated, Steps 2 to 4 take care of sending them to the user layer and sending the highest ranked queries to the query answering layer for processing. Since the ranking is based on heuristics and may not be perfect, sending the top-K list of graph patterns allows a user to select a different top-1 pattern if the highest ranked pattern is not their intended interpretation.

When this happens, the processing of the originally dispatched top-1 query is halted and query processing for the newly selected graph pattern begins.

Elaborating on the algorithms requires the introduction of some concepts: ?-path covers and ?-graph exploration graphs which define structural information maintained by DPI and GeFree. Candidate root is a key concepts for Rabit index and GeFree.

B. Keyword Query Interpretation in SKI  1) Foundations:  DEFINITION 3.1: A ?-path cover of a node r in graph G is denoted by ?(?, r, G) = {pi}, where pi is a path such that ?pi, pi ? ?(?, r, G) if and only if r ? G is the source node of pi and |pi| ? ?, i.e. the path cover ?(?, r, G) contains all reachable paths of length less than or equal to ? from r. For example, a 2-path cover of node D in the graph shown in Fig. 3 is {D,D ? A, D ? B, D ? E, D ? X , D ? X ? N , D ? X ? I , D ? H ? M , D ? H ? I , D ? H ? E, D ? E ? H , D ? E ? I , D ? E ? F}.

DEFINITION 3.2: A ?-Exploration Graph of a node r in graph G (denoted by g?r ) is a rooted subgraph of G, which contains all edges in ?(?, r, G). For example in Fig. 3, let GS be the whole graph, the subgraph in the box is a 2-exploration graph rooted at node Z : g2Z , which contains all edges in ?(2, Z,GS) = {Z ? Q,Z ? Q ? M,Z ? Q ? S,Z ? Q ? R}.

DEFINITION 3.3: Given a keyword query Q and a schema graph GS , a candidate root of Q is the root node r of a ?- exploration graph g?r , which contains at least one hit of each     Fig. 3. Example for the definitions of ?-path cover and ?-Exploration Graph. Arrows represents exploration states on an undirected schema graph  keyword in Q. For example, in Fig. 3, I is a candidate root for keyword query k1, k2, k3, because the 2-exploration graph g2I contains a hit P (matches k1), K (matches k2) and Y (matches k3). Those hits (such as P,K, Y in g2I ) that are covered by the ?-exploration graph g?r rooted at a candidate root r are called productive hits. Productive hits can always reach a candidate root following a path of length less than or equal to ?.

2) Identifying Candidate Roots: Different from the graph exploration based approaches, where roots are identified by exploring paths originated from each hits, in this section, we introduce the idea of fast candidate roots and productive hits identification.

Group Reachability Bitmap Index. Given a keyword query Q = {ki} , in order to identify a group of candidate roots, a ?group reachability? question that needs to be answered is: Given a set of groups of nodes, whether every node in a group of nodes CR can reach at least one node in ALL the other groups within ? hops. We propose a group reachability bitmap index (Rabit) to identify candidate roots and productive hits more efficiently. For each node ui in the graph, we propose to use a bit vector denoted by ?i =< bi1, b  i 2, ...b  i |V (GS)| > to  represent the nodes that can reach ui within ? hops. Notice that, in Fig. 3, each bit vector for each node is 26 bits long because there are 26 nodes in that graph, which can then be represented using a 32-bit integer, such that we can use one integer to represent the ? exploration graph for each node.

Let ? be a function that maps a set of nodes U = {u1, ...um} to bit vector such that only bui = 1 iff ui ? U . Now, we can check the reachability of two nodes using bitwise AND (i.e., &) in the following way: we can check check if node H can reach A in 2 hops by calculating ?A & ?({H}) = 56885252 & 262148 = 262148, where ?({H}) = 262148.

Using the Rabit index, we can identify for each group of keyword hits, a set of neighboring nodes that can reach at least one hit in that group by using bitwise OR operation.

For example, in Fig. 3, x = GetNeighbors({A,C}, 2) = ?A | ?C = 56885252 | 12255232 = 67043332 = 111111111100000000000001002, which means the set of node {A,B,C,D,E, F,G,H, I, J,X} is the union of neighbors of {A,C}. Then, we can identify a bit vector that repre- sents the common nodes in all groups of neighboring nodes.

This can be achieved by bitwise AND operation, and those nodes are candidate roots. For example, for keyword query ?k1,k2,k3? in Fig. 3, the candidate roots can be calculated  in the following steps: the 3 groups of hits for each key- word are G1 = {A,P}, G2 = {K,T}, G3 = {Y,R}.

For k1, x1 = GetNeighbor(G1, 2) = 57023492; for k2, x2 = GetNeighbor(G2, 2) = 1295074; for k3, x3 = GetNeighbor(G3, 2) = 1303427. Then x1 & x2 & x3 = 131072 = 000000001000000000000000002, which means, only the node I is the candidate root. Those hits that can NOT reach any candidate roots are un-productive hits and therefore, should be pruned. Those un-productive hits can be identified using bitwise AND operation in the similar way.

3) GeFree: A Graph Exploration Free Approach: After iden- tifying candidate roots, we present another important index called dense path index (DPI). Having unproductive hits pruned, given a set of candidate roots CR = {ri}, for keyword query Q, and each root ri, there are many possible interpretations rooted at ri. However, only knowing the roots is not enough to identify the top-K interpretations among all possible interpretations that rooted at each root in CR. The paths from a root node to all hits need to be computed and assembled to construct an interpretation.

Dense Path Index. The dense path index is a two-level hierarchical index. The first layer is called node-exploration graph map, or NE map, which is organized as a hash table that maps any node r in GS to a ?-exploration graph g?r .

NE(r) = g?r denotes such mapping. The second layer of the dense path index is called destination-path map, or DP map that maps a destination node to a set of paths: For each ?-exploration graph, the ?-path cover of r, i.e., ?(?, r, g?r ) is pre-computed and those paths in ?(?, r, g?r ) are grouped by destination nodes ?(?, r, g?r ) = {Pv0 ? Pv1 ? ... ? Pvm}, where Pvi is called a path group of vi, where vi ? V (g?r ) is a destination node, and ?i, j, Pvi ?Pvj = ?. DP (v, g?r ) = Pv denotes the mapping for g?r from a destination node v to the path group Pv of v. The ?-path cover can be organized as a hash table that maps any destination node vj ? V (g?r ) to the path group of vj , i.e., Pvj .

For each root-keyword pair, they are updated and stored in PCM after each query generation and retrieved from PCM during query time ) at most the top-K minimum weighted paths are necessary for computing top-K interpretations. For example, given a keyword query Q =< w1, w2 >, considering a candidate root r, assuming that we are only interested in top-2 interpretations, let P1 =< p11, p  2, p  3 > be the top-3  paths from r to any hits of w1; P2 =< p21, p 2 > be the  top-2 paths from r to any hits of w2, any combinations of paths including p13 will not form a top-2 interpretation and should not be investigated during the processing of generating top-K interpretations. The GeFree algorithm is illustrated in Algorithm 1.

GeFree Algorithm. For each keyword wi, only productive hits are left and stored in H[i] for wi (line 4). For each candidate root ri, the corresponding ?-exploration graph is returned using NE map (line 7). Then, for each keyword wj , H[j] contains a set of productive hits for wj ; for each productive hit vjk, DP map returns a path group Pk (line 11).

For a candidate root ri and a keyword wj , Top-K root- keyword paths are computed by merging topK-heaps from each path groups of all productive hits of wj into a priority queue PQj of size K (line 12 and line 13). In line 14, for the specific root ri, a sorted list Sj containing K paths     Algorithm 1 GeFree 1: Input: Q = {wi};CR = {ri}; PKE = {ui}.

2: TOPK = ? is a priority queue for maintaining top-K interpretations 3: for all wi ? Q do 4: H[i] = hit(wi) ? PKE; 5: end for 6: for all ri ? CR do 7: g?ri = NE(ri); 8: for all wj ? Q do 9: PQj ; // Initialize a priority queue for maintaining top-K paths  10: for all Hit vjk ? H[j] do 11: PG = DP (vjk, g?ri ); 12: Calculate Pk : TopK paths in PG as a heap; 13: Pk ? PQj ; 14: Sorted Path Group Sj = PQj .HeapSort(); 15: end for 16: end for 17: TOPK = TopKCombinations({Sj}); 18: end for 19: return TOPK;  is computed for each keyword. |Q| lists are computed in total. TopKCombinations({Sj}) is an algorithm to quickly generate top-K combinations of paths from |Q| sorted path lists. The algorithm is based on the TopKCombinations algorithm proposed in [9]. This algorithm suggests an early termination strategy such that top-K combinations will be generated without enumerating all combinations of paths and has guaranteed O(K |Q|) time complexity. The time complexity of GeFree is O(|CR|(K |Q|+K|PKE| lg(K))), where CR is the set of candidate roots, and PKE is the set of all productive hits, K is the number of top-K interpretations generated.

Because in the worst case, CR may contain all nodes in the graph and PKE is equal to a set of all possible hits, the worst case time complexity is O(n(K |Q|+Km lg(K))), where n = |V (GS)| and m =  ? |hit(wi)| is the total number of hits. In comparison, the time complexity for graph exploration based algorithm as reported in CoSi [9] is O(nd?K |Q|), where d is the degree of the graph.



IV. EVALUATION  We evaluated the scalability of the proposed multi-tenant query interpretation system (SKI) by comparing its performance with other systems (CoSi [9] and TKQ2S [11]). In this evaluation, we mainly focused on measuring the efficiency improvement and scalability in terms of concurrency because the effective- ness of the personalized techniques proposed in CoSi has been studied in our prior work [9].

Datasets and Testbed: Two real-life datasets were employed: (a) DBPedia 3.6 (approx. 300 classes, 3K property types, 3.5 million entities ? 678 million triples) and (b) the ?Billion Triple Challenge 2009? or BTC (1.19 billion triples). For the BTC, we created the schema graph from its dataset, which includes 150232 classes (nodes) and around 1.3M properties (edges).

For each experiment, we first initialized random weights and used the same set of initial weighs for all personalized algorithms to represent the bootstrapping context of user query history. The evaluation was conducted on a cluster of up to 30 slave nodes, each of which is equipped with Intel dual core 2.0 GHz CPU and 8GB RAM. All algorithms were implemented with C#, and all results were averaged over at least 5 trials.

Tasks and Metrics: We designed two tasks to evaluate the performance of each approach. The first task measured the performance metrics such as execution time and DOTA for each query and dataset. We introduced DOTA or Degree Of  Data/Appr. Graph PCM. KS-MAP DPI RABIT EstMaxU BTC-S 337 2.8 221.94 155.66 25.6 2857 BTC-C/T 445 ? ? ? ? 17 DBPedia-S 1.1 0.07 38.83 6.75 1.33 114286 DBPedia-C/T 1.4 ? ? ? ? 5714  TABLE I. MEMORY CONSUMPTION AND CONCURRENCY (MB) ? SKI(S), COSI/TKQ2S(C/T)  Term Ambiguity in our previous work [9] that characterizes the ambiguity of a query as a reflection of how much work (i.e. exploration search space) is needed for its interpretation.

DOTA is defined as a function of the number of combinations of all keyword hits. The second tasks measured the latency of query responses while varying the MPL (Multi-Programming Level), i.e. the number of concurrent running programs.

Queries: We employed 8 real life queries from Semantic Search Challenge 20114. The additional details can be found in the project page5.

A. Task 1. Measuring Execution Time and DOTA.

We recorded the execution time and DOTA of the 8 queries (Q1-Q8) in the query set. Fig. 4(a) shows that SKI generally outperformed CoSi for both datasets. Fig. 4(b) shows that the queries tend to have much higher DOTA in the BTC dataset than in DBPedia because all keywords appeared in both datasets but with varying frequencies because BTC was a superset of the DBPedia dataset. (Note that the queries are ordered by the DOTAs of queries over DBPedia, not BTC.) The performances of both CoSi and SKI dropped when interpreting the same queries on a dataset with larger scale since the degree of ambiguity increases for the same keyword query.

For queries Q6 to Q8, the DOTA increased significantly; SKI performed much stable on both BTC and DBPedia while the performance of CoSi dropped considerably because the search space increased significantly with the growth of DOTA. In particular, the DOTA of Q2 over BTC was larger than the DOTAs of Q1 and Q3; therefore, the time spent by CoSi for Q2 on BTC was higher than that for Q1 and Q3.

B. Task 2. Measuring Query Latency.

In this task, we increased the MPL and measured the cor- responding response latency of concurrently running queries to compare the degree of concurrency. Due to the resource contention between multiple programs, the performance and memory consumption of the personalized interpretation al- gorithm impact the response latency of concurrently running queries for different users. Fig. 4(c) shows the impact of MPL on the latency (in milliseconds) for interpretation algorithms.

Although all approaches experience increased latency as MPL increases, the rate of increase is higher with the exploration- based approaches than the index approach of SKI. This sug- gests that the concurrency overhead for CoSi and TKQ2S is higher than SKI. Note that SKI supports much higher multi- programming level while keeping low latency. CoSi or TKQ2S were not able to maintain reasonable latency for MPL greater than 5 due to high memory consumption and CPU overhead.

As an explanation for this behavior, we report the amount of memory consumption of SKI, CoSi and TKQ2S in Table I for each user. Note that the reported memory usage of graph for graph exploration-based algorithms includes the overhead of  4https://km.aifb.kit.edu/ws/semsearch11/ 5http://research.csc.ncsu.edu/coul/SKI/experiments.xlsx     Fig. 4. (a) The execution time of the three approaches (SKI, CoSi, and TKQ2S) and (b) The DOTAs for the query set QS, (c) The latency of the three approaches while varying the MPL.

SC5 SC10 SC15 SC20 SC25 SC30 1000 54.67 78.88 89.24 107.57 150.37 166.39 5000 81.52 129.69 178.43 229.45 278.85 265.45  10000 80.45 152.59 215.47 268.22 307.46 353.27 TABLE II. THROUGHPUT  maintaining intermediate graph exploration states, e.g., paths explored and cursors generated. The column EstMaxU shows the estimation of the maximum number of user queries that can be running concurrently based on the memory consumption of each approach. In case of BTC dataset, each user in CoSi/TKQ2S requires around 445MB for maintaining graph exploration states associated with the summarized schema graph while the SKI consumes only 2.8MB for PCM and other indexes for each user. Thus, CoSi/TKQ2S can only support up to 17 users using 8GB memory, but SKI can handle up to 2857 users concurrently.

Additionally, we conducted experiments on the interpretation slave clusters (SC) with SKI deployed on them and report the throughput in Table II. Six groups of experiments were conducted with varying sizes of an interpretation cluster (up to 30 slave nodes) and different sizes of the query mixes (1k to 10k queries). The throughput (queries per second) of the larger cluster was higher.



V. RELATED WORK  For approaches that do not require graph exploration, BLINKS [3] proposes a similar idea to pre-compute i) node to keyword index and ii) keyword to node index. However, BLINKS employs a distinct root semantics where a root node identifies a unique sub-graph that connects all keywords by shortest paths. In this paper, we propose to save and manage richer path information (not only shortest path) and generate answers with Steiner tree semantics, which implies larger search space. In addition, BLINKS maintains mappings from keyword to lists of nodes ordered by costs; EASE [12] proposes EI-index, where ordered weighted r-radius graphs for pair wise tokens are pre-computed. However, adapting these kinds of indexes to personalized query interpretation such as CoSi [9] has some challenges. Because after every query, the classes and properties associated with the query, as well as related concepts and properties, will need to have their weights increased to reflect the impact of the query on the context model, the ordering of all indexes containing such classes and properties will need to be updated. For existing techniques this may require a complete rebuild after each query which is impractical.



VI. CONCLUSION  This paper presents an approach for ?interpretive? search that scales well under high concurrent workloads. The approach achieves this by relying on a suitable set of indexes rather than expensive graph exploration based algorithms. Comprehensive evaluation over real world datasets showed very promising results.



VII. ACKNOWLEDGMENT  This work was partially funded by NSF grant IIS-0915865.

