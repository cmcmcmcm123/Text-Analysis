Learning from Multiple Data Sets with Different Missing Attributes and Privacy  Policies: Parallel Distributed Fuzzy Genetics-Based Machine Learning Approach

Abstract?This paper discusses parallel distributed genetics- based machine learning (GBML) of fuzzy rule-based classifiers from multiple data sets. We assume that each data set has a similar but different set of attributes. In other words, each data set has different missing attributes. Our task is the design of a fuzzy rule-based classifier from those data sets. In this paper, we first show that fuzzy rules can handle missing attributes easily. Next we explain how parallel distributed fuzzy GBML can handle multiple data sets with different missing attributes.

Then we examine the accuracy of obtained fuzzy rule-based classifiers from various settings of available training data such as a single data set with no missing attribute and multiple data sets with many missing attributes. Experimental results show that the use of multiple data sets often increases the accuracy of obtained fuzzy rule-based classifiers even when they have missing attributes. We also discuss the learning from a data set under a severe privacy preserving policy where only the error rate of each candidate classifier is available. It is assumed that no information about each individual pattern is available. This means that we cannot use any information on the class label or the attribute values of each pattern. We explain how such a black-box data set can be utilized for classifier design.

Keywords-Evolutionary algorithms, genetics-based machine learning, parallel distributed implementation, fuzzy rule-based classifiers, horizontally partitioned data sets.



I.  INTRODUCTION In knowledge extraction and data mining, useful data are  often collected and stored in different organizations around the world (e.g., hospitals in different countries). As a result, data can be viewed as a mixture of data sets, each of which is from a different site. In this case, data sets are heterogeneous due to various reasons such as different testing equipments in each organization and different regulations in each country.

The availability of each data set is also often totally different in each site due to different security and privacy policies.

In this paper, we discuss the learning from multiple data sets under the following two scenarios. In one scenario, it is assumed that each data set has different missing attributes. In the other scenario, some data sets are assumed to have a very severe privacy policy as well as different missing attributes.

The first scenario, in which each data set has different missing attributes, is illustrated in Fig. 1 using three data sets DA, DB and DC. Missing attributes in each data set in Fig. 1 are {x1, x4} in DA, {x4, x6} in DB, and {x1, x3, x5} in DC  among the seven attributes {x1, x2, ..., x6, y} where ?y? is a special attribute for a class label. We assume that the class label attribute is not missing in any data set. In privacy preserving data mining [1]-[4], multiple data sets of the type in Fig. 1 are called ?horizontally partitioned data? [5] where the existence of missing attributes is not usually assumed explicitly. The main feature of our multiple data sets is that each data set has different missing attributes. Our multiple data sets are different from ?vertically partitioned data? [5] in privacy preserving data mining where attributes are partitioned into several attribute subsets.

ID x1 x2 x3 x4 x5 x6 y C1 9 1 8 0 C2 6 1 7 1 C3 5 2 7 1  Site C Data Set DC  ID x1 x2 x3 x4 x5 x6 y A1 9 2 2 9 1 A2 8 1 3 6 1 A3 9 5 1 5 0  Site A Data Set DA  ID x1 x2 x3 x4 x5 x6 y B1 1 8 1 1 0 B2 1 8 2 3 0 B3 3 9 2 1 1  Site B Data Set DB   Figure 1.  Multiple data sets with different missing attributes (Scenario 1).

In the second scenario, we assume that some sites with data sets have a very severe privacy preserving policy. More specifically, we assume that only error rates of candidate classifiers can be obtained from each of those sites. No other information is available. This scenario is illustrated in Fig. 2 where Sites A and C are assumed to have such a severe privacy preserving policy. Whereas the data set DB is fully available to the classifier designer, the other data sets DA and DC are black-box data sets for the classifier designer. The classifier designer cannot see the contents of DA and DC. We assume that these two black-box data sets can be used only for the calculation of error rates of candidate classifiers.

ID x1 x2 x3 x4 x5 x6 y C1 9 1 8 0 C2 6 1 7 1 C3 5 2 7 1  Site C Data Set DC  ID x1 x2 x3 x4 x5 x6 y A1 9 2 2 9 1 A2 8 1 3 6 1 A3 9 5 1 5 0  Site A Data Set DA  ID x1 x2 x3 x4 x5 x6 y B1 1 8 1 1 0 B2 1 8 2 3 0 B3 3 9 2 1 1  Site B Data Set DB  Full access  Classifier Designer Candidate classifier  Candidate classifierError rate  Error rate   Figure 2.  Learning under a severe privacy preserving policy (Scenario 2).

Applications of evolutionary computation to knowledge extraction and data mining are called genetics-based machine learning (GBML [7]-[10]). A rule set is often handled as an individual and coded as a string. Recently Franco et al. [10] demonstrated the high performance of GBML in comparison with other classifier design approaches such as decision trees and support vector machines. GBML has also been actively applied to the design of fuzzy rule-based classifiers under the name of fuzzy GBML. Fuzzy GBML is called genetic fuzzy systems (GFS) in the fuzzy system community [11]-[14].

The main advantage of GBML is its flexibility in the handling of various goals in classifier design. Complexity measures such as the number of rules and the number of conditions in each rule as well as accuracy measures such as false positive and false negative can be integrated into a single fitness function. They can also be handled as separate objectives in multiobjective GBML algorithms to search for a number of non-dominated tradeoff classifiers [15], [16].

Classifiers with different tradeoffs can be obtained by a single run of a multiobjective GBML algorithm (e.g., simple classifiers with a few rules and complicated classifiers with high accuracy). In GBML, it is also easy to use constraint conditions such as the upper bound on the number of rules.

Whereas GBML is a flexible classifier design approach, its real-world applications are not always easy due to its heavy computation load. Evolutionary search for an accurate classifier in a complicated large-scale real-world task often needs thousands of generations. In each generation, the creation and the fitness evaluation of hundreds of candidate classifiers are performed.

As an efficient speed-up trick of GBML algorithms, we proposed their parallel distributed implementation [17], [18].

A population of classifiers is divided into multiple sub- populations as in an island model of parallel evolutionary computation [19], [20]. Training data are also divided into multiple subsets. A single training data subset is assigned to each sub-population. To avoid the overfitting of classifiers in each sub-population to the assigned training data subset, the assignment of the training data subsets is rotated periodically over the sub-populations. We showed in our former study [18] that the computation time of our fuzzy GBML algorithm [21] was decreased by its parallel distributed implementation to about 2% of that of its standard implementation. This is because both the training data and the population were divided into seven subsets (i.e., (1/7)2 = 1/49  2%).

In this paper, we show that our fuzzy GBML algorithm [18], [21] can handle the above-mentioned two scenarios: data sets with missing attributes and black-box data sets with the severe privacy preserving policy. After explaining how these two scenarios can be handled, we examine the effect of using multiple data sets in each scenario on the accuracy of obtained fuzzy rule-based classifiers. Experimental results obtained from the use of multiple data sets are compared with those from a single data set (e.g., DB in Fig. 2).

This paper is organized as follows. In Section II, we first explain fuzzy rules and fuzzy rule-based classifiers. The handling of data sets with missing attributes in Fig. 1 is also discussed in Section II. Then we explain our fuzzy GBML algorithm in Section III where we also show its variant for  black-box data sets with the severe privacy preserving policy in Fig. 2. In Section IV, we examine the accuracy of fuzzy rule-based classifiers designed from multiple data sets in each of the two scenarios through computational experiments.

Finally we conclude this paper in Section V.



II. FUZZY RULE-BASED CLASSIFIERS  A. Fuzzy Rules for Classification Problems A standard classification problem is defined by a set of  labeled patterns in a pattern space. Let us assume that we have m training patterns xp= (xp1, xp2, ..., xpn), p = 1, 2, ..., m with n continuous attributes from M classes where p is a pattern index and xpi is an attribute value of the i-th attribute xi in the p-th pattern xp . Each pattern is assumed to have a class label, which is one of the M classes. For ease of explanation, we further assume that each attribute value xpi has already been normalized into a real number in the unit interval [0, 1]. This means that the pattern space of our classification problem is an n-dimensional hypercube [0, 1]n.

The basic form of fuzzy rules for our n-dimensional classification problem is as follows:  Rule Rq: If x1 is Aq1 and ... and xn is Aqn then Class Cq ,    (1)  where Rq is a rule label of the q-th fuzzy rule, Aqi is an antecedent fuzzy set of Rq on the i-th attribute xi, and Cq is a consequent class of Rq.

Antecedent fuzzy sets often have linguistic labels such as ?small ?, ?medium? and ?large?. In Fig. 3, we show typical examples of antecedent fuzzy sets with linguistic labels. The meaning of each antecedent fuzzy set Aqi is mathematically specified by its membership function Aqi( ). For example, the membership functions of the three fuzzy sets in Fig. 3 are written for 0 x 1 as follows:  Small(x) = max{1 2x, 0},                                   (2) Medium(x) = min{2x, 2 2x},                                   (3) Large(x) = max{2x 1, 0}.                                 (4)  When antecedent fuzzy sets have linguistic labels, fuzzy rules can be interpreted as linguistic rules such as ?If x1 is small and x2 is large then Class 1? and ?If x1 is large and x2 is small then Class 2?. These rules are easy for human users to understand. Linguistic interpretability of fuzzy rules is one advantage of fuzzy rule-based classifiers.

Attribute Value  M em  be rs  hi p  0.0  1.0  0.0 1.0  small medium large   Figure 3.  Typical antecedent fuzzy sets with linguistic labels.

Fuzzy rules of the form in (1) have high interpretability.

However, their classification ability is not always so high. In this paper, we use the following type of fuzzy rules with a rule weight CFq to enhance their classification ability:  Rule Rq: If x1 is Aq1 and ... and xn is Aqn then Class Cq with CFq .      (5)  The rule weight CFq of Rq , which is a real number in the unit interval [0, 1], works as the strength of Rq in fuzzy reasoning as explained in the next subsection [22], [23].

B. Fuzzy Reasoning in Fuzzy Rule-Based Classifiers A fuzzy rule-based classifier is a set of fuzzy rules of the  form in (5). Let S be a fuzzy rule-based classifier. When an input pattern xp= (xp1, xp2, ..., xpn) is presented to the fuzzy rule-based classifier S, first the compatibility of xp  with the antecedent part of each fuzzy rule Rq  in S is calculated from the membership function Aqi( ) of each antecedent fuzzy set Aqi  using the product operation as follows:  Aq(xp ) = Aq1(xp1) Aq2(xp2) Aqn(xpn),     (6)  where Aq= (Aq1, Aq2, ..., Aqn) shows the antecedent part of Rq.

The input pattern xp  is classified by a single winner rule. The winner rule RW  is defined for the input pattern xp  as  AW (xp ) CFW  = max{ Aq(xp ) CFq  | Rq S}.        (7)  The input pattern xp  is classified as the consequent class CW of the winner rule RW. If multiple fuzzy rules have the same maximum value in (7) and their consequent classes are different, the classification of the input pattern xp  is rejected.

Its classification is also rejected when no fuzzy rule in S is compatible with xp . When we use fuzzy rules of the basic form in (1), the most compatible rule is chosen as the winner rule in (7). As shown in (7), the rule weight CFq of each fuzzy rule Rq works as the strength of Rq in the winner rule selection. The single winner-based fuzzy reasoning method in (7) has been widely used since the early 1990s [24]. One advantage of this reasoning method is its high explanation ability for the classification decision. The winner rule can be used to explain the reason for the classification decision.

C. Handling of Missing Attribute Values We can easily handle input patterns with missing values  by the single winner-based fuzzy reasoning method. Let us assume that the j-th attribute value xpj of the input pattern xp is missing. In this case, we calculate the compatibility grade  Aq(xp ) of the input pattern xp  with the antecedent part Aq  of the fuzzy rule Rq  in (6) by specifying Aqj(xpj) as Aqj(xpj) = 1.

The reason for using this heuristic is its simplicity. Since xpj is missing, we only know that its value is a real number in the normalized domain interval [0, 1]. By replacing xpj with [0, 1] in Aqj(xpj), we have Aqj([0, 1]) = 1.0 since the domain interval [0, 1] is fully compatible with any antecedent fuzzy set on [0, 1]. It should be noted that the specification of  Aqj(xpj) as Aqj(xpj) = 1 is the same as removing Aqj(xpj) from (6). That is, we can ignore the condition corresponding to the missing attribute value. In this manner, we can easily handle incomplete patterns with missing values.

This simple mechanism for the handling of missing value has the following potential drawback. Let us assume that a fuzzy rule-based classifier is trained using a data set DA with two missing attributes x1 and x4 in Fig. 2. In this case, classifier performance is independent of the 1st and 4th conditions Aq1 and Aq4 of each fuzzy rule. That is, any random changes of Aq1 and Aq4 have no effect on the error rate. As a result, it is not likely that each rule in the obtained fuzzy rule-based classifier has appropriate conditions on x1 and x4. This issue should be addressed in future research.

D. Heuristic Fuzzy Rule Generation If the antecedent part of a fuzzy rule has already been  specified, its consequent class and rule weight can be easily determined using compatible training patterns with its antecedent part in a simple heuristic manner [22]-[24]. Let us assume that the antecedent part Aq  of a fuzzy rule Rq  has already been specified. In this case, its consequent class Cq and rule weight CFq  are determined in the following manner.

First the compatibility grade of each training pattern xq  with the antecedent part Aq  is calculated by (6). Next the confidence value from the antecedent part Aq  to each class (i.e., Class k, k = 1, 2, ..., M) is calculated as follows:  Conf (Aq Class k) = m  p p  k p  q  p q   Class  )(  )(  x  x  A  x A  .          (8)  When no class has a confidence value larger than 0.5, we do not generate any fuzzy rule with the antecedent part Aq .

When the confidence value for a particular class Cq  is larger than 0.5, we generate a fuzzy rule with the antecedent part Aq  and the consequent class Cq . Then its rule weight is specified as follows [23]:   M  Ck k  qqqq  q  kConfCConfCF  )Class()Class( AA . (9)  From (8), this formulation can be rewritten as follows:  1)Class(2 qqq CConfCF A .                    (10)  In this manner, we can determine the consequent class Cq and the rule weight CFq for the antecedent part Aq. The antecedent part of each fuzzy rule in a fuzzy rule-based classifier is specified by our fuzzy GBML algorithm as we will explain in the next section. It should be noted that our heuristic rule generation method is applicable to data sets with missing attributes. However, it is not applicable to black-box data sets. This is because the confidence value in (8) cannot be calculated from black-box data sets.



III. FUZZY GENETICS-BASED MACHINE LEARNING  A. Outline of Our Fuzzy GBML Algorithm Our fuzzy GBML algorithm in this paper is the same as  in our former study [18]. Our fuzzy GBML algorithm is used to design a fuzzy rule-based classifier with fuzzy rules of the     form in (5). Each fuzzy rule Rq is represented by a string of length n using its n antecedent fuzzy sets Aq1, Aq2, ..., Aqn.

As antecedent fuzzy sets, we use don?t care (i.e., an unit interval [0, 1]) and 14 triangular fuzzy sets in Fig. 4. These fuzzy sets are denoted by 15 integers from ?0? for don?t care to ?14? for the right-most fuzzy set in the bottom-right plot in Fig. 4. Thus a fuzzy rule is represented by an integer string of length n using the alphabet of the 15 integers. As a result, the total number of different strings is 15n. Each of those strings shows a different fuzzy rule.

1.0  0.0 1.0Attribute value  3 4 5  M em  be rs  hi p  1.0Attribute value  1 21.0  0.0M em  be rs  hi p    1.0Attribute value 1.0Attribute value  10 12 1413116 97 8 1.0  0.0M em  be rs  hi p1.0  0.0M em  be rs  hi p   Figure 4.  Fuzzy partitions with 14 antecedent fuzzy sets.

A fuzzy rule-based classifier S with |S| fuzzy rules is represented by a concatenated integer string of length n |S| where each substring of length n shows a single fuzzy rule.

The number of fuzzy rules is not pre-specified (i.e., |S| is not a pre-specified constant parameter). Thus the length of each string can be different. The number of fuzzy rules can be automatically determined for each application task in our fuzzy GBML algorithm.

A fuzzy rule-based classifier S is evaluated in our fuzzy GBML algorithm by the following fitness function:  fitness(S) = w1 f1(S) + w2 f2(S) + w3 f3(S),              (11)  where w1, w2 and w3 are non-negative weights, and f1(S), f2(S) and f3(S) are as follows:  f1(S): Training data error rate of S in percentage, f2(S): The number of fuzzy rules in S (i.e., f2(S) = |S |), f3(S): The total rule length of S.

The number of antecedent conditions of a fuzzy rule excluding don?t care conditions is called the rule length. The total rule length is the total number of antecedent conditions in S excluding don?t care conditions (i.e., the sum of the rule length of fuzzy rules in S). The fitness function in (11) should be minimized. The use of (11) is to simultaneously perform the accuracy maximization and the complexity minimization. The weight values in (11) are specified as w1 = 100, w2 = 1 and w3 = 1 in our computational experiments.

Our fuzzy GBML algorithm is a hybrid algorithm of Pittsburgh-style GBML and Michigan-style GBML as shown in Fig. 5. In this subsection, we explain the Pittsburgh-style framework. The Michigan-style part is explained later.

Let us denote the population size by NPop. In the ?Initialization? step in Fig. 5, an initial population with NPop integer strings is generated. The number of substrings in each  initial string (i.e., the number of fuzzy rules in each initial rule set) is 30 in our computational experiments. To generate an initial string, we randomly choose 30 training patterns. A single fuzzy rule is generated from each training pattern xp= (xp1, xp2, ..., xpn) by probabilistically choosing an antecedent fuzzy set for each attribute xi using its compatibility grade with the attribute value xpi. The selection probability of each antecedent fuzzy set is proportional to its compatibility grade with xpi. After choosing n antecedent fuzzy sets, each of them is replaced with don?t care using a pre-specified don?t care probability. This probability is specified as (n 5)/n in our computational experiments. Thus each initial fuzzy rule has five conditions on average.

In the ?Selection? step in Fig. 5, each string in the current population is evaluated by the fitness function in (11). Then NPop pairs of parents are selected by binary tournament selection with replacement based on their fitness values.

In the ?Genetic Operations? step, a string is generated from each pair of parents by randomly choosing substrings from each parent. The number of selected substrings from each parent is randomly specified. Thus the length of a new string can be different from that of its parents. This crossover operation is applied to each pair of parents with a pre- specified probability, which is 0.9 in our computational experiments. When the crossover operation is not applied, one of the two parents is randomly selected. A new string is generated as a copy of the selected parent.

Each integer in the newly generated string is randomly replaced with another integer using a pre-specified mutation probability. In our computational experiments, the mutation probability is specified for the new string S as 1/n |S| where n |S| is the string length of S. In the ?Genetic Operations? step, NPop strings are newly generated by crossover and mutation. A Michigan-style algorithm, which is explained in the next subsection, is applied to each of the generated new strings with a pre-specified probability. This probability is specified as 0.5 in our computational experiments.

In the ?Population Update? step in the left plot of Fig. 5, the current population and the newly generated NPop strings are merged. The best NPop strings in the merged population are selected to form the next population.

Initialization  Selection  Genetic operations (Crossover and Mutation)  Michigan-style part  Termination condition  Yes  No  Population update  Choose the best individual  Michigan probability  New rule generation ? Genetic rule generation ? Heuristic rule generation  Yes  No  Michigan-style part  Population update  Pittsburgh-style framework  Rule set   Figure 5.  Our hybrid fuzzy GBML algorithm [18].

If the termination condition (50,000 generations in this paper) does not hold, the updated population goes back to the ?Selection? step. Otherwise, the best string in the updated population is chosen as the finally obtained classifier.

B. Michigan-Style Part of Our Fuzzy GBML Algorithm The Michigan-style part in Fig. 5 can be viewed as a  local search procedure for each string. A single string S in the Pittsburgh-style framework is handled as a population of fuzzy rules. Each fuzzy rule Rq in the string is an individual in the Michigan-style part. The fitness of Rq in S is defined by the number of correctly classified training patterns by Rq when S is used to classify all training patterns. Since we use the single winner-based fuzzy reasoning method, we can identify a single responsible fuzzy rule for the classification of each pattern. The worst 20% of fuzzy rules are removed from S. The number of fuzzy rules to be generated is the same as that of the removed rules. A half of new fuzzy rules are directly generated from misclassified training patterns in the same manner as in the initial fuzzy rule generation. The other fuzzy rules are generated from the existing fuzzy rules in S by binary tournament selection, uniform crossover with the probability 0.9, and mutation with the probability 1/n.

The modified rule set S is sent back to the Pittsburgh-style part after only a single iteration of the Michigan-style part.

C. Parallel Distributed Fuzzy GBML Algorithm Parallel distributed implementation in our former study  [18] is illustrated in Fig. 6. As in [18], a population of size 210 is divided into seven sub-populations of size 30 in this paper. Training data are also divided into seven subsets of the same size: D1, D2, ..., D7. The seven sub-populations and the seven data subsets are distributed over seven CPUs. Our fuzzy GBML algorithm is locally executed at each CPU for a pre-specified number of generations (i.e., rotation interval).

Then the training data subsets are rotated over the CPUs.

Three specifications of the rotation interval are examined: 10, 100 and 1000 generations. A copy of the best rule set in each island is migrated to an adjacent island. The migration is always performed every 100 generations. As shown in Fig. 6, the rotation and the migration are executed in the opposite directions. After the 50,000th generation, 210 rule sets are evaluated using all data sets. The best rule set with respect to the fitness function is chosen as a finally obtained classifier.

CPU  Training data rotation  Training data  Po pu  la tio  n  CPU CPU CPU CPU CPU CPU  Rule set migration  D2 D3 D4 D5 D6 D7D1   Figure 6.  Parallel distributed implementation [18].

D. Modification of Fuzzy GBML for Black-Box Data Sets Let us assume that the classifier designer cannot access  any data sets except for a single data set D1. As we explained in Section I using Fig. 2, we assume that only the error rate of a candidate fuzzy rule-based classifier is available from each of those black-box data sets. In this situation, we cannot use the Michigan-style part since no information about the fitness of each fuzzy rule is available. Thus we remove the Michigan-style part when our fuzzy GBML algorithm is executed on a black-box data set.

In the Pittsburgh-style framework, we need the full information on training patterns to generate initial fuzzy rules. Since D1 is fully available, initial fuzzy rules are always generated from D1. When the antecedent part of a fuzzy rule is changed by mutation, the information on training patterns is needed to determine the consequent class and the rule weight. In this case, we use the available data set D1. That is, D1 is always used to generate new fuzzy rules even when fuzzy rule-based classifiers are evaluated on another data set. In this manner, we utilize a fully available data set and other black-box data sets.



IV. COMPUTATIONAL EXPERIMENTS  A. Settings of Computational Experiments The main objective of our computational experiments is  to examine the potential usefulness of our parallel distributed implementation in the handling of the two scenarios: One is multiple data sets with different missing attributes in Fig. 1, and the other is multiple black-box data sets in Fig. 2. We use four data sets in Table I in the KEEL database [25]. For each data set, we artificially generate multiple training data subsets with different missing attributes within the ten-fold cross-validation (10CV) framework. In 10CV, given patterns are divided into ten subsets: One is used as test data and the others are used as training data.

TABLE I.  FOUR DATA SETS USED IN THIS PAPER.

Data Set Patterns Attributes Classes Phoneme 5,404 5 2  Page-blocks 5,472 10 5 Segment 2,310 19 7 Satimage 6,435 36 6   The training data are further divided into seven subsets of  the same size: D1, D2, ..., D7. We remove some attributes from these subsets in order to generate multiple data sets with different missing attributes in the first scenario. In the second scenario, we assume that only the first training data subset D1 is fully available. Due to the severe privacy preserving policy, only error rates of candidate classifiers on each of the other data subsets Di (i = 2, 3, ..., 7) are available.

Our two scenarios can be rewritten in our computational experiments as follows:  Scenario 1: The classifier designer can fully access all the seven training data subsets Di (i = 1, 2, ..., 7).

Scenario 2: The classifier designer can fully access D1.

Due to the severe privacy preserving policy, only error rates of candidate classifiers on Di (i = 2, 3, ..., 7) are available.

We artificially generate multiple data sets with different missing attributes in the following two manners:  Setting 1: We remove only a single attribute from each training data subset Di except for D1. More specifically, we remove the i-th attribute xi from Di (i = 2, 3, ..., 7). As a result, xi is missing in Di (i = 2, 3, ..., 7) while no attribute is missing in D1. In the case of the phoneme data with five attributes (x1, x2, x3, x4, x5), xi is removed from Di (i = 2, 3, 4, 5), and x1 and x2 are removed from D6 and D7, respectively.

Setting 2: Let n* be the number of attributes to be removed from Di (i = 2, 3, ..., 7). For each data set in Table I, n* is specified as the smallest integer not smaller than n/6 so that every attribute is removed from at least one training data subset Di. For example, n* is specified as n* = 4 for the segment data with 19 attributes since n/6 19/6 3.17. We randomly choose n* attributes to be removed from each Di (i = 2, 3, ..., 7) under the following conditions: (i) Every attribute should be removed from at least one subset, and (ii) no attribute should be removed from more than two subsets.

As a result, a different subset of n* attributes becomes missing in Di (i = 2, 3, ..., 7) while no attribute is missing in D1. The random selection of removed n* attributes is updated when the entire 10CV procedure is completed. In this paper, we iterate 10CV five times using different data partitions into ten subsets (i.e., 5 10CV). Thus the selection of removed attributes is updated five times.

These two settings are examined under the two scenarios.

Since D1 with no missing attributes is always available, it looks a good idea to design a fuzzy rule-based classifier from D1 without using any other training data subsets. This idea is illustrated in Fig. 7 where D1 is used in all sub-populations.

In this paper, Fig. 6 with the seven data subsets and Fig. 7 with only D1 are compared. The same parallel distributed algorithm is used in Fig. 6 and Fig. 7. In order to choose the final fuzzy rule-based classifier under the same condition in Fig. 6 and Fig. 7, only D1 is used for classifier selection. That is, 210 individuals at the final population are evaluated using D1. Then, the best individual is selected as the final classifier.

CPU  Training data rotation  Training data  Po pu  la tio  n  CPU CPU CPU CPU CPU CPU  Rule set migration  D1 D1 D1 D1 D1 D1D1   Figure 7.  Parallel distributed implementation with seven duplicates of D1.

Our computational experiments are performed in the same parameter specifications in our former study [18] such as the use of seven sub-populations of size 30 (i.e., 210 rule sets in each generation in total) and the termination at the 50,000th generation. The training data rotation interval is  specified as 10, 100 and 1000 generations while the migration interval is specified as 100 generations. We also examine an additional specification: no training data rotation and no rule set migration. Average accuracy of the finally obtained fuzzy rule-based classifiers on test data is evaluated over five iterations of 10CV (i.e., 5 10CV). We do not remove any attributes from the test data. That is, each test pattern is classified using its all attribute values in 10CV. In the following, we report the average accuracy on test data.

B. Experimental Results from Setting 1 In the first setting, D1 has no missing attribute while each  of the other six subsets Di (i = 2, 3, ..., 7) has a single missing attribute. When a data set has many attributes such as the satimage data with 36 attributes, negative effects of a single missing attribute seem to be small. Thus it may be a good idea to use not only D1 with no missing attribute but also the other six data sets with a single missing attribute. However, when a data set does not have many attributes such as the phoneme data with five attributes, negative effects of a single missing attribute may be large. Thus the benefit of using all the seven training data subsets may be small or negative.

To numerically examine these discussions, we compare the following three cases: the use of D1 as in Fig. 7, the use of all the seven subsets Di (i = 1, 2, ..., 7) as in Fig. 6 in Scenario 1, and the use of all the seven subsets in Scenario 2 (i.e., only D1 is fully available). Experimental results on the four data sets in Table I are summarized in Figs. 8-11. When we use only D1, the same average accuracy is obtained from different specifications of the rotation interval. However, a slightly different average accuracy is obtained from ?None? with no rotation and no migration.

In Fig. 8 on the phoneme data with five attributes, we can observe a clear negative effect of using all the seven training data subsets (black and red open circles) in comparison with the use of only D1 (blue closed circles) as expected. In Figs.

9-11, better results are obtained by the use of all the seven training data subsets (black and red open circles) than the use of only D1 (blue closed circles) in many cases.

Regarding the comparison between the two scenarios, better results are obtained in many cases from Scenario 1 with full access to all data subsets (e.g., Fig. 10 and Fig. 11).

However, better results are obtained from Scenario 2 in some cases than Scenario 1 (e.g., rotation interval 1000 in Fig. 9).

100 100010 Rotation interval  Te st  D at  a A cc  ur ac  y (%  )      None  Seven Subsets (Scenario 1) Use of only D1  Seven Subsets (Scenario 2)   Figure 8.  Results on the phoneme data with five attributes (Setting 1).

100 1000 None10  Te st  D at  a A cc  ur ac  y (%  )  Rotation interval     Seven Subsets (Scenario 1) Use of only D1  Seven Subsets (Scenario 2)   Figure 9.  Results on the Page-blocks data with ten attributes (Setting 1).

100 100010  Te st  D at  a A cc  ur ac  y (%  )       Rotation interval  Seven Subsets (Scenario 1) Use of only D1  Seven Subsets (Scenario 2)  None   Figure 10.  Results on the Segment data with 19 attributes (Setting 1).

100 100010  Te st  D at  a A cc  ur ac  y (%  )       Rotation interval None  Seven Subsets (Scenario 1) Use of only D1  Seven Subsets (Scenario 2)   Figure 11.  Results on the Satimage data with 36 attributes (Setting 1).

C. Experimental Results from Setting 2 In the second setting, D1 has no missing attribute while  about n/6 attributes are missing in the other six data subsets.

Similar results are obtained from the first and second settings for the phoneme data with five attributes since the number of missing attributes is one in both settings. Figs. 12-14 show experimental results on the other data sets in Setting 2.

Since much more attributes are missing in Figs. 12-14 (i.e., two in Fig. 12, four in Fig. 13, and six in Fig. 14) than Figs. 9-11 with a single missing attribute, positive effects of using all the seven data subsets decrease from Figs. 9-11 to Figs. 12-14. However, better results are still obtained by the use of all the seven data subsets (black and red open circles) than the use of D1 (blue closed circles) in Figs. 12-14.

100 100010  Te st  D at  a A cc  ur ac  y (%  )  Rotation interval     None  Seven Subsets (Scenario 1) Use of only D1  Seven Subsets (Scenario 2)   Figure 12.  Results on the Page-blocks data with ten attributes (Setting 2).

100 100010  Te st  D at  a A cc  ur ac  y (%  )       Rotation interval None  Seven Subsets (Scenario 1) Use of only D1  Seven Subsets (Scenario 2)   Figure 13.  Results on the Segment data with 19 attributes (Setting 2).

100 100010  Te st  D at  a A cc  ur ac  y (%  )       Rotation interval None  Seven Subsets (Scenario 1) Use of only D1  Seven Subsets (Scenario 2)   Figure 14.  Results on the Satimage data with 36 attributes (Setting 2).

One interesting observation in Figs. 12-14 is that better results are obtained in many cases from Scenario 2 than Scenario 1. This may be because new fuzzy rules are always generated from D1 with no missing attributes in Scenario 2.

In Scenario 1, new fuzzy rules are generated from D1 with no missing attributes and also from the other six data subsets Di (i = 2, 3, ..., 7) with missing attributes.



V. CONCLUSION In this paper, we examined the potential usefulness of our  parallel distributed fuzzy GBML algorithm for fuzzy rule- based classifier design from multiple data sets with different missing attributes. We also examined its potential usefulness under the assumption of the severe privacy preserving policy where data sets were handled as black-box data sets. More     specifically, we assumed that a black-box data set was used only for calculating the error rate of each classifier. No other information (e.g., attribute values of each pattern, its true class, and its classification result) were available.

In our computational experiments, we divided training patterns into seven data subsets: one complete data subset with no missing attributes and six incomplete data subsets with different missing attributes. We observed that classifier performance was improved by the use of all the seven data subsets in comparison with the use of only the complete data subset. This improvement was also observed even when the six incomplete data subsets were black-box data sets.

It was always assumed in our computational experiments that one data subset was fully available. It is an interesting future research issue to examine the learning from multiple data subsets where no data subsets are fully available (i.e., all data subsets have different missing attributes and the severe private preserving policy). In such a difficult situation, more sophisticated handling of missing values may be needed since all data subsets have missing attributes. More efficient evolutionary learning may be also needed since we cannot generate fuzzy rules directly from training patterns.

