

A Parallel Algorithm for Mining Association Rules  Junrui Yang  Dept. of Computer Science Xi'an University of Science and Tech  yangjurui66@sina.com  Abstrac t - There are disadvantages of producing vast candidate items set and correspondence in the traditional  parallel algorithms for mining association rules. One  comparative efficient parallel algorithm for mining association rules PBFI-Miner is presented. It uses the bit objects to express  data and to improve the FP-Tree; and uses parting strategy to  achieve near optimal balancing between processors. The  processors communicate with bit object groups so that the  algorithm efficiency is increased. Experimental result verifies  the efficiency of the PBFI-Miner.

Keywords-parallel mining; association rule; frequent items  set

I. Introduction  Discovering association rules is an important problem of Knowledge Discover, whose purpose is to find out the association relation among the itemsets. The study of association rule mining has attracted tremendous interest among researchers and practitioners in recent years.

There has been considerable research in designing fast sequential algorithms and scored great fruit. Since the databases to be mined are often very large, and the association rule mining is computationally and I/O intensive, we must rely on high-performance parallel mining method.

In addition, it is a great challenge to enhance efficiency of single processor with limited memory and computer ability.

So parallel algorithms come forth and we have made a remarkable achievement[  -7].

The first three parallel algorithms named CD, DD, and CaD[  1] are proposed by Agrawal and eta\. The CD algorithm is a simple parallelization of Apriori. Every processor has the copy of all the candidate itemsets and begins to parallel working. The DO algorithm distributes the candidate itemsets equally with cycling method to the processors, then each processor only scans its local partition. The CaD algorithm is the combination of CD and DD, which is partition assigned. All the three parallel algorithms suffer from high communication and a great deal of redundancy calculations. The IDD[Z] algorithm is based on DD algorithm.

In IDD, instead of a round-robin candidate partitioning, it performs a single-item, prefix-based partitioning. Therefore, IDD algorithm is less redundancy and lower communication than DD. Cheung and his colleagues have ftroposed the APM algorithm, which is based on DIC. APM[ ] is a parallel algorithm in shared-memory systems. It uses global-pruning technique to decrease the size of candidate 2-itemsets. This pruning is most effective when the partitions are homogeneous. MLFPT[4] is based on FP-growth, which only need to scan the local database twice. It has devised a    Yashuang Yang  Dept. of Computer Science Xi'an University of Science and Tech  yangyashuang 1985@ 163.com  dynamic task scheduling strategy at different stages to achieve good workload balancing among processors. The database is divided equally and each processor creates local FP-tree in the stage of catching pattern information. Every processor shares all the local FP-tree in the mining stage.

MLFPT is a typical algorithm because it reduces the number of candidate itemsets and competition of resources effectively. BFDM[5] is based on FDM[6], it uses binary system to express itemset. So we can simply use "and", "or" and "XOR" to obtain candidate itemsets and the support counts quickly. FFDPM[7] is also based on FP-growth. The minor processor only works in the local database and creates the storage structure named FP-forest. At the same time, the main processor merges the local FP-forests synchronously and then distributes the task equally to the corresponding processors asynchronously. The algorithm adopts depth-first method in the mining stage.

This paper presents a new parallel algorithm PBFI-Miner(Parallel Bit Frequent Itemset Miner).

Experimental result verifies the efficiency of the PBFI-Miner.



II. Problem Description  A. Association Rule Mining  The basic problem of fining association rules introduced in [8] is as follow: Let 1= {iJ,i2, ... ,im} be a set of items and D a database of transactions. Each transaction has a unique identifier named Tid and contains a set of items named itemset. The support count of an itemset X, denoted cou(X). cou(X) is the number of X including in D. The support of X, denoted sup(X). sup(X) is the percentage of X contains in D. The relation of cou(X) and sup(X) is that cou(X) = sup(X)IDI.

Definition 1 Given D, minimum support count s and minimum support?, let sup(X)=s , cou(X)=?,and itemset  X ? I, if sup(X);:,:s or cou(X);:,:?, then X is called frequent itemset in D. The collection of X are called frequent sets, denoted FS. Otherwise they are called infrequent sets. The number of items in X is named X's length or dimension, denoted IXI. In this paper, frequent 1-itemset is called frequent item.

Definition 2 All the frequent items of D are in descending order by the support count. The list of sorting frequent items is called L1.

Given D, the task of association rule mining has two steps:  1) find all the frequent itemsets of D; 2) generate strong rules from the frequent itemsets.

The second problem is simple comparative -ly, we focus    on the first problem in this paper.

B. Parallel Mining of  Association Rules  The parallel mining of association rule is introduced as follow[  l]: we assume pl,p2, ... ,pn is a shared-nothing architecture. Each processor has a private  L,  f  c  d  b  e  a  position valne       I  memory and a private disk. The processors are connected by a communication network and can communicate only by passing message. OB'(i = 1,2, ... ,n) is the local database which stores in pi. The whole database DB is the combination of DB\ the whole number of transactions  D= iJDI' The parallel mining of association rule needs all i=l  processors working at the same time. And processor P'(i =1,2, ... ,n) only processes its local database DBi. The processors just communicate by passing message. At last, it finds the association rules in O.

Definition 3 The support count of X in DB\i= 1,2, ... ,n) is the number of X contained in DBi, which is called the local support count of X, denoted X.cod. But the support count of X in DB is called the whole support count, denoted X.cou.

C. Data format and operation of weighted bit objecl8j  We use binary strings with fixed length express frequent itemset. The binary string is named weighted bit object. The length of the binary string is determined by the number of frequent items in L1? It gives every position a weighted value according L1, called position value. Whether the item is in Ll decides the value of the binary position(if the item is in L1, then the position value is 1, or 0). The binary string with its position value is called bit object of the item.

Tid        Items  a, c, d, f, n  b, c, d, e, f, i, k  d, e, f, g, ill  b, f, p, s  c, d, f, j  a, b, c, e, h, 0  For example, given D in Tab. 1 , when ?=2, the Ll contains f, c, d, b, e and a.

The corresponding position value shows in Tab.2. In this instance, the frequent items in D are denoted as position value with the length ILd=6.

The third column of Tab.3 is the bit object of the corresponding item. For the convenience of  understanding, the second column of Tab.3 records the frequent items after sorting.

Let T(x) be the bit object of frequent item. T(x) is composed of 0 and l. The length of the T(x) is equal to the number of the bit object, such as T(c) = 110011 in the Tab.3.

Theorem 1 The number of the "1" that contains in the bit object T(x), denoted T(x).c. T(x).c is the support count of x.

For example, in the Tab.3, T(f,c) = T(f) &T(c) = 111110 & 110011 = 110010, then we know that T(f,c).c=3, as well as the support count of the itemset fc is 3.

It verifies that the "and" operation of bit object is an effective method to calculate the support count of the itemset.

Tab.1 Business database 0 Tab.2 Position value  Tab. 3 The bit objects of 0  Tid frequent item sets after sorting bit object  100 f, c, d, a 1 1 1 0 0 1  200 f, c, d, b, e I I 1 I I 0  300 f, d, e 1 0 1 0 1 0  400 f, b 1 0 0 1 0 0  500 f, c, d 1 1 1 0 0 0  600 c, b, e, a o I 0 I I I  D.IF P-tree  IFP-tree is a storafe structure of frequent information.

It is based on FP-tree  10]. In this tree, every node has 4 domains, whose name is node-name, node-count, node-link and node-parent. Node-link uses to point the same name node link, and the node-parent uses to point the parent node.

Furthermore, we create a head table named Htable for the convenience of traversal. The Htable has two domains with the name item-name and item-head. Node-name and item-name are all signed by the position value of the frequent item.

The construction algorithm of the IFP-tree is as follow: 1 ) It scans D the first time to generate the frequent  items and their support count, then creates Ll and position value table;  2) It gains the bit object of every item in D, then inserts the position value into the IF P-tree if the bit value is 1. The rest procedure is the same as literature {l 0].

The IFP-tree shows in Fig.l I-Ilable  itelll- item- head    I---+-----i -. ....... .

"--_L----.J -.-.-.-.-. ]:]  Fig. I IFP-tree of 0 with ?= 2    We can obtain property 1 easily from the creating process of IFP-tree.

property 1 For every frequent item X, we can obtain all the routes including X by the node link of X.

Definition 4 The same name node which item-head domain points to in the Htable composes the bit object of this frequent item, denoted the node's bitsets.

The value of certain bit object in its bitsets is decided by whether the prefix-route contains corresponding node. If it contains then the value is "I", or "0". The same node's value is "1". Other node whose position value is less than this node will be evaluated "0". The count of the same name node is denoted the number of the bit object, and stored in array A.

For example, the node with the position value 8(node d) in Fig.l, which contains two bitsets. The first one is "llI000". In this bit object, the leftmost two "1" indicate the nodes in prefix-route with position value "32" (node f)and "16"(node c). The third "I" indicates this node itself.

The last three position values are all "0" because these position value are all less than "8". Besides, the count of this node is 3, so the array A is denoted "3". It indicates that the count of fcd is "3". The second bit object is "101000".

The second position value is "0" because the node whose position value is 16(node c) is not existed in the prefix-route.

And the count of this node is "1", then the array A is denoted "1". It indicates that the count of combination fd is "1 ",  We can obtain theorem 2 from theorem 1 and definition 4 easily.

Theorem 2 All the frequent itemsets with the suffix X can be obtained through mergeing operation among these bitsets.

For example, the bitsets of node d contain two bit objects. In the first bit object, the position value of node d and node f are all "1", and the array A is denoted "3". The second bit object also has node d and node f, and the array A is denoted "1". So the support count of itemset df is 3+ 1 =4.

However, node d, c and f only appeared simultaneously in the first bit object and the array A is denoted "3", so the support count of item set dcf is 3+0=3.



III.Parallel Association Rule Algorithm  A. Mining idea and method of P BFI-Miner  The basic idea of PBFI-Miner is as follow: it uses bit object to express data and to improve FP-tree. According to the features of the IFP-tree and the length of the frequent itemsets, it uses parting strategy to achieve near optimal balancing between processors. The processors construct bit objects themselves and communicate with each other by bit objects in order to reduce communication load. Every processor uses depth first strategy to mine frequent itemsets.

The basic method and process of the PBFI-Miner is as follow:  1) If there are n processors involved in mining the transaction database D, the process has four steps. First, D is divided into n parts (n sub-database ) averagely. Second,   each processor pi(i=1,2, ... ,n) scans its sub-database the first time, and gains the local l-itemsets and its support counts.

Third, each processor exchanges their local l-itemsets and support counts, then merges the l-itemsets in order to get the whole frequent items. At last, we get L1 and construct the position value table.

For example, if there are two processors to mine the database D, we divide D into two parts. Tid 100, 200 and 300 are processed by pI, the rest are processed by p2. After processing we get the local 1-itemsets and their local support counts. Let ?=2, we can get L1 contains f, c, d, b, e and a, which is shown in Tab.2.

2) Each processor pi constructs their local IFP-tree in the second scan of D. They adopt parting strategy to deal with frequent items. In order to achieve near optimal balancing between processors, they use the method of modulo n so that adjacent frequent items are distributed into different processors. Another advantage of adopting this method is the smaller of the position value, the heavier of the mining task. So a, b and c are assigned to pI, the rest are assigned to p2. We obtain the local IFP-tree shown as Fig.2.

Htable pi p2    Fig. 2 The example of the parallel IFP-tree  3)Each processor constructs their local bit objects (the method of construct process is introduced in part 2.4). The bit objects of node e is shown in Tab.4.

TabA The bit object groups of node e in p1and p2  processor f c d b e a A  I I I I 1 0 1 pi  1 0 1 0 1 0 1  p2 0 1 0 1 1 0 1  4) Each processor mmes all frequent Itemsets WIth dIfferent frequent item as suffix. At the same time, each processor adopts depth first strategy that deals with the frequent items, which is taked out bottom-up from Htable. Because information is stored in local IFP-tree structure, the processors need exchanging their message in the parallel mining. They exchange bit objects of frequent items to mine frequent itemsets according to theorem 2. Besides, every processor needs synchronization before frequent item mining, thus the processors can gather the whole bit objects.

B. Algorithm description of PBFI-Miner  Input: the minimum support count?, local I FP-tree of 0 with? Output: frequent itemsets FS= U FS,    (I) Initialize FS,=NULL; II step (I) to step (9) are the procedures of mining in p', and gain frequent item sets FS, of P' (2) for each x E Htable II mining frequent items bottom-up from Htable (3) { construct Bitsets of node x; } (4) if1: node x is assigned to P'to mine) (5) MPI _ Gather(gather the Bitsets of node x from pi (jeri) ); (6)else MP1_ Bcast(Bitsets of node x); (7)MPI Barrier; II synchronization of processors (8) x_MIner ( Bitsets,Begin, FS" CurrentItem ); II mine frequent item sets of node x  (9) return FS, (10) FS= U FS, Procedure x_Miner (Bitsets,Begin,FS"CurrentItem) II Beign shows the position of current item, End shows the highest weight position, CurrentItem shows the position value of current item (I) Tempmfi =Currentltem; II Tempmfi stores the position value of  current item (2) for ( i =Begin; i'SEnd; i + + ) (3) { if ( ( T( i) nr( i + I) ). counC?) (4) Add Tempmfi To FS,; II add Tempmfi to the frequent  item sets of the current item (5) x_Miner( Bitsets, i + I,FS"Tempmfi +item( i + I) position  value) ; }

IV.Performance evaluation  We test the PBFI-Miner on two processors and compared with MLFPT algorithm, because they have the similar structure. All our experiments are performed on 2.1 G Hz AMD Athlon 64 X2 Dual Core 4000+ with 1 G of memory, running at Windows XP SP2. The codes of the two algorithms are complied using Microsoft Visual C++ 6.0.

The experimental database is mushroom database provided in http://mlearn.ics.uci.edu/databases/.The database has 8124 records, noted 23 attributes of mushroom.

We test this PBFI-Miner algorithm from two respects: correctness and efficiency.

In the respect of correctness, given the minimum support is 20%, 50% and 80% respectively, the testing result of the two algorithms is consistent. And the count of the frequent itemsets is 37951, 1543 and 163 respectively.

In the respect of efficiency, we test the two algorithms with mInImUm support from 10% to 100%. The experimental result shows in Fig.3. Experimental result verifies the efficiency of the PBFI-Miner. The less the minimum support is, the better efficiency PBFI-Miner has.

o..s  o. ,  0.35  o. ,  .. 0-25  ? 0.2 0.1'  0.1  0.05  10 20 30 40 50 t;O 70 8() iO 100  Fig. 3 The test results on database The reasons that PBFI-Miner has high performance are as follow:  a) The structure of IF P-tree compresses the database sufficiently.

b) It doesn't need to create condition pattern tree, and uses bit operation to simplify support count operation.

c) It doesn t need to generate candidate itemsets in the   mining process.

d) It divides the frequent items averagely as possible  according to the heavy of mining task So it achieves near optimal balancing between processors.

e) Each processor communicates with transferring bitsets but not local frequent itemsets and support count, so it reduces the telecommunication traffic.

j) When the minimum support is small, the number of frequent itemsets and calculation amount will increase. At that time, the above 5 reasons are more obvious.

v.ConcJusion  This paper proposes a parallel association rule mining algorithm PBFI-Miner based on bit object. Firstly, this algorithm uses bit object to express data and IFP-tree structure to compass the database sufficiently. Secondly, it adopts intersection operation of bit object to find the frequent itemsets and their support count, and it doesn't need to generate a great number of condition pattern trees.

Thirdly, the algorithm uses parting strategy to achieve near optimal balancing between processors. At last, in order to reduce telecommunication traffic, the processors transfer bitsets instead of local frequent itemsets and support count.

Experimental result verifies the efficiency of the PBFI-Miner.

