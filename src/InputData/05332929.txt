- 3863 -

Abstract: One of the most important issues in any association rule mining is the interpretation and evaluation of discov- ered rules. Thus, most algorithms employ the support-confidence framework for evaluating association and classification rules. Unfortunately, recent studies show that the support and confidence measures are insufficient for filtering out unin- teresting association rules, for instance, even strong association rules can be uninteresting and misleading. To deal with this limitation, the support-confidence framework can be suplemented with additional interestingness measures based on statistical significance and correlation analysis. In this paper, a novel fuzzy association rule-based classification approach is proposed, where ?2 is applied as a correlation measure. The algorithm is based on Genetic Network Programming (GNP) and discover comprehensible fuzzy association rules potentially useful for classification. GNP is an evolutionary optimization algorithm that uses directed graph structures as genes instead of strings and trees of Genetic Algorithms (GA) and Genetic Programming (GP), respectively. This feature contributes to creating quite compact programs and im- plicitly memorizing past action sequences. The proposed model consists of two major phases: 1) generating fuzzy class association rules by using GNP, 2) building a classifier based on the extracted fuzzy rules. In the first phase, ?2 is used for computing the correlation of the rules to be integrated into the classifier. In the second phase, the ?2 value is used as a weight of the rule when calculating the matching degree of the rule with new data. The performance of the proposed algorithm has been compared with other relevant algorithms and the experimental results have shown the advantages and effectiveness of the proposed model.

Keywords: association rule mining, classification, fuzzy association rules, fuzzy membership functions, genetic network programming.

1. INTRODUCTION  Classification is one of the several tasks of data mining and it is a very important area of learning in the database field of the real world. One of the comprehensible mod- els is the association rule-based classification that com- bines the advantages of traditional classification and as- sociation rule discovery. A class association rule is gen- erally expressed as IF-THEN rule, i.e., IF [term1 AND term2 AND ... ] THEN [class]. Each term of the an- tecedent is a pair of [attribute, value]. The consequent is the result of classification, that is, the class value of the attributes. Recently, extensive research has been car- ried out to develop enhanced methods for classification and higher classification accuracy is obtained than tra- ditional classifiers. However, recent studies show that the associative classifiers suffer from some problems in- herited from association rule mining such as the limited support-confidence framework. To address this weak- ness, several measures have been proposed to evaluate the significance of the rules and to focus only on those that are significant accurately and statistically. On the other hand, a correlation measure can be used to enhance the support-confidence framework for association rules, that is, A? B[support,con f idence,correlation] is used, where the rule is measured not only by its support and confidence but also by the correlation between A and B.

Among many different correlation measures, the ?2 test is one of the most important because of its solid statistical  basis. Many successful techniques utilize the ?2 test for independence which is based on the diferences between the expected number of occurrences of a pair of itemsets and its observed number [1]. The primary assumption is that these diferences will be small for independent item- sets. A small ?2 value leads to the rejection of the hy- pothesis that the itemsets are correlated.

In this paper, a novel fuzzy association rule-based clas- sification approach is proposed, where ?2 is used as a correlation measure. The algorithm is based on Genetic Network Programming (GNP) and discover comprehen- sible fuzzy association rules which are potentially useful for classification. The fuzzy discretization technique is proposed for dealing with databases with continuous at- tributes. Fuzzy sets help to overcome the so-called sharp boundary problem by giving different membership val- ues, not only 1 and 0 given by traditional discretization methods. Moreover, fuzzy sets can make the discovered rules more understandable for the users. On the other hand, GNP is one of the evolutionary algorithms inspired by biological evolution [2], [3], [4], which is an extension of Genetic Algorithms (GA) and Genetic Programming (GP). The main difference among them is the representa- tion of the solutions. GA evolves strings as solutions and it is mainly applied to optimization problems. GP was formulated later in order to expand the expression ability of GA by using tree structures. GNP uses directed graph structures as solutions instead of strings or trees, there-  ICROS-SICE International Joint Conference 2009 August 18-21, 2009, Fukuoka International Congress Center, Japan  PR0002/09/0000-3863 ?400 ? 2009 SICE    - 3864 -  fore GNP can deal with complex problems more effec- tively and efficiently than GA and GP [5]. GNP produced many novel and outstanding results in the areas such as Data Mining [6], [7], Intelligent Mobile Robot [2], Multi Agent System [3], Elevator Group Supervisory Control System [8], Stock Market Prediction [9], Automatic Pro- gram Generation [10], and so on.

2. ?2 TEST FOR INDEPENDENCE AND CORRELATION  In statistics, ?2 test is a widely used method for test- ing the independence or correlation among variables. Ba- sically, ?2 test is based on the comparison of observed frequencies with the corresponding expected frequencies.

The closer the observed frequencies are to the expected frequencies, the larger the weight of evidence in favor of independence is. If all the variables are in fact inde- pendent, the ?2 value would be 0. If it is higher than a cutoff value (6.63 at the 99% significance level), the independence assumption is rejected. Notice that the cut- off value for any given significance level can be obtained from widely available tables for the ?2 distribution. For- merly, many other successful techniques utilized the ?2 test for independence or correlation [1], [11], [12], [13].

In the proposed algorithm, ?2 test is used for generating correlated fuzzy class association rules as well as weights of the fuzzy rules for building the classifier. By adding a correlation measure to the support-confidence frame- work, the discovery of more meaningful correlated rules becomes possible.

The ?2 statistic is defined as follows:  ?2 = ? AllCells  (O?E)2 E .

(1)  Where, E denotes the value of the expectation under the assumption of independence and O the value of the observation. Then, let support(X) = x, support(Y ) = y, support(X ?Y ) = z and the number of database tu- ples equal N. If events X and Y are independent, then support(X ?Y ) = xy. Table 1 is the contingency of X and Y : the upper parts are the expectation values under the assumption of their independence, and the lower parts are observational.

Table 1 The contingency table of attributes X and Y .

Y ?Y ?row X Nxy N(x? xy)  Nz N(x? z) Nx ?X N(y? xy) N(1? x? y+ xy)  N(y? z) N(1? x? y+ z) N(1? x) ?col Ny N(1? y) N  We can calculate ?2 using x, y, z and N from Table 1 as follows:  ?2 = N(z? xy)2  xy(1? x)(1? y) . (2)  ?2 test could be used in multi-dimensional vari- ables. However, in association rule mining only two-dimensional variables are needed, i.e., for two- dimensional contingency table its degree of freedom is 1. ?2 test is a very effective method, however it has also some limitations [1]. The ?2 test rests on the normal ap- proximation to the binomial distribution. This approxi- mation breaks down when the expected values are small.

Therefore, statistics texts recommend the use of ?2 test only if (1) all cells in the contingency table have expected value greater than 1; and (2) at least 80% of the cells in the contingency table have the expected value greater than 5.

3. FUZZY ASSOCIATION RULE MINING AND CLASSIFIER  The proposed fuzzy association rule mining and clas- sification model consists of two major phases: 1) generat- ing fuzzy class association rules by using GNP, 2) build- ing a classifier based on the extracted fuzzy rules. In the first phase, taking the GNP?s structure into account, the extraction of fuzzy association rules is done without iden- tifying frequent itemsets. The frequent item set search- ing would be the bottleneck of all the association rule mining algorithms due to its long searching time. More- over, fuzzy rules are updated by evolving the member- ship functions through generations in order to obtain the best qualified rules for building the classifier. The sup- port, confidence and ?2 measures are easily calculated taking the GNP?s structure into account [6]. In the sec- ond phase, all of the generated fuzzy rules are used to predict the class of the test data. For each test data, the classifier computes the average matching degree between the data and the rules in each class. The ?2 value is used as a strength of the rule when calculating the matching degree of the rules and the test data. Finally, the class with the largest matching degree is assigned to the test data. The accuracy on the test data set is calculated as the number of correctly classified test data divided by the total number of test data.

3.1 Fuzzy Class Association Rule Mining Since the accuracy of a classification model can be  largely affected by the partitioning of continuous at- tributes, a fuzzy discretization technique is reviewed for dealing with databases with continuous data [14]. Firstly, the values of all continuous attributes of the database are fuzzified into three linguistic terms (e.g. low, middle and high). These linguistic terms are defined by the combina- tion of trapezoidal and triangular membership functions symmetrically spaced [See Fig. 1]. Each continuous at- tribute is associated with its own membership functions.

TID in Fig. 1 shows the transaction number. In addition, the parameters of the membership functions are evolved    - 3865 -  generation by generation in order to discover more in- teresting rules. Uniform and non-uniform mutation [15] were used for the evolution of the parameters of the mem- bership functions.

(a) Fuzzy attributes obtained from databases with continuous values.

(b) Definition of the membership functions.

Fig. 1 The proposed fuzzy discretization technique.

The main task in this phase is to extract the fuzzy class association rules from the fuzzified training set. The rules have the following form:  If (Ai isQi)??? ?? (Aj isQj) ? (C = k), where, Qi, ...,Qj are the linguistic terms of the fuzzy  attributes Ai, ...,Aj and k denotes the class label of the class attributeC (k = 0,1,2, ...K).

The basic structure of GNP for the extraction of fuzzy class association rules is shown in Fig. 2. The fuzzy rules are represented as the connections of judgment nodes in GNP [6], [7]. Each judgment node examines the fuzzy attribute values. P1 is a processing node and is a start- ing point of extracting association rules. Each processing node has an inherent numeric order (P1, P2,. . . , Ps) and is connected to a judgment node. Yes-side of the judgment node is connected to another judgment node. No-side of the judgment node is connected to the next numbered pro- cessing node. The calculation of the measurements such  us support, confidence and ?2 is made using processing nodes [6], [7]. Judgment nodes can be reused and shared with some other association rules because of GNP?s fea- tures. All GNP individuals are searched in parallel at the same time.

Fig. 2 Basic GNP structure for fuzzy association rule mining.

Once a GNP individual starts the searching for associ- ation rules, the transition from one judgment node to an- other is determined probabilistically by using the fuzzy values. That is, the fuzzy value is used for moving to the Yes-side or No-side of the judgment node as Fig. 3 and Fig. 4 show. In Fig. 3, r is a random variable in (0,1), ai is the value of fuzzy attribute Ai and ?Qi(ai) is the value of the membership function ?Qi(Ai) when the value of fuzzy attribute Ai is ai. A random number is generated and compared to the membership value of the fuzzy attribute. If the random number is smaller than or equal to the membership value, then go to the Yes-side of the judgment node, otherwise, go to the No-side of the jugdment node.

Fig. 3 Probabilistic transition from one judgment node to another.

In order to calculate the support, confidence and ?2 of the fuzzy rules, the total number of tuples moving to Yes-side at each judgment node is calculated for every processing node [6], [7]. In Fig. 2, N is the total number of tuples, a, b, c and d are the number of tuples moving to Yes-side at each judgment node and a(k), b(k), c(k) and d(k) are the number of tuples moving to Yes-side at each judgment node that satisfy the class k. These counts    - 3866 -  Fig. 4 Transition from one judgment node to another using probability Pt determined by fuzzy values.

are used for the calculation of the measurements. Table 2 shows how to calculate the support and confidence of the fuzzy rules extracted from the GNP individual in Fig. 2.

Table 2 Support and confidence of fuzzy association rules.

association rules supp. conf.

A1 High? A2 Low b/N b/a A1 High? A2 Low?A3 Mid c/N c/a  A1 High? A2 Low?A3 Mid?A4 Low d/N d/a A1 High?A2 Low? A3 Mid c/N c/b  A1 High?A2 Low? A3 Mid?A4 Low d/N d/b A1 High?A2 Low?A3 Mid? A4 Low d/N d/c  The mined fuzzy class association rules that satisfy the minimum support, confidence and ?2 thresholds are stored with its significance measures and fuzzy parame- ters in a pool through generations. Ocassionally, a fuzzy rule already stored in the pool can be once again ex- tracted, in that situation, the membership functions and ?2 values might be changed, where only the fuzzy rule with higher ?2 value could replace the same old fuzzy rule in the pool along with its fuzzy parameters. There- fore, the pool is updated in every generation and only important fuzzy rules with higher ?2 values and better adapted fuzzy parameters are stored.

3.1.1 Fitness function of GNP The fitness of GNP for classification is defined as fol-  lows:  F = ? r?R  {?2(r)+10(n(r)?1)+?new(r)}. (3)  Where, R: set of suffixes of extracted important association rules  satisfying the minimum measurements thresholds in a GNP individual.

?2(r): ?2 value of rule r.

n(r): the number of attributes in the antecedent of rule r.

?new(r): additional constant defined by  ?new(r) =  ? ?new (rule r is new) 0 (rule r has been already extracted)  (4)  Notice that in Eq.(3) we do not take into account the consequent term because GNP individuals are used to ex- tract fuzzy classification rules, where the consequent is fixed.

3.1.2 Genetic operators of GNP Elite selection method is used. Thus, once all  crossovers and mutations have been performed, all the produced GNP offspring are sorted by their fitness val- ues and only 1/3 best individuals are selected for repro- duction. The following genetic operators are executed to GNP individuals:  ? Crossover: Operator producing two offspring from parents. Uniform crossover is used. Judgment nodes are selected as crossover nodes with the probability of Pc.

? Mutation-1: The connection of the judgment nodes is changed by mutation rate of Pm1.

? Mutation-2: The function of the judgment nodes is changed by mutation rate Pm2.

All the connections of the processing nodes are changed randomly in order to extract rules efficiently.

The flowchart of the proposed fuzzy class association rule mining method is described in Fig. 5.

Fig. 5 Flowchart of the proposed fuzzy class association mining method.

- 3867 -  3.2 Building a Classifier Model In this section, the proposed algorithm is described for  the classification after fuzzy association rule mining. An associative classification model is based on the discov- ered rules. Therefore, the set of rules is used to deter- mine an unknown class label. In the proposed method, the GNP-based data mining algorithm generates a pool of fuzzy association rules for each class in the dataset.

Then, the rules in each pool are used to predict the class of the test data d. Recall that each fuzzy rule was stored in the pool with its own fuzzy parameters. Then, for the test data d, the classifier computes the average matching degree between data d and the rules in class k. Now, the ?2 value is used as a weight of fuzzy rule r when calcu- lating the average matching degree of the rules and test data d. Finally, the class with the highest average match- ing degree is assigned to the test data. The accuracy on the test data is calculated as the number of correctly clas- sified test data divided by the total number of test data.

The classification of test data d is determined as follows:  1) Rk: Provide the set of suffixes of rules in class k, (k = 1,2 . . .K).

2) mk(d): Compute the average matching degree between data d and the rules in class k.

mk(d) =  |Rk| ?r?Rk Dk(d,r), (5)  Dk(d,r) = Sk(d,r) Sk(r)  ??2(r), (6)  where, Dk(d,r) : matching degree between data d and rule r  in class k.

Sk(d,r) : the sum of the fuzzy membership values of  the fuzzy attributes in the antecedent of fuzzy rule r in class k, which are calculated by data d.

Sk(r): the number of attributes in the antecedent of fuzzy rule r in class k.

?2(r): ?2 value of fuzzy rule r.

3) Predict in such way that data d belongs to the class having the highest mk(d).

4. SIMULATION RESULTS  To evaluate the performance of the proposed GNP- based association rule mining and classifier, Iris dataset from UCI (University of California at Irvine) reposi- tory has been used [16]. In terms of the classification accuracy, the proposed model has been compared with three other evolutionary systems: CEFR [17], ESIA [18], BGP[19] and three Apriori-like mining methods: CMAR, C4.5 and CBA that are described in [20]. These methods were selected because they have obtained good results in comparison with other data mining classification systems  and because they have been applied to some of other data sets used in our experiments. The comparison was per- formed under the same conditions in terms that: all of them deal with continuous values, they deal with clas- sification problems, uses the support/confidence frame- work and evaluate their models trough the classification accuracy. The comparison was also performed under the same conditions with CEFR method due to the follow- ing reasons: CEFR is an evolutionary computation based method (Genetic Programming) that deals with continu- ous attributes using fuzzy discretization, discovers fuzzy classification rules based on a fuzzified database, uses three fuzzy membership functions and evolves the param- eters of the fuzzy membership functions. The Iris dataset is one of the most well-known datasets in machine learn- ing literature. The dataset contains three classes of Iris plant: Setosa, Versicolor and Virginica. The algorithm classifies the examples based on four attributes: sepal length, sepal width, petal length and petal width. There are 50 instances of each class in the dataset. The parame- ters used for the extraction of fuzzy class association rules by GNP are summarized in Table 3. All algorithms have been developed in a Java-based software development en- vironment. Experiments were performed on a 1.50GHz Pentium M with 504MB RAM.

Table 3 Parameters for fuzzy classification rule mining.

Parameter Value Population size 120  Maximum generations 500 Number of processing nodes 20 Number of jugment nodes 200  Crossover rate 1/5 Mutation of the conecction rate 1/3 Mutation of the function rate 1/5  Mininum support 0.01 Minimum confidence 0.5  Minimum ?2 6.63 ?new 150  In order to obtain the best performance of the proposed algorithm, the following methods were studied:  ? Evolution of the fuzzy membership functions using uniform and non-uniform mutation.

? Estimation of the matching degree with and without using the ?2 value as a weight of the fuzzy rule.

The number of extracted fuzzy rules per each class in the dataset using the uniform and non-unifirm muta- tion is shown in Fig.6, while Fig.7 shows the classifica- tion accuracy of the different proposed methods. It can be seen from Fig.6 that the GNP-based association rule mining using non-uniform mutation extracts more rules than GNP with uniform mutation. This is because, non- uniform mutation reduces the disadvantages of random mutation by searching the space uniformly at early gen- erations and very locally at later generations. In other words, the non-uniform mutation has the advantage of higher probability for random search at early stages and    - 3868 -  much better local fine-tuning ability at later stages.

Fig. 6 Number of extracted fuzzy rules by GNP with uniform and non-uniform mutation.

Fig. 7 Classification accuracy of the proposed methods.

It can be seen from Fig. 7 that the evolution of the fuzzy membership functions using non-uniform muta- tion and taking the ?2 value into account as a weight of the rule can obtain higher classification accuracies. Ev- idently, assigning appropriate weights to the rules ob- tained by GNP will achieve higher classification accu- racies. A sample of the extracted fuzzy rules is shown in Fig. 8. Table 4 shows the classification accuracies of seven methods including the proposed one on the Iris dataset. It can be seen from Table 4 that the proposed GNP-Fuzzy method outperforms all the other methods.

From Fig. 6, Fig. 7 and Table 4, we can draw the follow- ing conclusions: (1) The proposed method can extract correlated fuzzy rules in the selected database by tak- ing the GNP?s structure into account. (2) The fuzzy dis- cretization technique developed for dealing with contin- uous data shows the significance in the rule?s extraction process since fuzzy class association rules in the pool are used directly for the final classifier. (3) It is easy to calcu- late the membership values, however the critical task is to find appropiate membership functions. This is achieved by evolving the fuzzy parameters using non-uniform mu- tation, which shows its effectiveness for discovering new fuzzy rules generation by generation. (4) The proposed method builds a classifier based on the average degree of  matching of the rules in each class with test data. (5) We use support, confidence and also the correlation mea- sure ?2 value for calculating the significance of the rules, therefore, more effective rules are involved in the classi- fier model. Using the ?2 values as the correlation mea- sure for extracting fuzzy rules and also using them as weights of the fuzzy rules leads to the improvement of the classification accuracy. (6) Finally, the proposed method extracts fuzzy classification rules which are more com- prehensible for the users.

Fig. 8 Sample of the extracted fuzzy classification rules.

Table 4 Comparison of the classification accuracy (%).

Classification approach Method Accuracy GNP-Fuzzy GNP 97.5 CEFR-Miner GP 95.3  ESIA GA 95.3 BGP GP 94.1 CBA Apriori 94.0 C4.5 Apriori 95.3  CMAR Apriori 94.7  5. CONCLUSION  In this paper, a fuzzy association rule mining and clas- sification method based on GNP have been proposed. We have shown that the features of GNP make the proposed model easy to formulate and use. Taking the structure of GNP into account, the extraction of fuzzy association rules is done without identifying frequent itemsets used in most Apriori-based data mining algorithms. The fuzzy membership functions are used for fuzzy rules extraction, where their parameters are evolved in order to perform the global search in the space of candidate membership functions. The method of how to apply ?2 values to min- ing association rules is also discussed. The experiments of the proposed method and its comparisons with other methods demonstrate that the algorithm is very effective.

