

Abstract  In this paper, we first describe the classical Apriori Algorithm. And then, we present the defects exist in this algorithm. Such as spending a lot of time to produce the candidate item-sets , scanning the database in a simple method, and so on. At last we promote our improved Apriori Algorithm which consists of three parts. The first part is reducing the number of judgments, and the second part is reducing the number of candidate frequent item-sets. The last part is optimizing the database. And the experimental results proved our improvement  1. Introduction  With the popularization of computer and development of Database Technology, more and more data are stored in the large databases. Obviously speaking, it is impossible to find useful information without using efficient methods. And then, Data mining (DM) techniques have emerged as a reflection of this request. Association rules mining, an important research direction, is aim to find out the dependence of among multiple domains basing on a given degree of support and credibility.

Association rules mining process is divided into two steps. The first step is to find the frequent item-sets which support degree is large than the initial support degree from the transaction database; the second step to generate the rules of value from the frequent item-sets, and the acquisition of frequent item-sets is the key step during mining association rules procedure. In 1993, R.

Agrawal first promoted an association rule mining algorithm named apriori algorithm (AA). And in the following year, Agrawal proposed two kinds of improved AA named AprioriTid algorithm and AprioriHybrid algorithm. What?s more, subsequent researchers have also given a lot of improvement for the AA. However, all of these improved algorithms have the following problems in varying degrees. The  first problem is these algorithms need a lot of time to produce the candidate frequent item-sets. And the second one is these algorithms have to scan the transaction database many times to do the pattern-matching for candidate frequent item-sets.

These two issues are both the hotspots and difficulties during current research on mining association rules. In our paper, we promote a faster and more efficient algorithm based on the classical AA  2.Basic conception  The concept of the association rules was first proposed by R. Agrawal. It is used to describe the patterns of customers' purchase in the supermarket. The association rules can be formally defined as:  Definition 1: Let { , , , , }1 2 3 nI i i i i? ? be a set of items.

D is a transactional database. Where  ( , , , )ki k 1 2 3 n? ?  is an item. Tid is the exclusive identifier of transaction T in transactional database.

Definition 2: The implication of the form X Y? is called an association rules. Where X I? ,Y I? , and X Y? ? ? .

Definition 3: Let D be a transactional database. If the percentage of transactions in D that contains X Y? is s%, the rule X Y? holds in D with Support s . If the percentage of transactions in D  containing X that also contain Y is c %, the rule X Y? has Confidence c .The definitions of probability are:  ( ) ( )Support X Y P X Y? ? ? , ( ) ( | )Confidence X Y P Y X? ? .

Rules that satisfy both minimum support threshold (min-sup) and minimum confidence threshold (min-conf) are called strong rules.

Definition 4: If the support of item-sets X is greater than or equal to minimum support threshold, X is called frequent item-sets. If the support of item-sets X is smaller than the minimum support threshold, then X is called infrequent item-sets.

3. The basic idea of Apriori Algorithm  Generally speaking, AA uses an iterative method to search the rules Layer by layer. We should find out the 1-item-set named 1L at first, and then we use 1L  to identify the set of 2-item-set named 2L .Go on this operation until we can?t seek out the item-set. Here there are two parts during the AA:  a.Connection Step Generate a new set of candidate item-set named kC ,  here k is the length of candidate item-set. kC is the produced through the connection operation of 1kL 	 .

Here 1kL 	 is a frequent item-set and 1k 	 is the length of this frequent item-set. The connection rules reads as follows. Let 1L and 2L belong to the 1kL 	 . If all the items of these two frequent item-set are same except their last items, then they can be connected  b.Pruning Step Actually speaking, it is scanty that all the subset of  kC fill the min-sup. As a result, we must determine how many subset of kC are belongs to kL by scanning the transaction database D . That is to say, we should determine the support of every item-set in kC in order to delete the candidate item-set which can?t match the min-sup.

4. Apriori Algorithm Performance Analysis  From the Implementation of AA, we can find there are three fatal defects exist in this algorithm  a) First, we need to scan the database repeatedly.

That is, we need to scan the whole database every time when we calculate an item-set.

b) The time complexity and space complexity are too high due to its large candidate item-sets.

c) There exist many rules, discovered by the method which is based on the theory of credibility, which have no practical significance.

5. Improvement of Apriori Algorithm  In this paper, we decide to improve the performance of AA in the following three aspects:  a) Reduce the number of judgments.

b) Reduce the number of candidate frequent  item-sets.

c) Optimize the database.

5.1 Reduce the number of judgments  During the process of AA, all these transactions have already been sorted. Therefore, we can affirm that the candidate frequent item-set is ordered. And any comparison between the two candidate item-set  is ordered on the bit comparison .That is to say, we can reduce the number of judgments during the process of producing candidate frequent item-set  through the use of this property. The details are as follows.

Definition 1: Let us compare two frequent item-set named lx and ly . If  [ ] [ ] [ ] [ ] [ ] [ ],lx 1 ly 1 lx i 1 ly i 1 lx i ly i 1 i k? ? ? ? ? Then we can say that lx is smaller than ly : lx ly? . If  there exists m frequent item-sets and 1 2 ml l l? ? ?? , we can allege that these item-sets are ordered. There are many properties for this definition.

Property 1: For any item of k-item-set, there exists [ ] [ ]l 1 l 2? .

Proof: Because l is an ordered item-set, so the property is proved.

Property 2: For any item of k-item-set: ,lx ly .let 1 x y z m? ? ? ? .

If [ ] [ ] [ ] [ ] [ ] [ ],lx 1 ly 1 lx i 1 ly i 1 lx i ly i 1 i k? ? ? ? ? , than we can get that [ ] [ ]lx j lz i?  while counter j is smaller than z and larger than 1.

Proof: Because y z? , so we can affirm ly lz? .

Therefore, if [ ] [ ]ly i lz i? , [ ] [ ]lx i lz i?  is true when j equals to i which is a specific number. By the same token, if [ ] [ ]ly i lz i? , [ ] [ ]ly p lz p?  is true when j equals to p which is a specific number.

We can optimize the link step by using the properties mentioned above.

With regards to these two k-1 frequent item-set named lx and ly , if these two item-set can?t be connected, then we can affirm that all the item-sets after lx  and ly can?t satisfy the connection condition .As a result, there is no need to determine whether the item-sets  which are behind the item-set lx  and ly  satisfy the connection conditions or not.

What?s more, both item-set lx and item-set ly  get from k-item-set. So, repeated connection operations are existed during the Traversal process. That is, the result of connecting x  and y is same to the result of connecting y to x. So, it is necessary to execute further optimization.

,1 2declare TL TL , ;1 K 1 2 K 1Set  TL L TL L	 	? ?  1foreach lx TL     { 2foreach ly TL { [ ] [ ] [ ] [ ]if  lx 1 ly 1 lx i 2 ly i 2? ?  [ ] [ ]lx k 1 ly k 1 ? 	 ) { ;c lx ly? ?  { }k kC C c? ? ;2 2TL TL x? 	 }  //Item-set lay behind ly can't connect to lx } }  5.2 Pruning the frequent item-sets  Frequent item-sets have the following properties: Property 1: The necessary condition for a  k-dimensional becomes a frequent item-set is that all the (k-1)-dimensional subsets are also frequent item-set.

Property 2: Let k-dimensional item-set { , , , }1 2 kx i i i? ? , ( )K 1L j k 1	 ? 	  is true when j  belongs to X, then we can say that X is not a frequent item-set. Here ( )K 1L j	  means the number of j  in  ( )K 1L j	 .

Proof: Let X be a k-dimension item-set. Now we  take any k 1	 elements from X . Obviously, there are k  possibilities. So, there are k 1	  project j  in all the (k-1)-dimension item-set which are produced by X .

As far as the above properties are considered, we can get a conclusion. The details are as follow.

Let ci , 1	 kLc , here i is an project, c is an element and 1	KL  is a k-dimension frequent item-set . If the inequality ( )K 1L j k 1	 ? 	  is established, then the  candidate k-dimension 1	KC  item-set produced by  1	KL  can?t be a frequent item-set. As a result, there is no need to let 1	KC  participate in join operations.

Here is the new strategy for pruning the frequent item-set.

Calculate ( )K 1L j	 . Here ( )K 1L j	  is the frequency  of ( )K 1L j	 , and ' { ( ) |, }k 1j L U A A L 	 ?  Find the projects which frequency are smaller than k 1	  and then put them into a Set name 'I .

Get rid of the frequent item-set of K 1L 	  which  contains the subset of 'I , than we can get a new K 1L named 'K 1L 	 .

5.3 Database optimization  Mark a delete tag on all the transactions of item-set which not contains the kC during the calculation of kC .

Therefore, there is no need to take these item-set into consideration in the following calculation. The efficiency can be more and more obvious with the growth of value k.

6 Improved algorithm description  Input: Transaction D , Minimum support threshold: min-sup;  Output: Li , Frequent item-set in D ; Here is the flow chart: (1) );(_1__1 DitemsetfrequentfindL ? / / find  the 1-itemset (2) 1( 2; ; )kfor k L k	? ? ? ? ?  (3) { sup);min_,(_ 1	? Kk LgenaprioriC / / KCreate the candidate itemset C? ? ? ?  (5) .k kL C itemset? (6) } (7) kreturn L=UL  Procedure apriori_gen( 1kL 	 ,min_sup); (1) ,1 2declare TL TL (2) ' { / ( ) }k 1Get  I i L i k 1	? ? ?  (3) 'k 1 k 1Set  L L I	 	? (4) ,1 k 1 2 k 1Set  TL =L TL L	 	? (5) 1foreach lx TL (6){ 2foreach ly TL (7)  { ( [ ] [ ] [ ] [ ]if lx 1 ly 1 lx 2 ly 2? ? (8) [ ] [ ] [ ] [ ])lxk 2 lyk 2 lxk 1 lyk 1	 ? ? (10)   { c lx ly? ? (12)    ( _ )k 1if has infrequent_itemset(c,L ) (13)  { delete c } (16)  { }k kC C c? ? (17)  2 2TL TL lx? (18)   } (19)   else break; } (21) } Has_infrequent_item-set ( c , K 1L 	 ) (1) for  each (k-1) subset s of c .

(2) k 1if  s L  return true; else return false	? .

7 Experimental Result  We compared the performance of our improved     algorithm with the classical AA. The experimental platform is Intel Core(TM) 2 CPU 6600 2.4GHz.

2.00G RAM Windows XP Operating System. It is based on Microsoft Sql database. The algorithm adopts C# program and compiles in Visual Studio 2005 experiment environment.

Our experiment uses a fictional supermarket transaction database which consists of 10000 TDs and 120 items.

Experiment 1: Number of items: 120; Number of TD: 10000;  0 0.005 0.01 0.015     Support Degree  E la  ps ed  T im  e  Constrast1(with different Support Degree)  AA IAA  Fig 1. Experiment Contrast with different Support degree  From Fig 1, we can see that the execution time of IAA is shorter than AA while under different support degree.

Experiment 2: Support Degree:0.005 Number of items:120  0 2000 4000 6000 8000 10000 12000        x 104  Number of TD  E la  ps ed  T im  e  Constrast2(with different Number of TD)  AA IAA  Fig 2. Contrast with different Number of TD  From Fig 2, we can see that the execution time of IAA is shorter than AA while under different number of trading services.

Experiment 3: Support Degree: 0.005 Number of TD: 10000  0 20 40 60 80 100 120           x 104  Number of Items  E la  ps ed  T im  e  Constrast3(with different Number of Items)  AA IAA  Fig 3. Contrast with different number of items  From Fig 3, we can see that the execution time of IAA is shorter than AA while under different number of items.

The above three experiment results demonstrate that while comparing the classical AA, the IAA improves the overall performance by reducing the number of scanning the database, using the new data representation and adopting a new Connection method between items.

8 Conclusions  In this paper, an improved Apriori-based algorithm IAA is proposed. Our improvement consists of three parts which are reducing the number of judgments, adopting new pruning strategy and optimize the transaction database. These improvements can greatly reduce the redundant operation while generating frequent item-sets and association rules in the database.

Validated by the experiments, the improvement is notable.

Acknowledgements  The paper is supported by National Natural Science Foundation of China (60872115), Shanghai?s Key Discipline Development Program (J50104).

