A Vehicle License Plate Recognition Method Based on Neural Network

Abstract   It is of great significance how to identify car licence  rapidly and accuratly in the modern urban traffic management system. Hopfield NN is a feedback network with association function. It can figure out the weight of network according to some rules and update every nerve cell?s state constantly in curse of the network evolvement. This paper presents a method identifying noise of vehicle license plate with dispersed Hopfield NN .programming calculating and simulating in MATLAB and that validating the method correct. It provides a new fast and effective method for the vehicle licence identification.

1. Introduction   Buring the course of vehicle use, by the natural environment impact of wind and sun, resulting in blurred license plate font is unclear, difficult to identify.

In face of this identification problem of font with noise, how the information from these incomplete fonts to extract complete information, the key issues is the font identify.

Due to having a powerful matrix calculation capabilities, MATLAB language is widely used in various control areas. Meanwhile, Hopfield neural network is a function of the feedback network with Lenovo, it can be calculated the weight of the network according to certain rules. In the course of evolution , the network can constantly updating the state of all neurons, the key of problem is the state of the neurons when the network evolves to a stable time [1][2]. The paper proposes a MATLAB-based and discrete Hopfield neural network (DHNN) method to achieve identification with noise fonts,through a variety of the tests of the font with noise, the method proved highly effective.

2. Introduction on discrete Hopfield neural network   In 1982, Professor J.J.Hopfield, California Institute of Technology physicist, proposed a kind of introduced "energy function" concept feedback neural networks - Hopfield network [3]. The basic structure of discrete Hopfield network as shown in the figure 1, this network is a single network, order network is composed of n units, N1?N2?? ,Nn, that express n neurons, they are both input units and output units , their transfer characteristic function are f1? f2? ... ?fn, their threshold value are ?1? ?2? ... ??n.

In the discrete Hopfield network, each node generally chooses the same transfer function, and it is the sign function, that is:  ? ? ?  <? ?  =====  )sgn()()()( 21 x  x xxfxfxf n  (1)  In order to facilitate analysis, we select all the node threshold value equal, and equal to zero, that is:   Figure 1. Hopfield network structure  ?1=?2=?=?n=0               (2) At the same time, x=(x1,x2??,xn), x?{-1,+1}n , it is  the network input; y=(y1,y2??yn), y?{-1,+1}n , it is the network  output; v(t)=(v1(t),v2(t)??vn(t)), v(t) ?{-1,+1}n , it is the   DOI 10.1109/GrC.2010.126     network state at time t, t?{0?1?2,?} , it is the discrete time variable; wij  is the connection weights from Ni to Nj, because Hopfield is symmetric, that is:  wij=wji , j,i?{0?1?2,?n}           (3) In the network, the connection strength among all n  nodes with the matrix W that, W is a n ? n square.

In the process of running, after input a the original  input mode from the original impetus, the network will feedback back to its output and as the next input. After some times cycles (iterations), on the premise of the network structure meet certain conditions, the network will eventually stabilize at a steady pre-set point.

expression using the following formula:  vj(0)=xj  vj(t+1)= ? ? ?  ? ? ? ? ?  =  n  i jjijj tvwf  )( ?          (4)  After some point t , the network status will no longer change, that is, v(t+1)=v(t), then the output are:  y=v(t)                  (5)  3. The principle of Hopfield network recognizes the noise characters   For Hopfield network, it will eventually stabilize to a fixed-point attractor. if we set the model of ready memory to a network stable equilibrium point, then when the network starts from some initial state of closing distance to the equilibrium point (the equivalent of the model is contaminated), it can think out of the model[4][5].

Set input mode is X, if the network is stable, then the steady state output sgn (WX) will also be X, which should:  X=sgn(WX)              (6) Network element formula is:  xj=sgn(? =  n  i iji xw  )             (7)  To meet (7), we have wji=?xixj   (? is the learning rate)   (8)  Vector formula is: W=?XXT                (9)  As discrete Hopfield network of the non-self-loop wij = 0 is easy to stability, so the weight matrix can obtain from the following forms:  W=?(XXT-U) (U is the unit matrix)    (10) If the input mode is {X1,X2?Xp}, then (8) where  promotion is:  wji=? ? =  p  p pjpi xx  ,,             (11)  The corresponding vector type is:  W=?? =  p  p  T pp XX  (12 )  If  taking wjj=0, then (11)?(12) type are changed:  wji=? ? ? =  p  ji p  pjpi xx  ,,         ?13?  W=? ? =  ? p  p  T pp UXX  )(        (14?   4. The example on based on MATLAB and the Hopfield network identification with noise fonts   In summary, if putting a font size set to 12 ? 10 black and white images, each piece is 120 pixels points, +1 that black, -1 that white, for example ?5?, the basic wait for the storage vector shown to below figure 2:   Figure 2: Wait for the storage mode (vector)  diagram Vector expression:  Xp=  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  ?  ?  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  ?  ?  ?? ?? ???????? ???????? ???????? ?? ?? ???????? ???????? ???????? ?? ??     By (14) determine the weights     W=? ? =  ? p  p  T pp UXX  )( , in this take ? = 1.

Then the basic vector as input, after the experiment that the basic vector is the network stability state. To achieve identification to the noise fonts, the fundamental vector can increase the noise, that is, each pixels point probability of variation to 0.25 (-1 to +1 or vice versa), the fonts vector contaminated can with CX said. Which may achieve in the following zaoshengzifu () function in MATLAB written.

Used the contaminated fonts vector to test, after a certain number of iterations ,it will stabilize at the basic vector Xp on. the above process algorithm can be achieved by the following MATLAB statements: %%%%%%%%%%%%start%%%%%%%%%%%%%%%%%%  %%%%%%%%%%%% clc; close all; Xp= [-1 1 1 1 1 1 1 1 1 ?1 -1 1 1 1 1  1 1 1 1 ?1 -1 1 1 -1 -1 -1 -1 -1 -1 ?1 -1 1 1 -1 -1 -1 -1 -1 -1 ?1 -1 1 1 -1 -1 -1 -1 -1 -1 ?1 -1 1 1 1 1 1 1 1 1 ?1 -1 1 1 1 1 1 1 1 1 ?1 -1 -1 -1 -1 -1 -1 -1 1 1 ?1 -1 -1 -1 -1 -1 -1 -1 1 1 ?1 -1 -1 -1 -1 -1 -1 -1 1 1 ?1 -1 1 1 1 1 1 1 1 1 ?1 -1 1 1 1 1 1 1 1 1 -1];             %%% Basic character %%%  CX=zaoshengzifu(Xp,120)    %%% With 25% of the manic voice of character %%% N=0; for i=1:1:120  if CX(i)~=Xp(i) N=N+1; end end for j=1:50 if CX==Xp;  disp('succeseful!!'); break else B=sign(W*CX'); CX=B'; D=Xp'-B; end end  if j>49 disp('fail') end N                           %%% Iteration  times %%% %%%%%%end%%%%%%%%%%%%%%%%%%%%%%%%%%  %% Meanwhile, ?zaoshengzifu ()? is the sub function, it  can generate with a certain amount of noise characters.

In this paper, used standard characters have 25% pixels to be contaminated, the original code of  MATLAB language is as follows: function  [zaoxiang]=zaoshengzifu(xiang,N) for i=1:1:N a=rand; if a<=0.25 xiang(i)=-xiang(i); end end zaoxiang=xiang;   5. Conclusion   Experiments show that the human eye can not recognize the fonts when the noise reaches 25%. The paper applies M language to program on discrete Hopfield network algorithm which can  identify with 25% noise characters in MATLAB, Simulation results show that this method can effectively identify to be contaminated fonts, it is simple and easy to used in practice.

6. References  [1]Yuan ceng-ying, ?Artificial Neural Network and Its Application?[M],Beijing, Qinghua university press,1999.

[2]Zhang nai-rao,Yan ping-fan, ?Neural networks and fuzzy control?[M],Beijing, Qinghua university press,1998.

[3]Hopfield J J. Neural Networks and Physical Systems with Emergent Collective Computational Abilities,Proceeding of the National Academy of Science 79:2554~2558,1982.

[4]Zhang cheng-fu ect. ?The issues about associative memory neural network?, acta automatica sinica ,Vol.20, pp.513-521, 1994.

[5]Bruck J. On the convergence properties of the Hopfield model  proc.IEEE 1990 78:1579~1585.

