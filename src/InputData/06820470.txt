Proceedings of ICCT2013

Abstract: In recent years, big data processing has been a trend. Hadoop and some other cloud computing technologies make batch processing possible to process big data. Storm is like a real-time Hadoop. Storm model is easy, but it?s difficult to deal with complex Topology due to the increasing inter-dependences between components. This paper proposes a novel method which simplifies the Storm Topology programming model by combining Spring with Storm. It provide a modular approach and a unified configuration model to build topologies and easy to use API for using Storm.

Meanwhile, this paper propose a system to process data and realize the K-Means clustering algorithm in Storm.

The practice results is shown and analyzed to prove the effectiveness of the system and model, at the same time it proves that Storm can improve the clustering algorithm processing speed.

Keywords: Stream processing; Storm; Spring; K-Means; GPS; Kafka  1  Introduction As the amount of data increases, big data processing technologies are also developing. Hadoop [1] is a representative distributed data processing technology for cloud computing. While people have high demand on real-time response now so that Storm [2][3] appears.

Storm is an open-source distributed realtime computation system. It is especially designed for processing endless stream data, which makes stream processing easier and reliable. The biggest difference between Storm and Hadoop is Storm never stop unless you kill it explicitly.

The GPS data is generated constantly over time and space from cars, which is large but reflect the temporal and spatial characteristics of urban traffic network, making it necessary to manage this dynamic data.

Through the cluster analysis based on cars' location information by time, we can not only learn traffic information in real-time but provide a reasonable basis for road planning of the city.

Therefore, the GPS data requires effective analysis technology for meaningful information search to mirror traffic condition. However, the traditional database based real time analysis methods cannot meet the requirements because their limited performance on the speed of response for solving large scale data. As an alternative solution, realtime big data processing analysis methods is required. Storm is very simple in this challenge which processes data seems like a water  treatment system. Spout [4] reads data from external data source and then emits the data to Bolt [4] to process until the whole Topology [4] is completed. And Storm is not an expensive solution to solve problems with large streaming data sets at all. However, as the Topology logic becomes complex, the coupling and the dependences among components will increase.

Thus, this paper aims to propose structure and computing environment needed for analysis of large-scale GPS data which was collected. The proposed system consists of three parts: data gathering, data analysis, and data storage. Our focus is on data import and data analysis module. The data gathering module simulates stream status by Kafka [5][6], and there are related introduction about Kafka and Storm in [8][9][10][11]. The K-Means is used for the GPS data analysis, which is the most important for this paper.

Data storage module save the results through files. In fact, files, relational databases or NoSQL databases are all acceptable data sources and result storage.

Meanwhile, this paper improved the traditional programming model of Storm by combining Spring with Storm which realized the definition of Topology based on XML configuration files. In github, mykidong realize the Storm-spring-example, but each Spout/Bolt need its own ApplicationContext.xml [7]. This paper realized all of the components defined in one ApplicationContext.xml file. Finally, the paper implemented the GPS data analysis module using new Storm Topology programming model. In addition, the experimental results was shown and analyzed to prove the effectiveness of the model.

The structure of this paper is organized as below: In section 2, related technology used in the analysis system will be introduced. In section 3, proposed the system architecture, and process the K-Means algorithm based on Storm. How to implement the system in the Storm and the evaluation will be proposed in section 4. Lastly this paper will be concluded with the suggestions for future research.

2  Related work  2.1 Storm Model Storm is similar to Hadoop. Storm?s task is called Topology which is submitted to the master node to execute. Topology is a programming model which contains processing logic to process large-scale data in parallel. There are two kinds of components in a Topology: Spout and Bolt. How to transmit messages  ____________________________________     Proceedings of ICCT2013    among components is decided by streaming grouping [4].

The Spouts, Bolts and the stream between components compose Topology. Figure 1 shows the structure of the Topology used in the analysis system in this paper.

Figure 1 The Storm Topology  The above illustration shows how a simple Topology would look like in this paper. There are five components in the Topologys: KafkaSpout, SplitBolt, InitBolt, KmeansBolt and WriteBolt. At the KafkaSpout, it reads stream data from Kafka and emits its output in parallel to SplitBolt. At all kinds of Bolt, the tuple created at the last stage is passed to the next Bolt by processing according to user?s definition. In this process, the Storm implements Topology program model and framework so that we only focus on the implement of the Spout and Bolt function, and the rest process including distribution and parallel processing is automatically done by the Storm framework.

2.2 K-Means Algorithm A GPS terminal can track where you are in real time according to the time, the longitude and the latitude information. The data of this paper comes from a northern city in China. Through analyzing these data you can learn the traffic conditions of the city and also provide a reasonable basis for road and urban planning.

As a classical partition clustering algorithm, K-Means partitions the samples into clusters according to Nearest Neighbor Principle between the samples and the centroid of the clusters. Because of its easy to describe and implement, and its efficient to handle large data sets, the algorithm has been widely used in natural language processing and text clustering and many other fields, etc.

Nowadays, with the development of distributed technology, distributed technology combines with the cluster algorithm has become a research hotspot.

Currently, the traditional and improved clustering algorithms are rewritten into the parallel MapReduce computation model to execute, but on Storm related algorithms are not implemented, so this paper realize the K-Means algorithm based on Storm.

2.3 Spring Spring Framework is an open source, lightweight, inversion of control, and aspect oriented container framework. Its architecture is based on the dependency  injection design pattern. The key benefit of this approach is that it enables the developers to build loosely coupled applications. Flexible dependency injection with XML and annotation-based configuration styles bring all business bean into Spring container and manage all beans. This minimizes the dependency of application code on the container, which in turn improves productivity, maximizes the opportunity for code reuse, and improves testability. Storm Spring provides a unified configuration model to build Storm topologies in a Spring XML configuration. The Storm topology can be assembled freely by Storm developers based on the Spring Framework.

2.4 Kafka Kafka is a high-throughput distributed messaging system developed for collecting and delivering high volumes of log data with low latency [6]. Kafka cluster is  totally distributed, including consumer, producer and Kafka brokers.This paper uses Kafka to transform the files into streaming data to realize the real distributed computing.

3  The System Architecture Based on The Storm  3.1 System Architecture The implementation of the K-Means algorithm is important for our GPS data analysis in Storm. It decides the clustering results. However, the traditional K-Means method cannot be used in Storm directly. It need to be improved for the parallel execution. Therefore, this paper simulates a real-time system to analyze the GPS data of a northern city by Storm platform which is shown in Figure 2. It mainly includes data collecting module and analysis module, and the source data and result is stored in files.

GPS  data    (files)  Kafka  Cluster (transform  files  into  message  queue)  Nimbus  ZooKeeper  Bolt  Spout  Supervisor   Figure 2 The Analysis System  The collecting module collects data from external and push them into Kafka message queue. Each message includes time, longitude, latitude and some other related information. Then the data is processed by Storm. The    Proceedings of ICCT2013    difference is the Topology is realized through the XML configuration file by combining with Spring. K-Means algorithm is used as an analysis engine for the collected large-scale GPS data. Based on such framework and algorithm, we can get the results easily and efficiently as if real time statistics.

3.2 Data Collecting Storm does not define the source of data processing, so the data can be logs files, database and message queue, etc. As long as Spout implements the corresponding interface it can read the data from anywhere.  However, there is a problem. Since the data is likely on different computers, Spout can not know which machine the data is. Even if the data exists on the same machine,  the number of tasks that should be assigned to execute this Spout can only be one which does not meet the distributed features otherwise the data will be read the same times as parallelism.This paper presents the solutions as follows:   Figure 3 Data Collection Module  Kafka middleware unify disparate data into the message queue. Storm as the consumers of message queue makes the problem of reading data in parallel solved. Meantime, different Topology shared data sources become available and it improves the scalability of the system. Through messaging middleware layer, it masks external data source details and Storm-Kafka plugin for Storm is available. However, the introduction of Kafka will undoubtedly bring a certain complexity, which increase the threshold for application development on the Storm.

The data collection structure is as above Figure 3.

3.3 K-Means Algorithm The system uses K-means algorithm for data clustering to extract meaningful information. As a traditional clustering algorithm, the standard processing flow is presented as follows. Suppose we want to divide the data  into k clusters:  1)Choose k cluster centers randomly as the initial center: u1 u2, uk.

2)In the kth iteration, for each data, compute the distance to the k centers choose the most closest to and assign the data point to this cluster.

3)Re-compute centers by methods such as average.

4)If the new set of k cluster centers is the same as those calculated in previous, the algorithm would be terminated. Otherwise, it should return to step 2.

The clustering algorithm based on the Storm consists of four stages: pre-processing data; init stage; k-means stage and write result stage. Figure 1 shows the Topology of the GPS data analysis system based on Storm. This paper uses the same time data for clustering analysis according to the time field because our data is ordered in time.

3.4 Spring For Storm The definition of the task in Storm is very easy. Take our topology for an example. The definition of Topology using TopologyBuilder is as follows Figure 4 the Figure 5 shows the same Topology defined using Spring configuration files.

Figure 4 Define Topology Using TopologyBuilder   Figure 5 Define Topology Using Spring Configuration Files  Notice that the creation and submission of the Topology is handled by the IoC container. Topology, Spout and Bolt are all seen as beans, then place them in Spring container to complete the initialization. By combining    Proceedings of ICCT2013    Spring with Storm, the Storm components configuration and task deployment are all unified to Spring bean to manage. The Topology is assembled via the configuration file so that it reduces the dependency of application code on the container.

How to develop a Topology? The implementation of Topology function is mainly dependent on the Spout and Bolt. The definition of the Topology using Spring Configuration Files is processed in steps as follows  Steps 1, define the Spout and Bolt standard interfaces for using in Spring XML. Here are a few examples  a)Topology Interface: IProcessorTopology  b)Spout Interface: IRichSpoutDef  c)Bolt Interface: IRichBoltDef  Steps 2, using the standard interfaces to develop a Topology.

Steps 3, assemble Topology.

a)For easy assembly, we give a setter method for class Topology?s Spout and Bolt attribute.

b)Create the implementation class of Spout and Bolt.

c)Build Storm topology in a Spring XML configuration.

Steps 4, submit the Topology to Storm cluster to Run.

4  Implementation  and Evaluation This section will describe the system's detail implementation, including data import, K-Means algorithm's parallelization using the new SpringStorm model, and I compared the execution time between based on SpringStorm and TopologyBuilder, between reading messages form Kafka and file, between based on Storm and a standalone Java program.

The system was developed on a cluster of 3 virtual machine. One is as Kafka server and one supervisor, one is Storm nimbus and zookeeper, the last one is as Storm supervisor. Every server has a 512M RAM and 20G dists. The operation system is ubuntu 12.4. The Storm is Storm-0.7.4, Kafka is Kafka-0.7.0, Zookeeper is Zookeeper-3.4.3.

4.1 Implementation Data is downloaded from the datatang.com, including more than twenty thousand taxis GPS location data of a northern city in March, we use some sample data to do the experiment. The data is saved as a text file with 493MB units from 1 PM to 4 PM on March 15. First, the program will feed GPS data into Kafka through Producer program to simulate that data is the form of flow. Then write topology, this article develop the Topology using the new model according to the steps mentioned above to verify the availability of the model this paper presented. Figure 6 shows the main beans of the GPS data analysis module based on SpringStorm.

The whole topology was build through the idea of componentization, and it consists of five components.

The system injects dependencies into its topology using the dependency injection service, separating the building from using forcibly.

First, Storm as Kafka?s consumer feeds GPS data through Kafka and emits every message as input data of the next step. Second, we split the message into multiple fields. In this process, the time, longitude and latitude fields were emitted to the init step. Third, init the cluster state including cluster centers, cluster set and error sum of squares, then transfer these information to kmeans step. Fourth, the K-Means algorithm is calculated, the result value is transfered to the write step. Fifth, the result is written into file, because of involving writing file operation, this step can not realize parallelization.

Figure 6 The Main Beans Of The Topology Based On  SpringStorm  4.2 Evaluation Three experiments have been conducted on the test  set. One is to evaluate the performance of the SpringStorm module, and I compared and analyzed the execution time between the proposed SpringStorm based K-Means algorithm and the traditional Storm based algorithm. One is to evaluate the performance of Storm based reading messages from Kafka and reading messages from file. The other is to evaluate the performance based on Storm and simply standalone Java program. The results are shown in table I, table II and table III.

Proceedings of ICCT2013    TABLE I Comparation of Execution Time Based on SpringStorm and TopologyBuilder  SpringStorm based TopologyBuilder 1m16s 1m12s  TABLE II Comparation of Execution Time Based on Storm Reading message form Kafka and file  Read message form Kafka Read message from file 1m12s 1m4s  TABLE III Comparation of Execution Time Based on Storm and standalone Java program  Storm based standalone Java program 1m12s 2m23s     Figure 7 The K-Means Result  Table I shows the comparation of execution time between based on SpringStorm and TopologyBuilder.

The result shows that the proposed method building topology based on Spring XML file has almost the same performance with the traditional TopologyBuilder model.

From Table II, we can see that reading data from Kafka costs more time than reading data directly from files. It was likely to be because the Kafka cluster would loss some performance, and our data sets and loads are not high so that the result in the performance degradation.

Meanwhile, we need to control the amount of messages having been emitted but not processed to prevent the Memory and CPU from becoming a bottleneck.

As shown in the above Table III, performance improved almost double in executing K-Means algorithm based on Storm compared with a simply standalone Java program.

On mass data processing, Storm?s distributed environments offer huge advantages over similar workloads deployed in a standalone system. Figure 7  shows the clustering results for a second .

5  Conclusions and Further Work Nowadays how to mining useful information from a mass of data almost as quickly as the production of information becomes a popular topic. This paper presented a massive data processing system based on Storm and improved its topology model by combing with Spring. Finally, this paper       implemented the K-means Clustering algorithm based on improved Storm model.

The system is used by combing Storm with Kafka and Spring. Storm reads data from a Kafka cluster. And data is processed by topology builded in a Spring XML configuration to assemble different components. From the experiments we can see that the performance was improved effectively based on Storm compared with executing a standalone java program. And using Spring has little influence on performance. However, there is performance degradation while using Kafka cluster.

In the area of highly-parallel batch processing, there have been quite a lot of research. However, less research in the fields of real-time stream processing especially about Storm. In the future, I will extend research based on Storm and further improving the performance of Storm, and also research how to combine other technologies with Storm.

