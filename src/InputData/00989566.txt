Interestingness, Peculiarity, and Multi-Database Mining

Abstract  In order to discover new, surprising, interesting pat- terns hidden in data, peculiarity oriented mining and multi- database mining are required. In the papel; we introduce peculiarity rules as a new class of rules, which can be dis- covered from a relatively low number of peculiar data by searching the relevance among the peculiar data. We give a formal interpretation and comparison of three classes of rules: association rules, exception rules, and peculiarity rules, as well as describe how to mine more interesting pe- culiarity rules in multiple databases.

1 Introduction  The goal of this work can be summarized in a phrase: peculiarity oriented mining in multiple databases for dis- covering interesting patterns. There are two keywords in this phrase:  The first keyword is peculiarity, which is a kind of in- terestingness, long identified as an important problem in data mining [lo, 23, 241. Peculiarity, unexpected rela- tionships/rules (with common-sense) may be hidden in a relatively low number of data. Thus, we may focus on some interesting data (peculiar data), and then we find more novel and interesting rules (peculiarity rules) from the data.

We argue that the peculiarity rules are a typical regular- ity hidden in a lot of scientific, statistical, and transaction databases. Sometimes, the ordinary association rules with common-sense cannot be found from numerous scientific, statistical or transaction data, or although they can be found, the user may be uninterested in the rules because data are  Y.Y. Yao Dept. of Computer Science  University of Regina Regina, Saskatchewan S4S OA2, Canada  E-mail: yyao@cs.uregina.ca  Setsuo Ohsuga Dept. of Infor. and Computer Science  Waseda University 3-4- 1 Okubo Shinjuku-Ku, Tokyo 169, Japan  rarely specially collectedkored in a database for the pur- pose of mining knowledge in most organizations.

The second keyword is multiple databases, which are the objects of discovery and learning. So far the main stream in the KDD community is limited to rule discovery in a single universal relation (or an information table) [ 1, 111. Multi- database mining is to mine knowledge in multiple related information sources. Generally speaking, the task of multi- database mining can be divided into three levels:  1. Mining from multiple relations in a database.

Although theoretically, any relational database with multiple relations can be transformed into a single uni- versal relation, practically this can lead to many issues such as universal relations of unmanageable sizes, in- filtration of uninteresting attributes, loss of useful rela- tion names, an unnecessary join operation, and incon- veniences for distributed processing.

2. Mining from multiple relational databases.

Some concepts, regularities, causal relationships, and rules cannot be discovered if we just search a sin- gle database because the knowledge hides in multiple databases basically [23].

3. Mining from multiple mixed-media databases.

Many datasets in the real world contain more than just a single type of data 115, 231. For example, medi- cal datasets often contain numeric data (e.g. test re- sults), images (e.g. X-rays), nominal data (e.g. person smokes/does not smoke), and acoustic data (e.g. the recording of a doctor?s voice). How to handle such multiple data sources is a new, challenging research is- sue.

566 0-7695-1119-8/01 $17.00 0 2001 IEEE    The rest of this paper is organized as follows: Section 2 discusses more detail on interestingness and peculiarity.

Section 3 gives a formal interpretation and comparison of three classes of rules: association rules, exception rules, and peculiarity rules. Section 4 presents a method of peculiarity oriented mining. Section 5 extends the peculiarity oriented mining into multi-database mining. Finally, Section 6 gives concluding remarks.

2 Interestingness and Peculiarity  Generally speaking, hypotheses (knowledge) generated from databases can be divided into the following three types: incorrect hypotheses, useless hypotheses, and new, surprising, interesting hypotheses. The purpose of data mining is to discover new, surprising, interesting knowl- edge hidden in databases. Hence, the evaluation of interest- ingness (including peculiarity, surprisingness, unexpected- ness, usefulness, novelty) should be done in pre-processing and/or post-processing of the knowledge discovery pro- cess [3, 5, 6, 9, 231. Here, ?evaluating in pre-processing? is to select interesting data before hypotheses generation; ?evaluating in post-processing? is to select interesting rules after hypotheses generation. Furthermore, interestingness evaluation may be either subjective or objective [ 101. Here, ?subjective? means user-driven, that is, asking the user to explicitly specify what type of data (or rules) are interesting and uninteresting, and the system then generates or retrieves those matching rules; ?objective? means data-driven, that is, analyzing structure of data (or rules), predictive perfor- mance, statistical significance, and so forth.

Zhong, Yao, and Ohsuga proposed peculiarity rules as a new class of rules [23]. A peculiarity rule is discovered from peculiar data by searching the relevance among the peculiar data. Roughly speaking, data are peculiar if they represent a peculiar case described by a relatively low num- ber of objects and are very different from other objects in a dataset. Although it  looks like the exception rule from the viewpoint of describing a relatively low number of objects, the semantic of the peculiarity rule is with common-sense, which is a feature of the ordinary association rule 11, 141.

Illustrative Example. The following rule is a pecu- liarity one that can be discovered from a relation called Supermarket-Sales (see Table 1 ) in a Supermarket-Sales database: rule1 : meat-sale(1ow) A vegetable-sale(1ow) A  We can see that this rule just covers data in one tuple on July-30 and its semantic is with common-sense. Hence, al- gorithms for mining association rules and exception rules may fail to find such useful rules. However, a manager of the supermarket may be interested in such rule because it  fruits-sale(1ow) + turnover(very4ow).

Table 1. Supermarket-Sales  July-2 . . .  . . .  . . .  . . .  . . .

...

shows that the turnover was a marked drop.

In order to discover such peculiarity rule, we first need  to search peculiar data in the relation Supermarket-Sales.

From Table 1, we can see that the values of the attributes meat-sale, vegetable-sale, and fruits-sale on July-30 are very different from other values in the attributes. Hence, the values are regarded as peculiar data. Furthermore, rule1 is generated by searching the relevance among the peculiar data. Note that we use the qualitative representation for the quantitative values in the above rules. The transformation of quantitative to qualitative values can be done by using the following background knowledge on information gran- ularity: Basic granules:  bgl = {high, low, very-low}; bgn = {large, small, very-small}; bgs = {many, little, very-little); . . . . . . .

Specific granules: kanto-area = {Tokyo, Tiba, Saitama, ...} ; chugoku-area = { Yamaguchi, Hiroshima, Shimane, ...}; yamaguchi-prefecture = { Ube, Shimonoseki, ...}; . . . . . . .

That is, meat-sale = 12, vegetable-sale = IO, fruits-sale = 15 and turnover = 100 on July 30 are replaced by the gran- ules, ?low? and ?very-low?, respectively.

3 Interpretation of Rules  This section gives the formal interpretation and compar- ison of three classes of rules: association rules, exception rules, and peculiarity rules.

3.1 A Framework for the Interpretation of Rules  Typically, a rule can be expressed in the form, q5 3 $J, where q5 and Q are formulas of certain language used to de- scribe objects (tuples) in the database. In order to have a precise interpretation of rules, we need a formal model in which various components of rules can be interpreted. We adopt the decision logic language (DL-language) studied by Pawlak [ 1 1 1 ,  in Tarski?s style through the notions of a     model and satisfiability. The model is a database S consist- ing of a finite set of objects U .  An object 11: E U either satisfies a formula 4, written IC k s  4 or in short z k 4, or does not satisfy the formula, written -a 4. The satisfia- bility depends on the semantic interpretation of expressions and must be defined by a particular rule mining method. In general, it should satisfy the following conditions [ 111:  (1) z + +iff not + 4, (2) (3) (4)  (5)  z I= 4 A $ iff I= 4 and 5 I= $1 2 k 4 V $  iff IC k 4 o r 5  I= 111, z k 4 -+ $ iff z k -+v $7 z 4 =$iff z + 4 -+ $ a n d z  k $ -+ d1  where 1, A, V, -+ and = are standard logical connectives.

If d, is a formula, the set rns (4) defined by  ms(d,) = E U I z I= 4 )  (1) is called the meaning of the formula 4 in S. If S is un- derstood, we simply write rn(4). Obviously, the following properties hold [ 111:  (4 474) = -d4)7 (b) 4 4  A $> = 44) " 4 $ ) 7 ( c )  4 4  v $1 = 4 4 )  U m($>1 (4 4 4  + $) = 4 4 )  U 4 $ ) 7 ( e )  4 4  5 $1 = (m(d,) n m($)> U (-44) n 4 N ) .

The meaning of a formula 4 is the set of all objects hav- ing the property expressed by the formula 4. Conversely, 4 can be viewed as the description of the set of objects m(4).

Thus, a connection between formulas and subsets of U is established.

A formula 4 is said to be true in a database S, written k s  d,, if and only if m(4) = U, namely, 4 is satisfied by all objects in the universe. Two formulas q5 and $ are equivalent in S if and only if m(4) = m($).  By definition, the following properties hold [ 111:  6) k s  4 iff 44) = U1 (ii) +S 14 iff m(4) = 0,  (iv) k s  q5 $ iff m(4) = rn($).

Thus, we can study the relationships between concepts de- scribed by formulas based on the relationships between their corresponding sets of objects.

A rule, 4 + $, can be interpreted by logical implication, namely, the symbol=+ is interpreted as the logical implica- tion -+. In most cases, the expression 4 -+ $ may not be true in a database. Only certain objects satisfy the expres- sion, 4 -+ $. The ratio of objects satisfying 4 -+ $ can be used to define a quantitative measure of the strength of the rule:  ( i 4  ,,ps 4 -+ $ iff 44) G d$),  II, -$ 4 a b -d C d  where 1 .  I denotes the cardinality of a set. It measures the de- gree of truth of the expression 4 -+ $ in a database. A prob- lem with the logic implication interpretation can be seen as follows. For an object, if it does not satisfy 4, by defini- tion, it satisfies 4 -+ $. Thus, even if the degree of truth of 4 -+ $ is very high, we may not conclude too much on the satisfiability of $ given the object satisfies 4. In reality, we want to know the satisfiability of $ under the condition that 4 is satisfied. In other words, our main concern is the satisfiability of $ in the subset m(4). Obviously, logical im- plication is inappropriate in this case. For the same reason, the notion of conditional has been proposed and studied in the context of rule based expert systems [4].

Totals a + b c + d  3.2 Probabilistic Interpretations of Rules  In data mining, rules are typically interpreted in terms of probability. A detailed analysis of probability related measures associated with rules has been given by Yao and Zhong [ 191. We review a few relevant measures. The char- acteristics of an rule, 4 + $, can be summarized by the following contingency table:  Totals 1 a + c  b + d  I a + b + c + d = n a = Im(4 A $11, 6 = Im(dJ A +)I, c = I N 7 4  A $ 1 1 1  d = lm( iq5A +)I.

From the contingency table, different measures can be de- fined to reflect various aspects of rules.

The generality of 4 is defined by  (3)  which indicates the relative size of the concept 4. A con- cept is more general if it covers more instances of the uni- verse. If G(4) = a, then (lOOcu)% of objects in U satisfy $. The quantity may be viewed as the probability of a ran- domly selected element satisfying 4. Obviously, we have 0 I G ( 4 )  I 1.

The absolute support of + provided by 4 is the quantity: AS(4  =+ $) = AS($+$)  (4)  The quantity, 0 5 AS($Id) 5 1, shows the degree to which 4 implies $. If AS(q!~14) = a,  then (lOOa)% of objects  I d $ , )  f- 74411 a - - - Im(4)I a + b '     satisfying q5 also satisfy $. It may be viewed as the condi- tional probability of a randomly selected element satisfying 11, given that the element satisfies 4. In set-theoretic terms, it is the degree to which m(4) is included in m($). Clearly, AS(Qlq5) = 1, if and only if m(q5) C m(11,).

The change ofsupport of $ provided by q5 is defined by CS(q5 + $1 = CS($I4) = AS(11,P) - G(11,)  (5 )  Unlike the absolute support, the change of support varies from - 1 to 1. One may consider G( $) to be the prior prob- ability of 11, and AS($Iq5) the posterior probability of $ af- ter knowing 4. The difference of posterior and prior prob- abilities represents the change of our confidence regarding whether q5 actually relates to 11,. For a positive value, one may say that 4 is positively related to $; for a negative value, one may say that q5 is negatively related to 11,.

The generality G($) is related to the satisfiability of 11, by all objects in the database, and AS(4  + 11,) is related to the satisfiability of 11, in the subset m(q5). A high AS($ + 11,) does not necessarily suggest a strong association between q5 and 11,, as a concept $ with a large G($) value tends to have a large AS(4  + $) value. The change of support CS(q5 + $) may be more accurate.

- an - (U + b)(a + C )  - (a  + b)n  3.3 Comparison of Association Rules, Exception Rules, and Peculiarity Rules  Within the proposed framework, we can easily analyze the ordinary association rules by a slightly different formu- lation. Let I denote a set of items and T denote a set of transactions. For each item i E I, we define an atomic ex- pression FtZ} = (i = 1) with the satisfiability given by  (6) t E T ,  t /= F{a} iff t contains i,  (7) and m(F{,))  = {t  E T I t contains 2 ) .

For each subset A I, we define a formula FA = AaEA F{%}. A transaction satisfies the formula FA if it con- tains all items in A. For two disjoint subsets of items A and B, an association rule can be expressed as FA + FB. The association rule, FA + FB, is interpreted as saying that a customer who purchases all items in A tends to purchase all items in B.

Two measures, called the support and the confidence, are used to mine association rules. They are indeed the gener- ality and absolute support:  SWP(FA + FB) = G(FA A F E )  = G(J?AuB), conf(F~ + Pi) = AS(FA + FB). (8)  By specifying threshold values of support and confident, one can obtain all association rules whose support and con- fident are above the thresholds.

Association rules can be extended to non-transaction databases so that both the left hand and right hand sides are formulas expressing properties of objects in a database.

With an association rule, it is very tempting to relate a large confidence with a strong association between two concepts.

However, such a connection may not exist. Suppose we have conf(q5 + 11,) = 0.90. If we also have G(q5) = 0.95, we can conclude that 4 is in fact negatively associated with $. This suggests that an association rule may not reflect the true association. Conversely, an association rule with low confidence may have a large change of support. In mining association rules, concepts with low support are not con- sidered in the search for association. On the other hand, two concepts with low supports may have either large con- fidence or a large change of support. In summary, algo- rithms for mining association rules may fail to find such useful rules. Other mining algorithms are needed.

Exception rules have been studied as extension of associ- ation rules to resolve some of the above problems [ 141. For an aSS6CiatiOn rule, 4 + $, with high confidence, one may associates an exception rule 4 A q5? + i$. Roughly speak- ing, @ can be viewed as the condition for exception to rule q5 + 11,. To be consistent with the intended interpretation of exception rule, it is reasonable to assume that q5 A q5? + -$ have a high confidence and low support. More specifically, we would expect a low generality of q5 A 4?. Otherwise, the rule cannot be viewed as describing exceptional situations.

Consequently, exception rules cannot be discovered by as- sociation rule mining algorithms.

Recently, Zhong, Yao, and Ohsuga [23, 241 identified and studied a new class of rules called peculiarity rules. In mining peculiarity rules, one considers the distribution of attribute values. More specifically, attention is paid to ob- jects whose attribute values are quite different from that of other objects. This is referred to as peculiarity data iden- tification. After the isolation of peculiarity data, peculiar- ity rules with low support and high confidence, and conse- quently high change of support, are searched. Although a peculiarity rule may share the same properties with an ex- ception rule, as expressed in terms of support and confi- dence, it does not express exception to another rules. Se- mantically, they are very different. Furthermore, algorithms forming peculiarity rules are different from mining associ- ation rules and exception rules. It should be realized that peculiarity rules only represent a subset of all rules with high change of support.

Based on the above discussion, we can qualitatively characterize association rules, exception rules, and peculiar- ity rules as shown in Table 2.

From the viewpoint of support, both exception rules and peculiarity rules attempt to find rules that are missed by as- sociation rule mining methods. While exception rules and peculiarity rules have a high change of support values, in-     Table 2. Qualitative characterization of asso- ciation rules, exception rules, and peculiarity rules  Rule I G(SUDD) I AS(conf) I CS I semantic  x i 1  X n 1  Association rule: & * $  I High 1 High I Unknown I common- x,2 ... xaj ... rim  X n 2  ... xnj ... I n n  sense Exception rule:  Unknown High exceprion  Peculiaritv rule: & * *  I Low 1 High 1 High 1 common-  dicating a strong association between two concepts, associ- ation rules do not necessarily have this property. All three classes of rules are focused on rules with high level of ab- solute support. For exception rule, it is also expected that the generality of 4 A 4? is low. For peculiarity, the generali- ties of both 4 and 1c, are expected to be low. In contrast, the generality of right hand of an exception rule does not have to be low.

From Table 2, one may say that rules with high abso- lute support and high change of support are of interest. The interesting on the generality of rules depends on the partic- ularly application. The use of generality (support) in asso- ciation rule mining is mainly for the sake of computational cost, rather than semantics consideration. Exception rules and peculiarity rules are two subsets of rules with high ab- solute support and high change of support. It may be in- teresting to design an algorithm to find all rules with high absolute support and high change of support.

4 Peculiarity Oriented Mining  The main task of mining peculiarity rules is the identi- fication of peculiarity data. According to our previous pa- pers [23, 241, peculiarity data are a subset of objects in the database and are characterized by two features: (1) very dif- ferent from other objects in a dataset, and (2) consisting of a relatively low number of objects.

There are many ways of finding the peculiar data. In this section, we describe an attribute-oriented method.

4.1 Finding the Peculiar Data  Table 3 shows a relation with attributes A I ,  Az,  . . ., A,.

In Table 3 ,  let xij be the ith value of Aj ,  and n the number of tuples. The peculiarity of xij can be evaluated by the Peculiarity Factor, PF(xi j ) ,  Table 3. A sample table (relation) I Ai 1 Az 1 ... I Aj  I ... I A, ]  Table 4. An example of peculiarity factors for a continuous attribute  Region I ArableLand Hokkaido I  Yumuguchi Okinawu 147 59.4  It evaluates whether xij occurs in relatively low number and is very different from other data x k j  by calculating the sum of the square root of the conceptual distance between xij and x k j .  The reason why the square root is used in Eq. (9) is that we prefer to evaluate closer distances for a relatively large number of data so that the peculiar data can be found from a relatively low number of data.

Major merits of the method are the following: 0 It can handle both the continuous and symbolic at-  tributes based on a unified semantic interpretation;  Background knowledge represented by binary neigh- borhoods can be used to evaluate the peculiarity if such background knowledge is provided by a user.

If X is a continuous attribute and no background knowledge is available, in Eq. (9),  (10) N(xi j ,xkj)  = (xij - x k j l .

Table 4 shows the calculation of peculairity factor. If X is a symbolic attribute andor the background knowledge for representing the conceptual distances between xij and X k j  is provided by a user, the peculiarity factor is calculated by the conceptual distances, N(xi j , xk j )  [8, 18, 23, 241.

However, the conceptual distances are assigned to 1 if no background knowledge is available.

There are two major methods for testing if the peculiar data exist or not (it is called selection ofpeculiar data) after the evaluation for the peculiarity factors. The first is based on a threshold value as shown in Eq. (1 I) ,  threshold = mean of PF(xi j )  + cr x standard deviation of PF(xi j ) ,  (11)     where cy can be adjusted by a user, and cy = 1 as default.

The threshold indicates that a data is a peculiar one if its PF value is much larger than the mean of the PF set. In other words, if PF(z i j )  is over the threshold value, s i j  is a peculiar data.

One can,observe that peculiar data can be selected objec- tively by means of the threshold we are proposing, and the subjective factor (preference) of a user can also be included in the threshold value by adjusting the cy.

The other method for selection of peculiar data uses the chi-square test that is useful when the data size is suffi- ciently large [2].

4.2 Attribute Oriented Clustering  Searching the data for a structure of natural clusters is an important exploratory technique. Clusters can provide an informal means of assessing interesting and meaningful groups of peculiar data.

Attribute oriented clustering is used to quantize contin- uous values, and eventually perform conceptual abstrac- tion [21]. In the real world, there are many real-valued at- tributes as well as symbolic-valued attributes. In order to discover the better knowledge, conceptual abstraction and generalization are also necessary. Therefore, attribute ori- ented clustering is a useful technique as a step of the pecu- liarity oriented mining process.

It is a key issue that how to do clustering in the environ- ment in which background knowledge on information gran- ularity can either be used or not according to whether such background knowledge exists. Our approach is to provide various methods in the mining process so that the different data can be handled effectively.

If background knowledge on information granularity as stated in Section 2 is available, it is used for conceptual ab- straction (generalization) andor clustering.

If no such background knowledge is available, the near- est neighbor method is used for clustering of continuous- values attributes [7].

4.3 An Algorithm  Based on the above-stated preparation, an algorithm of  Step 1. Execute attribute oriented clustering for each at-  Step 2. Calculate the peculiarity factor PF(z i j )  in Eq. (9)  Step 3. Calculate the threshold value in Eq. (1 1) based on  Step 4. Select the data that are over the threshold value as  finding peculiar data can be outlined as follows:  tribute, respectively.

for all values in an attribute.

the peculiarity factor obtained in Step 2.

the peculiar data.

Step 5. If the current peculiarity level is enough, then goto Step 7.

Step 6. Remove the peculiar data from the attribute and thus, we get a new dataset. Then go back to Step 2.

Step 7. Change the granularity of the peculiar data by us- ing background knowledge on information granularity if the background knowledge is available.

Furthermore, the algorithm can be done in a parallel- distributed mode for multiple attributes, relations and databases because this is an attribute-oriented finding method.

4.4 Relevance Among the Peculiar Data  A peculiarity rule is discovered from the peculiar data, which belong to a cluster, by searching the relevance among the peculiar data. Let X ( z )  and Y(y) be the peculiar data found in two attributes X and Y respectively. We deal with the following two cases:  0 If both X ( s )  and Y(y) are symbolic data, the rele- vance between X ( s )  and Y(y) is evaluated by  that is, the larger the product of the probabilities of PI and PZ is, the stronger the relevance between X ( z ) and Y ( y )  is.

If both X ( z )  and Y ( y )  are continuous attributes, the relevance between X ( s )  and Y(y) is evaluated by us- ing the method developed in our KOSI system [22].

Furthermore, Eq. (12) is suitable for handling more than two peculiar data found in more than two attributes if X ( z ) (or Y(y)) is a granule of the peculiar data.

5 Multi-Database Mining  Building on the preparatory in the previous sections, this section extends peculiarity oriented mining into multi- database mining.

5.1 Peculiarity Oriented Mining in Multiple Databases  Generally speaking, the tasks of multi-database mining for the first two levels stated in Section 1 can be described as follows:  First, the concept of a foreign key in the relational databases needs to be extended into a foreign link because we are also interested in getting to non-key attributes for data mining from multiple relations in a database 1161. A     major work is to find peculiar data in multiple relations for a given discovery task while foreign link relationships ex- ist. In other words, our task is to select n relations, which contain the peculiar data, among m relations (m 2 n) with foreign links.

The method for selecting n relations among m relations can be divided into the following steps:  Step 1.  Focus on a relation as the main table and find the peculiar data from this table. Then elicit the peculiar- ity rules from the peculiar data by using the methods stated in Section 4.

Step 2. Find the value(s) of the focused key correspond- ing to the mined peculiarity rule (or peculiar data) in Step 1 and change its granularity of the value(s) of the focused key if the background knowledge on informa- tion granularity is available.

Step 3. Find the peculiar data in the other relations (or databases) corresponding to the value (or its granule) of the focused key.

Step 4. Select n relations that contain the peculiar data, among m relations (m 2 n). In other words, we just select the relations that contain peculiar data relevant to the peculiarity rule mined from the main table.

A peculiarity rule can be discovered from peculiar data hidden in multiple relations by searching the relevance among the peculiar data. If the peculiar data, X ( x )  and Y(y), are found in two different relations, we need to use a value (or its granule) in a key (or foreign key/link) as the relevance factor, K(lc), to find the relevance between X ( z ) and Y(y). Thus, the relevance between X ( z )  and Y(y) is evaluated by  R2 = Pl(K(lc)lX(z))P2(K(lc)lY(Y)). (13)  Region Yamaguchi  . . .

Furthermore, the above-stated methodology can be ex- tended for mining from multiple databases. A chal- lenge in multi-database mining is a semantic heterogene- ity among multiple databases because usually no explicit foreign key/link relationships exists among them. Hence, the key issue of the extension is how to findkreate the rel- evance among different databases. In our methodology, we use granular computing techniques based on semantics, ap- proximation, and abstraction for solving the issue [8, 201.

We again use the illustrative example mentioned at Sec- tion 2. If a manager of the supermarket found that the turnover was a marked drop in one day from a supermarket- sale database, he/she may not understand the deeper rea- son. Although rule1 as a peculiarity rule (see Section 2) can be discovered from the supermarket-sales database, the deeper reason why the turnover was a marked drop is not explained well. However, if we search several related in- formation sources such as a weather database as shown in  Date . . . I Weather July-I . . . sunny July-2 . . . cloud  Table 5. Weather  1 t \ 1 July:30 1 t \ \ I typhinino. 2) I July-31 cloud  . . .  . . .  . . .  . . .

Table 5 ,  we can find that there was a violent typhoon that day. Hence, we can understand the deeper reason why the turnover was a marked drop. For this case, the granule of aa'dx = Ube in Table 1 needs to be changed into region = yamaguchi for creating explicit foreign link between the supermarket-sales database and the weather database. This example will be further described in the next section.

5.2 Representation and Re-learning  We use the RVER (Reverse Variant Entity-Relationship) model to represent the peculiar data and the conceptual re- lationships among the peculiar data discovered from mul- tiple relations (databases) [23]. Figure l ,  as an example, shows the results mined from two databases on supermar- ket sales at Yamaguchi prefecture and the weather of Japan.

The point of which the RVER model is different from an ordinary ER model is that we just represent the attributes that are relevant to the peculiar data and the related pecu- liar data (or their granules) in the RVER model. Thus, the RVER model provides all interesting information that is rel- evant to some focusing (e.g. turnover = very-low, region = yamaguchi, and date = July-30 in the supermarket-sale database) for learning more interesting rules among multi- ple relations (databases).

Re-learning means learning more interesting rules from the RVER model. For example, the following rule can be learned from the RVER model shown in Figure 1 : rule2 : weather(typhoon) -+ turnover( very-low).

We can see that a manager of the supermarket may be more interested in rule2 (rather than rulel) because rule2 shows a deeper reason why the turnover was a marked drop.

6 Concluding Remarks  We presented a method of mining peculiarity rules from multiple databases, and a formal interpretation and compar- ison of three classes of rules: association rules, exception rules, and peculiarity rules. We showed that such peculiar- ity rules represent a typically unexpected, interesting regu- larity hidden in databases.

Here we should mention that Liu's group systemati- cally investigated how to analyze the subjective interesting-     A Supermarket Sales DB  Meat-sales(low) &  I I A weather  Figure 1. The RVER model mined from two databases  ness of association rules [9, 101. The work of his group is about subjective evaluation of interestingness in post- processing (i.e. evaluating the mined rules). In contrast, our work is about objective evaluation of interestingness in pre- processing (i.e. selecting interesting data (peculiar data) be- fore rule generation). In particular, our approach can mine a new class of rules: peculiarity rules in multiple databases.

So far, as examples with respect to the first two levels of the multi-database mining tasks mentioned in the Introduc- tion, a number of databases such as Japan-survey, amino- acid data, weather, supermarket, web-log, have been tested for our approach. The results have been partly discussed in our papers [23, 241. Currently, we are also working on the third level of the multi-database mining task, that is, mining from multiple mixed-media databases [ 171.

Our fcture work includes developing a systematic method to nine the rules from multiple databases where there are no explicitly foreign key (link) relationships, and to induce more interesting rules from the RVER model dis- covered from multiple databases by cooperatively using in- ductive and abductive reasoning.

