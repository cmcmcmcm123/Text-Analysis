Efficient Strategies for Many-task Frequent Pattern  Mining in Cloud Computing Environments

Abstract-The goal of data mining is to discover the hidden  useful information from large databases. Mining frequent patterns from transaction databases is an important problem in data mining field. As the size of database increases, the computation time and the required memory increase severely.

Parallel and distributed computing techniques have attracted extensive attentions on the ability to manage and compute the significant amount of data in the past decades. The difficulty of mining large database launched the research of designing parallel  and distributed algorithms to solve the problem. However, most of the past studies did not focus on the many-task issue that is very important, especially in cloud computing environments. In cloud computing environments, application is provided as service  like Google search engine, meaning that it will be used by many users at the same time. In this paper, we propose a set of strategies for many-task frequent pattern mining. Through empirical evaluations on various simulation conditions, the  proposed strategies deliver excellent performance in terms of execution time.

Keyword?Data mining, cloud computing, association rule mining, frequent pattern mining

I. INTRODUCTION  The basic conception of frequent pattern mining problem is to discover the pattern whose frequency of appearance in the database is greater than a specific threshold. An association rule is defmed as X=>Y, where X and Y are sets of items. The concept of association rule mining is to discover the sets of items tending to associate with the others in the database. The studies on association rule mining can be classified into two types, 1) the generate-and-test [w] (Apriori-like) approach and 2) the frequent pattern growth approach [5] (FP-growth-like).

The Apriori-like methods iteratively generate candidate itemset of size (k+ 1) from frequent itemset of size k and scan the database repetitively to test the frequency of each candidate itemset. Definitely, the Apriori-like methods suffer from the large number of candidate itemsets, especially when the support threshold is small. In view of this reason, Han et al. [5] proposed a novel data structure, named frequent pattern tree (FP-tree), in which the transactions are compressed and stored. A mining algorithm, namely FP-growth was also proposed for discovering the frequent patterns from the FP-    Yu-ChinLuo  Department of Computer Science and Information Engineering  National Kaohsiung University of Applied Sciences Kaohsiung, Taiwan  kim-x@yahoo.com.tw  tree. FP-growth needs only two scans on physical databases and therefore has a great improvement on the execution time.

As the size of database increases, the computation time and the required memory increase severely. Many studies on association rules mining were proposed mainly to improve the efficiency in terms of execution time. In the past decades, parallel and distributed computing (PDC) techniques have attracted extensive attentions on the ability to manage and compute the significant amount of data. The difficulty of mining large database launched the research of designing parallel and distributed algorithms to solve the problem [3], [4], [6], [7], [8], [9], [10], [11], [12], [13]. The main approach of the existing studies is to divide the database and then to distribute each part of the database to nodes or processors for mining with the goal to distribute the computation loading.

During the mining process, the nodes will exchange required transactions from each other. The workload of data exchanging among nodes becomes heavy when the average length of transaction is long or the size of database is large.

Although many algorithms have been proposed, the execution efficiency of frequent pattern mining is still a challenge to the researchers due to the data explosion.

In [9], the authors proposed a data mining method named CARM, which is able to efficiently utilize the cloud nodes to discover frequent patterns in cloud computing environments, but did not discuss the many-task issue that is very important in this kind of environments. The authors [9] focused on only the aspect of speeding up the mining process for a single task.

In cloud computing environments, application is provided as service like Google search engine, meaning that it will be used by many users at the same time. In this paper, we propose a set of strategies for many-task frequent pattern mining. Through empirical evaluations on various simulation conditions, the proposed strategies deliver excellent performance in terms of execution time.

In the following sections, we briefly review related work in Section 2. In Section 3, the strategies for many-task frequent pattern mining are presented. The empirical evaluation for performance study is made in Section 4. The conclusions are given in Section 5.



II. RELATED WORK  In this section, we review the past studies on the three subjects closely related to this research, namely A) FP-tree and FP-growth and B) CARM algorithm.

A. FP-tree and FP-growth  Han et al. [5] proposed a tree based data structure named FP? tree and the corresponding mining algorithm named FP-growth for discovering frequent patterns. The algorithm requires two scans on database to complete the mining task. The first scan is to calculate the support of each item. In the meantime, it also creates a header table recording the item name, its corresponding support and the first node-link linking to the fIrst node in the FP-tree carrying the same item name. The items of the header table are sorted descendingly by the support. In the second scan, for each transaction, the items with support smaller than the threshold are filtered out and the remaining items are sorted in descending order by the support value. The sorted items of each transaction are inserted to the tree, namely FP-tree. The structure of an FP-tree consists of a root node labeled as null, a set of item-prefix subtrees as the children of root, and a header table. The structure of the nodes of FP-tree is as <item-name, count (support), node-link>, in which the item? name is the item name used for identification, the count is the number of transactions reaching this node by the same path from root, and the node-link is a pointer linking to the next node in the FP-tree with the same item name. To insert a transaction, P, into the FP-tree, T, we check whether T has a child, n, such that n. item-name is identical to the item-name of the first element of P. If the node exists, the count of n is increased by 1. Otherwise, it creates a new node, m, with the same item name as n. Meanwhile, the count of m is set to 1, the parent link is set to T, and its node-link is set to the nodes with the same item-name via the node-link structure. We recursively perform the insertion in order for each item in P until each item is inserted into the FP-tree. After the FP-tree is constructed, FP? growth is used for discovering the frequent patterns. An item of the header table is selected to construct the conditional FP-tree by inserting all of the prefix paths of the item, which can be retrieved by node-link structure in header table. The name of the item is called the conditional pattern base. Then the FP? growth is executed recursively and the conditional pattern base is cascaded by new one in each recursion until the conditional FP-tree contains only a single path or is an empty tree. The frequent patterns can be easily generated by the cascaded conditional pattern base and the FP-tree. After processing each item in header table, all of the frequent patterns are obtained.

B. CARM Algorithm  The algorithm CARM consists of two algorithms, High? workability Distributed FP-Mine, abbreviated as HD-Mining, and Fast Distributed FP-Mine, abbreviated as FD-Mining. The main functionality of HD-Mining is to utilize the cloud nodes to mine the dataset that is with huge amount of frequent patterns, brought by the small support threshold, the large number of items, or the large database. The limitation of the conventional algorithm for mining this kind of dataset is the available memory of a single node. HD-Mining can merge the memory of several nodes to discover the frequent patterns.

Furthermore, cloud computing techniques are often expected   to have high computation ability. The proposed FD-Mining focuses on the fast discovery of frequent patterns by utilizing the cloud nodes, and is useful to the applications that emphasize real time mining.

To process a mining task, CARM invokes FD-Mining fIrSt in order to fast discover the frequent patterns. Since FD-Mining occupies more memory than HD-Mining, HD-Mining will be invoked if FD-Mining cannot mine the database. Finally, the algorithm ends with returning the frequent patterns. In CARM, the execution efficiency is set as the highest priority. Therefore, CARM applies FD-Mining first. If FD-Mining fails, CARM will use HD-Mining to complete the mining task.



III. PROPOSED STRATEGIES FOR MANY-TASK FREQUENT PATTERN MINING  In distributed environments, workload balancing among computing nodes is a critical issue. A good strategy for distributing workload will have minimal idle time and minimal complete time. Our proposed strategies for many-task frequent pattern mining are designed for CARM algorithm. CARM is an FP-tree based algorithm, and therefore to distribute the workload by header items is an intuitive way. Before applying the idea for load balancing, two characteristics should be discussed.

1) The required mining time of each conditional pattern base is different.

In the mining process of FP-growth, each item of head table will be used as a conditional pattern base and the algorithm will then reconstruct a corresponding FP-tree. The process will be performed recursively until the FP-tree is empty. The possibility of having two same FP-trees with different conditional bases is very low and consequently the mining time of each conditional pattern base is different.

2) The required mining time for each conditional pattern base cannot be known in advance.

The FP-tree structure of each conditional pattern base is decided by the corresponding subset of data and FP-growth will reconstruct FP-trees in the mining process so the mining time cannot be known in advance.

Because the required mining time for each conditional pattern base is different and cannot be known in advance, we propose a set of strategies with the goal to balance the workload under these two characteristics.

1. Balancing Strategy by Equal Working Set (EWS)  The strategy works as the follows::  A. Construct the initial FP-tree and the header table namedHT.

B. Uniformly partition the HT into N disjoint subsets, named ht], ht], ... , and htN, where N is the number of available computing nodes.

C. Distribute the FP-tree with ht; to i-th computing node for mining.

In Step B, the header table is uniformly partitioned into N parts in which each part has the same number of header items. Suppose there are M items of the header table. The strategy will randomly select MIN items for each computing node. Because the required mining time for each conditional pattern base is different and cannot be known in advance, we use random selection in this step.

2. Balancing Strategy by Request On Demand (ROD)  The EWS strategy is expected to incur a lot of idle time because the two challenge characteristics make it difficult to distribute the workload equally. To reduce the idle time and the complete time, this strategy use the method named request on demand. The strategy works as the following steps:  A. Construct the initial FP-tree and the header table namedHT.

B. Wait for computing node's requesting.

C. If the computing node does not have the FP-tree, distribute the FP-tree with an unprocessed header item to the computing node for mining. Otherwise, distribute only an unprocessed header item to the computing node.

D. Repeat Step C until all header items in HT are processed.

The advantage of this strategy is that the idle time will be the minimal and the workload can be balanced. Although ROD has the advantages, the complete time is expected to be extended for it requires large a lot of times of data transmission over network.

3. Balancing Strategy by Small Size Working Set (SSWS)  The advantages of EWS and ROD are the minimal times of data transmission and the most workload balanced respectively.

The third strategy in designed to find the trade-off between EWS and ROD. To avoid large amount of data transmission times as ROD, the proposed SSWS strategy partitions the header items into several working set in which the size of each working set is equal. Unlike ROD distributes to computing node one header item per time, SSWS distributes a set of header items per time to reduce the cost of data transmission.

The detailed steps are as described below.

A. Construct the initial FP-tree and the header table namedHT.

B. Partition the HT into disjoint subsets, where each subset is with the L header items.

C. Wait for computing node's requesting.

D. If the computing node does not have the FP-tree, distribute the FP-tree with a subset of header items to the computing node for mining. Otherwise, distribute only the subset of header items to the computing node.

E. Repeat Step C until all header items in HT are processed.

In Step B, if L is large the strategy will be identical to EWS.

If L is set to one, the strategy will be identical to ROD.

Therefore, determining the value of L is critical to the mining process.

4. Balancing Strategy by Progressive Size Working Set (PSWS)  SSWS attempts to find the trade-off between EWS and ROD.

Only through detailed experiments can determine a suitable value of L. In this paper, we propose a strategy that is able to balance the workload by adjusting the size of working set dynamically. Unlike SSWS using a fixed size of working set, this strategy decreases the size of working set progressively in the mining process. The strategy works as follows:  A. Construct the initial FP-tree and the header table namedHT.

B. Let N be the number of available computing nodes and HTR be the remaining header items not processed.

Partition the HTR into N+ 1 disjoint subsets, named ht], ht2' ... , and htN+J. Copy htN+J to HTR?  C. Distribute the FP-tree with ht; to i-th computing node for mining.

D. Repeat Step B until all header items in HT are processed.



IV. EXPERIMENTAL RESULTS  To evaluate the performance of the proposed algorithm, CARM, we use IBM's Quest Synthetic Data Generator [1] to generate the workload data for mining. The experiments were conducted on a cloud system with three clouds. The fIrst cloud contains four nodes, including the kernel node, in which each node is equipped with an E8400 2.4GHZ CPU, 1GB of available RAM and 320GB of disk storage. The second cloud and third cloud contain four and three nodes respectively, in which each node is equipped with a P8600 2.4GHZ CPU, 1GB of available RAM and 160GB of disk storage. The network bandwidth among these three clouds is 100 Mbitlsec. The network latency from cloud 1 to cloud 2 is 20 ms on average.

The network latency from cloud 1 to cloud 3 is 18 ms on average. Note that the kernel node is responsible for receiving the requests and is not used for mining. Therefore totally ten nodes can be used for mining in the system. To verify the performance, since there are very few parallel and privacy? preserved algorithms of frequent pattern mining, we select the BTP-tree for comparison, which is one of the most efficient algorithms that can parallelize the mining task on grid systems.

Both of CARM and BTP-tree were implemented in Java, and the message passing among nodes and remote function call were implemented in Java RMI technology. Since the most of the existing parallel algorithms are database dividing approach, we select the most efficient one, BTP-tree, for performance comparison.

Effects of varying the number of tasks  In the experiment, we investigate the effects of varying the number of tasks for the proposed strategies and BTP-Tree in terms of execution time by varying the number of tasks from 10 to 50. We generate 50 dataset for performance evaluation.

The transaction length is modeled as uniform distribution bounded from 10 to 30 and the mean is set to 20. The number    of transactions is modeled as normal distribution and the mean is set to 150K. The support threshold is modeled as uniform distribution bounded from 0.1 % to 1% and the mean is set to 0.5%.

Figure 1 shows the required execution time of our proposed strategies and BTP-tree increases with the increase in the number of tasks. It is observed that the required execution time of each of our strategies is less than that of BTP-Tree. The slope of BTP-Tree is about 14.4 and the slope of our proposed strategies is about 3.1. It means that our proposed strategies can utilize the computing nodes more efficiently. Another main reason BTP-Tree requires more time for mining is that BTP-Tree needs to distribute the pieces of dataset to computing nodes. The size of transmitted dataset is equal to the size of original dataset. It can be seen that the data transmission requires a lot of time for BTP-Tree.

Figure 2 shows the execution time of the four strategies. It is observed that PSWS is the best one. We also found that ROD requires the most execution time because of the lots of times of data transmissions. The required execution time of EWS is 166.3 second, which is 10% larger than that of PSWS, 151.6  700 ---------- EWS ? ? ? ? ? ? ? ? 0 ? ? ?  ROD  -- ? -- SSWS -.. ? .-.. psws  U ---<>-- BTP-tree <ll 500  ? <ll E i= 400  c  '"5 " 300 <ll X  w  "..,..

10 15 20 25 30 35 40 45 50  Number of Tasks  Figure 1. The execution time for our proposed strategies and BTP-tree with number of tasks varied.

---- EWS ????? .. ?0???? ROD  ;; ---.--- SSWS 140 _ .. --6._ .. PSWS /..

U // /.' <ll '// ? 120 y: '  <ll vI' E  i= 100 c :s  80 " <ll x  w    10 20 30 40 50  Number of Tasks  Figure 2. The execution time for our proposed strategies with number of tasks varied.

second.



V. CONCLUSIONS  In this paper, we have presented a set of strategies for efficiently utilize the cloud nodes to discover frequent patterns in cloud computing environments based on CARM algorithm.

The proposed strategies, including EWS, ROD, SWSS and PWSS, have good performance in many-task environments.

Through empirical evaluations on various simulation conditions, the proposed strategies deliver excellent performance in terms of execution time.

