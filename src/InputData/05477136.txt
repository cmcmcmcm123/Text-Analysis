Towards a Discovering Knowledge   Comprehensible and Exploitable by the End-user

Abstract?The main goal to extract knowledge in database is to help the user to give semantics of data and to optimize the information research. Unfortunately, this fundamental constraint is not taken into account by almost all the approaches for knowledge discovery. Indeed, these approaches generate a big number of rules that are not easily assimilated by the human brain. In this paper, we propose a new approach for Knowledge Discovery in Databases through the fusion of conceptual clustering, fuzzy logic, and formal concept analysis.

While basing on the hierarchical structure offered by the lattices, we proceed to discover the Knowledge in a hierarchical way. Thus, according to the degree of detail required by the user, this approach proposes a level of knowledge and different views of this knowledge, so the user can easily exploit all knowledge generated. Moreover, this solution is extensible; the user is able to choose the fuzzy method of classification according to the domain of his data and his needs.

Keywords;  Clustering, formal concept analysis, Fuzzy Logic, knowledge discovery in databases, association rules.



I. INTRODUCTION Nowadays, we notice a growing interest for the  Knowledge Discovery in Databases (KDD) methods. Thus, several algorithms for mining association rules were proposed in the literature, they are based on neural networks, trees, concept lattices, association rules, etc. [1]. However, generated rules by these algorithms, exceeding some times of thousand rules, are not easily assimilated by the human brain. In this case, the user must choose among these rules those which are intimately bound to the operation that he wants to carry out [2, 3]. Several approaches of reduction of this big number of rules have been proposed like the use of quality measurements, syntactic filtering by constraints, and compression by the representative or generic bases [4].

Authors of [4] show that with this method the number of generated rules has been reduced but remains always thousands of rules.

To our opinion, the big number of the generated rules is due because these approaches try to determine rules starting from the enormous data set.  To cure this problem, we propose a new KDD approach having the principal following characteristics: Extract knowledge taking in consideration another  degree of granularity into the process of knowledge extraction. Indeed, we propose to define rules (Meta- Rules) between classes resulting from a preliminary  classification on the data. Then, we automatically deduce knowledge about the initial data set.

Discover knowledge, which covers parts of the primary database at different levels of abstraction. Thus, we define the level i of knowledge as the set of knowledge on all objects verifying i properties. Therefore, according to the degree of detail required by the user, this approach proposes a level of knowledge, so the user can easily exploit all knowledge generated.

Propose different views of knowledge discovered according to the user's needs.

The knowledge discovered contains no redundant rule.

Also, we prove that this solution reduced considerably  the number of generated rules, offered a better interpretation of the data and optimized both the space memory and the execution time. This approach is extensible; the user is able to choose the fuzzy method of classification according to the domain of his data and his needs.

The rest of the paper is organized as follows: Section 2 presents the basic concepts of discovering association rules, Fuzzy conceptual scaling and Formal Concept Analysis (FCA). Section 3 presents problems and limits of the existing knowledge discovery approaches. Section 4 gives notations related to our new approach that we proposed. Section 5 describes our KDD model. Section 6 presents how the user can easily exploit knowledge generated by our approach.

Section 7 enumerates the advantages of the proposed approach. Section 8 validates the proposed approach. We finish this paper with a conclusion and a presentation of some future works.



II. BASIC CONCEPTS In this section, we present the basic concepts of  discovering association rules, Fuzzy conceptual scaling and FCA.

A.  Discovering Association Rules Association rules mining have been developed in order to  analyze basket data in a marketing environment. Input data are composed of transactions: each transaction consists of items purchased by a consumer during a single visit. Output data is composed of rules [5]. Even if this method was introduced in the context of Market Business Analysis, it has many applications in other fields, like webmining or textmining. It can also be used to search for frequent co- occurrences in every large data set.

DOI 10.1109/DBKDA.2010.36     The first efficient algorithm to mine association rules is APriori [6]. The first step of this algorithm is the research of frequent itemsets. The user gives a minimum threshold for the support and the algorithm searches all itemsets that appear with a support greater than this threshold. The second step is to build rules from the itemsets found in the first step.

The algorithm computes confidence of each rule and keeps only those where confidence is greater than a threshold defined by the user. One of the main problems is to define support and confidence thresholds. Other algorithms were proposed to improve computational efficiency. Among them, we mention CLOSED [7], CHARM [8], TITANIC [9, 10], GENALL [11] and PRINCE [12].

Several varieties of lattice have been introduced with these algorithms,  like  Iceberg Concept lattices  [10],  where the nodes are frequent closed itemsets  ordered by the inclusion relation, Minimal Generators Lattice [12], where the nodes are the minimal Generators (called  key itemsets) are ordered by the inclusion relation. In these cases, we don't construct the FCA on the data but on the found itemsets. For more detail the reader can see [12].

B. Fuzzy conceptual scaling and FCA Conceptual scaling theory is the central part in Formal  Concept Analysis (FCA). It allows introduce for the embedding of the given data much more general scales than the usual chains and direct products of chains. In the direct products of the concept lattices of these scales the given data can be embedded [13].

FCA starts with the notion of a formal context specifying which objects have what attributes and thus a formal context may be viewed as a binary relation between the object set and the attribute set with the values 0 and 1. Wille?s definition of a concept is a pair consisting of a set of objects (the extension) and a set of attributes (the intension) such that the intension consists of exactly those attributes that the objects in the extension have in common, and the extension contains exactly those objects that share all attributes in the intension [13]. In [14], an ordered lattice extension theory has been proposed: Fuzzy Formal Concept Analysis (FFCA), in which uncertainty information is directly represented by a real number of membership value in the range of [0,1]. In this case, the similarity of a fuzzy formal concept is defined as follow:  Definition. The similarity of a fuzzy formal concept 111 ,BAC  and its subconcept 222 , BAC  is defined  as:   21 , AA  AA CCS   where  and  refer intersection and union operators on fuzzy sets [15], respectively.

In [16, 17, 18, 19], we showed as these FFCA are very powerful as well in the interpretation of the results of the Fuzzy Clustering, in Optimization of the flexible query that in the definition of a summary of a Database.

Example: Let a relational database table presented by Table1 containing the list of AGE and SALARY of Employee.

TABLE I.  A RELATIONAL DATABASE TABLE.

SALARY AGE t1 800 30 t2 600 35 t3 400 26  t4 900 40 t5 1000 27 t6 500 30   Table 2 presents the results of fuzzy clustering (using  Fuzzy C-Means [20]) applied to Age and Salary attributes.

For Salary attribute, fuzzy clustering generates three clusters (C1,C2 and C3). For AGE attribute, two clusters have been generated (C4 and C5).   In our example, Cut (Salary) = 0.3 and Cut (Age) = 0.5,  so, the Table 2 can be rewriting as show in Table 3.

TABLE II.  FUZZY CONCEPTUAL SCALES FOR AGE AND SALARY ATTRIBUTES  SALARY AGE C1 C2 C3 C4 C5 t1 0.1 0.5 0.4 0.5 0.5 t2 0.3 0.6 0.1 0.4 0.6 t3 0.7 0.2 0.1 0.7 0.3 t4 0.1 0.4 0.5 0.2 0.8 t5 - 0.5 0.5 0.6 0.4 t6 0.5 0.5 - 0.5 0.5  TABLE III.  FUZZY CONCEPTUAL SCALES FOR AGE AND SALARY ATTRIBUTES WITH Cut .

SALARY AGE C1  C2 C3   C4 C5 t1 - 0.5 0.4 0.5 0.5 t2 0.3 0.6 - - 0.6 t3 0.7 - - 0.7 - t4 - 0.4 0.5 - 0.8 t5 - 0.5 0.5 0.6 - t6 0.5 0.5 - 0.5 0.5   The corresponding fuzzy concept lattices of fuzzy  context presented in Table 3, noted as TAH?s are given by the linediagrams presented in the Figure 1 and 2.

Figure 1.  Salary TAH      Figure 2.  Age TAH

III. PROBLEMS AND MOTIVATION The traditional algorithms try to trace the decision tree or  the FCA or one of these extensions to extract the association rules.  In this case, researchers always focus on giving an optimum set of rules modeling in a faithful way the starting data unit, after having done a data cleansing step and an elimination of invalid-value elements. To our point of view, limits of these approaches consist in extracting the set of rules departing from the data or a data variety like the frequent itemsets or the frequent closed itemsets, which may be huge. Thus we note the following limits: These approaches require a big space memory for data  modeling and an important execution time for the management of their data structures;  The rules generated from these data are generally redundant rules;  These algorithms generated a very big number of rules, almost thousands, that the human brain cannot even assimilate;  Some previous works demonstrated that the behavior of these algorithms of association rules extraction varies strongly according to the features of the used data set [21]. The number of the generated association rules in general varies from several ten of thousands to several millions [3, 22].  The Execution times obtained strongly vary according to the used algorithm [23];  Generated rules by these algorithms don't take into account the data semantics nor the importance of an attribute in relation to another in the data description, according to the specific domain of this data set; and  Generally the goal to extract a set of rules is to help the user to give semantics of data and to optimize the information research. This fundamental constraint is not taken into account by these approaches.

To cure all these problems, we propose a new approach  for knowledge extraction using conceptual clustering, fuzzy logic, and FCA.



IV. NOTATIONS RELATED TO OUR KDD MODEL In this section, we present some news concepts for our new approach.

Definition. A fuzzy Clusters Lattice (FCL) of a Fuzzy Concept Lattice, is consist on a Fuzzy Concept Lattice such as each equivalence class (i.e. a node of the lattice) contains  only the intentional description (intent) of the associated fuzzy formal concept. We make in this case a certain abstraction on the list of the objects with their degrees of membership in the clusters. The nodes of FCL are clusters ordered by the inclusion relation.

Definition A level i of a FCL is the set of nodes of FCL having cardinality equal to i.

Definition A Knowledge level is an abstraction level is regarded as a level in the FCL generated.

Definition. Let I= {C1, C2, ?, Cp, Cq , ?, Cn} n Clusters generated by a classification algorithm.

A fuzzy association meta-rule (called meta-rule) is an implication of the form  R: I1  => I2 (CF) where  I1 = { C1, C2, ?, Cp } and I2={ Cq , ?, Cn }. I1 and I2 are called, respectively, the premise part and conclusion part of the meta-rule R. The value CF is in ]0..1] and called Confidence Factor of this meta-rule. This value indicates the relative degree of importance of this meta-rule.

R is interpreted as follows:  if an object belongs to a  cluster C1  C2 ?  Cp then this object can also belongs to the cluster Cq ?  Cn with a probability equal to CF.

Note that classical (or crisp) association meta-rules can  be defined as a special case of fuzzy association meta-rules.

Indeed, when CF=1, then a fuzzy association meta-rule is equivalent to a classical one.

Example. Let R: C1 => C2  (60%). This means that any object belongs to a cluster C1 can also belongs to the cluster C2 with a probability equal to 60%.

Definition. Let A1,A2...,Ap,Aq,?An; n attributes having respectively {l11,l12...,l1m },{l21,l22... ,l2m}..., {lp1 ,lp2..., lpm },{lq1,lq2...,lqm}?., ,{ln1,ln2...,lnm} as linguistic labels.

A fuzzy association rule (or rule) is an implication of the form               r: I1  => I2,   (CF); where I1 = { A1(l1), A2(l2), ?, Ap(lp) } and I2= { Aq(lq), ?, An(ln) }.

Ai(li) models the attribute Ai having a linguistic label li. I1 and I2 are called, respectively, the premise part and conclusion part of the fuzzy rule r. The value CF is in ]0..1] and called Confidence Factor of this rule.

Definition. We define Meta Knowledge (respectively.

Knowledge), as a set of fuzzy association meta-rule (respectively. rule).

We define the level i of Meta Knowledge (respectively..

knowledge) as the set of fuzzy association meta-rule (respectively. rule) on all objects verifying i properties.

Proposition 1: Rewriting meta- rule  Let C1= {A1, A2, ?, An} and C2={B1 , ?, Bm} two set of Clusters. The fuzzy association meta-rule     R : A1,..,An => B1,..,Bm    (CF)  is equivalent to R1 defined as follow:  R1: A1,..,An => C1,..,Cq    (CF)    such that {C1,?,Cq} = C2\C1   (  Ci, Ci  {A1,?An})   Proposition 2: Rule Generation Given C1={A1.., An},  C2={B1.., Bn} and  C3={D1.., Dn} three set of Clusters and R1,R2 two meta rule defined as follows:    R 1: A1,..,An => B1,..,Bn   (d1); and   R 2: B1,..,Bn => D1,..,Dn    (d2) Then, we deduce the meta rule defined as follows: R 3: A1,..,An => D1,..,Dn      (d3);  such that d3= d2(d1) = d2*d1  Example.  From the two meta-rule R1 and R2 defined as R1 : C2 => C2,C4    60% and  R2 : C2,C4 =>C2, C3, C4  53% .

We can deduce  R3: C2 =>C2, C3,C4   31%. R3 can rewriting as: R3:         C2 => C3,C4                  31%.

This rule is interpreted as follows: 53% of 60% of the objects which belong to C2 obtained by the rule R1, can also belongs to the cluster C3 and C4 with a probability equal to 31%.



V. KDD MODEL DESCRIPTION In this section, we present the architecture of the KDD  model and the process for discovering knowledge.

A. System Architecture Our KDD model takes the database records and provides  the set of knowledge correspondent. Figure 3 shows the proposed approach. It consists of two steps: the first step consists in data organization and the second aims at Extraction of Knowledge.

Figure 3.  KDD Model  B. Theoretical Foundation of the KDD model In this part, we present the theoretical foundations of the  proposed approach, based on the following properties: Properties 1 The number of clusters generated by a classification  algorithm  is always  lower  than the number of starting objects to which one applies the classification algorithm  All objects belonging to one same cluster have the same proprieties. These characteristics can be deduced easily knowing the center and the distance from the cluster.

The size of the lattice modeling the properties of the clusters is lower than the size of the lattice modeling the properties of the objects.

The management of the lattice modeling the properties of the clusters is optimum than the management of the lattice modeling the properties of the objects.

Properties 2  Let C1, C2 be two clusters, generated by a classification algorithm and verifying the properties p1 and p2 respectively. Then the following properties are equivalent:  C1  C2  (CR) object O1  C1 =>  O1 C2 (CR) object O1  C1,  O1 checks the property p1 of  C1 and the property p2 of C2.  (CR)  Properties 3  Let C1, C2 and C3 be three clusters generated by a classification algorithm and verifying the properties p1, p2 and p3 respectively. Then the following properties are equivalent:       C1, C2 = > C3  (CR)   object O1  C1   C2 = > O1 object C3 (CR) object O1  C1   C2 then O1 checks the properties  p1, p2 and p3 with (CR)  The proof of the two properties rises owing to the fact  that all objects which belong to a same cluster check necessarily the same property as their cluster.

C. Data Organization Step This step gives a certain number of clusters for each  attribute. Each tuple has values in the interval [0,1] representing these membership degrees according the formed clusters. Linguistic labels, which are fuzzy partitions, will be attributed on attribute?s domain. This step consists of TAH?s and MTAH generation of relieving attributes. This phase is very important in KDD Process because it allows to define and interpreter the distribution of objects in the various clusters. We already used this step in [16, 17, 18, 19].

Example: Let a relational database table presented by Table 1 containing the list of AGE and SALARY of Employee. Table 2 presents the results of fuzzy clustering applied to Age and Salary attributes.

The minimal value (respectively. maximal) of each cluster corresponds on the lower (respectively. higher) interval terminal of the values of this last. Each cluster of a     partition is labeled with a linguistic labels provided by the user or a domain expert. For example, the fuzzy labels young and adult could belong to a partition built over the domain of the attribute AGE. Also, the fuzzy labels low, Medium and High, could belong to a partition built over the domain of the attribute Salary. The Table 4 presents the correspondence of the linguistic labels and their designations for the attributes Salary and Age. The corresponding fuzzy concept lattices of fuzzy context presented in Table 5, noted as TAH?s are given by the line diagrams presented in Figure 1 and 2.

TABLE IV.  CORRESPONDENCE OF THE LINGUISTIC LABELS AND THEIR DESIGNATIONS  Attribute Linguistic labels Designation Salary Low C1 Salary Medium C2 Salary High C3 Age Young C4 Age Adult C5  TABLE V.  FUZZY CONCEPTUAL SCALES FOR AGE AND SALARY ATTRIBUTES WITH Cut .

SALARY AGE  Low  C1 Medium C2  High C3  Young C4  Adult C5  t1 - 0.5 0.4 0.5 0.5 t2 0.3 0.6 - - 0.6 t3 0.7 - - 0.7 - t4 - 0.4 0.5 - 0.8 t5 - 0.5 0.5 0.6 - t6 0.5 0.5 - 0.5 0.5   This very simple sorting procedure gives us for each  many-valued attribute the distribution of the objects in the line diagram of the chosen fuzzy scale.  Usually, we are interested in the interaction between two or more fuzzy many-valued attributes. This interaction can be visualized using the so-called fuzzy nested line diagrams.  It is used for visualizing larger fuzzy concept lattices, and combining fuzzy conceptual scales on-line. Figure 4 shows the fuzzy nested lattice constructed from Figure 1 and 2.

Figure 4.  Fuzzy Lattice:  MTAH  D. Phase of Discovering Knowledge This step consists on three phases: FCL Generation,  Discovering Meta knowledge and Deduction Knowledge. In the following, we detail these different steps.

1)  FCL Generation The goal of this phase is make a certain abstraction on  the list of the objects with their degrees of membership in the clusters. Indeed, to determine the set of fuzzy meta-rule we don't need more to safeguard the data since we already safeguarded the distance between these nodes.  Thus, from the fuzzy lattice, obtained in the first step, we can draw the correspondent FCL. The nodes of FCL are clusters ordered by the inclusion relation. As shown from the Figure 5, we obtain a lattice more reduced, simpler to traverse and stored.

Figure 5.  Fuzzy Clusters Lattice  FCL  Considering the FCL in Figure 5, we can generate the following levels with the corresponding FCL. The Level 0 and Level 6 are both the root and leaves of FCL. The Level 1 corresponds to the nodes {C1}, {C5},{C2}, {C4}. It allows the identification of the clusters which permits to deduce knowledge. The Level 2 corresponds to nodes {C2, C5},{C2, C4},{C2, C3},{C1, C4}. This level permits to identify all the existing overlapping between two clusters.

Thus, it allows the knowledge discovery of all objects belonging to the intersection of the two clusters. Generally Level i corresponds to the nodes having i clusters. This permits to identify all the existing of overlapping between i clusters. It allows the knowledge discovery on all objects belonging to the intersection of these i clusters. Note that the nodes of Level 4 has all the departing arcs with weight d=0; i.e. since there is no object belonging to the intersection of this clusters. Consequently, there is no knowledge to discover. Also, note that the Level 5 corresponds to the leaves of FCL, therefore, there is no knowledge to discover.

2) Discovering Meta knowledge  In this subsection, we present our algorithm for discovering Meta Knowledge from a FCL.

Given an FCL, the derivation of fuzzy association meta- rules can be performed straightforwardly. Indeed, the meta- rule represent ?inter-node? implications, assorted with the FC, between two adjacent comparable equivalence classes,     i.e., from a set of clusters to another set of clusters immediately covering it. The confidence Factor will be equal to the weight of the arc binding the two nodes.  Such an implication brings into participate two comparable equivalence classes, i.e. of a set of clusters towards another set of cluster including it in the partial order structure.

a) Principle for discovering knowledge from FCL Rule1: Discovering meta rule  Let C1={A1.., An} and C2={B1.., Bm} two nodes of FCL such as C2 is successors of C1 in the lattice and having as distance d>0 (weight of the arc) the generated meta-rule will be defined as follows: R : A1,..,An => B1,..,Bm      (d)   Note that, If d=0 this implies that there is no object in  common to the two concepts C1, C2. There is no knowledge to discover. This implies that it doesn't exist no knowledge to generated.

Example The meta-rule C5  C2,C5 (0,83), is generated starting from the two equivalence classes, whose their respective nodes are Clusters {C5}, {C2,C5} having as distance d=0.83.

Rule2: Discovering meta rule  Let C1={A1.., An} and C2={B1.., Bm} two nodes of FCL such as C2 is successors of C1 in the lattice and having as distance d>0 (weight of the arc). The generated meta-rule will be defined by  R : A1,..,An => C1,..,Cq      (d) such that  {C1,?,Cq} = {B1.., Bm}\{A1.., An}    (  Ci, Ci  {A1,?An}) Example The meta-rule C5  C2 (0,83), is generated starting from the two equivalence classes, whose their respective nodes are Clusters {C5}, {C2,C5} having as distance d=0.83.

Rule3: Generated meta-rule  Let C1={A1.., An} C2={B1.., Bn} and C3={D1.., Dn} three concepts such as C2 successors of C1 and C2 successor of C3 having as respectively distance d1 and d2.

The generated meta-rule will be defined by: R 3: A1,..,An => D1,..,Dn      (d2*d1)   Example The meta-rule C2 =>C2, C3,C4       31% is generated starting from the three equivalence classes, whose their respective nodes are Clusters {C2} {C2,C4}and {C2, C3, C4 } having as distance 0.60 and =0.53.

This rule can be simplified as follows C2 = > C3, C4 31% .

This is interpreted as follows:  31% of the objects which belong to C2 check the properties modeled by the clusters C3 and C4  b) Algorithm for Discovering Fuzzy Association Meta- rules  This algorithm traverses the search space (FCL) by level to determine the Fuzzy Meta Rules Set (FMRS). As input it takes the lattice of Clusters FCL and  returns, as output, the list of all Fuzzy Meta Rules Set (FMRS) generated. It works as follows: For each non empty node  FCL in descending,  we generate all meta-rules with one cluster conclusion (level 0). Then, generate the set of all meta-rules with two Clusters conclusions. The same process is applied to generate conclusions with four clusters, and so on until conclusions with n clusters have been generated. The pseudo-code for this algorithm is given in the Figure 6.

Note that Niveau_max (FCL) is a function return the number of clusters modeled in the FCL.

Figure 6.  The pseudo-code for Diskovering FMRS algorithm  Find_Cluster (FCL, i, S) is a procedure allow to compute the set S containing all set of clusters modelled in the nodes to level i.

Generate_Rule(FMRS,FMRS1) is a  procedure permits to determine the set of all rules which one can deduce with part of the FMRS set  by applying the Rule3.

Let's note that the FMRS set doesn't contain any redundant rule. Indeed one has the following proposition:  Proposition 3  If the system of extraction rules traverses the search space  by level of the lattice of clusters then no rule generated by this system is redundant (all the generated rules are obligatorily distinct).

Proof. This is due that of a level to another of the lattice the nodes are obligatorily distinct (by definition even of a level of lattice).

3) Deduction Knowledge In this part, we present, in the first, the rule of  Transformation of a fuzzy association meta-rule into fuzzy association rule  Generating Meta-knowledge Input: Fuzzy Cluster Lattice FCL Output : FMRS: Fuzzy Meta Rules Set Begin FMRS := Find_Cluster(FCL, 0, S) ; For  each  subconcept Cj ={y1,?ym}of Ci in S r.premise= r.conclusion={y1,y2,?ym} r.CF=1 FMRS=FMRS  {r} End For Nmax :=Niveau_max(FCL) ; For Niv  :=1  to Nmax-1 do Find_Cluster(FCL, i, S) ; For  Ci={x1,?xm}  in  S   do For each  subconcept Cj ={y1,?ym}of Ci  and having (d>0) r.premise=  {x1,x2,?xn} r.conclusion={y1,y2,?ym} \ {x1,x2,?xn} r.CF=d FMRS=FMRS  {r} End For End For End For Generate_Rule(FMRS,FMRS1); FMRS:= FMRS  FMRS1 End.

Rule: Transformation of a fuzzy association meta-rule into fuzzy association rule  Let A1,A2...,Ap,Aq,?An be n attributes having respectively {l11,l12...,l1m} {l21,l22...,l2m} ... , {lp1   ,lp2... ,lpm},{lq1,lq2...,lqm}?., ,{ln1,ln2...,lnm} as linguistic labels.

Let I= {C1, C2, ?, Cp, Cq , ?, Cn} be a n Clusters generated by a classification algorithm. Each Ci designates linguistic labels for a given attribute.

The fuzzy association meta-rule R: C1,..,Cp => Cq , ?, Cn (CF)  is transformed in   R1 defined as follow: R1: A1(l1), A2(l2), ?, Ap(lp) =>  Aq(lq), ?, An(ln) (CF) such that  Ai(i) is the linguistic label for attribute Ai  design the cluster Ci.

Example. Let us consider Table 4 presents the correspondence of the linguistic labels and their designations for the attributes Salary and Age.

The meta-rule C5 => C2  83% is transformed in Age(Adult) => Salary(Medium)    83%

VI. HOW THE USER CAN EXPLOIT KNOWLEDGE GENERATED BY THIS APPROACH ?

As we mentioned at the beginning,  the essential goal of the extraction of knowledge is to help the user to seek information in this data set and to satisfy his needs. In this section we propose different views of knowledge generated.

According to the user's needs the generated rules can be ordered in several ways.

Indeed,  while changing our point of entrance view, it is possible to have a different view point on data. So we can model our knowledge with three different views.

To order the list of rules by level of Knowledge (every level i of knowledge fact to intervene i properties).

To order the list of the rules by the characteristics which an object must check so that it can verified a certain properties.

To order the list of rules by properties that can have an object knowing that it verifies a p property.

Moreover, this approach makes it possible to the user to  define a cut on the rules generated by the system to specify until which coefficient CF, it gives confidence to a rule.

Beyond this value the rule can be considered as weak and will not be taken into account.

Examples  1) The user wants to know all the objects checking two properties.  For this, we seek the rules describe in level2; so we find, as example, the following rules:  Salary(Low) => Age(Young)     80% 2) The user wants to know, what are properties that must have an employee, so that he will have a medium salary? For this, we seeks the rules having like conclusion Salary(medium); so we find the two following rules:  Age(young)  =>  Salary(Medium)    65% Age(Adult)  =>  Salary(Medium)              83%  This we can interpret it as follows: to have a medium salary the person must be young (65%) or adult (83%)  3) The user wants to know that are properties which an employee can check, if he has a low salary.    For this, we seeks the rules having like premise Salary(low); so we find the two following rules:  Salary(Low) => Age(Young) 80% Salary(Low) => Salary(Medium), Age(Adult) 53% This we can interpret it as follows:  having the low salary  two cases is possible: - Either this person is young   80% , or - Either this person is adult and has medium salary 53%:  this means that his salary in the superior part of the interval modelled low Salary.

Remark. The fact of having in the same rule Salary(Low) and Salary(Medium), is not contradictory but this means that the person has low Salary which are in the overlapping in the part medium Salary. This implies that his Salary is necessarily in the highest zone of the low Salary and in the lowest zone of medium Salary.



VII. ADVANTAGES OF THE NEW APPROACH Different advantages are granted by the proposed  approach: 1)  The definition of the Meta knowledge concept:  This definition is very important, since the number of rules generated is smaller: we define the set of meta-rules between the clusters and we can generate automatically the association rules between the data, if we want more details.

Also, this concept permits to have a global view on the data set which is very voluminous. Thus, it models a certain abstraction of the data that is fundamental in the case of an enormous number of data.

2) The definition of the level of knowledge concept: This approach enables us to hide and to exhibit the details encapsulated while moving between the different levels of the hierarchy during the discovery of knowledge. Thus, according to the degree of detail required by the user, we can propose a level of knowledge (more general level 1 towards most specific level N).

3) Extensibility of the proposed approach: 1) Our approach can be applied with any fuzzy classification algorithm to classify the initial data. 2) We can generate the maximum of knowledge on our initial data set; it?s enough to modify the choice of the classification criteria. These criteria can be chosen by the user like parameters of entry according to the importance of the attribute in its applicability. 3) We can classify our data according to different criteria and obtain different clusters which generate a different set of Meta knowledge

VIII. VALIDATION OF THE PROPOSED APPROACH To validate the approach proposed, we chose:  1) The  FCM (Fuzzy C-Means) algorithm for a fuzzy classification of the data set, and 2) The Ganter algorithm [24] for the construction of the lattice. We currently develop this approach with JAVA language.

About complexity: 1) The space complexity, whatever the number of database records, is thus reduced to a constant value, i.e., about 1O . This characteristic is fundamental in     the treatment of the large database in knowledge discovery.

2) The temporal complexity includes the following costs:  - Construction of the attribute?s clusters.

- Building the fuzzy lattice.

For cluster?s construction, the complexity of fuzzy clustering algorithms is about 2NCO , where N  corresponds to database table records number and C  is the maximum number of clusters. For fuzzy lattice construction, temporal complexity of lattice construction algorithm is about 2NO  .

IX. COMPARISON WITH OTHER APPROACHES.

The approach that we propose in this paper offers a set of  knowledge. The number of rules is really defined by the end- user. Indeed, in the first step of our approach, the user must specify the number of clusters to generate by FCM algorithm to classify his data.

Example  In our case, the user specified a number = 3 for the attribute Salary and a number = 2 for the attribute Age.

Consequently we obtain 5 clusters.

In our approach, each cluster corresponds to a predicate.

The lattice constructs, will be a lattice with N levels, N is equal to the number of clusters. By definition of the lattice, level 0 and level N contain 1 only node. The Level i contains a number of node equal to the number of overlapping between i clusters. This number will be equal to the  maximum to  C i  N The rules are generated by level: of the level i at the level  i+1. A rule is defined of a node of level i towards a node of level i+1. The maximum number of rules which can be  generated is, in consequence, equal to C i  N   * C i  N      We have N levels in the lattice = >  The maximum Number of rules =    Ni  i (C i  N  * C i  N   )   Example In our case N=5 Let us calculate the maximum number of nodes for each  level: The level 0 contains 1 node. The level N contains 1 node.

C05  =  1 (level 0) C15  =  5  (level 1) C25  = 10 (level 2) C35  = 10 (level  3) C45 =    5 (level 4) C55  =   1 (level 5)      Let us calculate the maximum number of rules which can be generated: level 0 -> level 1 :   1*5 =    5 rules   (maximum) level 1 -> level 2 :   5*10 = 50 rules  (maximum) level 2 -> level 3 : 10*10 =100 rules  (maximum) level 3 -> level 4 : 10* 5 =    50 rules (maximum) In conclusion, we will have to the maximum 205 rules.

As we show, what is important is that in our approach,  this number of generated rules, is independent of the size of the data. It rather depends on the number of generated clusters by the phase of classification. This number of clusters is given in entry by the user and it is the user who defines the linguistic labels for his clusters.

Let's note that another solution can be possible, is to use an algorithm of classification that didn't have like entry the number of clusters generated: in this case, the algorithm proposes the best classification for the set of data and the user specifies the linguistic labels for every class.

The comparison with the existing approaches can be made another level, indeed the algorithms proposed don?t take into account any semantics of the data, and to our knowledge these approaches don't treat the problem of knowledge utilization. All the researchers focused themselves on the reduction of the set of rules of a variety of hundreds of rules, by proposing the concept of metadata, or on the method of visualization of this great number of rules.

Our principle in this approach is to propose an extraction of knowledge based on the ties semantics of the data which is in our opinion more interesting, that the one existing which bases on the form (syntax) objects.

To our opinion, it is not a question to compare the results, according to the number of generated rules which is distinctly lower in our case, obtained in the other approaches and those obtained in our approach. Rather it is necessary to see the degree of utilisability of generated knowledge. Indeed what it is the interest to propose several approaches of knowledge extractions, whereas the user cannot benefit to better exploit these gigantic data?

In this approach we proposed different views according to which the user can exploit his data. In addition the fact to allow the user to choose attributes to classify and the numbers of generated clusters allows the user according to his needs to fix these choices. Indeed, the user can (1) apply any classification algorithm, and (2) generate the maximum of knowledge on its initial data set:  it?s enough to modify the choice of the classification criteria. These criteria can be chosen by the user like parameters of entry according to the importance of the attribute in its applicability.



X. CONCLUSION In this paper, we presented a new approach that permits  to extract knowledge combining classification and FCA methods. Generally, the researchers in this field use FCA based on Lattice theory or classification. All these methods generate a big number of association rules that are not easily assimilated by the human brain.

To resolve this problem, we proposed a new KDD model. It consists of two steps: the first organizes the database records in homogeneous clusters having common properties which permit to deduce the data?s semantic. This step consists of TAH?s and MTAH generation of relieving attributes. The second permits to Discovering Knowledge. It consists to deduce the Fuzzy  Cluster Lattice corresponding to MTAH lattice generated in the first step, then traverse this lattice to extract the Meta Knowledge ( Set of fuzzy associations meta-rules on the clusters ), and in end deduce the rules modeling the Knowledge (Set of fuzzy associations rules on the attributes). While basing on the hierarchical structure offered by the lattices, we proceed to discover the Knowledge in a hierarchical way. Thus, according to the degree of detail required by the user, this approach proposes a level of knowledge and different views of this knowledge.

Moreover, this solution is extensible; the user is able to choose the fuzzy method of classification according to the domain of his data and his needs.

This solution reduced considerably the number of generated rules, offered a better interpretation of the data and optimized both the space memory and the execution time.

As futures perspectives of this work, we mention 1) to test our approach on several the large data set, and 2) to define a new intelligent method of evaluation of requests which takes into account the Meta knowledge and/or the knowledge base generated by our KDD model.

XI. REFERENCES [1] P. Berkhin, ?Survey of clustering data mining techniques?, Technical  report, Accrue Software, 2002.

[2] M. Zaki, ?Mining Non-Redundant Association Rules?, Data Mining  and Knowledge Discovery, No 9, 2004, p. 223?248.

[3] G. Stumme, R.Taouil, Y. Bastide, N. Pasquier, and     L. Lakhal,  ?Intelligent structuring and reducing of association rules with formal concept analysis?, Proceedings of KI?2001 Conference, Vienna, Austria, Lecture Notes in Artificial Intelligence 2174, Springer- Verlag, September 2001, p. 335?350.

[4] N. Pasquier ?Data Mining : Algorithmes d'Extraction et de R?duction des R?gles d'Association dans les Bases de Donn?es?, Th?se, D?partement d?Informatique et Statistique, Facult? des Sciences Economiques et de Gestion, Lyon, 2000.

[5] R. Agrawal, T. Imielinski, and Swami A., ?Mining Association Rules between sets of items in large Databases?, Proceedings of the ACM SIGMOD Intl. Conference on Management of Data, Washington, USA, June 1993, p. 207-216.

[6] R. Agrawal, and R. Skirant. ?Fast algoritms for mining association rules?. In Proceedings of the 20th Int'l Conference on Very Large Databases, pages 478-499, June 1994.

[7] N. Pasquier, Y. Bastide, R.Taouil, and L. Lakhal,          ? Efficient Mining of Association Rules Using Closed Itemset Lattices?, Information Systems Journal, vol. 24, no 1, 1999, p. 25-46.

[8] M. J. Zaki, and C. J. Hsiao, ? CHARM : An Efficient Algorithm for Closed Itemset Mining ?, Proceedings of the 2nd SIAM International Conference on Data Mining, Arlington, April 2002, p. 34-43.

[9] G. Stumme, R. Taouil, Bastide Y., Pasquier N., and L. Lakhal, ?Fast Computation of Concept Lattices Using Data Mining Techniques?, BOUZEGHOUB M., KLUSCH M., NUTT W., SATTLER U., Eds., Proceedings of 7th Intl. Workshop on Knowledge Representation Meets Databases (KRDB?00), Berlin, Germany, 2000, p. 129-139.

[10] G. Stumme, R.Taouil, Y. Bastide, N. Pasquier, and     L. Lakhal, ? Computing Iceberg Concept Lattices with TITANIC?, J. on Knowledge and Data Engineering (KDE), vol. 2, no 42, 2002, p. 189- 222.

[11] S. Ben Tekaya, S. Ben Yahia, and Y. Slimani. ?Algorithme de construction d`un treillis des concepts formels et de d?termination des g?n?rateurs minimaux?, ARIMA journal, Novembre 2005, Num?ro sp?cial CARI'04, pages: 171-193, 2005.

[12] T. Hamrouni, S. Ben Yahia, and Y. Slimani. ?Prince : Extraction optimis?e des bases g?n?riques  de r?gles sans calcul de fermetures?.

In Proceedings of the Intl. INFORSID Conference, Editions Inforsid, Grenoble, France, pages : 353--368, 24-27 May 2005  [13] B. Ganter, and R. Wille, Formal Concept Analysis: mathematical foundations. (translated from the German by Cornelia Franzke) Springer-Verlag, Berlin-Hei delberg 1999.

[14]  T.Thanh, H.Siu Cheung, and C. Tru Hoang, ?A Fuzzy FCA-based Approach to Conceptual Clustering for Automatic Generation of Concept Hierarchy on Uncertainty Data.? ,CLA 2004, pp. 1?12, ISBN 80-248-0597-9.

[15]  L. Zadeh. Fuzzy sets. Information and Control, (69):338-353, June  [16]  M. Sassi, M., A. Grissa Touzi, and H. Ounelli, ? ?Interpretting Fuzzy Clustering Results based on Fuzzy Formal Concept Analyis?, IEEE London, UK, 2007.

[17]  A. Grissa Touzi, M. Sassi, and H. Ounelli,  ?Using Formal Concept Analysis for Flexible Querying Optimization?, 23nd International Conference on Computers and Their  Applications, (CATA?08), Mexico, Avril 2008  [18]  A. Grissa Touzi, M. Sassi, and H. Ounelli, ?An innovative contribution to flexible query through the fusion of conceptual clustering, fuzzy logic, and formal concept analysis?, International Journal of Computers and Their Applications. Volume. 16, N?. 4, pp 220-233, December, 2009.

[19] M. Sassi, A. Grissa Touzi, and H. Ounelli, ?A Fuzzy Linguistic Database Summarization Approach?, Fuzzy Systems Conference, 2008.

[20] J.C,  Bezdeck,  R.Ehrlich,  and  W.Full,  "FCM: The Fuzzy  C-Means Clustering Algorithm", Computers and Geoscience, vol. 10, no. 2-3, pp. 191?203, 1984  [21]  N. Pasquier, Y. Bastide, R.Touil, and L.Lakhal, ?Pruning closed itemset lattices for association rules?, Proceedings of 14th Tunisia, 26?30 October 1998, p. 177?196.

[22] M. J. Zaki, ?Generating Non-Redundant Association Rules?, Knowledge Discovery and Data Mining,Boston, MA, August 2000, p.

34-43.

[23]  Y. Bastide, R.Taouil, N. Pasquier, G. Stumme, and L.Lakhal, ?Mining frequent patterns with counting inference?, SIGKDD Explorations, vol. 2, no 2, 2000, p. 66-75.

[24]  B. Ganter, ?Two basics algorithms in concept analysis?, Technical report, Darmstadt, 1984.

