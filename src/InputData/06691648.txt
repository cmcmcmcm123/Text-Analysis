Correlation-based Performance Analysis for Full-System MapReduce Optimization

Abstract?Big Data is changing this world at a surprising speed, and MapReduce plays a critical role in finding insights in Big Data. However, to efficiently extract insights from Big Data, performance optimization of MapReduce applications is a challenging task. To facilitate the full-system optimization of MapReduce applications, we propose a correlation-based performance analysis approach to efficiently identify critical outliers. The basic intuition is that critical outliers are key to the overall performance and they can only be accurately identified by correlating different phases, tasks and resources.

Based on the proposed approach, we further implement a correlation-based performance analysis tool, called SONATA. It can efficiently identify critical outliers, and then, recommend optimization suggestions for practitioners based on embedded rules. Since the performance overhead is key to the applicability of a performance tool, we conduct experiments to demonstrate that SONATA is a practical tool with less than 5% overhead and good scalability. To demonstrate the effectiveness of SONATA, we share several cases during the performance tuning of IBM Platform SymphonyTMwith the help of SONATA.

Keywords-Big Data, MapReduce, Performance Analysis, Op- timization

I. INTRODUCTION  The ever-increasing volumes of data pose significant challenges on distributed computing technology. As one of the most popular programming paradigms to address these challenges, MapReduce [1] has been widely used in industry. Actually, following Google?s MapReduce, there also exists many varieties, such as, Apache Hadoop [2], Cloudera Enterprise [3], IBM InfoSphere BigInsightsTM [4], IBM Platform SymphonyTM [5], and so on.

Despite various underlying implementations of the MapReduce runtime, the performance optimization of MapReduce applications is still a great challenge since there exists numerous adjustable parameters in MapReduce framework. For example, Hadoop MapReduce contains more than 150 configuration parameters that may have non- trivial impacts on the performance. To make the tuning of MapReduce framework tractable, several approaches have been proposed to automatically determine the near-optimal MapReduce parameters with small overheads [6], [7].

In addition to the parameters of MapReduce framework, the performance of MapReduce execution is also heavily determined by configurations from other layers, such as, JVM, operating system, virtual machine and hardware. Thus, it is expected that a fine-grained full-system co-optimization technique could have potential to significantly improve the  performance. As an illustrative example, during the prac- tice of tuning Terasort to be executed on a 10-node IBM PowerLinuxTM7R2 cluster, we found that the performance improvement comes from different sources. In more detail, about 30% and 20% performance improvements stem from system software level (JVM, Garbage Collection (GC) and Huge Page, etc.) tuning and underlying hardware level tuning (Turbo mode, SMT (Simultaneous multithreading), and hardware prefetching, etc.), respectively. Nevertheless, due to the involvement of many parameters from different layers, the tuning process is much more complicated and always requires specialized expertise.

To ease the burden of full-system optimization, in this paper, we propose a novel full-system MapReduce opti- mization approach based on correlation-based performance analysis. The intuition is that the overall performance of MapReduce applications is always determined by the critical outliers, for example, the slowest map or reduce tasks that determine the overall execution. Thus, identifying critical outliers is most important for performance optimization of MapReduce applications. Actually, the critical outliers can only be accurately detected by correlating different subphases (of a task), tasks (e.g., map/reduce tasks) and resources (e.g., CPU, Memory and Disk). In other words, it is necessary to conduct correlation-based analysis to identify the real performance issues. Once performance issues are identified, some empirical rules could be applied to guide the practitioners to optimize the overall performance.

Based on the proposed correlation-based analysis ap- proach, we implement a full-system MapReduce perfor- mance analysis tool, which is called as SONATA, on IB- M Platform SymphonyTM. Apparently, to make such an instrumentation-based performance tool viable, the addition- al performance overhead should be low enough. To evaluate the performance overhead of SONATA, we conduct exper- iments with several widely-used MapReduce benchmarks.

The experimental results show that SONATA only causes less than 5% additional performance overhead for the evaluat- ed benchmarks, which well demonstrates the efficiency of SONATA.

To demonstrate the effectiveness of SONATA, we present several cases during the tuning of Terasort on IB- M PowerLinuxTM7R2 systems running IBM Platform SymphonyTM. Our experiences show that correlation-based performance analysis is indeed very effective and efficient      for full-system performance optimization, and we manage to sort 1TB data in 7 minutes on 10-node PowerLinuxTM7R2 systems running IBM Platform SymphonyTM.

The rest of the paper proceeds as follows. Section II introduces background of MapReduce programming model and the importance of critical outliers for performance tuning. Section III elaborates the proposed correlation-based performance analysis. Section IV details the implementation of SONATA. Section V evaluates the performance overhead and scalability of SONATA. Section VI presents several case studies of SONATA. Section VII compares SONATA with other MapReduce optimization approaches. Finally, section VIII concludes this paper.



II. BACKGROUND  A. MapReduce Background  The MapReduce programming paradigm executes a job in two phases: Map and Reduce. In the map phase, several map tasks are executed in parallel to process the corresponding input data. After all map tasks finished, the intermediate results are transferred to the reduce tasks for further pro- cessing. The map and reduce tasks communicate with a master node which dominates the MapReduce process in the centralized control system. In a typical implementation of MapReduce runtime, such as, Apache Hadoop, the primary controlling component on the master node is referred as Job Tracker (JT) while the secondary controlling threads on slave nodes are referred as Task Trackers (TT). The functions of the map and reduce tasks are usually defined and rely on the particular missions required by applications. Under this framework, the map and reduce tasks can implement massive data parallelism for large-scale data processing .

B. Critical Outliers  The execution of one MapReduce job consists of several parallel tasks, and outlier tasks refer to the tasks that take longer to finish than other similar tasks. In addition to these task-level outliers, there also exists outliers in different level, such as phase-level and resource-level outliers. The phase- level outliers are phases that dominate the entire execution of a task. The resource-level outliers are abnormal behaviors of resource usages, for example, CPU is not fully utilized, disk access is much slower than that of other nodes, and memory usage is over-used compared with that of other nodes.

Although outliers exhibit different behaviors compared with their counterparts, they may not have significant im- pacts on the overall performance. For example, the outlier tasks do not lie in the critical path will not postpone all sub- sequent execution. Therefore, only critical outliers should be identified for performance diagnosis and optimization.

However, as the size of clusters (e.g., a cluster contains more than 2000 nodes has been deployed at Taobao [8]) and the parallelism of jobs (i.e., tens of thousands of tasks  are executed in parallel) continue to grow, the identifica- tion of critical outliers is extremely complicated and time- consuming for engineers in industrial practice.



III. CORRELATION-BASED PERFORMANCE ANALYSIS  In this section, we introduce the proposed correlation- based performance analysis approach to effectively and efficiently identify critical outliers.

The basic intuition of correlation-based performance anal- ysis is to correlate different phases, tasks and resources to effectively and efficiently identify critical outliers. As shown in Figure 1, all those correlations can be roughly grouped in- to 4 classes, that is, phase-phase correlations, task-task cor- relations, task-resource correlations, and resource-resource correlations.

Figure 1. All correlations can be grouped into four types, that is, phase- phase, task-task, task-resource and resource-resource correlations.

A. Phase-Phase Correlations  The correlation between different phases is utilized to identify the critical phases of one task?s execution. This correlation is especially useful for the optimization of MapReduce runtime engine. By dividing the execution of one task into different important subphases, and then instru- menting them during execution, the designers of MapReduce engines can easily identify the critical paths for potential optimization. For example, during the performance opti- mization of a MapReduce engine, when encountering long- tail reduce tasks, multi-threaded processing is a potential solution to accelerate these tasks. In addition to the design- ers of MapReduce engines, the end-users can also benefit from such correlations. For example, they can quantitatively compare the execution details of different implementations of user-defined routines, and then improve the efficiency accordingly.

B. Task-Task Correlations  The correlations between tasks mainly target to identify the slow map or reduce tasks. Although the identification of slow tasks is straightforward, it is non-trivial to reveal the underlying reasons of such phenomenons. To offer more insights of such slow tasks, we further consider two types of task-task correlations, that is, inter-node and intra-node task-task correlations.

During the performance analysis, inter-node correlations help to easily identify the slow tasks among all nodes. Once a number of tasks are recognized as the slow tasks, we should further verify whether such tasks are on the same node. Once such tasks are executed on different nodes, we should mainly examine the data input size of each task to determine unbalanced data partition. Otherwise, we should check the system configuration of the node where the slow tasks are running. Moreover, for an abnormal node, the intra- node correlations can identify the slow tasks running on it. Since the system configuration is the same for all tasks on this node, the unbalanced data partition and scheduling issues (e.g., inappropriate setting of task slots) could be considered as the main reasons for the slow tasks.

C. Task-Resource Correlations  Once critical outliers of tasks are identified, the correla- tions between such tasks and the corresponding resources are used to identify the critical outliers of resources, e.g., the low usage of resources that may impair the overall performance.

As shown in Figure 2, task 1469 is first identified as a critical outlier since it delays the overall execution of the map phase. Since task 1469 is executed on node JUNO2, we correlate it with the resources on node JUNO2. With respect to the CPU utilization, we can see that during the execution of task 1469, the CPU utilization drops significantly. To improve the CPU utilization in the transition from the map tasks to the reduce tasks, we could start the shuffle phases earlier or schedule more reduce tasks to this node to occupy the CPU.

D. Resource-Resource Correlations  The correlations between different resources are also useful for performance diagnosis and optimization. Similar to task-task correlations, there are two kinds of resource- resource correlations, that is, inter-node and intra-node correlations.

The inter-node correlations are conducted by correlating the same resources (e.g., network) between different nodes.

As a result, the abnormal resource usage can be easily identified. For example, a slow network adapter may delay the shuffle phases to all nodes. In this case, the critical tasks are not easy to identify since the shuffle phases of all tasks are postponed, this performance issue can only be detected by conducting inter-node resource-resource correlation.

The intra-node correlation is conducted by correlating different resources on the same node, and potential perfor- mance optimization might be adopted accordingly. As shown in Figure 3, the total network bandwidth is about 1.3GB/s, while the corresponding CPU usage is more than 95%. In this case, since two 10GbE network cards are used for inter- node communication, the main bottleneck is the CPU usage.

Actually, the large data transfer rate also aggravates the load of CPU usage. To ease this burden, RDMA (Remote Direct  Figure 2. The correlation between task and resource to identify tasks or phases that are bottlenecks.

Memory Access) would be a very promising technique to release CPU from costly data copy operations [9] to further improve the overall performance.

Figure 3. The correlation of resource and resource to identify potential performance optimization.

E. Workflow of correlation-based performance analysis  Based on four types of correlations, Algorithm 1 shows the basic workflow to conduct correlation-based perfor- mance analysis to effectively and efficiently identify crit- ical outliers. The first step is to utilize inter-node task- task correlations to identify a task set T contains critical outliers of tasks. Then, intra-node task-task correlations can     determine whether all tasks or a subset of tasks in T run on the same node. For each task ti in task set T , task- resource correlations should be leveraged to identify whether the corresponding resources are outliers. Besides, phase- phase correlations can be used to determine the most time- consuming phases for each outlier task. Even when there is no critical task, in other words, all tasks are completed very close, inter-node resource-resource correlations could be used to diagnose whether resource issues exist. Moreover, intra-node resource-resource correlations could offer more insights to determine potential performance optimization.

Finally, phase-phase correlations on the task with averaged statistics could provide suggestions for the optimization of user-defined routines or runtime engines.

Algorithm 1: Workflow of correlation-based perfor- mance analysis T = critical outliers of tasks determined by inter-node task-task correlations; intra-node task-task correlations to determine whether subsets Ts ? T are on the same node; for ti ? T do  task-resource correlations on ti to find outliers of resources; phase-phase correlations on ti to find critical outliers of phases;  end inter-node resource-resource correlations to diagnose resource issues; intra-node resource-resource correlations to determine potential optimization; phase-phase correlations on tavg find critical outliers of phases;

IV. SONATA: FULL-SYSTEM MAPREDUCE PERFORMANCE ANALYZER  Based on the proposed correlation-based performance analysis, we further implement SONATA, a full-system per- formance analyzer that first effectively and efficiently detects critical outliers, and then recommends suggestions for po- tential optimization. In this section, we elaborate the detailed implementation of SONATA.

A. Framework  SONATA consists of four main phases, that is, data collec- tion, data loading, performance visualization and optimiza- tion recommendation, which can be illustrated in Figure 4. In data collection, two types of runtime statistics, i.e., execution details and resource usage, on each node are collected, and then they are aggregated at a specified master node. In data loading, a data loader on the master node periodically retrieves data from aggregated statistics and writes them into the database. In performance visualization, the collect- ed runtime statistics are obtained from the database and displayed in a correlated mode via web-based performance visualizer. Meanwhile, when end-users using the visualizer to get a deep understanding of the MapReduce?s behaviors, the potential critical outliers could be efficiently identified and optimization suggestions are recommended by optimiza- tion recommendation. In the following sections, we present details of each phases.

Figure 4. The framework of SONATA for full-system MapReduce perfor- mance analysis.

B. Data Collection  As shown in Figure 5, there are two main components, that is, monitor and aggregator, for data collection.

The monitor is distributed on each node for gathering both the execution details of programs and hardware resource usage information. The basic idea to collect the execution details of programs is based on the MapReduce?s counters, which are useful mechanism to gather execution statistics and supported by most MapReduce implementations (e.g., Apache Hadoop and IBM Platform SymphonyTM). In more detail, we define several new counters for the interested execution phases, for example, the potential critical phases of MapReduce execution, and then add specific codes on the source codes of runtime engine to update the corre- sponding counters during execution. On the other hand, to collect the hardware resource usage information, such as CPU/memory usage, disk and network bandwidth, we leverage a lightweight performance monitoring tool, i.e., Ganglia [10]. More specifically, the monitor first reads the raw data from Ganglia and then generates organized data for processing by the aggregator.

Figure 5. The components for data collection.

The aggregator on the master node periodically collects the data from the monitors on all slave nodes. Then, the data are organized in XML format and written into a history file in order. Figure 6 illustrates an XML item of the collected execution details in the history file. To avoid a large size of the history files, the aggregator also periodically flushes the data in current history files into out-of-date files.

Figure 6. The counter MAP COMPLETE TIME is stored in XML format for Task 2 in Job 24002.

C. Data Loading  Since the data in current history file are temporary and it is non-trivial to efficiently manipulate file data for performance analysis, we consider to store the collected data into the database, which is implemented by the data loader. The data loader, which runs as a daemon on the master node, periodically reads the history file and writes the XML items into the database. The data loader can remember the last reading offset of the history file to avoid writing duplicate records into the database.

In addition to loading the history file into the database, the data loader also intercepts the data generated by the aggregator, and then the intercepted information is also written into the database. More specifically, once the data loader is invoked at a scheduled time, a new record, along with the current timestamp, will also be inserted into the database. Apparently, such dynamically updated information of running jobs is the basis of on-the-fly visualization and monitoring.

D. Performance Visualization  Currently, in performance visualization, four analysis views can be generated to present more insights of the execution of programs. The first one is the overall view, where the execution timelines of all map and reduce tasks are depicted. Thus, the users can easily observe information like how many tasks were running at any time point and how many map/reduce task waves. The second one is the resource view, where the CPU/memory usage, disk and net- work bandwidth are depicted. The users can easily identify abnormal usage curves of specific nodes from this view.

The third one is the breakdown view of the execution of one specific map or reduce task, and the users can easily identify the critical phases of one task. Actually, the above three views are correlated to facilitate the identification of critical outliers. For example, once a task in the overall view is selected, both the tasks running on the same node in the overall view and the resource usage curves in the resource view will be highlighted. Besides, the breakdown view will also display the execution details of the selected task. The fourth view is a table to list the detailed execution statistics of the entire jobs, for example, the status of the job, the  average execution time of all map tasks, and the HDFS written/read bytes, etc.

E. Optimization Recommendation  Figure 7. An illustrate example to automatically diagnose the hardware configurations.

Although end-users could only rely on the visualizer to conduct performance analysis, it would be very helpful to automatically determine critical outliers and thus provide optimization recommendations for inexperience users. Thus, in the optimization engine, we embedded several empirical rules to recommend tuning guidelines for potential perfor- mance improvements. Figure 7 shows an illustrative example to automatically diagnose the hardware configurations and present the optimization recommendations. In this example, by conducting task-task correlation, it can be easily found that only tasks on node JUNO2 (e.g., task 2584) are the crit- ical outliers, which indicates that there exists performance issues on JUNO2. To identify the root cause of this observa- tion, we further perform task-resource and resource-resource correlations. We found that on JUNO2, the CPU usage is overutilized ( > 99%) but the network access is underutilized (the maximal disk write speed is only 170MB/s) compared with other nodes, which implies that CPU of JUNO2 is one of critical outliers of this execution. Thus, SONATA recommends to check the CPU-related configurations, for example, the SMT setting, hardware prefetching, and CPU     frequency. Finally, we identify that this problem is caused by setting the SMT as 2 on JUNO2 while on other nodes the SMT is set as 4. Actually, such domain knowledge could be easily summarized as an empirical rule as shown in Figure 8.

Figure 8. The example in Figure 7 can be summarized as an empirical rule for automatic optimization recommendation.



V. PERFORMANCE EVALUATION  In this section, we evaluate the performance overhead and scalability of SONATA, which has been deployed on IBM Platform SymphonyTM.

A. Experimental Methodology  The MapReduce benchmarks for evaluation are widely- used Terasort and Wordcount, and the corresponding data sets are 1TB data from TeraGen and 210GB data from Bible.txt, respectively. The cluster we used for evaluation consists of up to 10 POWER7TMR2 servers, each contains 2 POWER7TMchips, and each chip has 32 hardware threads.

The detailed information of the evaluated cluster is listed in Table I.

Table I EVALUATED IBM POWER7 CLUSTERS  Cluster 10 PowerLinuxTM7R2 Servers  CPU 16 processor cores per server (160 total)  Memory 128GB per server (1280GB total)  Internal 6 600GB internal SAS drives Storage per server (36TB total)  Expansion 24 600GB SAS drives in IBM EXP24S SFF Storage Gen2-bay Drawer per server(144TB total)  Network 2 10GBe connections per server  Switch BNT BLADE RackSwitch G8264  The performance of MapReduce benchmarks is measured by the end-to-end execution time of a job. To resist stochastic effects, we run each benchmark five times and only the minimal value is treated as the measured performance. By comparing the performance of benchmarks running on the original IBM Platform SymphonyTMand the version attached with SONATA, we can quantify the additional performance overhead caused by SONATA.

B. Runtime Overheads  Figure 9 shows the performance overhead of SONATA (with respect to the original IBM Platform SymphonyTM) on 5- and 10-node clusters. The first observation is that the additional overhead caused by SONATA is very low for the evaluated benchmarks. For example, even for benchmark  Terasort running on the 10-node cluster, the performance overhead is only 3.5%. The second observation is that the additional performance overhead may vary for different benchmarks. For benchmark Wordcount, the performance overhead is only 1.5% when running on 10-node cluster.

The third observation is that even increasing the number of nodes, the performance overhead does not increase signifi- cantly for the evaluated benchmarks.

Figure 9. The execution overhead of SONATA compared with the original execution time without instrumentation.

The instrumented counters are collected for each task, and the number of tasks typically increases along with the data sizes. For example, when sorting 512GB data, the number of map tasks is only 1432, while sorting 1.5TB data, the number of map tasks increases to 2796. Therefore, the performance overhead may vary given different number of tasks. To evaluate the scalability of SONATA, we measure the performance of Terasort given 512GB, 1TB, and 1.5TB data. As shown in Figure 10, we can see that given different number of tasks, the performance overhead does not vary significantly, and the maximal execution overhead is still less than 5%. Thus, the results from our test cases suggest that SONATA will a practical tool when deployed in commercial environments.

Figure 10. The scalability of SONATA for different size of tasks.



VI. CASE STUDIES  In this section, we share our experiences on tuning the full-system performance of Terasort running against IBM Platform SymphonyTMon a IBM POWER7TMcluster with the help of SONATA. During the tuning process, the performance issues we encountered can be roughly grouped into three     main categories, that is, system problems, inappropriate runtime configurations, and runtime inefficiency.

A. Diagnosing System Problems  In addition to the example shown in Figure 7 where SONATA can efficiently facilitate the identification of inap- propriate configurations of CPU, e.g., SMT, prefetching and frequency setting, we further present an example to illustrate that an abnormal disk behavior can also be detected by SONATA. As shown in Figure 11, several reduce tasks on JUNO1 are critical outliers that postpone the overall execu- tion time. By correlating the tasks with the disk resources of the corresponding nodes, we found that the total disk loads on JUNO1 (< 1.72GB/s) are much more heavier than that of other nodes (e.g., < 864MB/s on node JUNO9).

Figure 11. Diagnosing disk problem via SONATA. Disk loads of node JUNO1 are much more heavier than that of other nodes (e.g., node JUNO9).

By examining the operations during the execution of this job, we finally identify that other users have run a disk benchmark on JUNO1 in the same time slot since this cluster was shared by several teams. After that, we obtain exclusive access to this cluster to avoid inferences from other teams.

B. Tuning Runtime Configurations  Similar to Hadoop MapReduce, there also exists many adjustable configurations in IBM Platform SymphonyTMfor MapReduce practitioners. Here we list three cases to illus- trate how SONATA can help optimize the runtime configu- rations.

The first tuning case is about the buffer usage in map tasks, as shown in Figure 12. In this example, it can be easily identified the critical tasks, such as task 402, by conducting task-task correlation. Actually, during the execution of this task, we can see that multiple sorts and spills (i.e., 2 sorts and spills) occur. Due to multiple sorts and spills, the resultant overhead is more than 49% of the overall map time. By identifying that the overhead of sorts and spills is larger than a predefined threshold (e.g., 20%), SONATA recommends to adjust the buffer-related parameters, for example, increase the parameter such as io.sort.mb. By increasing this param- eter, multiple sorts and spills could be completely eliminated and the overall performance is improved accordingly.

Figure 12. By correlating phase-phase correlation for critical tasks, potential optimization could be recommended accordingly. In this example, there are multiple costly sorts and spills in the critical map task. They could be eliminated by enlarging the parameter such as io.sort.mb.

The second example is about the tuning of another critical parameter, slowstart, for IBM Platform SymphonyTM, which determines the fraction of the number of map tasks that should be complete before reduce tasks are scheduled. As shown in Figure 13 (the bottom figure), by correlating different phases in a critical reduce task, the WaitInFetch phase is most time-consuming in shuffle, which occupies more than 99% of the overall execution time of the reduce task. Moreover, by correlating tasks with the resource usage (the middle figure), the corresponding CPU is not 100% fully utilized (i.e., 89%) in shuffle. Thus, we could consider to increase the value of slowstart to release more reduce slots to map slots before the completion of all map tasks.

The third tuning case is about the selection of appropriate compressors for data output. When sorting 1TB data via Terasort, by conducting phase-phase correlation for one critical map task, the shuffle phase, which transfers data from the map tasks to the reduce tasks, dominates the entire execution time (e.g., more than 70%). It is intuitive to compress the data to reduce the IO (disk and network) overheads, which is well supported by most MapReduce runtime engines. Since the efficiencies of different compres- sors vary significantly, SONATA can efficiently compare the performance of different compressors and recommend the best for further usage. By comparing the performance of DefaultCodec (zip) and Lz4Codec compressors, we found that the overall execution time of Default compressor is about 1.5 times longer than that of Lz4 compressor. Besides,     Figure 13. By correlating the slow reduce tasks with their subphases, the WaitInFetch phase is more than 99% of the overall execution time.

Besides, the CPU is not fully utilized during the shuffle phase. Thus, we could increase slowstart to let more map tasks scheduled for execution.

by utilizing Lz4 compressor, the shuffle ratio (with respect to the execution time of reduce tasks) can be reduced by 118%.

C. Improving Runtime Efficiency  In addition to the MapReduce practitioners, the perfor- mance tool is also very helpful for the runtime designers to optimize the implementation of MapReduce engines. In Apache Hadoop, the map and the reduce slots can only be used for the map and the reduce tasks, respectively. In IBM Platform SymphonyTM, the default configuration also follows this guideline that slots cannot be shared by the map and the reduce tasks. Figure 14 shows the execution behav- iors of Terasort when setting 32 map slots and 32 reduce slots on each PowerLinuxTM7R2 node (which contains 64 hardware threads). Apparently, we can see that during the first wave of map execution, the CPU utilization is relatively low on this cluster, e.g., the CPU utilization of node JUNO0 is less than 37%.

To improve the utilization of CPU, IBM Platform SymphonyTMoffers generic slots that can be shared between the map tasks and the reduce tasks. Figure 15 shows that given the same MapReduce parameters, by sharing slots between the map and the reduce tasks, the CPU utilization can be significantly improved to more than 50% for node JUNO0. In this case, the generic slots can improve the overall performance by 12.99% compared with the separated  Figure 14. Terasort running with separated map and reduce task slots.

slots (485s vs 422s).

Figure 15. Terasort running with shared map and reduce task slots.



VII. RELATED WORK  There exists a number of research efforts to propose performance analysis approaches and tools for efficient MapReduce processing.

Mantri is a system that monitors tasks and culls outliers using cause- and resource-aware techniques [11]. Although Mantri also focused on optimizing outliers, it can only ad- dress task-level outliers. In contrast, SONATA facilitates the full-system performance optimization by identifying phase- level, task-level and resource-level outliers.

HiTune is a scalable, lightweight and extensible perfor- mance analyzer for Hadoop MapReduce based on dataflow- based performance analysis [12]. Although HiTune also shows the execution details of tasks and resource usages as SONATA does, it cannot directly provide the correlations a- mong phases, tasks, and resources, which are most important     to efficiently identify critical outliers. Moreover, SONATA can monitor the behaviors of a job?s execution on-the-fly to facilitate online optimization, while HiTune only offers post-execution performance analysis.

Starfish is a self-tuning system that enables Hadoop users to get good performance automatically without deep understanding of many tuning knobs available [7]. One of the key features of Starfish is that it can automatically set the near-optimal parameters for Hadoop jobs. However, Starfish mainly focuses on the tuning of the parameters of Hadoop framework, which cannot be used to optimize the runtime engines and diagnose hardware problems. In other words, Starfish cannot facilitate full-system optimization.

Theia [13] is a visualization tool to generate visual signa- tures of each job?s performance by analyzing the application- level logs of a Hadoop cluster. The visual signatures facil- itate troubleshooting the performance problems (e.g., hard- ware failure, data skew, and software bugs, etc.) on the cluster. However, Theia cannot tackle with misconfigurations of runtime engine and underlying hardware.

Hadoop vaidya is a rule-based performance diagnostic tool for MapReduce jobs [14]. Although it can provide recommendations based on the analysis of runtime statistics, it cannot facilitate full-system optimization. PerfXPlain is a system enables users to ask questions about the relative performances (i.e., runtimes) of pairs of MapReduce job- s [15]. However, this system mainly focuses on explaining the performance similarity or difference between pairs of MapReduce job or task executions.

In summary, current approaches mainly target to the optimization of MapReduce parameters, which cannot be helpful for full-system optimization. In contrast, by cor- relating different phases, tasks and resources, SONATA is able to efficiently identify critical outliers for full-system optimization. Besides, the monitoring capability of SONATA can facilitate the online optimization of MapReduce appli- cations.



VIII. CONCLUSION  In this paper, we present a correlation-based performance analysis approach to efficiently identify the critical outliers for full-system MapReduce optimization. The key intuition is that the critical outliers can only be accurately and efficiently identified by correlating different phases, tasks, and hardware resources. Once critical outliers are identified, several empirical optimization rules can be deployed to tame them. The proposed approach is further implemented as a tool, named as SONATA. SONATA has been deployed on IBM Platform SymphonyTM, and experimental results show that it only causes less than 5% performance overhead for more than 2000 tasks on a 10-node PowerLinuxTM7R2 system.

Finally, with the help of SONATA, we manage to sort 1TB data in 7 minutes on this system running IBM Platform SymphonyTM.

ACKNOWLEDGEMENT  We would like to thank H. Peter Hofstee and Jian Li for sharing the cluster with us. We also would like to thank Zane Hu, Alicia Chin and Yonggang Hu for providing product supports.

