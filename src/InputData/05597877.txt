I-FAC: Efficient Fuzzy Associative Classifier for Object Classes in Images

Abstract  We present I-FAC, a novel fuzzy associative classifica-  tion algorithm for object class detection in images using  interest points. In object class detection, the negative class  CN is generally vague (CN = U ? CP ; where U and CP are the universal and positive classes respectively).

But, image classification necessarily requires both posi-  tive and negative classes for training. I-FAC is a single-  class image classifier that relies only on the positive class  for training. Because of its fuzzy nature, I-FAC also han-  dles polysemy and synonymy (common problems in most  crisp (non-fuzzy) image classifiers) very well. As asso-  ciative classification leverages frequent patterns mined  from a given dataset, its performance as adjudged from its  false-positive-rate(FPR)-versus-recall curve is very good,  especially at lower FPRs when its recall is even better. I-  FAC has the added advantage that the rules used for clas-  sification have clear semantics, and can be comprehended  easily, unlike other classifiers, such as SVM, which act as  black-boxes. From an empirical perspective (on standard  public datasets), the performance of I-FAC is much better,  especially at lower FPRs, than that of either bag-of-words  (BOW) or SVM (both using interest points).

1. Introduction  Association Rule Mining (ARM) enables the extraction  of latent frequent patterns which are based on their respec-  tive frequencies, and thus represent the dominant trends in  the given dataset. A new classification approach called  associative classification [12], [13], [14] has gained pop-  ularity of late, because of its accuracy, which can be at-  tributed to its ability to mine huge amounts of data in order  to build a classifier based on frequent patterns in a dataset.

The advantages of associative classifiers are that frequent  itemsets capture all dominant relationships between items  in a dataset, and that they deal only with statistically sig-  nificant associations. Thus, the classification framework  is robust because low-frequency patterns (noise) are elim-  inated during the ARM stage. But associative classifica-  tion, like many other classifiers, cannot be used directly on  datasets and domains which make heavy use of numerical  attributes (like image classification), as it expects categori-  cal/binary attributes. One method to circumvent this prob-  lem is to use binning or clustering to convert numerical  attributes to categorical attributes. But using crisp binning  or crisp clustering introduces uncertainty especially at the  boundaries of bins or clusters, leading to loss of informa-  tion. Small changes in the selection of number of bins or  clusters may lead to polysemy (one bin or cluster contain-  ing features with different meanings) and synonymy (two  features with same meaning mapped into different bins or  clusters), thus generating misleading results. A more ef-  fective way to solve this problem is having features be-  long to clusters with some membership value in the in-  terval [0, 1], instead of belonging entirely to a particular  cluster. Thus, fuzzy features replace categorical ones.

In this paper we present our algorithm I-FAC which  adapts fuzzy associative classification to fit the image clas-  sification perspective, by leveraging Speeded-Up Robust  Features (SURF) that can be extracted from images [1].

SURF is a fast scale and rotation-invariant interest point  detector and descriptor for images. These interest points  which can vary in number from image to image, can be  used for further processing, like clustering and classifica-  tion. Generally, obtaining the negative class set CN is an  issue in image classification due to its ill-defined nature as  compared to the positive class CP . Effectively, the nega-  tive class set CN = U ? CP , where U is the universal set of all images. But, conventional classifiers need both pos-  itive and negative classes for training. Because CN is not  well-defined, classifiers so trained (on a subset of the neg-  ative class) may not perform well on disparate test images.

The advantage of I-FAC is that only positive class samples  are required to train the classifier, with no reliance on neg-  ative class samples for training and without the need for  unlabelled examples or outliers. In the literature, one-class  classifiers which rely on unlabelled examples [6] or treat  outliers and noise as negative examples for training [7],  have been proposed.

In the bag-of-words (BOW) approach, each SURF  point belongs only to one of the clusters in the code-  book, which is created by applying crisp clustering (like  k-means) on a sizeable set of images. Using fewer num-  ber of clusters would avoid synonymy, but would at the  same time give rise to polysemy. Thus, in BOW deciding  upon the number of clusters that should be used is an im-  portant but difficult task, because of which ?1000-3000 are generally used. But, I-FAC relies on fuzzy c-means  (FCM) clustering [5] and creates far less number of clus-  ters (?100) using only the positive class training images, as compared to the number of clusters used for the code-  book in BOW, thus avoiding synonymy. Due to the fuzzy  nature of clusters, it is able to address polysemy as well.

The main contributions of this work are ? a) use of  fuzzy sets and logic in object class classification in im-   DOI 10.1109/ICPR.2010.1067    DOI 10.1109/ICPR.2010.1067    DOI 10.1109/ICPR.2010.1067    DOI 10.1109/ICPR.2010.1067    DOI 10.1109/ICPR.2010.1067     c1 ? ?1,1, c2 ? ?1,2, . . . , ck ? ?1,k, positive class label . . .

c1 ? ?n,1, c2 ? ?n,2, . . . , ck ? ?n,k, positive class label  Figure 1. Fuzzy-cluster based representation  ages. By doing so we can deal with polysemy and syn-  onymy better as compared to crisp sets. This is reflected in  the experiments section (Section 4 where usage of fuzzy  sets yields better results than obtained using crisp sets, b)  I-FAC is an associative classifier, which relies on frequent  itemsets. Frequent itemsets capture all dominant relation-  ships between items in a dataset. This helps in making the  algorithm more resilient to noise.

2. Related Work  [9] and [10] describe the application of ARM in de-  tecting features in images and videos respectively, with  the help of spatial configurations and local neighborhoods.

The video mining method proposed in [11] builds on local  neighborhoods of quantized local features. [3] is based on  the bag-of-words approach for generic visual categoriza-  tion.

3. I-FAC and Image Classification  This section describes key components of I-FAC for  image classification. SURF points extracted from CP are clustered using FCM clustering, followed by fuzzy  ARM. The fuzzy association rules are then transformed  into fuzzy classification rules during training. For actual  classification, membership values for the SURF points ex-  tracted from a test image are interpolated (using cosine-  similarity) with the centers of the fuzzy clusters gener-  ated previously in the training phase. The classification  is then done by calculating the cumulative fuzzy informa-  tion gain, in conjunction with a threshold ?.

3.1. SURF Point Generation  The first step in I-FAC extracts SURF points from im-  ages in the positive class training dataset, with no nega-  tive class images being used. Assuming we need k fuzzy  clusters, we run FCM (cosine distance metric is used) on  all the n SURF points extracted from the training im-  ages. From the k fuzzy clusters, for each SURF point  we have its membership value (?) in each of the k fuzzy  clusters. The k membership values for each SURF point  are then used to transform SURF-point-based representa-  tion of the images into a fuzzy-cluster-based representa-  tion. Each SURF point is represented as a separate record,  with each record consisting of k cluster (attribute) ids and  corresponding ? pairs <cluster id, ?>, followed by the  positive class label, as shown in Figure 1.

3.2. Fuzzy Association Rule Mining  Subsequently we use the fuzzy ARM algorithm (with  appropriate minimum support) described in [8] to extract  latent patterns in the form of fuzzy association rules from  the fuzzy-cluster-based representation of the SURF points,  as shown in Fig. 1. This algorithm is optimized to ex-  tract rules from very large datasets having many attributes  (high dimensions), which is common in the image domain.

The support supp(I) of an itemset I , in the crisp domain, is defined as the proportion of transactions in the dataset  which contain I . During fuzzy ARM, each of the k dimen-  sions corresponding to k clusters is taken as an attribute.

The membership values of a SURF point in each of the k  clusters provide the values for these k attributes (Fig. 1).

Moreover, support, as defined for crisp association rules,  has been generalized in a suitable way for the fuzzy envi-  ronment [2], [4]. A t-norm T , given by Eq. 1, satisfies the  condition T (x, 1) = x,?x ? [0, 1], with fuzzy sets A and B (in a finite universe D) lying in the range [0, 1]. The  cardinality of a fuzzy set in D is defined by Eq. 2. Using  Equations 1 and 2, we get fuzzy support, defined in Eq. 3.

TM (min) t-norm, the most popular t-norm, has been used  in I-FAC to derive the rule-set R (with m? rules) from the  fuzzy-cluster-based representation of SURF points.

A(x) ?T B(x) = T (A(x), B(x)) (1)  | A |= ?  x?D  A(x) (2)  sup(A ? B) =  | X |  ?  x?D  (A ?T B)(x) (3)  H(Y ) = ?  z ?  i=0  pi log pi (4)  H(Y | X) = ?  Prob(X)H(Y | X) (5)  IG(Y | X) = H(Y ) ? H(Y | X) (6)  3.3. Fuzzy Associative Classifier Training  Entropy and information gain are calculated for each  rule in the rule set R. Given a rule of the form X ? Yi, where X is an itemset composed of varying number of at-  tributes a1, a2, . . . , al, the entropy of X is given by Eq. 4,  where z is the number of classes being considered. Yi is  the class label pertaining to the rule. In the crisp case, the  fraction of records in the dataset where Yi occurs is de-  noted by pi. But, in the fuzzy case, pi of Yi is calculated  by taking the maximum membership value among all at-  tributes (clusters) in each record in which Yi exists. The  average conditional entropy H(Y |X) for Y , with respect to X , is given by Eq. 5. In the fuzzy case, H(Y |X) is calculated using a t-norm (TM t-norm in this case). The  frequency for each record involving Y is a function of the     minimum membership value of all attributes (fuzzy clus-  ters) a1, a2, . . . , al that are involved in X . The informa-  tion gain IG(Y |X) is given by Eq. 6.

ARM generates a large number of rules, most of which  are redundant, and are pruned by I-FAC. The information  gain of each rule and rule length i.e. number of attributes  in each rule, is used for the pruning process. Each rule rq is compared to all rq+1 to r  ?  m rules. A given rule rq (with  information gain IGq and rule length rlq) is pruned (R = R ? rq) if there exists another rule rs (with information gain IGs and rule length rls) which is a superset of rq,  and rlq < rls and IGq < IGs. After pruning, the size of  R reduces from m? to m??.

3.4. Image Classification  The actual classification stage is relatively straightfor-  ward, and is dependent upon the rule set R derived in the  training stage. But before that, we identify all the n? SURF  points in the image being classified. The centers of the k  clusters generated during the training phase are used to  calculate the fuzzy membership of each of the n? SURF  points in each of the k clusters. For each SURF point  s, cosine similarity values are calculated between s and  each of the k cluster centers. The normalized similarity  between each cluster center c and s is denoted as fuzzy  membership value ?sc. Similar procedure is followed for  all the n? SURF points, at the end of which we have a  record (in fuzzy cluster format representation) for each of  the n? SURF points. The membership value ?ij for each  cluster ci in each of the n ? records is aggregated to get one  record cr with cumulative membership values in each of  the k clusters of the whole image (Eq. 7).

Then, each rule r in the rule set R (with m?? rules) is  applied to this cumulative record cr. When r is applied,  we identify each of the t attributes (clusters) that are a part  of the precedent (right hand side of the rule) of r. The  cumulative fuzzy membership value (c?) for each of these  t clusters is extracted from cr. The product (Eq. 8) of  the arithmetic mean of these cumulative fuzzy member-  ship values and the information gain (IG) associated with  r is used to come up with a derived metric we call fuzzy  information gain (FIG). The cumulative fuzzy informa-  tion gain is calculated (Eq. 9) as each rule is applied on  cr. If at the end cumulative FIG ? threshold ?, then the image in question belongs to the positive class, or else  it belongs to the negative class.

?i = n  ?  j=1  ?ij where i = 1 to k (7)  FIG = ?  (IG) (  ?t  i=1 c?i  t  )  (8)  cumulative FIG = m?? ?  f=1  FIGf (9)  4. Performance Study and Results  We have compared I-FAC (with minimum support  supp between 0.005 and 0.05, depending on dataset,  fuzzification factor m = 1.5 and 100 fuzzy clusters) to two  baseline approaches, namely BOW and SVM, both based  on SURF points. The support value relies on how dense  or sparse the dataset is, the number of items (singletons)  involved in the dataset, and the average length of transac-  tions in the dataset ( [15]). In BOW, we count how many  times each visual word in the code-book occurs in an im-  age. A feature vector consisting of weighted frequency  of each ?word? from the bag of words is used for training  and testing. The results for BOW have been taken from  the baseline of [10], which uses 3000 clusters to create  the code-book. To generate a single feature vector per im-  age for SVM (libSV M implementation using RBF ker-  nel) classification, SURF points from an image are com-  bined using Latent Semantic Hashing. FPR-versus-recall  for SVM was calculated using a threshold for the probabil-  ity of positive class. CALTECH Cars (Rear) background  dataset was used as negative training set for BOW and  SVM. I-FAC does not expect any negative class training  set. The other datasets used are:  CALTECH Cars Rear: The positive class training, posi-  tive class test, and negative class test datasets respectively  are cars markus, cars brad, and the first 200 images from  CALTECH-101 background class.

TUD Motorbikes: CALTECH-4 motorbikes, TUD mo-  torbikes, and 200 random images from CALTECH-256  clutter class were used for positive class training, positive  class testing, and negative class testing respectively.

ETHZ Giraffes: Training was done on 93 images of  giraffes downloaded from Google Images. The positive  class test and negative class test datasets were 87 giraffe  images and the rest 168 images respectively from the  ETHZ Shape Classes dataset.

GRAZ Bikes: The positive class training and positive  class test sets respectively are randomly picked 25 and 38  images from the GRAZ bikes dataset. The first 200 im-  ages from CALTECH-101 background class dataset were  used as negative class test set.

CALTECH Faces: 52 randomly picked images from the  CALTECH Human Faces (Front) dataset were used for  each of the positive class training and test sets. The  first 200 images from CALTECH-101 background class  dataset were used as negative class test set.

I-FAC consistently performs well on the basis of FPR-  versus-recall when compared to either BOW (by high mar-  gins on all five datasets) or SVM (by high margins on  three datasets - Cars, Faces, and Giraffes, and by rea-  sonable margins on the remaining two datasets - Fig. 2).

It especially performs very well at low FPRs (? 0.3), which is highly desirable for an image classifier. The per-  formance of I-FAC can be attributed to two broad rea-  sons. First, its fuzzy nature helps avoid polysemy and     synonymy, which are common problems with BOW. Sec-  ond, SVM has to deal with a lot of noise in the train-  ing images, which hampers the creation of a clear hyper-  plane, affecting the assignment of probability with which  the positive class occurs in a given image. This problem  does not occur in I-FAC which uses only the positive class  for training, and makes a classification decision based on  cumulative FIG in conjunction with a threshold ?. For  each dataset, ? has been determined by cross-validation  on the respective positive and negative classes test sets.

The variation in ? influences the variation of FPR-versus-  recall curve for I-FAC in each dataset. Fig. 3 shows FPR-  versus-recall variation as number of clusters and m of  FCM is varied (for the Cars dataset), with best results  achieved when 100 clusters and m = 1.5 were used. At m = 1.001(m ? 1), FCM reduces to k-means, i.e. crisp clustering. Higher values of m (e.g. m = 2) gave worse results than those shown in Fig. 3.

