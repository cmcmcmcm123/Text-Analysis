

Abstract. With the ever-growing database sizes, we have enormous quantities of data, but unfortunately we cannot use raw data in our day-to-day reasoning/decisions. We desperately need knowledge. This knowledge is in most cases in the gathered data, but the extraction of it is a very time and resources consuming operation. In this paper we propose an improvement of the FP-Growth algorithm that focuses on applying a pattern-length constraint on the FP-Growth algorithm. This is, mining only frequent patterns with their length belonging in an interval selected by the user. The algorithm with this constraint applied can be used when only patterns with specific lengths are interesting for the user. The main advantage of running the algorithm with the length limitation instead of the classic FP-Growth algorithm is that the running time of the former is smaller, thus, the required information can be obtained in a shorter time.

Keywords: Data Mining, frequent pattern, FP-tree

I. INTRODUCTION    The term Data Mining, or Knowledge Discovery in  Databases, has been adopted for a field of research dealing with the automatic discovery of implicit information or knowledge within databases [7]. High performance is a key factor for data mining systems in order to allow a sufficient exploration of data and to cope with the huge amounts of data.

The implicit information within databases, and mainly the interesting association relationships among sets of objects, that lead to association rules, may disclose useful patterns for decision support, financial forecast, marketing policies, even medical diagnosis and many other applications. This fact has attracted a lot of attention in recent data mining research [7]. As shown in [1], mining association rules may require iterative scanning of large databases, which is costly in processing.

A very influential association rule mining algorithm, Apriori [1], has been developed for rule mining in large transaction databases. Many other algorithms developed are derivative and/or extensions of this algorithm. A large step forward in improving the performances of these algorithms was made by introduction of a novel, compact  data structure, called frequent pattern tree, or FP-tree [2], and the associated mining algorithms, FP-growth [2].

The main difference between the two is that the Apriori- like techniques are based on bottom-up generation of frequent itemset combinations and the FP-tree based ones are partition-based, divide-and-conquer methods.

FP-Tree?s efficiency of mining is achieved with three techniques: (1) a large database is compressed into a highly condensed, much smaller data structure, which avoids costly, repeated database scans, (2) FP-tree-based mining adopts a pattern fragment growth method to avoid the costly generation of a large number of candidate sets, and (3) a partitioning-based, divide-and-conquer method is used to decompose the mining task into a set of smaller tasks for mining confined patterns in conditional databases, which dramatically reduces the search space. The FP- growth method is efficient and scalable for mining both long and short frequent patterns, and is about an order of magnitude faster than the Apriori algorithm and also faster than some recently reported new frequent pattern mining methods.

In this paper we propose a new variant of the FP-Growth  Algorithm that focuses on applying a pattern-length constraint on the FP-Growth algorithm. This is, mining only frequent patterns with their length belonging in an interval selected by the user. The algorithm with this constraint applied can be used when only patterns with specific lengths are interesting for the user; for example, if a supermarket owner wants to know the effects of a special offer consisting of two products on the other related products, he might only be interested in patterns of length 3 or 4. The main advantage of running the algorithm with the length limitation instead of the classic FP-Growth algorithm is that the running time of the former is smaller, thus, the required information can be obtained in a shorter time.



II. PROBLEM DEFINITION   Association rule mining finds interesting association or correlation relationships among a large set of data items [8].  The association rules are considered interesting if they      SOFA 2009 ? 3rd International Workshop on Soft Computing Applications ? 29 July ? 1 August ? Szeged (Hungary) ? Arad (Romania)  satisfy both a minimum support threshold and a minimum confidence threshold [3].

A more formal definition is the following [4]. Let  = {i1, i2, ?, im} be a set of items. Let D, the task-relevant data, be a set of database transactions where each transaction T is a set of items such that T  . Each transaction is associated with an identifier, called TID. Let A be a set of items. A transaction T is said to contain A if and only if A  T. An association rule is implication of the form A  B, where A  , B  , and A  B = . The rule A  B holds in the transaction set D with support s, where s is the percentage of transactions in D that contain A  B (i.e., both A and B). This is taken to be the probability, P(A  B). The rule A  B has confidence c in the transaction set D if c is the percentage of transactions in D containing A that also contain B. This is taken to be the conditional probability, P(B|A). That is,   support(A  B) = P(A  B)   (1) confidence(A  B) = P(B | A)  (2)   The definition of a frequent pattern relies on the following considerations [5]. A set of items is referred to as an itemset (pattern). An itemset that contains k items is a k- itemset. The set {name, semester} is a 2-itemset. The occurrence frequency of an itemset is the number of transactions that contain the itemset. This is also known, simply, as the frequency, support count, or count of itemset. An itemset satisfies minimum support if the occurrence frequency of the itemset is greater than or equal to the product of minimum support and the total number of transactions in D. The number of transactions required for the itemset to satisfy minimum support is therefore referred to as the minimum support count. If an itemset satisfies minimum support, then it is a frequent itemset (frequent pattern).

The most common approach to finding association rules is to break up the problem into two parts [6]:  1. Find all frequent itemsets: By definition, each of these itemsets will occur at least as frequently as a pre-determined minimum support count [8].

2. Generate strong association rules from the frequent itemsests: By definition, these rules must satisfy minimum support and minimum confidence [8].

Additional interestingness measures can be applied, if desired. The second step is the easier of the two. The overall performance of mining association rules is determined by the first step. As shown in [2], the performance, for large databases, is most influenced by the combinatorial explosion of the number of possible frequent itemsets that must be considered and also by the number of database scans that has to be performed. The first of these problems seems to be resolved by employing a special compact data structure, FP-tree, and related algorithms, FP- growth, for the effective mining of frequent itemsets [2], but the second problem still holds for large databases.

Based on these facts, in this paper we propose a technique that improves on the performances of FP-tree based algorithms, by reducing the number of database scans from 2 to just a single scan and applying pattern length constraints to further reduce the processing time.



III. ALGORITHM IMPLEMENTATION  The implementation of the algorithm uses some  techniques described in [4] for building the FP-tree, such as storing the relations in the tree from a node to its parent instead of from a node to its children. Because pointers slow the execution speed of a program, the usage of pointers has been avoided, and the fact that each node has to store just the link to its parent allowed the application of this technique; instead of storing a dynamic list of children for each node, a vector of parents has been used to store the parent of each node in the tree.

Building the FP-Tree   This step is a very important one in the FP-Growth  algorithm, since the tree stores the transactions in a compressed manner, and the mining operations will be applied only on this tree once it has been constructed. The construction of the tree is done in 4 steps:  1. Reading the data. First, the transactions are read from an input file, the frequency of each individual item is counted, and all the transactions are stored in a dynamically allocated memory. The transactions have to be stored in computer?s memory for usage in the next steps. The input file is parsed for faster processing time.

2. Sorting the items in the transactions. In this step, the items in each individual transaction are sorted descending by their frequency of appearance. The algorithm used for sorting the items is quick-sort. Also, the items whose frequency is too small are removed.

3. Sorting the transactions lexicographically. The transactions are sorted lexicographically, with the shortest transactions coming first (i.e. the transaction ?abc? comes before ?abca?). This step is required because of the method that is used to construct the FP-Tree in the next step of the algorithm. Radix sort is used to sort the transactions, with a time complexity of O((N+E)*maxLength), where N is the number of transactions, E is the number of distinct items, and maxLength is the maximum length of a transaction.

This step runs fast considering that in most cases maxLength << logN and N / (N+E) ?1. After this step, at a closer look it can be seen that the structure of the FP-Tree is already defined, and all that remains is to build it.

4. Building the FP-Tree. To build the FP-Tree, the recursive technique described in [4] is used: at recursion step K, the k-th item in each transaction is used to split the database into sections, one for each item. This can be done easily because the transactions have been sorted lexicographically in the previous step. To build the FP-tree,     Cornelia Gy?r?di, Robert Gy?r?di, Mihail Der?idan, Livia Bandici ? Applying a pattern length constraint on the FP-Growth algorithm  at each step k, we process an interval [a,b], such that according to the lexicographic order of the transactions obtained at the previous step, in the interval [a,b] on level k-1 of the transactions there is just one item type present.

This item will be the parent node for all the nodes that we will obtain at this step, with the stored frequency equal to b-a+1. Knowing that the transactions are stored lexicographically, and that on level k-1 in the interval [a,b] we have only one item type, we can see that on level k in the interval [a,b] the items are sorted ascending by their id (this also means that items with the same id are grouped together ).  Considering that on level k we have m unique items, we will obtain m different intervals, which we will then process on step k+1 of the recursion; we will also add m nodes to the FP-Tree, each having as parent the unique item from step k-1 on interval [a,b]. To divide the interval [a,b] into m intervals, we use binary search. A visual explanation of how this step of the algorithm works is presented below:      Fig.1.The construction of FP-tree   Pattern Mining   The process of mining the frequent patterns is based on the classic FP-Growth. The main difference appears in the generation of combinations (line 5), where only combinations of a specific length are generated. The execution of the mining process is also stopped when the length of the current pattern (alpha) is greater then maxlength. Below is presented the pseudocode of the data mining.

Fig.2.The pseudocode of the modified  FP-Growth procedure   Test Results   Here are some graphical representations of the obtained results when running the algorithm on databases with different number of items and different threshold values.

On the Y axis is represented the running time of the algorithm in seconds, and on the X axis the length of the searched patterns. The red line represents the tests where the support threshold was 1%, and the blue line represents the tests with a 1.5% support threshold. The number of items in the file used for testing the algorithm is 100000. It can be clearly noticed that when mining patterns with a smaller length the program runs significantly faster than when mining for all the frequent patterns (the maximum length of a pattern in the input file was 20).

The results from Figure 3 show that the FP-Growth algorithm has a good performance, only for a smaller length patterns, (length pattern<10) with a small support threshold (less than 1.5%).

Red line ? 1% support threshold Blue line ? 1.5% support threshold  0.00  5.00  10.00  15.00  20.00  25.00  30.00  1 2 3 4 5 6 7 8 9 10 All  pattern length  ti m  e( s) 1.5%  1%  Fig. 3. Scalability of the FP-Growth algorithm function of the pattern length  0.00  20.00  40.00  60.00  80.00  100.00  120.00  10 20 30 40 50 60  number of transactions(K)  ti m  e( s)  FP-Growth with pattern length constraint  classic FP-Growth   Fig. 4. FP-Growth with pattern length constraint versus the classic FP-  Growth     SOFA 2009 ? 3rd International Workshop on Soft Computing Applications ? 29 July ? 1 August ? Szeged (Hungary) ? Arad (Romania)   The results from Figure 4 show that the FP-Growth  algorithm with constant pattern length equal 4 has a good performance compared with the classic FP-Growth algorithm on databases with different number of transaction for a constant support threshold. The execution time for the classic FP-Growth algorithm increases dramatically for a larger database, while the FP-Growth algorithm with constant pattern length has a considerably smaller execution time.

1 2 3 4 5 6 8 10 All  pattern length  ti m  e( s)  FP-Growth with pattern length constraint  classic FP-Growth   Fig. 5. Pattern length constraint FP-Growth (blue) with variable patterns length versus the classic FP-Growth (red)   In Figure 5 we compared the FP-Growth algorithm with pattern length constraint with classic FP-Growth algorithm using different pattern lengths on the same database. This comparison shows again that placing pattern length constraint can dramatically decrease the execution time.

1.5 1.4 1.3 1.2 1.1 1.05 1 0.95 0,9 threshold(%)  tim e(  s)  FP-Growth with pattern length constra int  class ic FP-Growth   Fig. 6. FP-Growth with pattern length constraint versus the classic FP- Growth with different threshold values   Running the pattern-length constraint FP-Growth versus the classic FP-Growth algorithm on the same data file with  different threshold values results in the same behaviour which is illustrated in figure 6.



IV. CONCLUSION   Our variant of the FP-Growth algorithm focuses on applying a pattern-length constraint on the FP-Growth algorithm. This is, mining only frequent patterns with their length belonging in an interval selected by the user. The algorithm with this constraint applied can be used when only patterns with specific lengths are interesting for the user; for example, if a supermarket owner wants to know the effects of a special offer consisting of two products on the other related products, he might only be interested in patterns of length 3 or 4. The main advantage of running the algorithm with the length limitation instead of the classic FP-Growth algorithm is that the running time of the former is smaller, thus, the required information can be obtained in a shorter time.



V. REFERENCES  [1] R. Agrawal, R. Srikant. ?Fast algorithms for mining association rules in large databases?. Proc. of 20th Int?l conf. on VLDB: 487-499, 1994.

[2] J. Han, J. Pei, Y. Yin. ?Mining Frequent Patterns without Candidate Generation?. Proc. of ACM-SIGMOD, 2000.

[3] C. Gy?r?di, R. Gy?r?di. ?Mining Association Rules in Large Databases?. Proc. of Oradea EMES?02: 45-50, Oradea, Romania, 2002.

[4] Christian Borgelt: An implementation of the FP- Growth Algorithm, http://www.borgelt.net/papers/fpgrowth.pdf [5] C. Gy?r?di, R. Gy?r?di, S. Holban, M. Pater. ?Mining Knowledge in Relational Databases?. Proc. of CONTI Informatics: 1-6, Timisoara, Romania, 2002.

[6] M. H. Dunham. ?Data Mining. Introductory and Advanced Topics?. Prentice Hall, 2003, ISBN 0-13- 088892-3.

[7] U.M. Fayyad, et al.: ?From Data Mining to Knowledge Discovery: An Overview?, Advances in Knowledge Discovery and Data Mining:1-34, AAAI Press/ MIT Press, 1996, ISBN 0-262-56097-6.

[8] J. Han, M. Kamber, ?Data Mining Concepts and Techniques?, Morgan Kaufmann Publishers, San Francisco, USA, 2001, ISBN 1558604898.

