GLFMiner: Global and Local Frequent Pattern  Mining with Temporal Intervals

Abstract?In this paper, we propose a new approach of mining temporal association rules. In conventional association rule mining algorithms, if the value of minimum support is set too high, we may lose lots of valuable rules. But if it is set too low, many trivial rules will be mined, and it is hard to distinguish which ones are valuable. When taking temporal factors into consideration, an itemset may not be frequent over the entire database but may be frequent in some specific intervals. Here, we propose a temporal association rule mining algorithm for interval frequent patterns, called GLFMiner, which can automatically generate all of the intervals without using any domain knowledge.

In our algorithm, we consider not only global frequent patterns but also local frequent patterns. Then, with the same value of minimum support, we can find plenty of valuable temporal rules and don?t lose any rule that conventional association rule mining algorithm can find. The experimental results show that our algorithm can mine more temporal frequent patterns than the conventional association rule mining algorithm.

Keywords- association rule; local frequent pattern; global frequent pattern; temporal frequent pattern

I. INTRODUCTION The problem of mining association rule is to discover all  rules that have support and confidence greater than or equal to the user-defined minimum support and minimum confidence thresholds. For example, examining the dataset of a supermarket, we may get an association rule like  Turkey Pumpkin pie (support=0.01%, confidence=5%)  which means that 0.01% of all transactions contain both turkey and pumpkin pie, and 5% of all transactions which contain turkey also contain pumpkin pie.

In fact, we can not regard the above rule as a prominent association rule due to the following two reasons. First, the support of that rule is low. It means that the turkey and pumpkin pie seldom coexist in the entire dataset. Second, the confidence of that rule is low too. It means that a large number of transactions which contain turkey do not contain pumpkin pies. However, if we only look at the transactions in a specific time interval, for example the week before Thanksgiving, it can be found that most of the transactions contain both turkey and pumpkin pie. It means that the rule, turkey pumpkin pie, has a high support and a high confidence in the specific interval, the week before Thanksgiving.

From the above example, an itemset may not be frequent for the entire database but may be frequent in some specific intervals. We can realize there are lots of meaningful frequent patterns which can be found in some specific intervals.

Therefore, it is important on how we can find these intervals of frequent patterns in an effective manner. In [4], Yingjiu proposed the calendar based script to find the time interval, but it has to devise the calendar based script by using domain knowledge. Here, we expect to automatically generate the intervals without any domain knowledge. Our proposed GLFMiner algorithm first transforms the database into a bit- map representation, and then recursively joins (k-1) itemsets to generate k itemsets in depth-first order. After joining the itemsets, GLFMiner will generate the intervals of frequent itemsets.

The frequent patterns mined from the conventional association rule mining algorithms are called global frequent patterns. There is a problem which may lead the user to make a wrong decision according to these association rules. For example, a shopkeeper mines an association rule, diaper beer, and then he/she may promote a sale package, 10% discount for buying beer and diaper together, in the winter. The promotion is doomed to failure. The main reason is that one does not know when is the right time to apply the rule ?diaper beer?. Most people like to drink beer in the summer, so ?diaper beer? may be suitable for the summer not winter. From the above example, it is important to generate the association rule which contains specific interval to be applied for the best result. Using GLFMiner algorithm we can not only get the frequent patterns of specific intervals, but also generate all the specific intervals for these local frequent patterns.

The rest of paper is organized as follows. In Section II, we will describe the temporal association rule mining problem and introduce the related work of temporal association rule mining. In Section III, the proposed GLFMiner algorithm is described in three folds: (1). read the database and transform transactions into the bit-map representation, (2). localize the bit-map representations of all items to form intervals, (3).

recursively join (k-1) itemsets to generate k itemsets and find local and global frequent itemsets. In Section IV, experimental results of synthetic datasets are given. Finally, we make a conclusion in Section V.

This research was supported by the National Science Council, Taiwan, under grants NSC 98-2221-E-035-059-MY2 and NSC 98-2218-E-007-005.



II. BACKGROUND AND RELATED WORK In past decades, various algorithms have been proposed to  efficiently discover the frequent itemsets in different applications. These methods include level-wise algorithms [1,2,3] and pattern-growth methods [4,5].

Temporal association rule mining is an extension of association rule generation. There are many temporal association rule mining algorithms being proposed recently.

They can mine more meaningful frequent patterns, temporal association rules of intervals and up-to-date association rules, than conventional association rule mining algorithm. We will introduce the related studies in the following.

Hong [6] addressed the up-to-date association rule. The main idea comes from that an itemset may not be frequent for an entire database but may be large up-to-date since the items seldom occurring early may often occur later. An up-to-date pattern is composed of an itemset and its up-to-date lifetime, in which the user-defined minimum support threshold must be satisfied.

It is possible to find interesting associations with a high confidence level but with small support. Ale [7] limited the total transactions to the ones belonging to the items' lifetime, those associations would be now discovered, as they would count on enough support. He expanded the notion of association rules incorporating time to the frequent itemsets.

Every item has a period of lifetime or lifespan in the database, which explicitly represents the temporal duration of the item information, i.e. the time in which the item is relevant to the user.

Lee [8] explored a new problem of mining general temporal association rules in publication databases. A publication database is a set of transactions where each transaction is a set of items of which each item contains an individual exhibition period. The author claimed that the current model of association rule mining is not able to handle the publication database due to the following fundamental problems, i.e., (1) lack of consideration of the exhibition period of each individual item; (2) lack of an equitable support counting basis for each item. He proposed a PPM algorithm.

The basic idea of PPM is to first partition the publication database in light of exhibition periods of items and then progressively accumulate the occurrence count of each candidate 2-itemset based on the intrinsic partitioning characteristics.

Tsai [9] proposed a new framework for data stream mining, called the weighted sliding window model. The proposed model allows the user to specify the number of windows for mining, the size of a window, and the weight for each window.

It emphasized the temporal factor and gave higher weight to recently happened events.

Li [10] studied the problem of mining association rules and related time intervals, where an association rule holds either in all or some of the intervals. To restrict to meaningful time intervals, he uses calendar schemas and their calendar-based patterns. A calendar schema example is (year, month, day) and a calendar-based pattern within the schema is (*, 3, 15), which  represents the set of time intervals each corresponding to the 15th day in March.

[10,11] assume that the transactions are time-stamped, so one can decide if a transaction occurs during a specific time interval. The others [6,7,8,9] don?t make this assumption.

In GLFMiner, we don?t assume the transaction is time stamped and use the transaction sequence as the temporal factor to generate all the intervals of itemsets. Our main contribution is that it can not only find out global frequent patterns in the whole database, but also discover local frequent patterns within the specific intervals.



III. ALGORITHM DESCRIPTION  A. Notation and definitions DB The database DB  |DB| The number of transactions in the database DB |DBi| The total number of transactions in the interval i of DB  T( ) The transactions containing  in the database DB Ti ( ) The transactions containing  in the specific interval i of DB  MinSup The minimum support threshold  MinLen The minimum length of an interval threshold  A frequent pattern is an itemset whose frequency in DB is larger than or equal to MinSup. Here, we propose the concept of local and global frequent patterns. GLFMiner performs a search for frequent pattern sets over a novel Interval-tree search space which is shown in Fig. 8. Each node in the Interval-tree, represented by an itemset-interval-tidset-count data structure, is in fact a prefix-based class. All the children with length k of a given node belong to its class since they all share the same prefix .

So, all the children in the same class can be joined to form (k+1) frequent patterns. Now, we show some definitions that will be used in the proposed algorithm later.

Table 1 An example dataset Tid Transaction Time Items 1 2009/7/1  a,b,d,f 2 2009/7/16 a,b,d,f 3 2009/8/3 d,f 4 2009/8/9 c,f 5 2009/9/10 a,f 6 2009/9/30 f 7 2009/10/3 c,e 8 2009/10/18 a,b,c 9 2009/11/8 a,b,c,d,e  10 2009/11/27 a,f  Definition 1: Interval-tree={Node1, Node2, ?, Noden}.

Interval-tree is a prefix based tree. The root node of Interval-tree is null. If Noden is the parent of Nodem, |Nodem|=|Noden|+1 and Noden is the prefix of Nodem.

Definition 2: The structure of a node for itemset  in the Interval-tree is defined as follows:  Struct {  2010 5th IEEE Conference on Industrial Electronics and Applicationsis 2249    Itemset TidSegmentSet }  where Itemset records frequent pattern  and each TidSegment records information of intervals. TidSegmentSet is the set of all TidSegments.

Interval information contains [begin,end](bitmap):count, where [begin,end] represents an interva .begin is the first transaction id in this interval, .end is the last transaction id in this interval; .bitmap is a consecutive number of 1 and 0 where 1 represents the corresponding transaction contains and 0 represents the corresponding transaction does not contain ; and .count is the number of the transactions which contain . For example, in Table 1, a[1,10](1100100111):6 represents that itemset ?a? appears in the interval [1,10], the corresponding bitmap is (1100100111) and the frequency of occurrence is 6. ab[1,2](11):2,[8,9](11):2 represents that itemset ?ab? appears in two intervals: [1,2] and [8,9].

Definition 3: An itemset  is called a global frequent pattern in a database DB if:  (1) Support ( ) = |T( )|/|DB| (2) Support ( ) ?MinSup  The definition of global frequent patterns is the same as the definition of frequent patterns of conventional association rule mining algorithm. For example, based on the MinSup=0.5, item ?a?[1,10] in Table 1 is a 1-global frequent itemset for the entire database, where the first transaction containing ?a? is 1 and the last transaction containing ?a? is 10.

Definition 4: An itemset  is called a local frequent pattern in a database DB if:  (1) Support ( ) = |Ti( )|/|DBi| (2) Support ( ) ?MinSup  Giving a MinSup, local frequent patterns represent the patterns whose counts are larger than MinSup just for the specific intervals. For example, if MinSup=0.5, itemset ?e? is a 1-local frequent itemset in the interval i=[7,9], because |Ti(e)|=2, |DBi|=3 and |Ti(e)|/|DBi|=0.67. However, it is not a global frequent itemset for MinSup=0.5.

Definition 5: Two consecutive intervals are called mergeable if and only if the following condition is met:  MinSupbeginend countcount  nn  nn ?+? +  ?  ? 1..

..

??  ??  where n-1[begin,end]:count and n[begin,end]:count are two consecutive intervals of .

For example, c[4,4](1):1, c[7,9](111):3, MinSupbeginend  countcount ?== +? +  +? + 67.0149  1..

..

??  ??  , they are called mergeable.

Definition 6: The merge of consecutive intervals is defined as follows:  Merge( n-1, n)= n-1 [begin,end](bitmap):count, where n-1[begin,end](bitmap):count and n[begin,end](bitmap):  count are two consecutive intervals of  to be merged, then n-1.begin= n-1.begin, n-1.end= n.end, n-1.count=( n-1. count  + n.count), and bitmap is adjusted accordingly.

For example, two intervals: cn-1[4,4](1):1, cn[7,9](111):3, Merge(cn-1,cn)=cn-1[4,9](100111):4, where cn-1.begin=cn-1.begin =4, cn-1.end= cn.end=9, cn-1.count=( cn-1.count+ cn.count)=(3+1) =4.

Definition 7: The minimum length of an interval is denoted as MinLen.

If the length of an interval is less than MinLen, it means this interval is not prominent enough. Then it will be deleted.

For example, the length of an interval is 1, the support of this interval is 100% and the confidence is 100% too. Since it is meaningless at all, we can regard it as a noise and delete it.

Definition 8: The nodes of itemset  and itemset  are called joinable, if and only if both the nodes  and have the same parent node in the Interval-tree.

Definition 9: The join of the nodes of itemset  and itemset is defined as follows  [begin,end](bitmap) join( [begin,end](bitmap), [begin,end](bitmap))  where as in the traditional definition of join.

.begin=Max( .begin, .begin)  .end=Min( .end, .end)  .bitmap=AND( [ .begin, .end].bitmap, [ .begin, .end].bitmap )  If ( .begin>= .end), it means that the intervals of itemsets and  are disjoined. Then, the node of itemset  will be discarded.

For example, [begin,end](bitmap)=join( ab[1,2](11), af[1,5](11001)=abf[1,2](11) = {a,b} {a,f}={a,b,f} .begin=Max(1,1)=1 .end=Min(2,5)=2 .bitmap=AND ( ab[1,2].(11), af[1,2].(11) )=AND(11,11)=11.

B. Main Algorithm The proposed algorithm is composed of two main steps.

First, it scans the database to find out the global frequency of each item and transforms all items into bit-map representation to speed up the following processing. Then, it localizes each item that is not global frequent and adds them to the Interval- tree.

Second, it recursively joins each item in depth-first order on the Interval-tree. After that, it localizes the joined itemset to find out the frequent intervals and add them to the Interval- tree. Those frequent intervals are output as temporal frequent itemsets. The pseudo code of GLFMiner algorithm is described in Fig. 1. In the following section, we will illustrate the detail steps of GLFMiner.

2250 2010 5th IEEE Conference on Industrial Electronics and Applicationsis      Main_Algorithm Input: (1) DB_File (2) MinSup (3) MinLen Output:(1) Global and Local Frequent ItemSet Begin 1)  RootNode=ScanDataBase(DB_File, MinSup, MinLen); 2)  FreqSet = RecursiveJoin(RootNode); End  Fig. 1 The main algorithm of GLFMiner  Function ScanDatabase Input:  (1) DB_File (2) MinSup (3) MinLen Output: (1) m_RootNode Begin 1)   m_RootNode  Create Root Node 2)   Candidate_Items  getItemFrequency (DB_File) 3)   for (each item in Candidate_Items) 4)     Begin 5)        If not global frequent 6)          Localize (Candidate_Items) 7)        If IsFrequent (Candidate_Items, MinSup, MinLen) 8)          m_RootNode.addChild (Candidate_Items); 9)     End 10)  Return m_RootNode End  Fig. 2 The pseudo code of ScanDatabase  Step 1: At first, GLFMiner scans the database, transformsds all items into bit-map representation and gets the frequency of each item to check whether it is global frequent. If it is not global frequent, Localize function is used to get local frequent intervals. The pseudo code of ScanDatabase is listed in Fig. 2. By using the dataset of Table 1 with MinSup=0.5, the bitmap representation of item ?a? is (1100100111) as shown in Fig. 3.  Because the count of item ?a? is 6 and is larger than MinSup |DB|=0.5 10=5, ?a? is a global frequent itemset. The bitmap representation of item ?b? is (1100000110). Since the count of item ?b? is 4 and is less than the MinSup threshold, ?b? is not a global frequent itemset and has to be localized.

a(1100100111), b(1100000110), c(0001001110), d(1110000010), e(0000001010), f(1111110001)  Fig. 3 The bitmap representation of items  Function Localize Input: (1) Node Begin 1) TIDSegmentSet = Partition (TIDSet(Node), MinSup) 2) TIDSegmentSet = MergeSegmentSet (TIDSegmentSet, MinSup) 3) TIDSegmentSet = PruneSmallThanMinLen (TIDSegmentSet) End  Fig. 4 The pseudo code of Localize  Step 2: Localize those intervals of items which are not global frequent. Localization contains three steps as shown in Fig. 4.

First, it partitions the bitmap representation of an itemset to find out the frequent intervals of that itemset. Then, it checks whether the two consecutive intervals can be merged in order to form a larger frequent interval. At last, it prunes the intervals whose lengths are less than MinLen.

Function Partition Begin 1)For each bitmap of Itemset ti 2)  k=1; Interval[1].begin==0  3)  For j=1 to n //n=the length of the interval { 4)    if (bitmap[j]=1) { 5)      if (Interval[k].count==0 ) { 6)          Interval[k].begin=j; 7)          Interval[k].count=1; } 8)      else { 9)          Interval[k].count++; 10)          Interval[k].end=j;  } }} 11)   else { 12)     if (Interval[k].count/(i-Interval[k].begin)<MinSup) and  (Interval[k].count  0) { 13)           Add_A_New_Interval_for_ti 14)           k++ 15)           Interval[k].count= 0 }}} End  Fig. 5 The pseudo code of Partition  Step 2-1: Partition the bitmap representation of an itemset. The related pseudo code is described in Fig. 5. For example, itemset ?d? is not a global frequent itemset, and the bitmap representation of itemset ?d? is (1110000010). The procedure of partitioning itemset ?d? is shown in Table 2.

Table 2 Partitioning the intervals of Itemset ?d? n Bit Interval  Action 1 1 d[1,1]:1 1/0.5=2  (1-1+1) 2 1 d[1,2]:2 2/0.5=4  (2-1+1) 3 1 d[1,3]:3 3/0.5=6  (3-1+1) 4 0 d[1,3]:3 3/0.5=6  (4-1+1) 5 0 d[1,3]:3 3/0.5=6  (5-1+1) 6 0 d[1,3]:3 3/0.5=6  (6-1+1) 7 0 d[1,3]:3 3/0.5=6 < (7-1+1) Add A New Interval 8 0   Skip 9 1 d[9,9]:1 1/0.5=2  (9-9+1)  10 0 d[9,9]:1 1/0.5=2  (10-9+1) Add A New Interval  Step 2-2: Merge the two consecutive intervals into a larger interval from the back to the front. The pseudo code is described in Fig. 6. Taking c1[4,4](1):1 and c2[7,9](111):3 for example (cn-1=c1 and cn=c2), because (c1.count+c2.count)/ (c2.end-c1.begin+1)=(1+3)/(9-4+1)=4/6>MinSup, c1[4,4](1):1 and c2[7,9](111):3 are merged into c1[4,9](100111):4.

Function MergeSegmentSet (TIDSegmentSet, MinSup) Input: (1) SegmentList,(2) MinSup Output: TIDSegmentlSet Begin 1)   n =|SegmentList | -2 2)   While(n>=0) 3)        if mergeable (Segmentn,Segmentn+1) 4)            SegmentList.remove (Segmentn+1) 5)            Segmentn= merge (Segmentn,Segmentn+1) 6)            if n == |SegmentList|-1 7)                n--; 8)       else 9)            n--; End  Fig. 6 The pseudo code of MergeSegmentSet  Step 2-3: Prune the intervals whose length are less than MinLen in order to remove trivial intervals. For example, if MinLen=0.2 and the length of d2[9,9]:1 is 1 which is less than 0.2 10=2, d2[9,9]:1 will be removed.

2010 5th IEEE Conference on Industrial Electronics and Applicationsis 2251    Step 3: Recursively join the itemsets in depth-first (DF) order from the root. The pseudo code is described in Fig. 7. The node of length (k-1) joins all the right siblings to generate the combined itemset of length k. Every joining procedure contains the following steps.

Step 3-1: Node 1 joins Node 2 (right sibling). For example, SonNode =a[1,10](1100100111):6 joins b[1,2](11):2  ab[1,2](11):2 SonNode =a[1,10](1100100111):6 joins b[8,9](11):2  ab[8,9](11):2  Step 3-2: Localize SonNode.

Step 3-3: If SonNode is frequent, add it as a child of Node 1.

Step 3-4: Add Node 1 to Frequent set FreqSet.

Function RecursiveJoin Input:  (1) ParentNode Output: (1) FreqSet Begin 1)for (each node1ParentNode ) 2)  Begin 3)     for (each node2  Right Siblings of node1 ) 4)        Begin 5)           SonNode = node1.Join(node2) 6)           If not global frequent 7)               Localize (Candidate_Items) 8)           If isFrequent (SonNode) Then 9)               node1.addChild (SonNode) 10)      End 11)   FreqSet=FreqSet node1 12)   FreqSet=FreqSet RecursiveJoin (node1) 13)   ParentNode.RemoveChild (node1) 14) End End  Fig. 7 The pseudo code of RecursiveJoin  C. A Complete Example Step 1: GLFMiner transforms each item in DB into bitmap  representation.

Step 2: Perform localization Repeat  Step 3-1: Node 1 joins Node 2 Step 3-2: Localize SonNode Step 3-3: If SonNode is frequent, add it as a child of Node 1 Step 3-4: Add Node 1 to Frequent set FreqSet.

Table 3 shows the part of procedure when deploying GLFMiner to mine the dataset of Table 1. Here, it just lists the construction procedure of the leftmost branch of the Interval- Tree. The complete Interval-tree is shown in Fig. 8.

Table 3 The part of procedures of deploying GLFMiner  Step  Bitmap representations of every item a(1100100111):6, b(1100000110):4, c(0001001110):3, d(1110000010):4, e(0000001010):2, f(1111110001):8  Step 2-1 Partition a[1,10](1100100111):6, b[1,2](11):2, b[8,9](11):2,c[4,4](1):1, c[7,9](111):3, d[1,3](111):3, d[9,9](1):1, e[7,9](101):2, f[1,10](1110110101):7  Step 2-2 Merge a[1,10](1100100111):6, b[1,2](11):2, b[8,9](11):2, c[4,9](100111):4, d[1,3](111):3, d[9,9](1):1, e[7,9](101):2, f[1,10](1111110001):7  Step 2-3 Prune a[1,10](1100100111):6, b[1,2](11):2, b[8,9](11):2, c[4,9](100111):4, d[1,3](111):3, e[7,9](101):2, f[1,10](1111110001):7  Step 3-1 Join(a,*) ab[1,2](11):2, ab[8,9](11):2, ac[8,9](11):2, ad[1,2](11):2, af[1,10](1100100001):5  Step 3-2 Localize ab[1,2](11):2, ab[8,9](11):2, ac[8,9](11):2, ad[1,2](11):2, af[1,5](11001):3  Step 3-3 Add node ab[1,2](11):2, ab[8,9](11):2, ac[8,9](11):2, ad[1,2](11):2, af[1,5](11001):3  Step 3-4 Add to Frequent set ab[1,2](11):2, ab[8,9](11):2, ac[8,9](11):2, ad[1,2](11):2, af[1,5](11001):3  Step 3-1 Join(ab[1,2],*) abd[1,2](11):2, abd[8,8](1):1, abf[1,2](11):2, abf[8,8](1):1 Step 3-2 Localize abd[1,2](11):2, abf[1,2](11):2 Step 3-3 Add node abd[1,2](11):2, abf[1,2](11):2 Step 3-4 Add to Frequent set abd[1,2](11):2, abf[1,2](11):2  Step 3-1 Join(abd[1,2],*) abdf[1,2](11):2 Step 3-2 Localize abdf[1,2](11):2 Step 3-3 Add node abdf[1,2](11):2 Step 3-4 Add to Frequent set abdf[1,2](11):2  Step 3-1 Join(abdf[1,2],*) Step 3-1 Join(abf[1,2],*)  Step 3-1 Join(ab[8,9],*) abc[8,9](11):2 Step 3-2 Localize abc[8,9](11):2 Step 3-3 Add node abc[8,9](11):2 Step 3-4 Add to Frequent set abc[8,9](11):2  Fig.8 The complete Interval-tree of Table 1  2252 2010 5th IEEE Conference on Industrial Electronics and Applicationsis

IV. EXPERIMENTAL RESULTS We implemented our algorithm in JAVA on an Intel Core  Duo Processor personal computer with 1.99 GHz and 4 GB RAM. The synthetic database of IBM dataset generator, T10I4D100K was used. In T10I4D100K, the size of a transaction is 10, the size of potential maximal frequent itemsets is 4, and the number of transactions is 100,000  GLFMiner algorithm was compared to the conventional association rule mining algorithm of Apriori without considering temporal intervals. In the first experiment, the relationship between the numbers of frequent patterns for different minimum support thresholds is shown in Fig. 9. Fig. 9 shows the results of T10I4D100K with MinLen=0.01 and MinSup=0.9 to 0.1. It is clear that the number of frequent patterns discovered by GLFMiner was larger than those mined by the conventional method.

2,000 4,000 6,000 8,000  10,000 12,000 14,000 16,000  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1  MinSupport Threshold  Fig. 9 The relationship between the numbers of frequent patterns for different MinSup thresholds of T10I4D100K  The variation between the numbers of local frequent patterns and different MinSup thresholds for T10I4D100K is shown in Fig. 10. We can observe that the smaller the MinSup is, the larger the count of local frequent patterns is.

0.09 0.08 0.07 0.06 0.05 0.04 0.03 0.02  MinSupport Threshold  Fig. 10 The relationship between the numbers of local frequent patterns for different MinSup thresholds of T10I4D100K  The variation between the number of frequent patterns and different MinSup thresholds for T10I4D100K with MinSup=0.4 and MinLen=0.009 to 0.001 is shown in Fig. 11.

We can observe that the smaller the MinLen is, the larger the count of frequent patterns is. When deploying GLFMiner algorithm, we can set a higher MinSup to cooperate with appropriate MinLen to mine the valuable frequent patterns.

0.009 0.008 0.007 0.006 0.005 0.004 0.003 0.002 0.001  Fig. 11 The variation between the numbers of frequent patterns and different minimum support of MinLen thresholds

V. CONCLUSIONS AND FUTURE WORK In this work, we have described the concept of global and  local frequent patterns and propose an approach, GLFMiner, to discover such patterns from a temporal dataset. We have achieved the following advantages:  Discover association rules which are frequent in some specific time intervals.

The mined association rules contain time attributes that make them more useful for users.

Valuable rules can still be mined using larger thresholds.

Automatically generate the intervals of frequent patterns.

