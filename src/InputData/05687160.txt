An Associative Watermarking based Image Authentication Scheme

Abstract?In this paper, we propose an associative wa- termarking scheme which is conducted by the concept of Association Mining Rules (AMRs) and the ideas of Vector Quantization (VQ) and Soble operator. Performing associative watermarking rules to the images will reduct the amount of the embedded data, and using VQ indexing scheme can easily recall the embedded watermark for the purpose of image authentication, and establishing the relation between the association rules on both the original image and the watermark image. The Vector Quantization decoding technique is applied to reconstruct the watermarked image from the watermarked index table. The experimental result shows that the proposed scheme is robust. When the watermarked images suffered from various kinds of image-processing procedures, such as Gaussian noise, brightness, blurring, sharpening, cropping, and JPEG lossy compression can be detected without the original images assistance.



I. INTRODUCTION  In the modern world of information, any kind of data is available to anyone over the Internet. Of all the data transmitted over the Internet, images are the most common means of message conveyance. However, the convenient access to the images on the Internet makes it easy for anyone to download, copy, edit, or distribute images with ease, which of course has a direct and severe impact on the copyright owners (many times the image creators themselves). Therefore, copyright protection for intellectual property on the Internet is an important issue [1], [2], [12]. Digital watermarking techniques have been proposed for the copyright protection of digital images [10]. In digital watermarking techniques, some types of watermarks such as logos, labels, trademark, or random sequence, representing the author?s ownership, are embedded into the desired digital image. Generally, a registration to the authentication center is necessary, which helps to solve ownership disputes by identifying the owner of the disputed media. If necessary, the embedded watermark in the digital image can be used to verify ownership [11], [16].

Watermarking techniques have been studied extensively  in the past. By taking account of the domain in which the watermark is embedded. Watermarking techniques can be classified into two broad categories: spatial domain and frequency domain techniques [3], [4]. In spatial domain schemes, the watermark is embedded by directly modifying the pixel values of the host image. On the other hand, watermarking techniques used in the spatial domain directly modify coefficients of images to achieve the purpose for watermarking [5], [16]. The watermarking technique proposed in this paper is based on vector quantization (VQ) [11], [12]. Strictly speaking, VQ cannot be categorized into either of the above types; rather, it is a kind of image compression technique that uses indices of codewords in the codebook to represent the input image and finally refers the index table as the original image.

The remainder of this paper is organized as follows. Brief introduction of vector quantization (VQ), association rule, and edge block detection are respectively introduced in Sec- tion (II). The detailed of the proposed scheme is presented in Section (III). Section (IV) shows the experimental results.

Conclusions are discussed in Section (V).



II. AN OVERVIEW  A. Vector quantization (VQ)  VQ is a simple data compression technique which was first proposed by Gray [2]. In the beginning, an image is segmented into several blocks with the same size, such as 4 ? 4. Each block consists of 16 pixels. These pixels, from left to right and top to bottom, can form a vector v = {v1, v2, ..., vk}, where k represents number of dimen- sions. The pixel value of each block is different, so before encoding, representative vectors, called codeword c, should be collected to form a codebook CB = {ci : i = 1, ..., L?1} , where L denotes the codebook size and i denotes the index value. The well-known LBG algorithm [11] can be employed to form the codebook. By clustering code words, it finds a representative codeword from each cluster and uses the representative code words to form a codebook. Through     Euclidean distance d(v, ci) shown in Eq. (1), where vj and cij are respectively the j  th elements of the vector v and ci, we can find code words nearest to the input vector and record the index value of each code word.

d(v, ci) =  ???? k?1? j=0  (vj ? cij) (1)  Once the closest codeword for v is found, the index i of the best matching codeword is assigned to the input vector v for the basis of future VQ decoding. VQ facilitates compression by means of transmitting or storing the index of the codeword instead of the codeword itself. In the decoding phase, the decoder also utilizes the same codebook to perform a simple table look-up operation for each index i, so as to obtain the corresponding codeword ci. Finally, ci is applied to reconstruct the input vector v [2].

B. Association rules  Association rule mining, which was first proposed by Agrawal et al. [8], is one of the most important topics in the area of data mining, and has many successful applications, especially in the analysis of consumer market-basket data [6], [17]. An association rule is a probabilistic relationship, with the form X ? Y between sets of database attributes, where X and Y are sets and termed as itemsets, and x  ? y = ?. It is inferred empirically from examination of  records in the database. Such a rule reveals that transactions in the database containing items in X tend to contain items in Y , and the probability, measured as the fraction of the transactions containing X also containing Y , is called the confidence of the rule. The support of the rule is the fraction of the transactions that contain all items in both X and Y [9].

C. Edge block detection method - the Sobel operator  Edge detection is the task of finding the boundaries between the objects that appear in a digital image [13]. Sobel operator is used to detect image edges by calculating partial derivatives in 3?3 neighborhoods. The reason of using Sobel operator is that it is insensitive to noise and it has relatively small masks than other operator such as Robert operator, two-order Laplacian operator and so on [14]. The detection Equations (2) and (3).

Gx = (Z7 + 2Z8 + Z9) + (Z1 + 2Z2 + Z3) (2)  Gy = (Z3 + 2Z6 + Z9) + (Z1 + 2Z4 + Z7) (3)  where Z?s are the gray levels of the pixels inside the mask.

The masks are moved pixel by pixel and the procedure is repeated until all possible locations have been computed.

Finally, the result generated in the gradient image whose size is the same as the original image. The block under  Figure 1 The overview of the proposed algorithm  consideration will be regarded as an edge block if any value of those two computed values is larger than the reselected threshold value [15].



III. THE PROPOSED IMAGE AUTHENTICATION SCHEME  In the proposed method both the original image X with size AX ? BX and the watermark W with size AW ? BW are divided into non-overlapping blocks with size k?k, and for each block, the codebook C (including Lk2-dimensional codewords) is utilized to find the closest codeword so as to obtain the index tables of the original image and watermark, XT and WT , respectively. The size of XT and WT are (AX  k ?BX  k ) and (AW  k ?BW  k ). Subsequently, association rules  defined upon 4-itemset are exploited to mine association rules from XT and WT , respectively. Then we embed the association rules generated from the watermark into the original image, the overall description of the proposed system are given in Figure (1).

A. Mining Association rules of the original image and watermark  For each index in the index tables of original and wa- termark images the 4-itemset association rules can be illus-     trated as (item1, item2, item3) ? (item4). The first three items are utilized to find the nearest original image rules for the watermark rules, and by changing the fourth item?s value of the rule, which is derived from some selected original image blocks, such that the watermark can be embedded.

The four items for each block?s rule are defined in Algorithm 1.

Algorithm 1 The four items for each block?s rule Input Parameters: T, S, Imagearray, ImageCells, Normalizedfactor Phase-I Embedding :  1: Calculate the mean of its index and the indices of its neighboring eight blocks  2: if the mean value >= T1 then 3: Item1 =1 4: else 5: Item1 = 0 6: end if 7: Calculate the variance of its index and the indices of its  neighboring eight blocks 8: if the variance value >= T2 then 9: Item2 =1  10: else 11: Item2 = 0 12: end if 13: Sobel is applied to do convolution on this block to  determine whether its corresponding codeword is an edge block or not  14: if any value of those two computed values >= T3 then 15: this block is an edge block, and Item3 = 1 16: else 17: it is = 0 18: end if 19: The item4 value is the corresponding index value in-  dicated in the index table, Where T1, T2, T3 are given threshold.

B. Embedding Process  The detailed procedure of hiding association rules WR in XR being derived from XT and WT is described as follows:  1) The first three items play a role as the matching pattern in XR and WR. ( i.e. if a rule wr = {(1, 0, 1) =? 5}in WR, then the matched rule from XR will be {(1, 0, 1) =? ?} where ? ? [0, L ? 1]). This matching process is repeated until each rule in WR has found at least one matched rule in XR, if there is any rule in WR unable to find a matched rule in XR, go to 2; otherwise, go to 3.

2) If any rule in WR has no matched rule in XR, any of the first three item values of this rule must be changed,  and go to 1. This process is repeated until each non- matched rule in WR find at least one matched rule in XR.

3) If any rule wr in WR has more than one matched rules, say s rules xr1, xr2, ..., xrs, the selected rule xr is so- called the most similar rule to wr. The similarity is defined as follows:  Similarity =  MSE ? TM (4)  MSE =  k ? k k?1? i=0  k?1? j=0  ((cwr (i, j) ? cxrt))2 (5)  Where 1 ? t ? s, TM is a given threshold, cwr is the codeword denoted by the index taken from the item4 value of wr, and cxrt is the codeword denoted by the index taken from the item-4 value of rule xrt which represents each rule of xr1, xr2, ..., xrs.

4) For any rule xr in {xr1, xr2, ..., xrs}. If there are more than one XT ?s block which derived the same rule xr then one of these xr?s relevant blocks is randomly selected for the watermark information. Subsequently, by replacing the index of this block with the item4 value of wr, the purpose for watermarking is successfully achieved.

5) VQ decoding is performed on the watermarked index table, which has been embedded with all the rules in WR, to reconstruct the watermarked image.

C. Extracting Process  For extracting the watermark from the watermarked image Y . Four keys should be recorded.

1) key1: the set of all selected XT ?s block?s locations.

2) key2: the set of original indices of these blocks.

3) key3: the MSE values between the codewords of orig-  inal indices of these blocks, and the codewords of indices of these blocks after embedding.

4) key4: for each element of key2, record all of its corresponding blocks in WT  Then the detailed process is described as follows:  1) Perform VQ encoding on the test image Y to obtain the index table YT .

2) Use key1 to pick out the watermarked blocks YTW from YT .

3) Calculate the MSE values between the code words indexed by all the elements in YTW and key2.

mse(1) = MSE(cYT W (1) ? CKey1(1)) (6) Let Q be the set comprised of all the {mse(l)}, l is the lth element in YTW and key2, cY TW (l) and ckey2 (l) stand for the codewords with indices YTW (l) and     key2(l), respectively; and MSE(cY TW (l), ckey2(l)) is the MSE value calculated from these two codewords.

4) Given a threshold TR and key3, Set  R = {mse(l)|mse(l) ? key3(l) ? TR} (7) and calculate  P = |R| |Q| (8)  Where |R| and |Q| denote the total quantities of ele- ments in R and Q  5) Given a threshold TS If P ? TS . Y is treated as a watermarked image and goes to 6, Otherwise, Y is not watermarked, and the extraction is terminated.

6) According to key4, restore each element in key into its corresponding locations on the watermark index table.

7) Do VQ decoding with the above results to reconstruct the extracted watermark

IV. EXPERIMENTAL RESULTS  In this paper we compare our experimental results with the method proposed by Shen and Ren [11]. This is because that the authors utilized the concepts of vector quantization (VQ) and association rules in data mining to propose a robust watermarking technique.The 4? 4 masks are used to detect edge block and each mask stands for different direction occurring in the edge block. Afterwards, those masks are applied to do convolution on the 4 ? 4 image block.

In this research , PSNR (Peak Signal-to-Noise Ratio) is used to evaluate the difference between the watermarked image and the original image; NC (Normalized Correlation) is applied to determine the degree of similarity between the original watermark and the extracted watermark. Here, AX and BX represent the height and width of the original image X , respectively. AW and BW are the height and width of watermark W. XW and XW separately denotes the watermarked image and the extracted watermark.

The original image and the watermark are divided into non-overlapping blocks with size 3 ? 3. The codebook used in this study adopts the traditional LBG method [18] to train a grayscale Lena image with size 512 ? 512, and the threshold for the termination of training is set as 0.05.

There are 256 codewords in this codebook, and the size of each codeword is 3 ? 3 pixels. Sobel operator is used to detect edge block since Sobel operator is insensitive to noise and it has relatively small masks than other operators such as Robert?s operator, two-order Laplacian operator and so on. The original image used in the experiments is a grayscale Lena image with size 512 ? 512.

Since in [11], the watermark is binary, in order to make the comparison of different methods objectively, binary watermark is applied. Here, watermarks with  different sizes are considered in the experiments. Also the parameters in this paper are the same in [11]. First, for convenience, the thresholds T1 and T2 are set as the half of the codebook size which is 128. The threshold T3 applied to determine whether an image block is an ?edge block? is set to 70, and TM = 80 is selected since it ensures the better PSNR value, threshold TR and TS for the judgment of whether an image is embedded with a watermark or not are set as 0.1 and 0.35, respectively.

(a) Watermarked with (b) Extracted watermark PSNR = 31.9998(dB) (64 ? 64)with NC = 0.9928  (c) Watermarked with (d) Extracted watermark PSNR = 31.8379(dB) (128 ? 128) with NC = 0.9871  (e) Watermarked with (f) Extracted watermark PSNR = 31.8379 (dB) (256 ? 128)with NC = 0.9875  Figure 2 Watermarking image and its watermark extraction  The image pixel of the binary watermark in our method is either 0 or 255. In order to minimize the distortion of the extracted watermark in this approach, the codeword with all values only 0 (c0) and the codeword with all values only 255 (c255) will be produced, and then replace these two codewords nearest to c0 and c255, respectively.

MSE (Mean-Square Error) as mentioned above is utilized     to decide two codewords will be modified to c0 or c255.

Thus, the codeword with the minimum MSE value between c0 and the codeword itself will be changed to c0. Similarly, the codeword with the minimum MSE value between c255 and the codeword itself will be changed to c255. Besides, since the codebook applied in our method is grayscale, the extracted watermark will be in grayscale form. However, in order to make objective comparisons between our approach and [11], the extracted grayscale watermark will be polarized. That is, the pixels with values larger than or equivalent to 128 will be reset to 255, and the pixels with values smaller than 128 will be reset to 0, respectively.

Fig. 2 shows watermarked images and the corresponding extracted watermarks of the proposed method.

Table (I) shows that the value of PSNR of watermarked images with different sizes of watermarks in the proposed method is greater than the value of PSNR of watermarked images in Shen and Ren method. It means that the watermarked image of our proposed method have better image quality. Since NC value can be anywhere between 0 and 1. The closer the NC value is to 1, the higher the accuracy is for the extracted watermark [14]. So the extracted watermark of our proposed method is more accuracy than the extracted watermark of Shen and Ren?s method.

Also the well-known image processing software, Pho- toshop, is applied to perform 32 image attacks (including JPEG lossy compression (quality level 0, 1, 2,..., 12), sharp- ening (1-3 times), adding in Gaussian noise (?= 2, 4, 6, 8, 10, 15 and 20), blurring (1-3 times) and 6 kinds of cropping methods) on the watermark images. Then NC is used to compare the difference between the original watermark and the extracted watermark. After applying 6 kinds of cropping attacks, JPEG lossy compression (quality level = 0), sharpening three times, adding in Gaussian noise (? = 20) and blurring three times to watermarked images of the proposed method and Shen and Ren?s method, we can obtain the corresponding extracted watermarks. Table II shows that no matter which kinds of attacks the watermarked images suffer from, extracted watermarks are still similar with the watermark extracted from non-attacked watermarked image.

Moreover, NC values calculated from extracted watermarks using the proposed method outperform Shen and Ren?s method especially in case of Gaussian noise and blurring.

Table I PSNR OF WATERMARKING IMAGE AND NC OF ITS WATERMARK  EXTRACTION  watermark PSNR NC PSNR NC Size proposed proposed Shen & Ren Shen & Ren  method method method method 64 ? 64 31.9998 0.9928 30.8683 0.9872 128 ? 128 31.8379 0.9871 30.7539 0.9772 256 ? 128 31.8379 0.9875 30.7493 0.9843  (a) 512 ? 512 original image (b) 128 ? 128 watermark  (c) Watermarked image (d) Extracted watermark with PSNR = 30.8466(dB) with NC = 0.9948  Figure 3 Watermarking image and its watermark extraction  Finally, we use another 512 ? 512 image, Mandril and another watermark to emphasis that the proposed method can be easily applied in different kinds of protected images.

Figs. 3(a) and 3(b) are the original images, 128 ? 128 watermark. Figs. 3(c) is the corresponding watermarked image. It is noticed that PSNR values of the watermarked image is smaller than watermarked image, Lena, since the codebook was trained using Lena only. Figs. 3(d) shows the extracted watermark. Then, we also apply the same image processings, JPEG lossy compression (quality level = 0), sharpening three times, adding in Gaussian noise (? = 20) and blurring three times, to the watermarked image, we obtain the corresponding extracted watermarks and there NC values are shown in table (III).



V. CONCLUSIONS  In this paper, a robust watermarking technique is pro- posed using vector quantization (VQ) and association rules     Table II COMPARISON BETWEEN THE NC VALUES OF WATERMARKS EXTRACTED FROM ATTACKED WATERMARKED IMAGES OF PROPOSED METHOD AND  SHEN AND REN?S METHOD  Experiments The proposed Shen & Ren method method  Quarter-cropped 0.9584 0.9509 Quarter-cropped and filled 0.9629 0.9618 with pixels valued Quarter-cropped 0.9600 0.9566 and replaced with the original image Half-cropped 0.9593 0.9566 Half-cropped and 0.9415 0.9344 filled with pixels valued Half-cropped and 0.9516 0.9433 and replaced with the original image JPEG lossy compression 0.9578 0.9452 (quality level = 0) sharpening three times 0.9608 0.9519 adding in Gaussian noise 0.9734 0.9314 (? = 20) blurring three times 0.9707 0.9457  Table III NC VALUES OF WATERMARKS EXTRACTED FROM ATTACKED  WATERMARKED IMAGES OF PROPOSED METHOD  Experiments NC JPEG lossy compression (quality level = 0) 0.9918 sharpening three times 0.9908 adding in Gaussian noise ( ? = 20) 0.9943 blurring three times 0.9933  depending on Sobel operator to detect edge of image. The reason of using Sobel operator was insensitive to noise and it has relatively small masks than other operator such as Robert?s operator and two-order Laplacian operator. The experimental result shows that the proposed scheme achieves more effective resistance against several images processing such as blurring, sharpening, adding in Gaussian noise, cropping, and JPEG lossy compression especially in case of Gaussian noise and blurring.

