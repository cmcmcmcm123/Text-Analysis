May 12, 2010 15:23 RPS : Trim Size: 8.50in x 11.00in (IEEE) icfcc2010-lineup?vol-1: F340

Abstract?Associative classification(AC) is a promising approach used for auto malware detection. However, when data operation occurs (training data added over time), traditional AC algorithms have to re-learn repetitive which is expensive or even become invalidly because of massive data and limited computing resource. To resolve the challenges above, an efficient incremental associative classification algorithm (EIAC) is proposed which can keep the last mining results and learn from the new data set. First, EIAC learns new potential ruleitems from the new data set; and then updates the frequent count of original and potential ruleitems by constructing and searching two trees based on FP-Tree respectively; at last, updates the classification association rules with the frequent information of updated ruleitems. The promising studies on real daily data collection and prediction illustrate that: compared with the traditional AC and other classification methods, EIAC can maintain the classification association rules effectively and ensure a higher predictability of the classification model. So it can be well used for malware detection.

Keywords-Association; Classification;  Incremental Learning; Malware Detection

I.  INTRODUCTION Malware is a program designed to infiltrate or damage a  computer system without the owner's consent. Nowadays, massive malware has presented a major security threat to computer users. Auto Malware Detection becomes a key technique for Network Security [1]. Associative classification(AC)[2-5] can be successfully used for malware detection. In malware detection, the data set for training is always very large and frequently updated. However, when the training set changeed, the existing AC algorithms always scan the changed data set in order to reflect the changes done[3, 6]. We propose an efficient incremental associative classification algorithm(EIAC) based on FP-Tree. It maintains the classification association rules (CARs) incrementally by keeping the last mining results and learning the new data. A comprehensive experimental study on a large collection of PE files obtained from the anti-virus laboratory of KingSoft Corporation is performed to compare the incremental algorithm with non-incremental algorithm.

Promising experimental results demonstrate that EIAC outperforms non-incremental algorithms and other classification methods in efficiency and accuracy both.



II. RELATED WORK Utilizing association rule discovery method to construct  classification systems is a promising approach[2]. Associative classification method has been used in malware detection system IMDS[4], which adopts the improved OOA_Fast_FP- growth algorithm to generate CARs for building the classifier. But without considering the efficient incremental maintain problem, whitch restricts the practical application of this method seriously. In malware detection, the data set for training is always very large and frequently updated, as a result the traditional method has to relearn the complete updated database every time to reflect the changes of the training data. Furthermore, as the training data set grows rapidly, it wastes the learned information seriously, and will aggravate the exhaustion of computational resource for one time mining.

So far, there are rarely studies on the incremental learning of associative classification[3, 6]. But there had been some studies on incremental association rule discovery algorithms, and we can use their ideas for reference to solve the incremental AC mining problem. FUP[7] and FUP2[8] are proposed to handle all update cases when data is added to and deleted from a database. So far, researchers had proposed some incremental association rule algorithms based on FP-Tree[9]. Such as methods in [10, 11], dealing with the association rule updating problem with minimum support changed and data operations occurred respectively. In [11], the authors focus on how to generate new frequent patterns after new transaction data added to training database.

Considering the challenges above, we propose an efficient incremental associative classification algorithm (EIAC) based on FP-Tree. It maintains the classification association rules (CARs) incrementally by keeping the last mining results and learning the new data. As avoiding re- learning the history data and using the compact FP-Tree structure, EIAC outperforms non-incremental algorithm and other classification methods in efficiency and accuracy both.



III. THE EFFICIENT INCREMENTAL ASSOCIATIVE CLASSIFICATION ALGORITHM  In this paper, resting on the analysis of Windows APIs called by PE files, we apply associative classification method in malware detection. That is to find out how a set of API calls support the specific objectives: Class= Malware and Class= Benign.

This research is supported by the National Natural Science Foundation of China under Grant No. 50604012     May 12, 2010 15:23 RPS : Trim Size: 8.50in x 11.00in (IEEE) icfcc2010-lineup?vol-1: F340  A. Problem description In this section, we will introduce the definitions used in  EIAC algorithm.

Definition 1 Support and Confidence[2, 4]  Let  I={I1,I2,?,Im} be an itemset. The support and confidence of the corresponding class association rule are defined as:  ( { }, )% *100%num I Class DBos DB  (1)  ( { }, )% *100% ( , )  num I Class DBoc num I DB  (2)  Where the function num(I Class, DB) returns the number of data in DB where I Class hold and num(I, DB)  means the number of data which contains I.

Definition 2 Frequent Ruleitem[2, 4]  Given mos% as the  user-specified minimum support. I is called frequent ruleitem in DB if os% mos%.

Definition 3 Class Association Rules[2, 4] Given moc% as the user-specified minimum confidence. The rule is a class association rule if oc% moc%. And I is called an accurate ruleitem.

B. EIAC algorithm Let L be the set of frequent ruleitems in original database  DB; MC be the set of frequent ruleitems relating to Malware; BC be the set of accurate ruleitems relating to Benign; MRS be the set of CARs related objective is Malware; BRS be the set of CARs related objective is Benign. After an incremental db (db contains only new malware data) is added to DB.NC is the set of frequent ruleitems in db which are relating to Malware. There are two steps in EIAC algorithm: Updating the frequent ruleitems and updating the CARs.

1) Update of frequent ruleitems based on FP-Tree The following properties are useful: Lemma 1: For each frequent ruleitem which is not  accurate in MC. It may generate a new malware rule: I Malware(os,oc). We can compute the rule?s os' oc' in updated database according to the following formulates:  ' ( { }, ) ( { }, ) | | | |  num I Malware DB num I Malware dbos DB db    ' ( { }, ) ( { }, ) ( { }, ) ( { }, )  num I Malware DB num I Malware dboc num I Malware DB db num I Benign DB  (4)  Lemma 2: A frequent ruleitem I in db can become a winner in the updated database DB db if and only if  ( { }, ) * |num I Class db mos db | )  (5) ( { }, ) (| | | |num I Class DB db mos DB db  (6) Lemma 3: If an original frequent ruleitem I becomes a  loser, then every longer ruleitem containing it cannot be a winner.

Based on the above analysis and properties, the update of frequent ruleitems in DB db is outlined as follows:  a) Filtering out the ruleitems which appeared in MC from NC: NC=NC-NC MC. Then for every ruleitem I NC, updating its corresponding support count in DB db and  choose the new frequent ruleitems: First, scan DB to delete items which are not 1-ruleitem in NC and order remainder items descending by their frequent count in NC; Second, construct a FP-Tree for pruned DB; Finally, update the frequent count of each potential ruleitem in DB db by searching the FP-Tree;  b) For every ruleitem I MC, updating its corresponding support count in DB db: First, scan db to delete items which are not 1-ruleitem in MC  and order remainder items descending by their frequent count in MC; Second, construct a FP-Tree for pruned db; Finally, update the frequent count of each original ruleitem by searching the FP-Tree;  c) For every ruleitem , calculate its corresponding support count in db by constructing and searching it like above.

For every ruleitem above, if num(I Class, DB db)<mos*(|DB|+|db|), means that it is not a frequent ruleitems in DB db, we call it as a loser. Then we can delete it. At last, we get the frequent ruleitem set NC MC relating to Malware and the frequent ruleitem set BC relating to Benign in updated database.

2) Update of CARs There are only new malware data in db, so only new  malware rules may be generated. The process of CARs update consists of three major parts: updating original malware rules; updating benign rules; generating new malware rules. Based on the enough information of frequent ruleitmes, the updating of CARs is very easy as follows:  a) Update original malware rules: For every CAR in MRS: I Malware(os,oc). Check I in updated MC. If I disappeared, which means the rule is invalid in the updated database. We can remove this rule from MRS straightly. Else we need to get the corresponding support count of I from MC.

And compute the rule?s os' and oc', in updated database according to formulates (3) and(4). If oc' moc , then the rule is still invalid in the updated database. So we remove this rule from MRS straightly. Else, update the rule?s value of support and confidence in updated database DB db;  b) Updating benign rules: For every CAR in BRS: I Benign(os,oc) . Read its support count in db. Then compute the rule?s os' and oc' according to the following formulates:  | |' | | |  os DBos |DB db (7)  | |' | | ( { },  os DBoc os DB num I Malware db)  (8)  If os'<mos or oc'<moc, then the rule invalidates in the updated database. So we remove this rule from BRS straightly. Else, update the rule?s value of support and confidence in updated database DB db;  c) Generating new malware rules: New malware rules come from two parts: Original frequent ruleitems which were not accurate in MC but become accurate in updated database generating new malware rules; New frequent ruleitems may generate new malware rules.

May 12, 2010 15:23 RPS : Trim Size: 8.50in x 11.00in (IEEE) icfcc2010-lineup?vol-1: F340  For every frequent ruleitem which was not accurate in MC. It may generate a new malware rule: I Malware(os,oc). We can compute the rule?s os' and oc' in updated database according to formulates (3) and(4).

For each potential frequent ruleitem in NC, it may generate a new malware rule: I Malware(os,oc). We compute its os' and oc' in updated database according to formulates (3) and(4) too.

For every ruleitem I above, if its os'> mos and oc' moc, the ruleitem do generate a new malware rule in updated database. Then we add the new rules into MRS straight. Else, this ruleitems is still just frequent but not accurate to compose a rule.

3) The EIAC algorithm outline Input: (1) DB: the original database; (2) db: an incremental malware data set; (3) MC: the set of frequent ruleitems relating to Malware in DB; (4) BC: the set of frequent and accurate ruleitems relating to Benign in DB; (5) MRS: the set of CARs related objective is Malware; (6) BRS: the set of CARs related objective is Benign; (7) NC: the set of frequent ruleitems in db, and relating to Malware; (8) mos: user-specified minimum support; (9) moc: user-specified minimum confidence.

Output: (1) MC': the set of frequent ruleitems relating to Malware in DB db; (2) BC': the set of frequent ruleitems relating to Benign in DB db; (3) MRS': the set of CARs related objective is Malware in DB db; (4)BRS': the set of CARs objective is Benign in DB db;  Algorithm: /* update the frequent ruleitems set*/ (1) NC'=NC-MC NC; (2) MC'=Update_FrequentItemsets(MC, db); (3) NC'=Update_FrequentRuleitems(NC, DB); (4) BC'=Update_FrequentRuleitems(BC, db); /* update original rules and generate new rules*/ (5) MRS'=Update_Rules(MRS, MC'); (6)BRS'=Update_Rules(BRS, BC'); // Generate new rules from the frequent itemsets which aren?t accurate ruleitems in MC'// (7) NewMRS=Generate_NewRules(MC',MRS'); // Generate new rules from potential frequent itemsets in NC'// (8) NewMRS=NewMRS Generate_NewRules(NC', MRS'); //Union all rules//  (9) MRS'=MRS' NewMRS.



IV. EXPERIMENT AND ANALYSIS We conduct two sets of experiments on the large  collection of PE files obtained from the anti-virus laboratory of KingSoft Corporation. First, we evaluate the performance of EIAC and traditional OOA_Fast_Fp-growth on a large data set. The second, we verify the precision of our classifier and other classification methods. Both the experiments are conducted under the environment of Windows XP OS plus Intel Core Duo 1.66GHz CPU and 1GB of RAM.

A. Experimental data set In this study, we use 10,000 malicious executables and  10,000 benign executables as training data set, other 5,000 malicious and 5,000 benign executables as test data set.

Useful information include: FileSort, as the PE type; FileName, as the name of the executables; APISeq, as Windows APIs called by PE files.

B. Results and analysis 1) Evaluation between EIAC and OOA_Fast_Fp-growth  Because of the higher efficiency of OOA_Fast_Fp- growth than Apriori and Fp-growth methods[4], we can directly use OOA_Fast_Fp-growth as a non-incremental comparison algorithm.

The experimental data is arranged as follow: split the 20,000 training data set DB as 5 parts: DB={DB0, DB1, DB2, DB3, DB4}; Where DB0 includes 6,000 malicious and benign executables respectively; DB1 and DB2 are both 2000 malicious executables;DB3 and DB4 are both 2000 Benign executables.

The experiments were done as follow: Set mos=0.05 moc=0.7 (recommend by malware analysis  and mining experts); EIAC incremental learning: mining DB0 as the initial learning database using OOA_Fast_Fp-growth in order to get the initial frequent patterns and CARs. Then mining the other 4 parts of data using the incremental methods EIAC; as the comparison experiments, re-learn the updated data set as a whole repetitive using OOA_Fast_Fp- growth, when the other 4 data sets were added one by one.

The results are shown in table , where FAIL means the algorithm is invalid to get rules within limited computational recourse.

TABLE I. COMPARISON OF TWO ALGORITHMS  Data set  Re-learning with OOA_Fast_Fp-growth  Numbers of CARs/CPU Time(hour)  Incremental learning with EIAC  Numbers of CARs/CPU Time(hour)  DB0 40035/1 40035/1 DB1 40329/2 40329/0.5 DB2 40147/5 40147/0.45 DB3 FAIL 41786/0.6 DB4 FAIL 43467/0.65 We can find that, re-learning the whole updated  database waste the learned information, and also exhaust the computational resource as the database becoming too large.

However, using our incremental learning algorithm EIAC avoid re-learning. So with the same values of parameters     May 12, 2010 15:23 RPS : Trim Size: 8.50in x 11.00in (IEEE) icfcc2010-lineup?vol-1: F340  (mos, moc) EIAC can maintain the CAR set efficiently, solved the incremental learning problems of frequent data insertion.

2) Comparison of different classification algorithms In this set of experiments, we compare EIAC with  Support Vector Machine and Decision Tree methods. That is using the J4.8 version of Decision Tree implemented in WEKA[12] and the SVM implemented in LIBSVM package[13], setting mos to 0.294 and moc to 0.98 respectively for EIAC. Then mine the 20,000 executables as training data, and validate the accuracy of each classifier on other 10,000 executables. Results shown in Table  indicate our method achieve most accurate malware detection.

Where TP, TN, FP, FN, DR, and ACY refer to True Positive, True Negative, False Positive, False Negative, Detection Rate, and Accuracy respectively.

TABLE II. COMPARISON OF DIFFERENT CLASSIFIERS  Classifiers TP TN FP FN DR ACY Decision 4078 4885 115 922 81.56% 89.63% Lib SVM 4401 4857 143 599 88.02% 92.58%  EIAC 4453 4897 103 547 89.06% 93.50% From the comparison, we observe that EIAC outperforms  other classification methods in both detection rate and accuracy. Decision Tree method exhaust too much RAM. In order to deal with large data set, researchers improved it with many techniques (sampling, scattering), which descend the accuracy especially with noise. For SVM, the overlapping between Malware and Benign data cause the trouble to separate them exactly, especially the unbalance of data in the overlapping field. All of these reasons declined the accuracy.

And some works [5] proved that a classifier with frequent pattern analysis is generally effective to solve the scalability and over fitting issues.



V. CONCLUSIONS AND FUTURE WORK In this paper, we introduce an efficient incremental  updating associative classification algorithm (EIAC) based on Fp-Tree, the main contributions are: (1) Considering the frequent adding operation on training database, EIAC can maintain the set of CARs incrementally; (2) use Fp-tree for reference, it can maintain the classifier efficiently; (3) Considering the relationship between data attributions with class entirely, it achieve higher detection accuracy than other classifiers. Experimental results improved that EIAC algorithm can quickly and effectively maintain the classification rules, and ensure the predictability of the classification model used for malware detection.

Furthermore, as a universal classification algorithm, EIAC can be directly used for many other categorization tasks, such as text mining and News classification etc.

