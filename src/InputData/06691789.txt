Secure Decoupled Linkage (SDLink) System for Building a Social Genome

Abstract ? Population informatics is the systematic study of populations via secondary analysis of massive data collections about people, called the social genome.  A major challenge in building the social genome is the difficulty in data integration of heterogeneous and uncoordinated data while protecting the confidentiality of the data subjects.  Here, we present our work in designing a flexible computerized third party linkage platform, Secure Decoupled Linkage (SDLink), which can provide both privacy protection and accurate high quality integrated data using a hybrid human-machine data integration system.  Our evaluation results show that chaffing used in combination with universe manipulation is very effective in blocking inferences during the clerical review process.

Keywords- privacy preserving record linkage; decoupled data;

I.  INTRODUCTION Today, nearly all of our activities from birth until death  leave digital traces in large databases that continuously collect, store, and process huge amounts of data about us.

Together, these massive data collections (termed ?Big Data?) about people collectively capture our social genome, the footprints of our society.  If properly integrated, analyzed, and interpreted, this social genome could offer crucial insights into many of the most challenging problems facing our society such as healthcare, education, and economics.

The field of population informatics is the systematic study of populations via secondary analysis of this social genome.  In particular, health informatics analyzes electronic health records to improve health outcomes for a population.



II. RELATED WORK: RECORD LINKAGE & PRIVACY Digital data about people often ends up in heterogeneous  and uncoordinated systems.  Without effective methods to integrate such information in coherent, usable ways, the data holds little value, introducing the need for record linkage ? the process of identifying record pairs which belong to the same real-world entity. However, the process of record linkage is complicated by the inherent nature of real data that are inconsistent, missing, erroneous, and continuously updated.  Absence of a common, error-free, unique identifier makes exact matching solutions inadequate (i.e. too many true links are missed), leading to approximate record linkage methods which require manual resolution of ambiguous links [1].  Most recently, for high quality linkages, there is more interest in interactive record linkage that uses a hybrid human-machine system which can take advantage of human interaction to manage errors in real data [2].

The goal of privacy preserving record linkage (PPRL) is to identify the records in one or more datasets that represent the same person, without compromising the confidentiality  of subjects involved [3]. Private record linkage is the most researched form of PPRL.  It is defined as computing the set of linked records given as input a matching function and then outputting them to the two private parties without revealing anything about the non-linked records. The goal is to apply the known matching function in a secure manner.

Consequently, the major challenges in private record linkage remaining for real applications is the lack of discussion on how to find the matching function that give high quality links and how the ambiguous links will be resolved without human interaction [4, 5]. Although relevant, private record linkage is a different use case than what we see in practice for population informatics where one trusted research entity (e.g. linkage center, health statistics division) obtains proper access to all data that need to be integrated while protecting the confidentiality of the subjects.



III. SECURE DECOUPLED LINKAGE (SDLINK) In this paper, we present the Secure Decoupled Linkage  (SDLink) platform that is based on the decoupled data access model presented in [6] and supports the trusted third party use case for population informatics. SDLink is a flexible computerized third party linkage platform that focuses on protection against attribute disclosure (i.e. does this person have cancer), rather than identity disclosure (i.e.

who is this person).

A. Shuffling and Encrypting The Connection Information The first step to building a computerized third party is to  decouple the identifying information (PII) from the sensitive information to block sensitive attribute disclosure [6].  The decoupling occurs in three steps.  First the full table is split into two tables, one for PII and another for the remaining sensitive data, denoted as T1= T1(PII)+T1(SD).  Second, the rows in the PII table are shuffled randomly so that the row association between T1(PII) to the T1(SD) cannot be easily derived.  Finally, asymmetric encryption is used to lock the row association information from the T1(PII) to the T1(SD).

Each private key, K(Ri), for row association of particular tables are given out to the custodians of each table who have the authority to grant access.  In SDLink, which has multiple decoupled tables, there is also a master key, K(T), that is used to lock the table association information for matching up Ti(PII) to Ti(SD).  In order for two tables to be linked, a user will have to obtain keys for row association to both tables from the custodians and present it to SDLink.  Then SDLink will use these keys and the master key it holds to link the tables using the identifying information, interacting with the user as needed to determine the mapping function and resolve ambiguous links, and then return the linked de- identified table, which include confidence levels of linkages.

B. Information Supression During Clerical Review What information is disclosed during clerical review has  much impact on the risk of disclosure during record linkage.

The goal is to only display the meaningful differences between the variables needed for record linkage and suppress other information (Fig. 1).  For example, difference between IDs (e.g. SSN) are recoded into number of different digits and transposes.  DOB comparisons are made on an element- to-element basis for month, day, and year taking into account transposes both within one element and between elements.

Conveying meaningful similarity information in names without fully disclosing it is the most difficult.  More research on meaningful differences for record linkage is needed. In our evaluation, we start with understanding the risk of fully disclosing names.  We show in the next section that even when names are fully disclosed, privacy can still be maintained due to the non-uniqueness of names, chaffing, and uncertainty in the universe around the data. Recoding can have an important side benefit of resulting in more consistent linkage decisions, both between different matches by one person as well as different people because it will help people use the same information for linkage decisions.

Figure 1.  Review Screen ([D]iff, [M]issing, [TX]=Transpose, [?]=Same)  C. Universe Manipulation and Chaffing Even when identifying information is separated from the  sensitive information, users can still infer attributes by using background knowledge.  For example, if someone you know (background knowledge) is on the cancer registry (group disclosure), they must have cancer (attribute disclosure).

Thus, strict decoupling via encryption along cannot guarantee no attribute disclosure. We employ additional methods to interfere with such possible inferences by manipulating the universe around the data that is displayed during review and adding fake data.  In the previous example, consider if you knew that the list being linked had people who did not have cancer (i.e. fake data).  Or if you did not know this was a cancer registry.  Furthermore, there is no way to know how many people named ?John Smith? exist in the universe of the data, especially when the universe is unknown.  Our experiments confirm that even with rare names fully disclosed, when the universe is effectively manipulated people are not able to confidently infer identity.

The probability of attribute disclosure through group membership is dependent on a variety of factors including any pre-existing information that is known by the observer, the knowledge on the nature of the list, and the uniqueness of the PII in the universe of the data. The threat model where Alice is the researcher doing the review and Bob has bribed Alice to find out the disease status of Ian is described  formally in Fig. 2.  In this example, Alice could memorize the name for the target subject, Ian, and could spot the same name during clerical review. It is important to note that, identifying the person is not a confidentiality violation yet.

Rather, the violation occurs when an identified person?s disease status becomes known.  Whether spotting the same name during clerical review can lead to confirmation that the real person of interest (IanBob) has cancer depends on two factors.  First, does the list represent everyone with cancer?

And second, how likely is it that the viewed name (IanPII) represents the actual real world entity (IanBob), which depends on factors such as the rarity of the name.  Here we discuss methods to further introduce uncertainty in inferring that IanBob has cancer by intentionally manipulating the universe around the displayed data point (IanPII) with little impact on the matching decision.  There are three methods of modification: (1) chaffing: literally change the nature of the universe by adding fake data, (2) fabrication: change the label/name of the universe presented to the researcher to obscure inference, and (3) nondisclosure: hide the identity of the universe from the researcher to reduce confidence.

Chaffing is the process of adding fake data to a dataset to enlarge the universe to such an extent where group membership no longer reveals sensitive information. It is comparable to a person concealing themself by becoming part of a large crowd.  In particular, by adding a certain type of fake data, we can fundamentally block attribute disclosure 1. Alice is a researcher who is responsible for resolving ambiguous links  via clerical review for a study on linking Cancer Registry data from two hospitals, LA and LB, located in NC.  During the process, she will be shown a partial list of PIIs from LA and LB to resolve the ambiguous links, denoted as LA(PII) (Alice) and LB(PII) (Alice).  The expected size of the partial list is a tiny fraction of the full lists.

2. The tables are decoupled as LA = LA(PII) + LA(SD), LB = LB(PII) + LB(SD), where LA(PII) is the PII from the hospital records in LA and LA(SD) is all columns except PII including all the sensitive data.  Alice has no access to LA(SD)  and LB(SD) which specify the type of cancer diagnosis in the registry along with other information.

3. Bob, who works for a health insurance company, bribes Alice to find out if Ian has cancer and gives Alice Ian?s full PII denoted as Ian(PII)  Note that there is no guarantee that Ian(PII) is unique in the universe of real world entities, denoted as RA, from which the data is collected.  We denote the unique real world entity that Bob is interested in as IanBob.

4. We assume that Alice knows that LA(PII) and LB(PII) are cancer registries.

5. During her clerical review process, Alice can combine her prior  knowledge of IanPII with the partial lists of PIIs given to her, LA(PII) (Alice) and LB(PII) (Alice), to make inferences.

Under simple uniform models and assuming IanBob has cancer, Risk (Bob finding out that IanBob. has cancer | IanPII. is on either LA(PII) or LB(PII)) =[Pr(IanPII ?LA(PII) (Alice))+Pr(IanPII ? LB(PII) (Alice))]*Pr(IanPII.==IanBob.) = very small since clerical review should occur in only a tiny percent of  the full lists   Thus the main threat of inferring that IanBob has cancer results from ? having seen his PII in one of the partial lists during review ? knowing that LA(PII) and LB(PII) are cancer registries ? AND the uniqueness of IanPII  in the universe RA  Figure 2.  Formal Threat Model     through group membership.  Disclosure through group membership can only occur when the list disclosed for review represents a homogenous group, such as cancer registry.  By adding real names to the list that do not have cancer, and letting the researcher know that the chaffing has occurred, the list is no longer homogenous and membership on the list has no meaning.  In sum, the researcher can no longer be certain of sensitive information based on group membership even if the identity has been disclosed.  The key to chaffing is to add the appropriate fake data so as to introduce uncertainty to attribute disclosure, but not to interfere with the matching decision.  The most effective method is to incorporate short refresher training covering how the list is chaffed, that a chaffed list effectively has an intractable universe, and thus inferences cannot be made with any reasonable certainty. Adding PIIs that the researcher is familiar with, such as their family and friends, into the list can be an effective method for subtle mental reminders that the list includes fake data obtained from the user.

An orthogonal method to changing the nature of the list through chaffing is to confuse the identity inference.  One method to block identity inference is to falsify the universe by presenting the list as if it came from a different data space. In our threat model, we might present the list to be from a hospital located across the country, say CA.  Such a false presentation of the list LNC as LCA would make it probabilistically impossible for them to infer that the viewed name (IanPII) represents the real person (IanBob) of interest who lives in NC.  In other words, by presenting the list as if it came from a different data space (LCA?DCA), the Pr(IanPII==IanBob)=0 because IanBob?DNC & IanPII?LCA?DCA & DNC?DCA=?.  Thus, if Alice believes IanPII? LCA, we effectively block any possible correct inferences on identity.

Sometimes it can be difficult to totally falsify the universe to a research team member responsible for clerical review.  In such situations, not specifying the universe until after the clerical review can also be useful.  When we provide Alice with records from an undefined universe, she can be led to similar uncertain conclusions about the identity of a person because they are led to assume the whole world as their universe.  In order for Alice to make a reasonably accurate inference from prior knowledge of the subject?s name, they need two pieces of information: the existence of the same name on the list and the number of real people with the same name in the universe where the list came from, R.

The probability that the spotted name on the list is the same real world entity of interest is 1 in n(same name in R). The rate of confidence is inversely correlated with the size of n.

When the universe is undefined and the researcher must assume a huge universe of anyone living in the US, even for rare names it is difficult to assume n=1 with certainty. Thus, even if the researcher is able to recognize a particular name, there will be a constant degree of uncertainty in their judgment.  Nondisclosure is quite similar to chaffing in that the universe becomes enlarged.  This allows for an increase in probability of comparable real world entities to exist, resulting in an increase in n(same name in R), which in turn reduces the confidence of the researcher about the identity.



IV. EVALUATION RESULTS To better understand what kinds of PII should be  disclosed to the researcher during clerical review, we did an experiment by conducting an online survey. The survey simulated the situation that the insider, Alice, would be in while performing the clerical review.  Our goal was to test how well the different methods worked to reduce identity disclosure and attribute disclosure.  In this experiment, we measured (1) the effect of chaffing, (2) the impact of the modification of the universe, both falsifying and non- specification, on identity inference, (3) the disclosure risk of different identifying information attributes; namely, the common name, the common name and DOB pair, and the rare name, (4) how these attributes interact with each other when used in combination, and (5) the effects of missing and erroneous data on the different methods using variations on the common name and DOB pair.

Meet George Brown, a student at Meadowgreen HS Using only the information provided here, how likely is it that the George Brown introduced above is the same person listed on the honor roll provided here?

A. Highly likely to be the same person B. Moderately likely to be the same person C. Slightly likely to be the same person D. I don?t know if they are the same person or not E. Slightly likely to be two different people F. Moderately likely to be different people G. Highly likely to be two different people  Meadowgreen HS Honor Roll  Amanda Ward Edward Jones Hilary Ford  George Brown Susan Miller David Green  Alexander Parker Brian Richards Daniel Parker Alex Parker    Figure 3.  Sample Survey Question for Common Name Scenario  Fig. 3 is the basic question set up.  The respondents are given different identifying data about a target student and an Honor Roll list with the same identifying data. Then we ask them to select their confidence level about the likelihood that the information given in the question and the honor roll refers to the same person (identity disclosure) on a seven- point Likert scale (i.e. three levels of yes, three levels of no, or I Don?t Know). The survey had in total 18 questions; six scenarios, each with three questions.  The six scenarios were ordered so that questions would build on each other. We started with the simple common name scenario, and then moved onto to common name and DOB.  The next two scenarios were common name and missing DOB followed by common name and transposed DOB.  The transpose was created by swapping month and date numbers in DOB (2/5 and 5/2).    The survey questions for these cases had the missing or transposed DOB in the honor roll for the target student.  We left rare name and chaffing to the last two sections because we wanted the respondents to get used to inferring identity before giving them the chaffed list experiment for attribute inference.  In the fifth scenario for rare name, the target student had a rare name (Rahul Ghosh) and the honor rolls included other rare names such as Viswanath Sastry, Jie Lee, and Michelle Pham. In addition, we changed the question slightly to ask how likely it is that the target student had made the honor roll (attribute disclosure) at his school.  The scale wording was also adjusted to indicate the confidence of having made the honor roll. We changed the question slightly so that we could ask     the respondents to answer the same question one more time, knowing that the honor roll included some fake data of students who did not make the honor roll. This is the sixth scenario, wherein we tested a given rare name as the identifying information on a chaffed list. For the three questions in each of the six scenarios, respondents were given the honor roll from the same high school (Same HS: ?Meadowgreen HS?), an honor roll from a different high school (Diff HS: ?Valley Mountain HS?, falsified), and finally an honor roll from an unknown high school (No HS:?A HS?, undefined).  We constructed the three honor rolls so that they shared some names including the target student but were sufficiently different from each other.

The full results are shown as 18 stacked bar charts in Fig.

4. Each of the questions corresponds to one stacked bar.  We tested the change in the confidence level of identity or attribute by comparing responses to different questions using the Wilcoxon signed rank test, a non-parametric T-test.  We mainly recruited from graduate students in various departments including public health and computer science, who we anticipate will be doing the clerical reviews.  We had 59 respondents.  Although we made no attempt to recruit from students with experience in data analysis, we obtained a good mix of respondents with various experiences in data. A previous paper [6] reported the demographics and data experiences of the respondents from this study with selected findings(8 of 18 questions). Here we present complete results on the effects of manipulating the universe and the impact of missing and erroneous data on the different methods. A summary of the impact of chaffing from [6] is also included.

A. Impact of Chaffing T-Test results between common name scenario and rare  name + chaffing scenario was surprising.  There was sufficient evidence (p-value < 0.005) to conclude that respondents were significantly less confident in the identity of rare names on a chaffed list compared to common names on an accurate list (Bar 1 vs. Bar 16).  Chaffing was very effective in preventing attribute disclosure of rare names during clerical review [6].

B. Impact of Falsifying or Undefining the Universe We found that manipulating the label of the displayed  list was quite effective in reducing confidence in identity in all cases.  In the base case for common names (George Brown from Meadowgreen HS), when a list was presented as being from the same high school, all but 11 answered Highly or Moderately Likely the Same Person indicating fairly high confidence in identity.  There was a dramatic shift in responses to the second question when a list was presented under a different universe (Valley Mountain HS) and even went on to assert that the person on the list was a different person.  Only 6 answered Highly Likely the Same Person while the number of respondents answering Highly Likely Different People shot up from 0 to 29. The median for the falsified universe is on the other end of the spectrum at Moderately Likely Different People.  The results from the third question, the list with no high school defined (A HS), were quite different from the first two questions. The vast  majority of the respondents fell in the middle of the spectrum with both the mode and median response being I Don?t Know. The combined response to Slightly Likely Same or Different People and I Don?t Know was 56%.  We conclude that the respondents were confused and could not confidently assert a response on whether the presented person was the same person or not.  The finding supports the hypothesis that an undefined universe will effectively introduce uncertainty such that people will not be able to make an affirmative conclusion about a name they find on the list.

Although not as strong an effect, we see a similar trend in the impact of falsified universe and undefined universe for scenarios where we presented the common name and DOB pair and a rare name.  Given a common name and DOB pair, the median response increased to Slightly Likely the Same Person for a different universe and Moderately Likely the Same Person for an undefined universe. In comparison, given a rare name, the median response was I Don?t Know for a different universe but again Moderately Likely the Same Person for an undefined universe.  Not surprisingly, the DOB and the rarity of a name serve to increase the confidence of the respondent compared to only a common name.  Nonetheless the modification of the universe still had the impact of reducing the confidence levels as indicated by the T-tests which confirmed statistically different medians in all cases when the universe was manipulated.  Most importantly, when used in combination with chaffing, the impact of manipulating the universe seems to have an additive effect (Bars 17 and 18).  The median response for rare names with the universe undefined dropped further to the ideal level of I Don't Know when using the chaffed list (Bar 18).  This is an important finding because it confirms that using a combination of chaffing and nondisclosure of the universe, names, including rare names, can be fully disclosed with minimum risk of attribute disclosure during the review.

It is quite interesting to note that given a list from a different high school, in all questions, there were some respondents who selected either Highly or Moderately Likely the Same Person as the target student.  The Pr (target studentA ? LX)=0 given that target studentA ? DA and DA?DX=? regardless of how rare the identity might be.

Logically it would be highly unlikely that a George Brown at Meadowgreen HS is the same George Brown at the Valley Mountain HS.  However, 15% still answered that they were Highly or Moderately Likely the Same Person.  For common name and DOB pair it was as high as 42% and for rare name it was 19%.  In the pretest of the survey, we asked informally about such responses.  Some respondents thought that the student may have transferred from one high school to the other or that the student was simultaneously enrolled in both schools.  The respondents were unconsciously adding new dimensions, such as time, into the situation to accommodate their personal belief that two people with the same name and DOB are highly likely to be the same person (Susan Miller, DOB=4/17/1994).  Given that Susan Miller is a fairly common name, we believe such responses strongly suggest the possibility of researchers making incorrect inferences and jumping to wrong conclusions.  It could in fact be true that     IanPII  IanBob, but when researchers make incorrect assumptions that IanPII==IanBob, harm can still occur.

Thus, it seems that this result points to the need for good training before researchers are allowed to do clerical review.

C. Missing and Erroneous Data Of all six scenarios, respondents were most confident  about the identity of the target student when presented with the common name and DOB pair where 50 out of 59 respondents answered Highly Likely the Same Person, with 7 more respondents answering Moderately Likely the Same Person. These results indicate that people are highly confident about a person?s identity given a pair of name and DOB.  This finding is supported empirically by Weber et al.

who show that the name and DOB pair was surprisingly effective for record linkage under certain circumstances [7].

Thus, we recommend that the raw DOB should not be disclosed in the PII list during the clerical review process.

Instead, information related to DOB should be displayed as differences as shown in Fig. 1.  However, this strong confidence in identity is quickly diminished in the scenarios with missing DOB and transposed DOB (Bar 4 vs Bars 7 & 10).  In this experiment, we tested the effectiveness of the different methods in the presence of missing and erroneous data, because such data is common in real-world big data.



V. CONCULSION We are planning a second study to focus on the different  methods for recoding names to understand its impact on both linkage decisions and disclosure.  Identity disclosure without sensitive attribute disclosure has little potential for harm [8].

Recognizing that the desire for privacy protection is for the sensitive data rather than the identifying data, we introduce SDLink, a simple but powerful data integration system that supports safe interactive record linkage so that errors from linkage can be managed throughout the full workflow.

Errors that are not properly managed in machine only data integration systems propagate to subsequence data analyses [9] leading to potential problems with incorrect analyses, which can ultimately result in incorrect decisions. Harm from inaccurate data and information can be as devastating as our concerns about privacy violations.

