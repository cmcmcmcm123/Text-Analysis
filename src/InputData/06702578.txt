Extending Summation Precision for Network Reduction Operations

Abstract?Double precision summation is at the core of numerous important algorithms such as Newton-Krylov meth- ods and other operations involving inner products, but the effectiveness of summation is limited by the accumulation of rounding errors, which are an increasing problem with the scaling of modern HPC systems and data sets. To reduce the impact of precision loss, researchers have proposed increased- and arbitrary-precision libraries that provide reproducible error or even bounded error accumulation for large sums, but do not guarantee an exact result. Such libraries can also increase computation time significantly. We propose big integer (BigInt) expansions of double precision variables that enable arbitrarily large summations without error and provide exact and reproducible results. This is feasible with performance comparable to that of double-precision floating point sum- mation, by the inclusion of simple and inexpensive logic into modern NICs to accelerate performance on large-scale systems.



I. INTRODUCTION  Technology scaling and architecture innovations in recent years have led to larger datasets and extreme parallelism for high performance computing (HPC) systems. It is projected that parallelism will increase at an exponential pace in order to meet the community?s computational and power efficiency goals [1]. This translates to operations, such as summations, with a larger number of operands that are also distributed over an increasing number of nodes. The sheer scale of these systems threatens the numerical stability of core algorithms due to the accumulation of errors for ubiquitous global arithmetic operations such as summations [2].

At the present time, 64-bit IEEE floating-point arith- metic is sufficiently accurate for most scientific applica- tions. However, for a rapidly growing body of important scientific applications, higher numeric precision is required.

Among those applications are computations with large, rel- atively ill-conditioned linear systems, multi-processor large- scale simulations, atmospheric models, supernova simula- tions, Coulomb n-body atomic system studies, mathematical physics analyses, studies in dynamical systems, and compu- tations for experimental mathematics. Recent papers discuss numerous such examples [3], [4], [5], [6], [7].

This manuscript has been authored by an author at Lawrence Berke- ley National Laboratory under Contract No. DE-AC02-05CH11231 with the U.S. Department of Energy. The U.S. Government retains, and the publisher, by accepting the article for publication, acknowledges, that the U.S. Government retains a non-exclusive, paid-up, irrevocable, world-wide license to publish or reproduce the published form of this manuscript, or allow others to do so, for U.S. Government purposes.

This work was supported by the Director, Office of Science, of the U.S.

Department of Energy under Contract No. DE- AC02-05CH11231.

Perhaps the most common instance where extra precision is needed is large summations, particularly when it involves both positive and negative terms, so that catastrophic can- cellation can occur. Even if all terms are positive, round- off error when millions or more terms are summed can significantly reduce the accuracy of the result, especially if the summation involves large and small numbers. This is important even for simple widely-used operations based on summations, such as matrix multiplications and dot products.

As an example of a real-world application where accurate summation is important, Y. He and C. Ding analyzed anoma- lous behavior in large atmospheric model codes, wherein significantly different results were obtained on different systems, or even the same system with a different numbers of processors [7]. As a result, code maintenance was an issue, since it was often difficult to ensure that a ?bug? was not introduced when porting the code to another system. Another concrete example is complex dynamical systems, where precision loss has been quoted as the main limitation [4].

Currently, researchers generally presume that nothing can be done to ameliorate such problems and are often concerned with bounding errors from precision loss to acceptable levels [8], [9], [10], [11], [12], [13]. A few have tried higher- precision arithmetic using software facilities, with relatively good success, although computational time for this software is often an issue [14], [15]. In the atmospheric model case mentioned above, researchers employed double-double (DD) arithmetic in the summations, which uses two double- precision variables to extend precision [14], and found that almost all numerical variations were eliminated. Others have even resorted to quad-double arithmetic [3], [14].

In modern HPC systems with large datasets, summations and other operations are often performed on operands dis- tributed across the network [16], [1]. Currently none of the high-precision software libraries support parallel sum- mations. Balanced-tree summations and other sorting or recursion algorithms that reduce round-off error accumu- lation [10], [15], [9], [12] are only efficient within nodes because they would incur an impractical amount of system- wide data movement for distributed operations. This leaves distributed operations prone to precision loss.

There are two natural ways to implement distributed summations with provably minimum data movement. One way is for nodes to send their partial sum (a single variable) to a single node to perform the summation and generate a single result. This only occupies a single node?s processor  2013 25th International Symposium on Computer Architecture and High Performance Computing  978-1-4799-2927-6 2013 U.S. Government Work Not Protected by U.S. Copyright DOI 10.1109/SBAC-PAD.2013.14     but completion time grows linearly with the number of operands and can also create network hotspots [17]. The other approach (used in most MPI implementations) per- forms the summation in a tree fashion, where each node adds a number of operands and passes the partial sum (also a single variable) to the next level of the tree. This approach requires logarithmic time to complete, but the latencies of each level of the tree greatly impact performance at scale as it incurs multiple communication delays between network interface cards (NICs) and local processors. Software im- plementations incur potentially long context switch penalties just to have processors at each node add a few numbers together, and may also cause these intermediate processors to wake up from potentially deep sleep.

Earlier work proposes NIC-based reductions in Myrinet networks [18] by modifying the drivers (and therefore using the host processor?s processing power), and showed that NIC-based reduction can yield performance gains even with as few as eight nodes [19]. Further work evaluated conduct- ing reduction operations exclusively in NICs and concluded that doing so increases efficiency, scalability and reduces execution time compared to performing the computations in processors [20]. This is made possible by using the pro- grammable logic in modern NICs [20]. However, this work only applied this method for double-precision variables due to the complex data structures and computation demands of arbitrary-precision libraries and the limited processing power of programmable logic in NICs. Even with double-precision variables, the low computational power of programmable logic can pose a significant performance issue [20]. The alternative, adding complex dedicated hardware to NICs for increased or arbitrary precision computations, increases design risk and complexity.

In this paper, we make the case that using a very wide integer to provide an uncompressed and exact encoding of the complete numerical space that can be represented by a double-precision floating point number, which we call big integer (BigInt), is well-suited for distributed operations. We demonstrate that BigInts incur no precision loss and can be productive and efficient to use in distributed summations, such as reduction operations, without increasing communi- cation latency compared to double-precision variables. In fact, this approach offers the promise of actually accelerating system-wide summations used by inner products for methods such as Newton-Krylov, because integer adders can be easily incorporated in NICs at speeds comparable to modern floating point units (FPUs), to avoid waking up and context switching processors. Therefore, we are able to move com- putation from the processor to the NIC without any precision or performance loss. This was previously possible only with double-precision variables due to the complex internal structures of arbitrary-precision libraries. Even though the size of a BigInt variable is 2101 bits?33? larger than a 64- bit double-precision variable?we observe insignificant loss  ???????   ?????   ???????  ???????  ????  ?????????????????? ?? ???  ???????   ?????   ???????  ???????  ????  ??????????????????????? ?? ?????? ?!

???????   ?????   ???????  ???????  ????  ??????????????? ?? ??????"???????????????????? ?? ????!

????? ???????  Figure 1: Double, long double and double-double variables.

in communication delay due to the fixed latency costs and packet overhead bytes in modern large-scale networks [21].

Therefore, BigInts readily apply to network operations and can be combined with past work on local-node computations that uses sorting and recursion or alternative wide fixed- point representations with dedicated hardware support [22], [23], [15], in order to provide reproducible system-wide operations with no precision loss.



II. BACKGROUND AND RELATED WORK  The format of double-precision variables is set by the IEEE 754 standard [24] and is shown in Figure 1. For double-precision variables, the total number of bits is 64, including the most significant bit which is the sign. The mantissa includes a silent bit at its most significant (53rd) position, which is 1 if the exponent is non-zero. Double- precision variables with a zero exponent are considered denormalized and are used to fill the gaps in the numbers that double-precision variables can represent close to zero. A denormalized double-precision variable encodes the number:  DenormalizedV alue = (?1)sign ? 0.Mantissa? 2?1022  If the exponent is non-zero, the number is considered normalized and a bias of -1023 is applied to the exponent value. Therefore, an exponent value of 50 represents an actual exponent of 50 ? 1023 = ?973. The decimal value of a normalized double is:  NormalizedV alue = (?1)sign ? [1 +Mant51(  )+  Mant50(  ) + ...+Mant0(1/2  52)]? 2Exp?1023  Normalized doubles encode numbers in the range:  2?1022 ? |V alue| ? (2? 2?52)? 21023  However, because of the limited mantissa bits, double- precision variables cannot represent all numbers in the above range [4]. In addition, operating on numbers that have significantly different exponent values causes bits to be dropped. For example, adding the numbers 2N and 2M     where N >= M+53 causes the latter number to be dropped because the 53 mantissa bits are not enough to retain both numbers. Even if the smaller number is not small enough to be fully discarded, it may have to be partly discarded for the same reason, or the result may require more than 53 mantissa bits [4]. Such precision loss is hard to predict in many applications and can appear with just two operands.

In a large summation this error accumulates in every sum of two numbers and therefore in a summation with millions or billions of operands the error may rise to unacceptable levels [3], [7], [5], [6].

Double-precision variables are fully supported in hard- ware with dedicated FPUs in modern processors [25]. They also include special values to represent infinity and a result that is not a number (NaN), as well as exceptions to set variables to those values when appropriate [24], [26].

Modern architectures include support for ?long double? variables. In the IEEE 754 standard [24], this is referred to as double-extended precision for which the byte width is 10 and translates to 19 or 20 decimal digits. In an x86 architecture long doubles are 80-bits long, with 64-bit mantissas and 15-bit exponents [27]. x86 processors include dedicated registers with this format, but the extra precision is lost once a long double variable is written back to memory.

In the past 10 years or so, high-precision software pack- ages have been produced which typically utilize custom datatypes and operator overloading to facilitate conversion.

One example is the QD package [14] which provides DD variables, where each 16-byte variable is the unevaluated sum of two 8-byte doubles of which the first consists of the ?leading? digits and the second the ?trailing digits? of the format?s value. That is, the first double contains the best 64-bit double-precision approximation to the answer, and the second double contains the difference between the exact answer and the first double. Similarly, a quad-double number is an unevaluated sum of four IEEE doubles. However, while such packages offer easy-to-use high-level interfaces, they still offer a limited amount of precision.

For arbitrary precision, packages such as ARPREC [28] and GNU GMP [29] are available. Other packages offer guarantees on the order of operations and rounding (since there is no standard) [30]. Inevitably, these packages sacri- fice speed and memory due to large arrays used in the inter- nal representations and lack of hardware support. Formats with variable-length mantissas have also been proposed, such as IEEE 854 [31]. Such formats are similar to double- precision variables because they use mantissa and exponent fields, but they also introduce additional complexity for op- erations and exception handling that make hardware support costly. Finally, wide fixed-point representations similar to BigInts have been used in hardware accumulators for local- node summations [22], [23], [15]. BigInts extend this work by applying this concept on distributed summations.

We found that existing software solutions are usually  ???? ???? ??   ???????????? ? ????? ??	?????????? ? ?????  ?????? ????????????? ?????????????? ? ?  Figure 2: A BigInt consists of 2101 bits. Bit positions cor- respond to an exponent after a bias of 1076. Positions right of 1076 correspond to negative exponents. For example, position 1000 corresponds to exponent 1000?1076 = ?76.

slow for most physical modeling and simulation codes, and the precision provided by DDs or quad-doubles are insufficient, especially for much larger simulations to come.

A DD summation requires approximately 20 operations, all performed in processor registers, which results in an approximately 2? to 5? slowdown compared to double- precision variables [14]. This slowdown becomes worse when using arbitrary-precision packages. As an example, ARPREC is approximately 2.5? to 4.5? slower than DD multiplication on a Sun Ultra 167 MHz processor [28], [14]. Alternative algorithms use sorting, recursion, or other computation or data movement overhead to provide exact results or with tight error bounds, as well as reproducibil- ity [15], [10], [9]. Due to their overhead, such algorithms are only practical within nodes. Because of the performance tradeoff, some researchers settle with bounding or predicting the computation error [8], [9], [10], [11], [12], [13].



III. DESCRIPTION  A. Big Integer Variables  Figure 2 illustrates the format of a BigInt variable. Essen- tially, BigInt variables remove the exponent field and expand the mantissa such that each bit?s location corresponds to an exponent value. To represent the same number space as the IEEE double-precision format, BigInt variables need to be 2101 bits since the 11-bit exponent field?s value ranges from 0 to 2048, and the exponent defines the value of the most significant (silent) mantissa bit. Thus, the lowest exponent value BigInt needs to represent is the lowest value of the exponent field (?1022) minus the number of mantissa bits (53), for a total of ?1075. BigInt variables also have a sign bit which we place in the least significant position.

Like integers, BigInts are an uncompressed representation and therefore can exactly encode the full range of real numbers in their number space. In other words, there is no gap in the range of numbers that are expressible by BigInts.

In addition, BigInts do not introduce any precision loss.

Therefore, they are well-suited for very large summations.

Figure 3 shows how a normalized double-precision vari- able maps to a BigInt. To convert from a denormalized double, the most significant bit of the double?s mantissa is inserted in position 53 (corresponding to exponent value ?1022). This does not overwrite the sign bit of BigInt because denormalized floats do not have a silent bit.

Converting the summation result from a BigInt back to a double, long double, or DD variable inevitably causes the     ????  ?????		? ?? ?????? ????????  ?????? ????????  ??????? ?????????????? ??  ???	?	?????????  ? ?? ? ?  ????????  ??????  Figure 3: A double-precision variable maps to a BigInt by inserting the most significant bit of the mantissa (the silent bit if set) in the position specified by the exponent. For example, an exponent of 1000 encodes an actual exponent of ?23 after applying the ?1023 bias. Therefore, the silent bit is inserted in position 1076?23 = 1053. The rest of the mantissa is inserted in adjacent less significant positions.

least significant asserted bits to be dropped if the distance between the leftmost and rightmost asserted bits in the BigInt is more than the length of the mantissa of the variable the BigInt is converted to. For example, when converting to a double-precision variable a BigInt with asserted bits at locations 100 and 10, the least significant bit will inevitably be dropped because 100? 10 > 53. If this precision loss is of concern to the application, programmers can retain BigInt or use another wide fixed-point for local-node summation similar to past work [22], [23], [15], or use any of the higher-precision formats or libraries such as recursion and sorting methods, ARPEC, QD, and GMP [28], [14], [29], [15], [10], [9]. It is key to realize that the conversion back to lower-precision formats discussed above is performed only for the final result or for local node processing, if at all.

The final result is guaranteed to be accurate as long as all arithmetic is performed with BigInt precision. Performing the entire operation with precision less than BigInt may produce an entirely different result due to precision loss in every summation of two numbers, as discussed in Section II; this effect accumulates over the course of large summations.

This precision loss can result in the most significant bits of the result, the bits well within the range of even double- precision variables, to differ compared to the result produced by BigInt because BigInt was able to correctly and exactly capture the contributions of all operands without losses.

The simplicity of BigInts enables fast and accurate nu- merics for software implementations and requires only sim- ple logic for hardware implementations for large summa- tions [22], [23]. Very little additional memory is required because only partial sums are projected to BigInt, instead of all operands, and only over the network for distributed operations. BigInt variables can be treated as long integers for addition, multiplication and division, even though they represent floating point numbers. Adding two BigInts can be accomplished with simple and inexpensive integer adders in a sequential manner; an adder of N bits length requires  N cycles. Therefore, in order to match the latency of a  highly-optimized FPU in modern Intel processors which has  a 5-cycle latency [27], the adder width needs to be 421 bits.

This makes adding hardware support for BigInts feasible and more likely to operate at comparable speeds to the node processors, in contrast to more complex libraries that also offer arbitrary precision.

BigInts of all 0s but with a sign bit of 1 represents ?not a real number? (NaN). A value of all 1s refers to infinity (Inf), used for numbers outside of the representable number space.

In this case, the sign bit distinguishes between positive and negative infinity, similar to IEEE 754 [24], [26]. Setting a BigInt to infinity or NaN is done by the hardware logic through simple checks without the need for exceptions, as in the IEEE 754 format. For example, the result of a summation is infinity if the addition of the most significant bits of two BigInts produces a carry. Similarly, in multiplications, the resulting BigInt is set to infinity if the result is wider than the BigInt. A BigInt of all 0s is the number 0.

B. Applicability to Network Operations  BigInts are good candidates for network-wide operations, such as MPI reductions where communication follows a tree- like fashion and every node sums the operands it receives and then transmits the partial sum (a single number) to the next level of the tree to produce a single result [32], [33], [34]. That is because the additional bits do not have a noticeable effect in communication delay for a small number of operands, as we show in Section V-D.

Past work has shown that performing computation in the NICs during reduction operations increases both scalability and consistency with speedups of up to 121% [20]. However, this has only been applied to double-precision variables because of the complex data structures of libraries with arbitrary precision and the limited programmable logic in terms of both area and clock frequency in modern NICs [20].

For instance, Elan3 in Quadrics QsNet provides a user- programmable, multi-threaded, 32-bit, 100MHz RISC-based processor with 64 MB local SDRAM, originally targeted for communication protocol modifications [35]. This processor is an order of magnitude slower than the multi-GHz node processors. Similar work which implemented the compu- tation logic in software drivers in a Myrinet network [18] showed that NIC-based reductions can be preferable to host- based (serial) reductions with as few as eight nodes [19].

The only way to offer high-speed computation in NICs without BigInts is to add dedicated high-speed floating- point computation hardware to NICs. The power and area consumed by a fully functional double-precision adder is substantial. In addition, including a full floating point into the NIC increases design complexity to a point that drasti- cally increases design risk for a very specialized function.

An example of the simplest double-precision FPU from the Tensilica design library requires on the order of 150,000 gates [36]. Even though FPU units support multiplication as well as addition, and therefore would be partially unused in     a distributed summation, floating point multiplication is less complicated to implement than addition [37]. Verification is non-trivial for even a circuit of this size and complexity, and this implementation is among the simplest available.

For future Infiniband 4x EDR interface theoretical peak bandwidth, operands would need to be summed at a rate of 100 Gigabits/sec. This would require a 32-bit carry- lookahead adder operating at 0.6 GHz (very modest clock rate). Operating as a ripple-carry, this would require 66 cycles to graduate a result, and consume about 380 gates for the adder (a negligible amount of area and power) [38].

For reduction operations with both local and network- wide computations, local computations can either use sorting or recursion techniques, or use wide fixed-point representa- tions with dedicated hardware support. Alternatively, local computations can be performed in the NICs using the BigInt format without using the local processor. However, because this option would transfer all local operands to the NIC instead of just the partial sum, it stresses the processor?NIC interconnect. Network-wide computations are performed in the NIC with BigInts, because sorting or recursion tech- niques would produce an excessive amount of system-wide data movement. This way, there is no precision loss in both local and distributed operations. Local computations can be performed in advance of the arrival of packets with partial sums such that when the reduction operation function call is made, the result (a single partial sum number) can be stored in the NIC in anticipation of other partial sums (operands).



IV. METHODOLOGY  We evaluate the impact of BigInts on computation pre- cision and performance of summations and MPI reduction operations [39] with millions to billions of operands. We first evaluate the numerical behavior and error accumulation of techniques applicable to network-wide operations, namely doubles, long doubles, DDs and BigInts, using serial test cases on large numbers of operands. Next, we evaluate the performance of MPI reduce() operations on payload sizes required for these different extended precision implementa- tions. Lastly, we estimate the impact of embedding BigInt summations into the NIC for future interconnect designs.

Numerical stability calculations are done in a single processor as they are designed entirely to understand the numerical behavior of different approaches. Each trial uses exclusively operands and operations of the appropriate pre- cision. In our architecture, long double-precision variables are 80 bits long, where 1 bit is the sign, 15 bits are for the exponent, and 64 bits for the mantissa [40]. We report the error of each precision type against BigInt as a percentage.

We also perform a bitwise comparison of the mantissa of each precision type against BigInt and report the first bit that differs. Due to the different representation with two double-precision variables that DDs use, we do not report bit-wise mantissa comparison results for DDs. Finally, we  ??  ????  ??  ????  ??  ????  ??  ????  ?? ???? ?? ???? ?? ???? ?? ????  Figure 4: One benchmark is calculating the arc length of this highly irregular function (g(x)).

perform a comparison of decimal digits of each variable in decimal form and report the position of the first decimal digit that differs. For example, the numbers 2.54 and 2.58 differ in the second decimal digit. For both decimal and bit comparisons, a value of minus one means that there is no difference, whereas a value of 0 means that the integer parts of the numbers differ in the decimal comparison.

Initially, we perform a composite summation of numerous equal small numbers to a large number. We vary the large and small numbers as well as the number of operands to illustrate precision loss as a function of summation size and operand values. We then show results for a funarc calculation that attempts to calculate the arc length of the irregular func- tion g(x) = x +  ? 0?k?10 2  ?k sin(2kx), over the interval  (0, ?). The task here is to sum ? h2 + (g(xk + h)? g(h))2  for xk ? (0, ?) divided into n subintervals, where n = 10000000, so that h = ?/10000000 and xk = kh. The function is shown in Figure 4. This function highly irregular, so that the arc length calculation will sum many highly varying quantities. If the limit on the summation were infin- ity instead of 10, the resulting function, while continuous and innocuous-looking, is in fact non-rectifiable?it does not have a finite arc length. In any event, it was chosen as a useful example for demonstrating round-off error when adding a large number of varying terms. Finally, to clearly show the effect of the limited mantissa bits, we use the geometric series:  k?  i=0  2?i = 1 ? (1? 2?k)  1? 1  = 2 ? (1? 2?k)  For performance results, we conduct communication and summation evaluations. To evaluate communication delay, we conduct 50000 MPI reduction operations for each pre- cision type in NERSC?s Hopper, which is a Cray XE6 cluster [41]. Because of the small payload of packets, we configure the NICs to use the eager message path to the processor [42] to avoid the latency of block transfers.



V. EVALUATION  A. Composite Summation  The precision loss in the first experiment is illustrated in Figure 5. Since each summation produces an error and the small numbers (10?8) we add to the large number (108) are     0 0.5 1 1.5 2 2.5 3 3.5 4  x 10    x 10 ?4  Number of operands  P re  ci si  on e  rr or  ( pe  rc en  ta ge  )  Error for composite benchmarks      Double  0 0.5 1 1.5 2 2.5 3 3.5 4  x 10   0.2  0.4  0.6  0.8   1.2  1.4 x 10  ?7  Number of operands  P re  ci si  on e  rr or  ( pe  rc en  ta ge  )  Error for composite benchmarks      Long double  0 0.5 1 1.5 2 2.5 3 3.5 4  x 10           x 10  ?21  Number of operands  P re  ci si  on e  rr or  ( pe  rc en  ta ge  )  Error for composite benchmarks      Double double  Figure 5: Adding operands with a value of 10?8 to a variable with the value of 108. BigInt equals the analytical result.

equal, the error grows linearly with the number of operands.

Also, the errors introduced by each variable type differ in orders of magnitude compared to BigInt, because doubles, long doubles and DDs have different levels of precision.

DD variables introduce approximately 10?16 less error than doubles. For better illustration, Figure 6 (left and center) compares bits and decimal digits with the BigInt result. As shown, double and long double variables have a large error, whereas the error for DDs is still noticeable.

Figure 6 (right) shows results for a summation where the large number (1012) is large enough such that double- and long double-precision variables drop the small numbers entirely. For those cases, summation is ineffective because the result equals the large number. Compared to adding to a large number of 10?8, the precision for DDs is also lower.

B. Computing Arc Length of an Irregular Function  To illustrate the precision loss in a realistic highly ir- regular mathematical computation, we use the funarc code on g(x), described in Section IV. In this experiment, the numbers are close enough such that operands are not fully discarded. The precision loss does not increase linearly with the number of operands because the function is highly variable. Figure 7 illustrates the percentage error compared to BigInt, and Figure 8 shows the bit and decimal digit comparisons. As shown, DDs still introduce noticeable error.

C. Geometric Series  Even though for i infinite the geometric series converges to the number 2, for natural values of i it should converge to less than 2. However, due to the limited number of mantissa bits, double variables report equal to 2 for i > 53 and long doubles for i > 64. DDs are accurate until i > 106. Beyond that, the second double-precision variable, which denotes the error contained in the first double-precision variable in DDs [14], cannot accurately capture the accumulated error because the error exceeds its 53 available mantissa bits. In contrast, BigInts are accurate until i > 1024.

D. Performance Evaluation  To evaluate the performance impact of BigInts in dis- tributed summations we use MPI reductions and measure  communication time using MPI constructs. MPI reductions are typically used for summations performed on operands distributed across a large-scale system [32], [34]. In such operations, communication progresses in a tree-like fashion where nodes in each level of the tree sum the operands they receive with their local operands, and pass the partial sum (a single number) to the next level [33].

Figure 9 shows the time spent in communication. BigInt increases communication time by approximately 35% com- pared to doubles, but only 2%-14% compared to DDs. Even though BigInts contain 2101 bits and therefore are 16? larger than 128-bit DDs, for such small sizes communication is latency-bound instead of throughput-bound. Therefore, BigInt does not increase communication time significantly because the additional bits lead to a minor increase since packet headers and fixed (zero-load) delays in the net- work and NICs dominate for small transfers. Our results are confirmed by past work [21] which showed that the communication delay for messages with payloads containing double-word, quad-word, and double quad-word variables is identical and approximately 12 ?s for up to 512 bytes, which is a larger payload size than BigInts (256 bytes).

We then estimate computation time. In modern Intel pro- cessors, double-precision additions performed on dedicated FPUs require 5 cycles [27]. Even though the peak rate for FPUs is 2 flops/cycle, summation throughput is limited by the FPU pipeline latency. Increased-precision representations are considerably slower. For example, as discussed in Sec- tion II, DD addition requires up to 20 operations. Arbitrary- precision libraries use more complex representations and therefore are even slower. BigInts can perform these op- erations at a rate that is comparable to DDs (20 cycles) only with an 106-bit integer adder, which can be easily integrated in modern NICs [20]. Computing in NICs avoids poten- tially large context switching or wake up delays for local processors, as well as data transfer latencies between the NIC and the processor that are typically significantly longer than the few cycles to perform integer addition. Context switching requires ?s [43], while waking up processors from deep sleep may require seconds [44], [45]. So the handful additional cycles required for extended precision and BigInts     0 0.5 1 1.5 2 2.5 3 3.5 4  x 10           Number of operands  F irs  t m an  tis sa  b it  of d  iff er  en ce  First mantissa bit of difference composite      Double  0 0.5 1 1.5 2 2.5 3 3.5 4  x 10             Number of operands  F irs  t d ec  im al  d ig  it of  d iff  er en  ce  First decimal digit of difference composite summation      Double Long double Double double  0 0.5 1 1.5 2 2.5 3 3.5 4  x 10           Number of operands  F irs  t m an  tis sa  b it  of d  iff er  en ce  First mantissa bit of difference composite      Double  Figure 6: Adding operands with a value of 10?8 to a variable with the value of 108 (left and center) or 1012 (right). In the center Figure, the lines for double and long double overlap on zero because the integer part also differs.

0 0.5 1 1.5 2 2.5 3  x 10           x 10  ?10  Number of operands  P re  ci si  on e  rr or  ( pe  rc en  ta ge  )  Error for function arc length      Double  0 0.5 1 1.5 2 2.5 3  x 10         x 10  ?13  Number of operands  P re  ci si  on e  rr or  ( pe  rc en  ta ge  ) Error for function arc length      Long double  0 0.5 1 1.5 2 2.5 3  x 10   0.2  0.4  0.6  0.8   1.2  1.4  1.6 x 10  ?14  Number of operands  P re  ci si  on e  rr or  ( pe  rc en  ta ge  )  Error for function arc length      Double double  Figure 7: Precision error compared to BigInt for computing the arch length of g(x) with a varying number of operands.

0 0.5 1 1.5 2 2.5 3  x 10           Number of operands  F irs  t m an  tis sa  b it  of d  iff er  en ce  First mantissa bit of difference funarc      Double  0 0.5 1 1.5 2 2.5 3  x 10             Number of operands  F irs  t d ec  im al  d ig  it of  d iff  er en  ce  First decimal digit of difference funarc      Double Long double Double double  Figure 8: Bit and decimal digit comparison for computing the arch length of g(x) with a varying number of operands.

are negligible compared to the network time. As discussed in Section III-B, the complexity of integer adders is an order of magnitude less than FPUs. Therefore, compared to FPUs, BigInt summations are feasible to perform at line rate using existing technology and consuming an order of magnitude fewer gates, using only integer adder components in a pipelined ripple-carry fashion. Therefore, BigInts enable reduction operations to complete in comparable time as operations with double-precision variables, while providing no precision loss in the same number space with exact encoding for every real number in that space.



VI. CONCLUSION  This paper makes the case that using a very wide integer, which we call BigInt, is well-suited for distributed oper-  0 2000 4000 6000 8000 10000 12000        Number of nodes  R ea  l t im  e (s  ec on  ds )  Distributed MPI reduce communication time      Double Long double Double double Big Int  Figure 9: Communication time for an MPI reduce operation.

ations. BigInts encode the same number space as double- precision variables but have a simple enough format to     perform operations such as additions in comparable time as double-precision variables with dedicated FPUs, using inexpensive hardware integer adders or programmable logic found in modern NICs. BigInts enable distributed reduction operations in large-scale systems with no precision or per- formance loss. Computing in NICs avoids the energy and latency costs of NIC to processor communication, as well as context switching or waking up the processor. Computing in NICs is only achievable by past work with double-precision variables due to the complex internal structures and system- wide data movement introduced by increased- or arbitrary- precision software libraries and algorithms.

