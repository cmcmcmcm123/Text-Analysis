Optimizing Queries over Semantically Integrated Datasets on MapReduce Platforms

Abstract?Life science databases generally consist of multiple heterogeneous datasets that have been integrated using complex ontologies. Querying such databases typically involves complex graph patterns, and evaluating such patterns poses challenges when MapReduce-based platforms are used to scale up process- ing, translating to long execution workflows with large amount of disk and network I/O costs. In this poster, we focus on optimizing UNION queries (e.g., unions of conjunctives for inference) and present an algebraic interpretation of the query rewritings which are more amenable to efficient processing on MapReduce.

Keywords-SPARQL; Life Science; MapReduce; Union;

I. INTRODUCTION Life science databases actively adopt Semantic Web tech-  nologies to deal with the increasing number and complexity of datasets, e.g., Uniprot1 is a central hub of functional information on proteins comprised of 16 sub datasets in RDF (approx. more than 1TB in N-triple). Querying such datasets often brings challenges to optimization, e.g., a large number of multi-values in datasets and unbounded properties in queries. In addition, inferences are frequently involved as a part of query processing because a given semantic model may ?entail? or imply data not explicitly stated. While some data warehouses provide online SPARQL endpoints, many of them do not fully handle such issues; therefore, users may want to explore the data by themselves, but may not have the capabilities to process such large datasets.

A distributed data processing framework on cloud can be a good alternative on these issues, e.g., MapReduce allows programs to be automatically parallelized over arbitrary- sized clusters of commodity-grade machines. Most graph pattern matching processes can be encoded into MR jobs or expressed with the high-level dataflow query languages used in the extensions of the MapReduce framework such as Hive and Pig. Supporting inference can also be achieved by materializing all entailed information and querying using regular methods since all information would then be explic- itly represented in the data. However, this process will need to be repeated after each update to guarantee completeness and consistency. A backward chaining with query re-writings can be used instead, which generates unions of conjunctive queries (UCQs) in [1], [2]. This technique expands a triple pattern in a query to include all other possible alternatives guided by an ontology using UNIONs.

1http://beta.sparql.uniprot.org  Query (w/ ?)  #TP #STP #Edges in STP  #S-O ??  #O-O ??  #Br in ?  UQ1+ 17 17 1 0 0 17 UQ2+ 51 20 3 0 0 17 UQ3 7 3 (4:1)/(4:0):1 2 0 2 UQ4+ 24 12 2 0 0 12 UQ12+ 24 12 2 0 0 12 UQ18 10 5 2 5 0 6  Table I. Characteristics of union queries  For complex ontologies, the number of the alternatives is large, leading to UNION queries with a large number of branches. Table I gives the characteristics of the example UNION queries provided by the Uniprot SPARQL endpoint page. UQ3 and UQ18 are queries that explicitly contain a UNION clause while others are inference queries expanded to UCQs using the rewriting rules in [2]. (UQx+ denotes the expanded query for UQx).

The efficiency of the evaluation of union queries on MapReduce-based platforms depends on the algebraic inter- pretation of the query. In trivial cases, e.g., each UNION branch contains only a single triple pattern, relational- style systems such as Hive detect the correlations across the UNION subqueries, merging the execution of multiple branches into the single MR job. However, other complex queries are often translated into the long MR workflows with a large number of joins. Fig. 1(a) shows the relational- style execution plan for the example query in Fig. 1(b) using k MR jobs for k UNION branches and an additional job for the union of the output from the branches. An optimization technique such as ?union pushdown? [3] might be applicable to relieve this issue. However, the translation of relational logical expressions to MapReduce dataflows might not always yield efficient execution workflows and so still warrants further investigation.



II. NESTED TRIPLEGROUP DATA MODEL AND ITS ALGEBRA (NTGA)  In some previous work, we introduced an alternative data model and algebra called the Nested TripleGroup Data model and Algebra (NTGA)([4]). The intuition behind NTGA is to manage related sets of triples. Our notion of relatedness here is a group of triples having the same subject or a Subject triplegroup, which can be produced by a GROUP BY operation on the Subject column of the triple relation. Such triplegroups can be considered candidate      Figure 1: (a) A relational-style plan for (b) an example union query, and (c) the corresponding NTGA-based plan.

matches to star subpatterns in a query if they contain at least one triple for each property in the star subpattern.

For example, a triplegroup tg1 = TG{p1,p2} consisting of two triples whose properties are p1 and p2 can be a valid match to the graph pattern {?s1 p1 ?o1. ?s1 p2 ?o2.}.

If necessary, we can produce an equivalent set of n-tuples from a triplegroup by splitting the triples in the triplegroup based on the property types, and then applying a Cartesian product between the resulting subsets, e.g., tg.triples(p1) ?? tg.triples(p2) where tg.triples(prop) is the set of triples in tg with property type prop.

An advantage of the triplegroup model is conciseness of representation, similar to the advantage of the nested relational model over the classic relational model. Further, the mapping of the NTGA logical plan to a MapReduce execution workflow highlights its advantages when consid- ering MapReduce platforms. NTGA provides a set of logical operators to deal with triplegroups, e.g., TG_GroupBy(?S) constructs labeled triplegroups by grouping the triples by the subject fields, TG_GroupFilter(??) filters out triple- groups that do not contain ?matching? subsets to any of the star subpatterns, and TG_Join(???) joins triplegroups to support s-o/o-o joins. In the first MR cycle of the workflow, the operators ?, ?S , and ?? are executed, which essentially filter out unnecessary triples and construct star-subgraphs (triplegroups) relevant to the query. Additional MR cycles are then required to join star-subgraphs using ???. The maximum number of additional cycles will be n, where n is the # of star pattern subqueries. In contrast, using the relational-style interpretation of the queries generally re- quires (2n?1) MR cycles. Such shorter execution workflows lead to benefits given that each MR incurs costs of expensive disk/network I/Os.

In this poster, we explore the extension of NTGA to optimize UNION query processing. We first consider the case in which all k UNION subqueries contain a single star pattern as the only graph pattern. Fig. 1(c) shows that we include all the graph patterns in each UNION as parameters to ?? , which evaluates multiple patterns concurrently in a single data pass (or MR job). For more complex cases, each union branch can contain more than single star patterns,  which requires joins between star-subgraphs. In this case, we rewrite the UNION operators in the query expression to disjunctive ORs in the parameter of the operator ???. This is achieved by extending the parameter to accept more than one star patterns using the primitives similar to a logical OR.

Figure 2: Execution time of union queries in Uniprot

III. EVALUATION  The experiments were conducted on an 80-node Hadoop (0.20.2) clusters in VCL2. NTGA was integrated into Pig 0.8.0, and a stable version of Hive (0.10.0) was selected as a benchmark target. Each colored rectangle in the bars of the Fig. 2 represents each MR job, e.g., Hive used 4 MR jobs for UQ3. In general, Fig. 2 shows that Hive plans performed worse than the NTGA one because the length of the MR execution workflow depends on the size of rewritings in Hive, i.e., the width (# of branches) of the UNION clause. For example, the input files were read 12 times for UQ4+ and UQ12+ where each MR cycle was used to process each branch of the UNION. Hive was unable to identify and exploit ?correlation? across the UNION subqueries because they are not composed of single triple pattern. The NTGA execution plan was able to merge all such correlated subqueries into a single execution cycle allowing input files to be scanned only once. This allowed NTGA to outperform the Hive for the UNION queries with large widths (? 5), e.g., NTGA was approximately 9 times faster than Hive for UQ12+ in Fig. 2.

