Associative Prediction Model and Clustering for Product Forecast Data

Abstract?Association rules are adopted to discover the  interesting relationship and knowledge in a large dataset.

Knowledge may appear in terms of a frequent pattern  discovered in a large number of production data. This  knowledge can improve or solve production problems to  achieve low cost production. To obtain knowledge and quality  information, data mining can be applied to the manufacturing  industry. In this study, we used one of the association rule  approach, i.e. Apriori algorithm to build an associative  prediction model for product forecast data. Also, we adopt the  simplest method in clustering, k-means algorithm to attain the  link between patterns. The real industrial product forecast  data for one year duration is used in the experiment. This data  consists of 42 products with two important attributes, i.e. time  in the week and required quantity. Since the data mining  processes need a large amount of data, we simulated these data  by using the Monte Carlo technique to obtain another 15 years  of simulated forecast data.  There are two main experiments  for the association rules mining and clustering. As a result, we  obtain an associative prediction model and clustering for the  forecasting data. The extracted model provides the prediction  knowledge about the range of production in a certain period.

Keywords-associative; association rules; prediction;  clustering; manufacturing

I. INTRODUCTION  Currently, the data in manufacturing industry is really  huge and consists of various stages. However, because of  the insufficient information many problems especially in the  operation management could not be solved efficiently.

Company needs reliable knowledge to make the right  decision particularly in forecasting or planning a system. It  is necessary for a company to get an accurate demand  forecasting for it to produce the required quantity at the  right time. One way to get useful information is by using the  data mining approach. Data mining is an analytic process  designed to explore data in search for consistent pattern and  relationship [1]. Typically, data mining techniques are  already used in business, medical and various domains.

In production operation, there are some important  decisions to make during the early planning stage such as  the production planning, customer demands and selection of  an appropriate manufacturing process [2]. In the  manufacturing domain, data mining can be used to provide  information for preventive maintenance, machine failure  prediction or quality control [3].

This research employed an association rule that can  identify interesting relationship, knowledge and frequent  pattern. The discovered knowledge or frequent pattern can  improve or assist in solving production problems in order to  achieve low cost production. On the other hand, the decision  quality can be improved to encourage a positive impact to  the company. In order to obtain good knowledge and predict  the outcomes, we proposed an associative prediction model.

After that, we applied the clustering techniques to group the  similarity and dissimilarity of the relationship and pattern.

This paper is organized as follows: Section II is about  the related work and previous research of associative  prediction model, clustering and manufacturing  productivity. In Section III, we present the methodology that  comprises of the step of data collection and how we conduct  the pre-processing, experiments and in section IV, the  results. In that section, results obtained from the two  techniques will be compared and discussed. Meanwhile the  Section V discloses the conclusions.



II. RELATED WORK  Traditionally, the statistical techniques are used in order  to discover the patterns in manufacturing data such as linear,  quadratic and logistic discriminate analyses [3,4]. However,  these statistical techniques face a problem when dealing  with massive data from a huge database or multiple  databases. According to [5], there are two main weaknesses  of the local methods when dealing with the huge data. First,  it is difficult to scale the high dimension data and second is  the lack of interpretability of the model data. Therefore, data  mining techniques can help to improve and solve the  problems especially in the manufacturing domain. This is  due to the fact that the manufacturing data consists of large  records and many attributes.

Associative prediction is a combination of two data  mining function that are the association rules and prediction  [6]. Association rule mining (ARM) is used to identify any  interesting relationships between a set of items in a database  especially for market basket analysis [6, 7]. ARM can also  be defined as the discovery of association rules showing the  attribute-value conditions that occur frequently together in a  given set of data [10]. In ARM, Apriori algorithm is known     to be the standard algorithm to the mine association rules  and it has been chosen for this study. The Apriori algorithm  uses prior knowledge to generate frequent patterns from the  dataset containing transactions [7, 14]. From [8], there are a  few works done using the association rules in the  manufacturing domain. They focused on the product design,  manufacturing process and decision support. The  association rule mining is used in past sales and product  records to discover the associations among the customer  needs, marketing employees and designers [9]. Production  data can be categorized as a time series data because the  sequences of values change with time. Association rules can  discover the temporal relationships that are hidden in these  data [20].

In this study, the proposed model is built using the  association rules to associate attribute values in order to  generate predictions or to estimate the expected outcomes.

Meanwhile, the prediction is a technique to predict a future  model of continuous-valued function. In predictive  techniques, some examples of the predictive data mining are  bagging, boosting, stacking and meta-learning. Usually,  prediction techniques are used for numerical and continuous  data. There are models generated from prediction techniques  that are linear, nonlinear and generalized linear model of  regression [6].

However to obtain good results, data mining should  provide multiple and/or integrated functionalities and  techniques [5]. Because of that, we proposed an associative  prediction model for product forecast data. In this research,  we used the Apriori algorithm. Apriori is a technique for  mining frequent itemsets for the Boolean association rules  [6]. The algorithm is suitable for the mining manufacturing  data due to the continuous change of the customers?  demands. Apriori algorithms can be used to provide  sufficient critical information and improve the  manufacturing productivity [11].

The third technique that we also applied is clustering.

Clustering is a method used to group similar items and  dissimilar items in clusters. It can also be used in certain  fields in manufacturing to group a set of items into classes  of similar objects. Generally, clustering is an unsupervised  learning [6]. In [8], there are already a few past researches  about clustering in manufacturing. It is a review based on  the application area in manufacturing like yield,  manufacturing process, design, defect detection, fault  diagnosis and supply chain. In clustering techniques, there  are five categories that can be classified; partitioning  methods, hierarchical methods, density-based methods,  grid-based methods and model-based methods.

In this study, we are applying the k-means method to  attain the link between the frequent patterns obtained from  the previous associative model. The k-means algorithm is  one of the simplest clustering techniques in partitioning  categories. This algorithm aims to partition n objects into k  clusters in which each observation belongs to the cluster  with the nearest mean. Mean also represents the cluster?s  centre of gravity [6]. The k-means algorithm can handle a  mixture of categorical and numerical attributes. This  algorithm does a distance computation by normalizing the  numerical attributes. It uses the Euclidean distance measure  to compute distances between the instances and clusters.

The method is relatively scalable and efficient in processing  large data sets. Thus, we are able to obtain the relevant link  between patterns in the associative prediction model.

Usually, it is computed using a fast, heuristic method that  generally produces good solutions [17].



III. METHODOLOGY  A. Data Collection and Pre-processing  There are four stages in data pre-processing phase; data  cleaning, data integration, data transformation and data  reduction [6]. The data is cleaned in such a way that the  missing values are handled and the noises are smoothened in  order to obtain a more consistent dataset for mining. Data  integration merges data from multiple sources of data.

Several attributes are transformed to categorical values and  reduced to limit categories to ensure the efficiency of the  mining process. Data reduction is the main challenge in pre-  processing because it needs to reduce the data size. It  involves aggregating the data to identify several attributes to  be removed and eliminate the redundant features.

The data were collected from a plastic component  manufacturer in Malaysia. The data consists of 42 product  parts which is represented by 42 files. After various  considerations, two important attributes were taken into  account in predicting the pattern for this forecast data. The  attributes were A1; days and A2; required quantity. Each  file contains 362 records that represent the required quantity  in days. After that, the records are reduced to 49 that  represent the required quantity in weeks. All 42 files were  combined to produce one large dataset. This step is  necessary in order to get the forecast pattern of one year for  all components.

Because the data mining needs a huge data to produce a  more accurate pattern we have to simulate the data of 15  years. In this study the Monte-Carlo simulation approach  have been used to simulate the 15 years forecast data. The  Monte-Carlo approach is based on the generation of  multiple trials to determine the expected value of a random  variable. This method using the RAND() function to  generate random numbers in interval (0, 1) and multiply  these by the range of each variable. The range is the  difference between the maximum value and the minimum  value [12, 13]. Equation (1) has been used in this simulation  for generating the required quantity in weeks. The  simulation produced 735 records for each product (i.e. 49  records in 15 years).

Random values = RAND ()*(max ? min) + min       (1)     In data transformation process, the market basket  analysis is applied to the dataset. The value of attribute A2  was converted into range and combined with other parts of  the product to produce p1r0, p1r1 and etc. We transform the  data into a range in order to get the dependencies that will  give the information on the frequency of the required  quantity [20].The p1r1 notation can be defined as product 1  (product latch noise eliminator) and r1 is range 1 that is  within the required quantity of 500 ? 1499. Attribute A1  only exists between attribute week1 until week49. The data  were mined to get the rules.

We conducted two main experiments that are the ARM  and Clustering. In ARM, there are two experiments using  the Apriori algorithms. First, we used four datasets because  of the limitations of the association approach. It is because  there is a great possibility to find many spurious  associations when involving a massive number of possible  associations in large dataset [18, 19]. This is also done to  select the important attributes in the 49 attributes. Then the  second experiment was conducted by using the best  attributes obtained from the first experiment. It is shown in  Table II. In clustering, we conducted the second stage of  experiment by applying the k-means method.



IV. RESULT  A. ARM  In ARM, two measurable parameters are used to measure  the importance of a rule; confidence measure and support  measure [15]. The minimum confidence (min_conf) and  minimum support (min_supp) are predetermined to control  the quality and the amount of generated rules [6, 7].

In the first experiment, the first dataset consisted data  from the attribute week01 to week10. This dataset was  measured by using min_supp of 0.25 and min_conf of 0.9,  0.8, 0.7 and 0.60 respectively. A thousand association rules  were generated from that experiment. The second dataset  was formed from the attribute week11 to week20, the third  dataset from the attribute week21 to week35 and the fourth  dataset contained the attribute of week36 to week49.

The best model from each datasets were chosen and  compared to each other. The rightmost column is the  number of rules generated after applying different min_supp  and min_conf. From the result in Table I, it shown that the  generated number of rules was constant at the confidence  value of 0.6 because the number of rules does not increase  even when min_conf was changed to 0.5 to 0.1. Therefore at  the first dataset, we get 1000 association rules and after that,  4 rules, 10 rules and lastly 8 rules. So overall, we get 1022  association rules with the min_conf value at 0.60.

TABLE I.        RESULT FIRST EXPERIMENTS  Attributes  Apriori Number of  Rules min_supp min_conf  week01- 0.25 0.90 1000  week10 0.25 0.80 1000  0.25 0.70 1000  0.25 0.60 1000  week11- week20  0.10 0.90 0  0.10 0.80 2  0.10 0.70 2  0.10 0.60 4  week21-  week35  0.10 0.90 0  0.10 0.80 3  0.10 0.70 10  0.10 0.60 10  week36-  week49  0.10 0.90 1  0.10 0.80 2  0.10 0.70 2  0.10 0.60 8  From the four datasets, we get 14 important attributes  and 1022 association rules. The attributes shall be applied in  the second experiment that also uses the Apriori algorithm.

Table II shows the number of rules generated for the values  of min_conf from 0.9 to 0.1. Based on these results, the  same observation can be conducted, as at the confidence  value of 0.6 the generated number of rules has stopped  increasing. The results shown in Table II involved all  attributes from week01 to week49.

These results were obtained after we used the generated  rules from the earlier four datasets. Table II also shows that  the decreasing min_conf does not improve the number of  rules generated. We evaluated the rules and chose the rules  that have min_conf value higher from 0.6. In addition, the  value of min_supp was set to 0.1 only. This is because if we  use another value of min_supp, no rules will be generated.

TABLE II.        RESULT SECOND EXPERIMENTS  Attributes  Apriori Number of  Rules min_supp min_conf  week01-  week49  0.10 0.90 2  0.10 0.80 10  0.10 0.70 18  0.10 0.60  30  0.10 0.50 30  0.10 0.40 30  0.10 0.30 30  0.10 0.20 30  0.10 0.10 30  TABLE III.     EXAMPLE OF THE RULES FROM PRODUCT DATASET  Rules Confidence  1.week33=p4r1  ==> week19=p4r1      1.00  2.week42=p3r3  ==> week45=p3r2     1.00  3.week31=p3r2  ==> week28=p3r2      0.88  4.week14=p4r4  ==> week19=p4r1      0.86  5.week17=p3r2  ==> week28=p3r2  0.86  6.week17=p4r2  ==> week19=p4r1     0.86  7.week19=p3r1  ==> week46=p3r2      0.86  8.week34=p3r1  ==> week21=p3r2    0.86  9.week34=p3r1  ==> week33=p3r1      0.86  10.week47=p4r1  ==> week49=p4r1    0.86  11.week21=p3r2  ==> week34=p3r1 0.75     12.week33=p3r1  ==> week34=p3r1 0.75  13.week19=p4r1  ==> week33=p4r1     0.70  14.week28=p3r2  ==> week17=p3r2      0.67  15.week46=p3r2  ==> week19=p3r1  0.67  Table III shows only 15 association rules using  min_supp 0.1 and min_conf, 0.2 after 18 numbers of cycles.

It is sorted by min_conf. From Table III, the first rule has  min_conf 1.00. The first rule was represented in week33 that  is within the period of 06 th  September to 12 th  September,  product 4 (retaining ring) have been produced in the range  of r1 (0 - 21999) and frequently associated with week19 (in  st May to 06  th June) and in the same production range of  product 4 (retaining ring), r1 (i.e. 0 ? 21999). However, the  13th rule showed otherwise that week19 is associated with  week33 but with an unequal min_conf, i.e. 0.70.

B. Clustering  Based on the result obtained from the associative  modelling as shown in Table II, we used k-means method  for the second experiments. We used 6 for the number of  clusters and 10 for value of seed with 30 association rules  from Table II. The seed value is used for generating a  random number. This number will be used in making the  initial assignment of instances to clusters. In general, the k-  means is quite sensitive on how clusters are initially  assigned. Thus, it is often necessary to try different values  and evaluate the results. We used 6 as the number of cluster  because it depends on the choice of distance measures with  only 14 attributes involved.

After the experiment was completed, the results show that  there were overlapping clusters with the same attributes.

Table IV shows all the attributes involved in the six clusters.

C is represented to cluster and it started with 0 until 5, i.e.

C0, C1, C2, C3, C4 and C5. Object in each cluster, such as  w14:p4r4 was represented in week 14, product 4 and range  production 4. In six clusters, we can see that there are same  objects in different clusters. For example, in C1, C2 and C5,  there are w21:p3r2 and w34:p3r1.

Other than that, we can also conclude for each cluster  that possesses the same characteristics in the objects.

Criteria in C0 has only object related with product 4;  retaining ring, C3 related with product 2; insulator AB, C4  related with product 1; latch noise eliminator. Then, C1, C2  and C5 are related with only product 3; housing.

C. Knowledge Analysis  Fig. 1 denotes the comparison between the association  and the clustering that occurred in 14 important attributes  (out of 49 attributes). These are the 30 final rules obtained  from Table 3. From the result, the knowledge obtained is the  frequent products discovered to be p3 and p4 (i.e. housing  and retaining ring). Housing component frequently appeared  in two ranges, r2 that represents the required quantity within  0 to 999, and r3, the required quantity range of 1000 to  1999. Meanwhile, retaining the ring frequently occurred in  three ranges (i.e. r1, r2 and r4). These ranges represent  values between 0 to 21999, 22000 to 41999 and 62000 to  81999.

There are relationships between the particular association  rules as some rules imply to others (Witten and Frank,  2005). Within the 14 discovered attributes, all attributes  have association with each other. For example, attribute  week33 is associated with week19, and otherwise.

TABLE IV.        EXAMPLE OF THE RULES FROM PRODUCT DATASET  C0 C1 C2 C3 C4 C5  w14 : p4r4  w17 : p4r2 w19 : p4r1  w21 : p4r3  w22 : p4r2 w28 : p4r3  w31 : p4r3  w33 : p4r1 w34 : p4r3  w38 : p4r1  w42 : p4r1 w45 : p4r1  w46 : p4r1  w47 : p4r2 w49 : p4r1  w14 : p3r1  w17 : p3r3 w19 : p3r3  w21 : p3r2  w22 : p3r1 w28 : p3r3  w31 : p3r1  w33 : p3r1 w34 : p3r1  w38 : p3r3  w42 : p3r1 w45 : p3r2  w46 : p3r3  w47 : p3r2 w49 : p3r3  w14 : p3r2  w17 : p3r2 w19 : p3r3  w21 : p3r2  w22 : p3r2 w28 : p3r2  w31 : p3r2  w33 : p3r2 w34 : p3r1  w38 : p3r3  w42 : p3r2 w45 : p3r1  w46 : p3r2  w47 : p3r1 w49 : p3r3  w14 : p2r1  w17 : p2r1 w19 : p2r4  w21 : p2r1  w22 : p2r2 w28 : p2r3  w31 : p2r1  w33 : p2r4 w34 : p2r5  w38 : p2r3  w42 : p2r4 w45 : p2r3  w46 : p2r1  w47 : p2r2 w49 : p2r4  w14 : p1r1  w17 : p1r3 w19 : p1r1  w21 : p1r1  w22 : p1r5 w28 : p1r6  w31 : p1r1  w33 : p1r1 w34 : p1r2  w38 : p1r4  w42 : p1r2 w45 : p1r5  w46 : p1r6  w47 : p1r1 w49 : p1r2  w14 : p3r3  w17 : p3r2 w19 : p3r2  w21 : p3r2  w22 : p3r3 w28 : p3r2  w31 : p3r2  w33 : p3r1 w34 : p3r1  w38 : p3r1  w42 : p3r3 w45 : p3r2  w46 : p3r3  w47 : p3r3 w49 : p3r3  However the min_conf between these two associations  are different. If week33 is associated with week19, the  product retaining ring produced is in the range of 21999, it  has min_conf of 1.0 and for another association rule; if  week19 is associated with week33 (with product retaining  ring with the same range), it only has min_conf 0.7.

Attribute week33 is also associated with week34 and  week21. In this dataset, at least one attribute is associated  with another attribute once and the most association that  may possessed by one attribute is four associations.

From Table IV, we attempt to relate the links between  the association rules in Table III. From two tables, we gain  knowledge that is displayed in Fig. 1. From that figure, it  showed only four clusters. This is because in the 30  association rules, association only occurred in C0, C1, C2  and C5. In C3 and C4, association does not happen between  the objects.

Figure 1. Association and clustering between attributes .



V. CONCLUSIONS  In manufacturing the environments, numerous factors  contribute to the productivity. These factors such as the  personnel, machine capacity or material are conditionally  dependent on one another. Due to this, the data mining  techniques can be applied on manufacturing data to assist  the manufacturer in getting an interesting and valuable  knowledge. In this paper, we used the Apriori algorithm to  obtain association rules and predict when the most frequent  production occurs in the plastic company. Also, we use the  k-means algorithm to uncover the link between the observed  frequent patterns. From the experiments, we obtained the  association prediction model and found two most produced  products, i.e. housing and retaining ring. Also, week 19 and  week 33 are the frequent weeks, so it can be concluded that  the production is massive in week 19 and week 33.

Further analysis can be done using other techniques in  association rules or clustering. Data in manufacturing  possess the characteristics of imbalance and fluctuate. This  will be an interesting challenge to the data mining  researchers to obtain interesting and valuable information.

This study can also be viewed from other angle to solve  another issue that might be raised in the plastic industry  such as the cycle time production, capacity, maintenance or  quality control.

