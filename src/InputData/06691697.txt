Evaluating Task Scheduling in Hadoop-based Cloud Systems

Abstract?Nowadays, private clouds are widely used for resource sharing. Hadoop-based clusters are the most popular implementations for private clouds. However, because workload traces are not publicly available, few previous work compares and evaluates different cloud solutions with publicly available benchmarks. In this paper, we use a recently-released Cloud benchmarks suite---CloudRank-D to quantitatively evaluate five different Hadoop task schedulers, including FIFO, capacity, na?ve fair sharing, fair sharing with delay, and HOD (Hadoop On Demand) scheduling. Our experiments show that with an appropriate scheduler, the throughput of a private cloud can be improved by 20%.

Keywords-Cloud, Hadoop, Taks scheduling, Evaluation.



I. INTRODUCTION Private clouds are widely used in modern enterprises  [1][2][3][4][5]. A well-known implementation of private clouds is Apache Hadoop [6], which is an open-source software framework for processing a large volume of data on a cluster. Commonly, a private cloud serves multiple users.

Each user may have different priorities, task types, and data sizes. Usually, such user variations are significant, leading to a challenge for task scheduling.

There are five task schedulers implemented in Hadoop: FIFO (First In First Out), capacity [7], na?ve fair sharing [2], fair sharing with delay [3], and HOD (Hadoop On Demand) scheduling [8]. FIFO, the default scheduler of Hadoop, executes tasks according to their arrival order. Capacity, a multi-user scheduler, designs a multi-level resource constraint to make full use of resources. In the fair sharing with delay scheduler, Zaharia et al. [3] propose a simple algorithm called delay scheduling for improving data locality: when the job that should be scheduled next according to fairness cannot launch a local task, it waits for a small amount of time, letting other jobs launch tasks instead.

HOD, built on Torque [9] resource manager, targets virtual Hadoop clusters.

Previous work [3] presents an evaluation among FIFO, na?ve fair and fair with delay scheduling. However, its workload traces are not publicly available, and hence users  can not repeat the experiments to compare or optimize different task scheduling algorithm.

In this paper, we use a publicly available Cloud benchmarks suite---CloudRank-D to evaluate five different Hadoop task schedulers, including FIFO, capacity, na?ve fair sharing, fair sharing with delay, and HOD (Hadoop On Demand) scheduling. In comparison with that in [3], the workloads in CloudRank-D are more diverse, including basic operations, data mining, and data warehouse operations, and user can increase or decrease both the data and workload scales according to their requirements. The main contribution of this paper is that we use a publicly available benchmark suite to quantitatively evaluate five Hadoop schedulers. We reports the performance of a small-scale Hadoop deployment, including average turnaround time, throughput, average execution time of job, average waiting time, and data processed per second. Our work provides a basis for further optimization of task scheduling in Hadoop-based systems.

The rest of the paper is organized as follows: Section II introduces Hadoop task schedulers as background knowledge. Section III describes the CloudRank-D. Section IV presents the evaluation of Hadoop?s five schedulers.

Finally, section V concludes the paper and shows future work.



II. HADOOP TASKSCHEDULER  A. Hadoop Overview The Apache Hadoop is an open-source software frame  work that is proposed for distributed processing of large data sets across clusters of computers. Hadoop consists of the MapReduce [10] model and the Hadoop Distributed File System (HDFS).

In MapReduce model, a job is divided two parts: Map task and Reduce task. Firstly, the data set is divided into several dependent blocks of data and delivered to Map tasks as key-value pairs. Map tasks produce intermediate key- value pairs, and then the intermediate key-value pairs are transferred to Reduce tasks in the shuffle phase. At last, the      intermediate data is processed by Reduce tasks to generate the final output key-value pairs.

The HDFS is designed for storing all input and output data, and multiple replicas of each data block are stored on many different cluster nodes.

B. Hadoop Task Scheduler In Hadoop, the task scheduler is a pluggable and  important module, which is used to assign the idle system resources to jobs according to a certain strategy. Because the task scheduler is pluggable, the users can select and design the schedulers according to their requirements.

Several schedulers are proposed by different organizations and researchers to satisfy their specific requirements. Here we just introduce the five common schedulers in Hadoop mentioned above.

1) FIFO FIFO scheduler is the default scheduler in Hadoop. In  FIFO scheduling, the first job in the work queue in terms of job submission time will be chose and performed by JobTracker firstly, and jobs? size or priority will be ignored.

The FIFO algorithm is efficient and easy to implement, but its drawback is also obvious, such as low resource utilization rates and no support for multi-user executions.

2) Na?ve Fair sharing The core idea of the fair scheduler is to assign resources  to all jobs on average as far as possible, and each job can get the same share of resources. When only one job is performed in the system, it will monopolize the entire cluster and use all computing resources. Once other new jobs are submitted, the system will assign idle task slots to them, in order to ensure that each job can achieve approximately the same amount of computing resources. The jobs that require less time can access the CPU and can be completed within a reasonable time, but the jobs that require more time to execute are also able to access resources at the same time [11].

All jobs are grouped and pushed into a set of job pools created by Hadoop in advance. Each job pool can be assigned minimum of share resources, and all pools have equal shares by default. But we can configure job pools as required, such as assigning shares depending on job type, and constraining the numbers of jobs executing at the same time.

Na?ve Fair sharing supports multi-users, and each user is assigned a job pool, which is assigned by equal share of cluster resources like other users, no matter how many jobs the user has submitted [11].

The advantage of na?ve fair is that it can improve the quality of service by supporting job classification schedule, in which resources are assigned by job type, and takes full use of resource, by the manual configuration of the number of jobs in parallel. But, it ignores the actual load condition of its nodes, easy to result in the load imbalance of nodes.

3) Fair Sharing with Delay Scheduling  In the case of Na?ve Fair sharing, a job may be launched with local data. So the fair sharing with delay scheduling is proposed to solve this problem. When a new job is submitted, the system will choose to delay task execution if there is no required data on the current assigned node, and then allow other jobs that meet data locality [3] to be scheduled first.

4) Capacity Scheduling Capacity scheduling supports multiple queues, and each  queue is allocated on a certain amount of resources, within the upper and lower limit. Each user can also set a certain limit to prevent the misuse of resources. Idle resources can be allocated to heavy load queues dynamically. [12]  Each queue uses FIFO scheduling. During the period of scheduling, the scheduler can choose an appropriate queue by calculating the ratio between the numbers of running tasks and allocated computing resources, and choose the smallest ratio; then, it can choose a job by the priority and the submitted time of the job, considering the limit of user resources and memory at the same time [7].

The advantages of capacity scheduler are listed as follow: it can improve resources utilization by supporting parallel executions of multiple jobs and sharing cluster for multiple users; it have high flexibility and execution efficiency by dynamically adjusting resource allocation; it can be used on large clusters and support jobs under intensive resources.

The disadvantage of capacity scheduler is that users need to learn a large amount of system information so as to select and set a queue.

5) HOD The HOD is not a true scheduler; it is proposed for  quickly building several independent virtual Hadoop clusters in a shared physical cluster, in order to achieve different purposes.

The HOD allocates nodes for a virtual Hadoop cluster with the Torque resource manager according to the needs of the virtual cluster. Then, the HOD starts every daemon in MapReduce and HDFS on the allocated nodes, and automatically creates configuration files for Hadoop daemons and clients [8].

The advantages of HOD are listed as follows: it is adaptive for the changing load, and the physical cluster resources can achieve the highest efficiency in this way; its security is quite higher because the nodes rarely share resources. But its performance is inefficient, and its configuration relies upon a solid understanding of cluster systems.



III. THE INTRODUCTION OF CLOUDRANK-D CloudRank-D [13] is a benchmark suite for private cloud,  which can help researchers to simulate various multi-user applications in industrial scenarios. As shown in Table I, the benchmark suite provides a set of 13 representative data analysis tools, including basic operations for data analysis, classification, clustering, recommendation, sequence     learning, association rule mining applications, and data warehouse operations. In the CloudRank-D design, diversity of data characteristics of workloads are considered, including data semantics, data models, data sizes, and characteristics of data-centric computation, e.g., the ratio of the size of data input to that of data output. Moreover, the users can easily increase or decrease both data and workload scale according to their requirements, e.g., different cluster size.

TABLE I.  DATA SOURCES OF EACH PROGRAM IN CLOUDRANK-D [13]  Application  Data sources  Sort  Automatically generated  Word count  Grep  Naive Bayes News and Wikipedia  Support vector machine  Scientist search  K-means  Sougou corpus Item based collaborative  filtering  Ratings on movies  Frequent pattern growth  Retail market basket data  Click-stream data of an on-line news portal  Traffic accident data  Collection of web html document  Hidden Markov model  Scientist search  Grep select  Automatically generated table Ranking select  User visits aggregation  User visits-rankings join

IV. EVALUATION We use the CloudRank-D benchmark to evaluate five  typical Hadoop schedulers including FIFO, capacity, na?ve fair sharing, fair sharing with delay scheduling and HOD.

A. Benchmarks and Methodology The real applications in private clouds running big data  applications can vary dynamically. Reference [14] In order to evaluate the Hadoop task schedulers in a proper way, and considering the scale of cluster we used, we synthesize a 100-jobs mixed workload with Cloud-D. Please note that with CloudRank-D, users can scale-up or scale-down the workload traces in terms of both data and workload scales according to their requirements. Please refer to the details in [15].

Table II shows the workload breakdown in CloudRank-D in terms of job number: 31% (Basic Operations), 35% (Data Mining Operations), 34% (Data Warehouse Operations). As shown in Fig. 1, according to the explanation in [15], the ratios of different workloads are consistent with usage percentages of applications in private clouds reported in [16].

Another important attribution of workloads is input data size. CloudRank-D follows the distribution of input data size reported in workload characterization of a large electronic commence---Taobao [17]. Table III shows the percentage of different input data in our experiments. The total size of input data of all workloads is about 1.7TB.

TABLE II.  WORKLOAD BREAKDOWN IN CLOUDRANK-D  Category Application Jobs  Basic Operations  Sort  9  Word count  11  Grep  11  Data Mining Operations  Na?ve Bayes 6  Support vector machine  6  K-means  7  Item based collaborative  3  Frequent pattern growth  7  Hidden Markov model  6  Data Warehouse Operations  Grep select  Ranking select  user visits aggregation  user visits-rankings join     Figure 1.  Usage percentages of applications in private clouds reported in  [16].

TABLE III.  THE PERCENTATAGE OF DIFFERENT INPUT DATA IN WORKLOADS.

Input Data size Percentage  <25MB 40.57%  25MB-625MB 39.33%  1.2GB-5GB 12.03%  >5GB 8.07%  Reported in [3], job submission in Facebook roughly follows an exponential distribution with a mean of 14  Image processing  2% Text indexing 16%  Log processing  15%  Web crawling 15%  Data mining 7%  Machine learning  11%  Reporting 17%  Data storage 17%     seconds [3]. With CloudRank-D, workloads are submitted in a random order following this distribution.

About the metrics, we select turnaround time (total time taken from the submission of a job till the end of the job execution), which is a performance metric from perspective of users and select the throughput in terms of the number of jobs finished per minute) to measure system capacity. And then we break down the turnaround time into average running time (the execution time of job) and average waiting time (the time of job wait in queue). We have also chosen data processed per second (DPS) to measure the data processing capability. According to [13][15], the metric of data processed per second is defined as the total amount of data inputs of all jobs divided by the total running time from the submission time of the first job to the finished time of the last job.

Hadoop parameter configuration can often have a great impact on system performance. In order to ensure all the five schedulers in the best situation in the case of evaluation, we optimize the Hadoop configuration according to the physical node in cluster before evaluation. And then we optimize the schedulers according to the cluster configuration and workload characteristics, modify Hadoop configuration file to use five schedulers to run the same mixed workloads, respectively.

B. Testbed To evaluate the Hadoop task schedulers, we deploy a  Hadoop cluster with 5 nodes (one NameNode and four DataNodes). Each node has the same hardware configuration: Intel Xenon E5645CPU, 16GBMemory, and 8TB Disk. These nodes are connected by Gigabit switch.

Each node has also the same software stack: CentOS 5.5 with kernel 2.6.34, Hadoop 1.0.2, Mahout 0.6, and Hive 0.11.Table IV lists the detail parameter configuration of the Hadoop cluster.

TABLE IV.  CONFIGURATION DETAILS OF NODES  CPU Type Intel CPU Core Intel ?Xeon E5645 6 cores@2.40G  L1 D/I Cache L2 Cache L3 Cache Memory Disk 6 ? 32 KB 6 ? 256 KB 12MB 16GB 8TB  OS Hadoop Mahout Hive CentOS 5.5 1.0.2 0.6 0.11  C. Hadoop Scheduler Evaluation Before the evaluation, we should optimize the Hadoop  configuration. Some Hadoop parameters and its values are shown in Table V.

We should also optimize the performance of five schedulers according to the cluster configuration and workload characteristics. And then when it is in a better performance, we run the mixed workload with five schedulers respectively by changing the profile of Hadoop.

The submitted sequence and job-interval are all the same. A shell script to submit 100-job in parallel is written  automatically; during the process of shell script writing, Hadoop logs are also recorded for debugging.

1) Data Processed per Second The data processed rate can show the performance of  private cloud system on a whole level. Fig. 2 shows the total running time of 5 different schedulers by running the whole workload. The total running time is about 5-6 hours.

TABLE V.  HADOOP PARAMETERS AND ITS VALUES  Hadoop Parameter Value Description  mapred.tasktracker.map.tasks.ma ximum 12  The maximum number of map tasks that will be executed simultaneously by a task tracker.

mapred.tasktracker.reduce.tasks.

maximum 12  The maximum number of reduce tasks that will be executed simultaneously by a task tracker.

mapred.map.tasks 48 Maximum number of concurrent running reduce task.

mapred.reduce.tasks 45 Maximum number of concurrent running map task.

dfs.replication 2 The actual number of replications specified when the file is created.

mapreduce.tasktracker.outofband .heartbeat TRUE  Open the out of band heartbeat.

Figure 2.  The total running time (103sec) of running full workload by  using five schedulers respectively.

As shown in Fig. 3, because the fair sharing with delay scheduling can solve locality problem, its DPS is 1.17 times that of Na?ve Fair sharing and 1.2 times of FIFO scheduler.

Capacity scheduler can enhance the utilization of system; it can improve the DPS by 4% than that of FIFO scheduler.

Fair with DS Na?ve Fair Capacity FIFO HOD  T ot  al ru  nn in  g tim  e (1  s)  Task Scheduler      Figure 3.  The Data Processed per Second (Megabytes processed per  second) of running full workload by using five schedulers respectively.

2) Turnaround time Turnaround Time can often show an intuitive view of  system performance at the user level, Fig. 4 shows the average turnaround time of five schedulers. Compared to HOD and FIFO schedulers, na?ve fair, fair with delay scheduling and capacity schedulers can significantly reduce the job average turnaround time. Especially, fair with delay scheduling consumes the least amount of time. It mainly because that these three schedulers can reduce network cost.

At the same time, these three schedulers limit the number of concurrent jobs, this limitation can reduce the cost of scheduling between jobs in task pool, and system can get a performance bonus. But from Hadoop log file we can see that fair with delay scheduling can affect some jobs with large size data, if the job doesn?t meet data locality, and the pool will have some other jobs to run, the job without data locality have to wait for some time, so some jobs with large size data will have longer time to finish than usual jobs.

Because of the cost of competition of each concurrent job in queue, FIFO scheduler performed not very well, and due to the extra virtualization cost, HOD scheduler performed even worse than FIFO scheduler.

Figure 4.  The average job turnaround time (103sec) of running full  workload by using five schedulers respectively.

a) Running time Fig. 5 presents the average running time of five  schedulers. Through limiting the number of concurrent jobs,  Hadoop can enhance the performance. Because of approving data locality, fair with delay scheduling can reduce average running time significantly, which is only 29% of that of FIFO scheduler and 26% of that of HOD scheduler. The HOD scheduler also has the longest average running time.

b) Waiting Time Fig. 6 shows the average waiting time of five schedulers.

Waiting time indicates the time of job in the queue waiting to be executed, because naive fair, fair with delay and capacity schedulers limits the number of jobs in parallel, its average waiting time is much longer than the other two schedulers.

Fair with delay scheduler can enhance system throughput, resource release is faster than Fair scheduler, so the average waiting time should be less than Fair scheduler which doesn?t use the delay scheduling algorithm. The limitation on the number of concurrent jobs in capacity scheduler is a little larger than Fair scheduler, so its average waiting time is shorter than that of Fair scheduler. As to FIFO and HOD schedulers, the mixed workload did not reach its maximum of concurrent jobs, and submitted jobs are running in parallel, so their average waiting time is almost zero. Thus, it can be seen that the cost of job scheduler in Hadoop is pretty large when jobs are executed in parallel, so to limit the number of concurrent jobs in certain size can significantly improve overall system performance.

Figure 5.  The average job running time (103sec) of running full workload  by using five schedulers respectively.

Figure 6.  Average job waiting time (second) of running full workload by  using five schedulers respectively.

Fair with DS Na?ve Fair Capacity FIFO HOD  D PS  (M B  /s )  Task Scheduler  0.0  0.2  0.4  0.6  0.8  1.0  1.2  Fair with DS Na?ve Fair Capacity FIFO HOD  T ur  n ar  ou nd  ti m  e (1  s)  Task Scheduler  0.0  0.2  0.4  0.6  0.8  1.0  1.2  Fair with DS Na?ve Fair Capacity FIFO HOD  R un  ni ng  ti m  e (1  s)  Task Scheduler        Fair with DS Na?ve Fair Capacity FIFO HOD  W ai  tin g  tim e  (s ec  .)  Task Scheduler     3) Throughput Through the throughput, system administrators can  evaluate system performance clearly, higher throughput indicates that the system can complete more jobs in unit time, and the system resources can be utilized sufficiently.

Fig. 7 presents the throughput (number of jobs processed in one minute) of five schedulers under mixed workload.

Because the mixed workload contains many large jobs, the value of throughput is low. By solving the locality problem, the throughput of fair with delay scheduling can gain an outstanding improvement, which is 1.2 times of that of default FIFO scheduler. Although Na?ve Fair sharing and capacity schedulers have different turnaround time, their throughputs are almost same; they are all larger than FIFO scheduler and HOD scheduler.

Figure 7.  The throughput (number of jobs processed in one minute) of  running full workload by using five schedulers respectively.

Through the above experiments, we find fair with delay scheduling scheduler is the most efficient scheduler; it can be shown in DPS, average turnaround time, average running time, and throughput. But due to the affection of data locality some jobs with large size will have longer time to finish than usual jobs.

For running mixed workload the Na?ve Fair sharing and capacity scheduler have the nearly same performance in throughput and DPS two administrator?s perspective, but na?ve fair has the shorter average turnaround time and capacity has the shorter average waiting time. Fair with delay scheduling, na?ve fair, capacity, these three schedulers are all have the better performance than default FIFO scheduler.

HOD scheduler preformed not very well, affected by the extra cost of virtualization.



V. CONCLUSIONS With the popularization of Hadoop, numerous private  clouds based on Hadoop clusters are established by many organizations. Since these data centers are often used by multiple users, optimizing the performance of Hadoop clusters is very necessary and significant. In this paper, we evaluate the five common Hadoop schedulers by using CloudRank-D, a publicly benchmark suite for private cloud.

Throughput, Turnaround time and Data Processed per  Second are chosen as the metrics of evaluation. Experimental results show that different task schedulers have different influences on system performance in different situation, so the choice of task schedulers is very critical for system performance improvement of Hadoop cluster. Specially, fair sharing with delay scheduling can improve data locality and reduce the cost of network communication between nodes, and DPS is improved by 20% than that of FIFO scheduler.

Optimization and design of the scheduler need to refer to the characteristics of the workload. In the future, we will use more complex workloads to study and evaluate more efficient task schedulers for Hadoop based cloud systems.

