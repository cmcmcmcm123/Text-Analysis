Risk Adjustment of Patient Expenditures: A Big Data Analytics Approach

Abstract?For healthcare applications, voluminous patient data contain rich and meaningful insights that can be revealed using advanced machine learning algorithms. However, the volume and velocity of such high dimensional data requires new big data analytics framework where traditional machine learning tools cannot be applied directly. In this paper, we introduce our proof-of-concept big data analytics framework for developing risk adjustment model of patient expenditures, which uses the ?divide and conquer? strategy to exploit the big-yet-rich data to improve the model accuracy. We leverage the distributed computing platform, e.g., MapReduce, to im- plement advanced machine learning algorithms on our data set. In specific, random forest regression algorithm, which is suitable for high dimensional healthcare data, is applied to improve the accuracy of our predictive model. Our proof-of- concept framework demonstrates the effectiveness of predictive analytics using random forest algorithm as well as the efficiency of the distributed computing platform.

Keywords-Healthcare Big Data, Risk Adjustment, Dis- tributed Computing, Random Forest, Patient Expenditure

I. INTRODUCTION  Risk adjustment model [1] performs as an actuarial tool to predict health costs based on the relative actuarial risks of a patient, which is becoming increasingly important due to their value towards (a) Identification of high-risk (future high cost or high utilization) individuals for program management, (b)Normalization of population to evaluate the provider effectiveness and efficiency in terms of manag- ing resources among different types of patient, (c) Pricing health plan or predicting future claims cost trends, etc..

There are many risk-adjustment models that have been pub- lished [2], where the CMS hierarchical condition categories (HCC) model has been adopted by CMS for Medicare risk-adjustment because of its transparency, simplicity of modeling, and clinical coherence [2]. CMS/HCC risk ad- justment model represents the patient diagnosis information with hierarchical condition categories (HCC) that effectively reduce the number of the diagnostic categories by imposing the hierarchies among diseases and use linear regression algorithm to train the predictive model mainly because of its computational efficiency and the robustness to limited data.

However, the nonlinear functional relationship between the  patient risk factors and the health costs cannot be sufficiently captured by linear regression model.

Health care industry is experiencing the impact of Big Data, which brings the opportunity to improve the accuracy of the risk adjustment model. The high volume of data can overcome the data noise and bias. On the other hand, Big data also enable the effectiveness of the advanced machine learning algorithms. In general, advanced machine learning algorithms have more parameters to be optimized than simple methods. Therefore, a limited supply of data may introduce the over-fitting problem and thus reduce its effectiveness, which is not an issue for big data applications.

Therefore, we aim to leverage advanced machine learning algorithms and healthcare big data to improve the prediction performance of risk adjustment model. For patient big data, the new processing environment is required to store, transfer and analyze voluminous data, which is beyond the ability of conventional data processing tools, for example Matlab.

Therefore, a distributed computing platform with the Apache Hadoop infrastructure [3] is employed in our study to support our data-intensive application. Hadoop derived from MapReduce [4] provides a distributed, scalable, and portable file system to hold vast amounts of data on a cluster of machines with high aggregate bandwidth across the clusters and uses ?divide and conquer? strategy to run an application in parallel across the cluster against parts of the stored data.

In addition, the large amount of risk factors of the patient expenditure including demographics, diagnoses, comorbidi- ties, etc. induces the data high-dimensionality, which also leads to the difficulty of modeling. Random Forests [5], as one type of ensemble machine learning algorithms, are particularly suitable to modeling the complex functional relationship in high-dimensional data, which can achieve increased performance by generating multiple prediction models each with a different feature subset. Therefore, we proposes a random-forest-based risk adjustment model running on the MapReduce platform to fight the ?curse of dimensionality?. This paper demonstrates the promising results of our prototype framework with respect to both prediction accuracy and computation efficiency.



II. PATIENT DATA  This paper utilized inpatient databases collected from New York State to test the proposed framework of the risk adjustment model for Healthcare big data. It contains a core set of clinical and nonclinical information on all patients,which allows estimation of inpatient expenditure based on various patient risk factors including demographics, principal and secondary diagnosis, and comorbidities.

A. Patient Feature Extraction  In this paper, we use CMS hierarchical condition cate- gories (HCC) to extract patient features, which is adopted by CMS for Medicare risk adjustment because of its trans- parency, ease of modification, and good clinical coherence.

To be specific, demographic risk factors included in the model are 24 mutually exclusive age/sex cells. For diagnosis information, CMS/HCC model first maps the raw diagnosis data coded with ICD9 code [6] to Condition Categories (CCs) and then map CCs to 70 hierarchical condition categories (HCC) by imposing hierarchies [7], as shown in Figure 1. In addition, multiple comorbidities, such as alcohol abuse, congestive heart failure, depression and diabetes are also incorporated to enrich the patient representation. Over- all the risk factors for patient expenditure are represented by 125 dimension features.

Figure 1. Diagnostic feature extraction using CMS-HCC model

III. PREDICTIVE MODEL IN MAPREDUCE PARADIGM  For predictive model, linear regression model is widely used as a standard one for risk adjustment [2], partly because of its robustness to limited data with high-dimensionality.

The availability of enormous patient data enables the ef- fective application of the advanced regression algorithms, which are better qualified to identify the nonlinear complex functional relationship in patient data. In this paper, Leo Breiman?s random forests algorithm as one type of advanced regression model is chosen to build the predictive model [5], because of its suitability for high-dimensional data. Given  the high-dimensionality of the patient risk factors, The ran- dom forest methodology use ?divide and conquer? strategy to achieve enhanced prediction performance, by training an ensemble of decision trees each with a different feature subset and using the vote scheme to combine the results.

Random forest also holds some other desirable advantages for this application such as robustness to noise and outliers, suitability for parallelization, and lack of dependence upon tuning parameters [5], [8]. The random forest regression model can be generally described by three steps:  ? Draw n bootstrap sample from the original patient data.

? For each of the bootstrap samples, grow a regression  tree. At each node randomly sample m risk factors and choose the best split among those variables.

? Predict new sample by aggregating the prediction of the n trees.

where the optimal value of free parameters (n and m) are determined by the best results of cross-validation dataset after scanning these parameters. Apache Hadoop is used to build a distributed computing cluster, which contains one master server and three slave servers for the initial prototype framework. We use Apache Mahout?s random forest implementation [9], [10] to train the risk adjustment model on the cluster, which builds enormous number of decision trees in the model in parallel.



IV. RESULTS  In this paper, we would like to evaluate the effectiveness of the random forest-based risk adjustment model and the efficiency of the distributed computing framework. The linear regression model used in Medicare risk adjustment is adopted as the baseline. Five-fold cross-validation is imple- mented on one hospital data (100,000 samples) to compare the performance between the linear regression and random forest regression model, where R2 is calculated to measure the prediction accuracy. The results show that the ran- dom forest (R2 = 0.38/0.008 (mean/ standard derivation)) significantly outperforms linear regression model (R2 = 0.31/0.01 (mean/standard derivation)), which indicates the effectiveness of the random forest to identify the complex patterns in high dimensional patient data and thus illustrates its capability of enhancing the risk adjustment model per- formance. The comparison of 2D histogram between linear regression and random forest for test data is shown in Figure 2, where x axis and y axis present the predicted inpatient expenditure (log10) and the actual/target inpatient expenditure (log10), respectively. The color is labeled by the number of test samples located at (x, y). If the inpatient expenditure of a sample is able to be correctly predicted, then the sample will lie along the diagonal. It is observed that there are more samples located close to diagonal for random forest model than linear regression model.

In addition, we evaluate the enhancement by distributed computing on multiple servers to address the computation     Target log  ( expenditure )  P re  di ct  ed lo  g 1 0(  ex pe  nd itu  re )     Random Forest  3 4 5 6   3.5   4.5   5.5  6 0       Target log  ( expenditure )  P re  di ct  ed lo  g 1 0(  e xp  en di  tu re  )     Linear Regression  3 4 5 6   3.5   4.5   5.5   Figure 2. Comparison of 2D histograms between linear regression and random forest for test data  burden induced by both model complexity and high volume of data. All New York inpatient data (3, 400, 000 samples) are used to build the random forest model (200 trees and 10 features per tree). Compared to running on a single server, we achieve a 2.32 times speedup by using Hadoop infrastructure to parallel the computation on 3 slave servers, where computation time on a single server is 299 sec and computation time on 3 slave servers is 121 sec.



V. DISCUSSION  This paper describes our ongoing research that uses ?di- vide and conquer? strategy to leverage health care big data and advanced machine learning technology to improve the risk adjustment model. Our results show that the random- forest-based model significantly outperform the linear re- gression model employed by CMS, which illustrates the effectiveness of the random forest algorithm to identify the complex relationship in high-dimensional patient big data. It also indicates its potentials to incorporate more patient risk  factors, such as disease history, insurance, income level, sec- ondary diagnoses to enrich the risk adjustment model. In ad- dition, it is evident that our distributed-computing platform successfully supports the data-intensive and computation- intensive application. The distributed-computing cluster can be expanded to enable learning the model from national- wide data set (billions of samples), and thus to exploit the power of big data in risk adjustment and other health care service areas.

