Text Categorization by MILO Tree Traversals

Abstract?This paper presents a new method based on  MILO for automatic text categorization. MILO classification technique is a new rule-based classification technique, which is different from traditional rule-based technique such as decision tree and association rule. MILO-based classification technique further analyzes the content structure of documents, and classifies them by finding underlying term that links across paragraphs. The previous research based on MILO extracted the classification rules from a single document at a time, and these extracted rules are locally associated with the document?s subject and independent with the rules that are extracted from other documents. Hence, this paper presents a tree structure which stores local rules from each document, and then through three tree: traversals, pre-order, post-order and breath-first-search order to transform local rules into global rules for text categorization. The experimental results have shown that our method has comparable accuracy against other techniques.

Keywords-Rule-based; pattern matching; text categorizaton; term distribution

I.  INTRODUCTION Text categorization is the task to assign unlabeled  documents into predefined categories according to its content. In recent years, thanks to the fast development of Internet technology, there are enormous amounts of information available every day. Hence it is extremely important to efficiently organize this large amount of information. Now the text categorization is focusing on using a lot of automatic techniques. There are many well-known automatic techniques such as SVM [1], decision tree [2], and Bayes classifier [3]. These techniques can quickly and accurately classify documents. Among all kinds of classifiers, the rule-based classifiers do provide an interesting advantage. The classification rules are easy to understand and thus they can be added, deleted, and modified through human knowledge. There are many representative techniques such as decision tree [2], Olex [4], and association rule [5].

Generally speaking, the rule-based classifiers construct the classification rules by finding valuable patterns from training documents. Then, the document can be classified by performing pattern matching between rules and documents.

For decision tree, a document is classified through checking the presence or absence of important terms, and the original content structures of the documents are ignored. To focus on this issue, previous MILO research [6] learned the  rules by observing the distribution of terms in document paragraphs, and these classification rules are related with the topic of a certain document. But, usually the topic is not included in a single document. Therefore, these documents with related topic may conceal valuable classification rules.

To establish these rules, this paper uses pre-order, post-order, and the breath-first-search order to convert local rules that are learning from single documents into global rules to classify documents.

The structure of this paper is arranged as follows: Section 2 describes the concept of our categorization method; Section 3 illustrates the experimental results, and Section 4 provides the conclusions.



II. BUILDING AN MILO CLASSIFIER  A. Basic Concepts In general, a document should have the basic structure  that can roughly be separated into three paragraphs, the beginning, the middle, and the end. We named these 3 paragraph as P1, P2, and P3 respectively; P1 usually is the beginning part of a document; P2 is the main body in a document; and P3 draws the conclusion. Whereas between terms in different paragraphs should have the relation of special meaning, this reflected the semantics of language.

We defined the relationship between terms as meaningful inner link objects, abbreviated as MILO. The MILO example diagram is shown as Figure1.

Figure 1.  The concept of MILO.

In Figure 1, the first paragraph illustrates origin of National Basketball Association (NBA) and its history of   DOI 10.1109/ICGEC.2010.169     development in the past; the second paragraph describes the NBA?s 100th celebration of anniversary, including the names of retired basketball players at the ceremony; the third paragraph records the reflections of players on this celebration. In between the paragraphs, the relation of link constituted by terms is MILO, shown in Figure 1, and the dotted line represents different MILO patterns between the paragraphs. There are 3 kinds of MILOs with lengths of 1, 2, 3 respectively. According to the example of MILO in Figure 1, we can illustrate the composition of MILO as Table ?.

TABLE I.  EXTRACTED MILOS FROM DOCUMENT  MILO Content Direction pattern m0 [league?retire?player] [P1?P2?P3] m1 [league?celebrate?player] [P1?P2?P3] m2 [league?retire] [P1?P2] m3 [league?celebrate] [P1?P2] m4 [retire?player] [P2?P3] m5 [celebrate?player] [P2?P3] m6 [league?player] [P1?P3] m7 [league] [P1] m8 [retire] [P2] m9 [celebrate] [P2] m10 [player] [P3]  By Table ?, we know that MILO has 7 kinds of direction patterns, so we will illustrate how to use MILO to build the classifier and to classify documents. Figure 2 contains the concept diagram of text categorization.

Figure 2.  Construction for MILO classifier.

First, according to pre-defined proportion, data set are divided into training sets and testing sets, and the training set is used to train classifier while the testing set is used for measuring classifier and producing accurate ratio. Each document in the training set initially went through paragraph normalization, and then the chi-square function was used to extract those terms considered important from training set.

When all documents have been preprocessed, the documents are stored into a database accordingly with the category of the document. Then through the proposed categorization algorithm, the MILO patterns are extracted from database of each category, and stored into a tree structure, called MILO tree, which completed the construction of the classifier.

When we want to classify the unlabeled document, we need to extract all MILOs in the unlabeled document, and then match them with the MILO classifier. Lastly, we assign one or more categories to the unlabeled document, and the process of text categorization is completed.

B. Preliminaries and Notations To simply illustrate the detailed algorithm, we have  defined some notations shown as follows: c:  a category, dc: a training document of c, Dc: a set of training documents in c, Pn: the n-th paragraph of dc, n = 1, 2, 3 in this paper, tni: an arbitrary term in Pn, DBPn: the database which stores all Pn of each dc in Dc, T: the number of selected distinct terms with highest chi- squared value, TS(DBPn)T: a reduced term set from DBPn consisting with selected T terms, Treec: a tree structure which stores the MILOs of c.

C. Data Set Preprocessing We must normalize each document and divide them into  three paragraphs before finding MILO patterns. Initially the number of distinct terms in a document would be counted.

After that, depending on the appearing sequence of these terms in the document, they would be separated into P1, P2, and P3, such that these three paragraphs have the same number of distinct terms. If the number of distinct terms cannot be divided by three, then P2 would have the greatest number of terms. After all documents have been preprocessed, P1, P2 and P3 in all documents are stored into DBP1, DBP2, and DBP3, respectively. Referred on Stopwords List [7], some commonly used words from three database DBP1, DBP2, and DBP3 are deleted, after that, let TS(DBPn) presents the reducing set of database DBPn. However, we need to consider the weightiness of term in each paragraph, thus finding out great weightiness of terms in each paragraph is required. Then we calculate weightiness of each term by using the chi-square function with TS(DBP1), TS(DBP2), TS(DBP3), for measuring the relationship between term ti and category c, the formula of chi-square function is developed as shown below.

))()()(( )**(*),(   DCBADBCA CBDANcti ++++  ?=?   (1)     A: occurrences of term ti in category c, B: occurrences of other terms in category c, C: occurrences of term ti in other categories, D: occurrences of other terms in other categories, N: A+B+C+D, total occurrences of all terms in all categories.

Through Formula (1), we could calculate the weightiness of terms with TS(DBP1), TS(DBP2), and TS(DBP3), respectively. The selected T terms, that have greatest chi- square value, are used to compose the set of important terms from each paragraph.

D. Construction of MILO Classifier Algorithm of extracted MILOs in a document dc is shown  as follows: Mc is a set of MILOs in category c, OMc is a set of number of occurrences with respect to each MILO in M, DMc is direction of MILOs in category c.

Algorithm Extract MILOs Input: P1, P2 and P3 of dc, TS(DBP1)T, TS(DBP2)T, TS(DBP3)T, Output: Mc, DMc, OMc Methods: (1) /* t1i, t2j and t3k represent the arbitrary terms in P1, P2,  and P3, respectively*/ (2) /* o1i,o2j and o3k represent the occurrences of t1i, t2j and t3k  in P1, P2, and P3, respectively*/ (3)  For each distinct t1i in P1 and t1i ?  TS(DBP1)T (4)    For each distinct t2j in P2 and t2j ?  TS(DBP2)T (5)      For each distinct t3k in P3 and t3k ?  TS(DBP3)T (6)         If dc has length 3 MILO (7)           Mc?Mc ? {[ t1i?t2j?t3k]} (8)           DMc?DMc ? {[P1?P2?P3]} (9)           OMc?OMc ? {( o1i + o2j + o3k)/3}  Steps(3)-(5) delete unimportant terms from each paragraph, for example, Step(3) would delete those terms that do not belong to TS(DBP1)T. Step(6) checks whether has length 3 MILO in dc, if so, then steps(7)-(9) would be executed; otherwise, do not extract MILO from dc. Step(7) stores the content of a MILO into Mc, and Step(8) stores the direction of a MILO into DMc. Step(9) stores the occurrences of a MILO in dc into OMc.

MILOs would be stored into Treec while extracted MILOs by Algorithm Extract MILOs from documents in Dc, and the concept diagram is shown as Figure 3. For example, referred to Figure 3, if a length 3 MILO [league?retire?player] in dc, ?league? would be stored into Level 2 that is the node of ?root?; ?retire? would be stored into Level 3; ?player? would be stored into Level 4. In Level 5, the square cell would be stored with the occurrence of MILO in category c, so if a MILO [against?star?retire] is extracted from a document, the occurrence is 8, and if the same MILO is extracted from another document, then the content of square cell in Level 5 would be 15. In this paper, only length 3 MILO was taken to construct Treec, because length 3 MILO is the most integrated and the most diversified across the whole content of document, and it also has the greatest relationship with the topic of a document, and the content includes the contents of length 2 and length 1 MILO, but other length MILO are still used in next section.

After all the MILOs are extracted from documents in Dc, the construction of Treec is then finished. Now, for controlling the quality of the MILO classifier, we must filter out some of the non-representative MILOs, so we let ? presents one of the MILOs in Treec. If support of ? is less than threshold ?, then we delete ? from Treec. The formula for calculating support is shown as follows:  c in  MILOslla of occurences The c in  of occurences The ?  (2) The above process is used to construct a MILO tree of  category c. After all of the MILO trees have been dealt with by the above process, the MILO classifier is then finished.

Figure 3.  MILO tree of Category c.

E. Docunemt Categorization with MILO When an unlabeled document performs paragraph  normalization and filters out common words depending on Stopwords List, and then we have to use all the terms to construct MILOs from unlabeled documents. Difference from the construction of classifier is that we only uses length 3 MILO in this section, thus we will take all kinds of length to match the MILO patterns. The algorithm of categorization is shown as follows.

Algorithm Categorization Input: classifier, d: unlabeled document, ?: a categorization factor, C: a set of categories Output: classification results Method: (1) Choose a type of traversal (2) For each MILO ??d (3)     For each c?C (4)        Trace Treec by the selected type of traversal and  store the result into Sc (5)             Matched_time[c] ? ??s matched times in Sc (6)     For each c?C, Total?Total + Matched_time[c] (7)     /* Total is used to store the total matched times */ (8)     For each c?C, Decision array[c] ? Decision array[c]  + Matched_time[c] /Total (9)    Find the max total confidence value in Decision array  and store into MaxDecideConf (10) For each c?C, if(Decision array[c] ? MaxDecideConf  * ?), then assign c to d In Step(1), we first choose a type of traversal for trace  Treec, all of three types traversal can be chosen and Step(4)     stores the string of result into Sc by trace Treec. For example, referred to Figure 3, we traced the MILO tree, the result is as shown follows: [league, retire, player, star, retire, celebrate, season, against, effort, league, star, retire], and then, Step(5) would perform pattern matching between the MILOs of d and Sc. After that the times they matched will be produced and stored into the array Matchedtime[c], for example, if one of MILO ? in d is [star?retire], after performing pattern match with Sc as mentioned above, and the result is matched  2 times in this case. Steps(6)-(8) would then calculate the confidence value in each category and store it into Decision array. Step(9) would pick the greatest confidence value from Decision array and present MaxDecideConf, and Step(10) determines whether the confidence value of category c in Decision array[c] is not less than that of MaxDecideConf * ?; if so, then the category c would be assigned to the unlabeled document d.

TABLE II.  RESULTS OF CATEGORIZATION TAKING ON THE WHOLE TRAINING SET (T=100, ?=0.000053, ? = 0.75)  Preorder  Postorder Breadth-First  -Search Naive Bayes Bayes Nets C4.5  Rocchio?s method  Rullo et al.

Pietramala et al. HARMONY  acq 93.0 93.6 93.1 91.5 88.3 85.3 92.1 87.0 87.2 95.3 corn 66.7 69.2 67.7 47.3 76.4 87.7 86.2 87.9 90.8 78.2 crude 79.9 80.0 79.2 81.0 79.6 75.5 81.5 80.1 77.0 85.7 earn 96.0 95.9 95.7 95.9 95.8 96.1 96.1 96.1 95.3 98.1 grain 36.1 36.1 35.5 72.5 81.4 89.1 79.5 90.8 91.6 91.8 interest 72.4 73.2 71.4 58.0 71.3 49.1 72.5 82.2 64.2 77.3 money-fx 79.1 76.6 77.8 62.9 58.8 69.4 67.6 69.3 66.5 80.5 ship 87.3 87.4 87.4 78.7 84.4 80.9 83.1 78.2 74.1 86.9 trade 80.9 82.8 81.3 50.0 69.0 59.2 77.4 52.6 61.8 88.4 wheat 71.0 67.1 68.8 60.6 82.7 85.5 79.4 91.4 87.5 62.8 Micro F 87.5 87.6 87.1 84.2 85.0 85.2 87.2 86.5 86.4 92.0

III. EXIPERMTNTAL RESULTS We have employed micro F1 in the survey of F.

Sebastiani [8] for classifier evaluation. Table ? shows the experimental results. The results of naive Bayes, Bayes nets, C4.5, and Rocchio?s method are obtained from [9]; the results of Rullo et al. and Pietramala et al.?s method are obtained from [10] and [11], respectively. Table ? clearly reveals the comparison results, it shows that our classification method based on three kinds of traversal are better than the other methods except HARMONY [12].

We have also conducted another interesting experiment: we used all the training documents to select the three terms set, but only take a few training documents to construct the classifier, the results of selecting top 5 training documents for each category (the documents are sorted according to their file ID) are shown in Table ? . It reveals that the accuracy of our method is better than HARMONY.

TABLE III.  RESULTS OF SELECTING 5 TRAINING DOCUMENTS FOR EACH CATEGORY (T=100, ?=0, ? = 0.75)  Preorder  Postorder Breadth-First-Search HARMONY Micro F 83.2  83.3  83.0  53.1

IV. CONCLUSION This paper presents a classification technique by  transforming local patterns to global patterns. The experimental results shows that the three kinds of traversal have a comparable accuracy against other techniques, and the proposed method can reach a high accuracy by selecting five training document documents in each category. On the internet, there are many kinds of documents such as free talk and news, and the content structures in these documents have different style. Therefore, we have future plans to investigate the efficiency of MILO in other benchmarks such as WebKB  and Ohsumed, and trying to find an appropriate way to further enhance the MILO?s performances.

