An efficient for discovery of Frequent Itemsets  Venkateswari S#, Suresh R.M*

Abstract? Association rule mining is a well researched method for discovering interesting relations between variables in large databases. The first phase of association rule mining is the discovery of frequent itemsets which is a critical step and plays important role in many data mining tasks. The existing algorithms for finding frequent itemsets suffer from many problems related to memory and computational cost. In this paper, we propose a new algorithm ILLT (Indexed Limited Level Tree) which gets frequent itemsets efficiently in the given database without doing multiple scans and extensive computation. ILLT algorithm works in two phases. First, the transactional data is converted into three level compact tree structures. Then, these trees are scanned to discover the frequent itemsets. Experimental status shows the effectiveness of the algorithm in mining frequent itemsets.

Keywords? Data Mining, e-commerce, frequent itemsets, ILLTree

I. INTRODUCTION  Large amount of data have been collected routinely in the course of day-to-day management, in business, administration, banking, e-commerce, the delivery of social and health services, environmental protection, security and in politics.

With the tremendous growth of data, users are expecting more relevant and sophisticated information which may be lying hidden in the data. Existing analysis and evaluating techniques do not match with this tremendous growth. Data mining is often described as a discipline to find hidden information in databases.   It involves different techniques and algorithms to discover useful knowledge lying hidden in the data [1].

Association rule mining has been one of the most popular data mining subjects which can be simply defined as finding interesting rules from collection of data [2]. The first step in association rule mining is finding frequent itemsets. It is a very resource consuming task and for that reason it has been one of the most popular research fields in data mining

II. PROBLEM STATMENT  Following is the formal statement of association rule mining for transactional databases [2,3]: Let I = {i1, i2,?im} be a set of literals, called items.  Let D be a set of transactions, where each transaction T is a set of items such that T ? I. A unique identifier TID is given to each transaction. A transaction T is said to contain X, set of items in I, if X ? T. An association rule is an implication of the form ?X?Y", where X ? I, Y ? I, and X?Y = ?. An item set X is said to be large or frequent if its support s is greater or equal than a given minimum support threshold?. The rule X?Y has a support s in the transaction set D if s% of the transactions in D contain X ? Y. In other words, the support of the rule is the probability that X and Y hold together among all the possible presented cases. It is said that the rule X ? Y  holds in the transaction set D with confidence c if c% of transactions in D that contain X also contain Y . In other words, the confidence of the rule is the conditional probability that the consequent Y is true under the condition of the antecedent X.

Association mining task can be broken into two steps:  The first step is to find each set of items, called itemsets, such that the co-occurrence rate of these items is above the minimum support ?, and this itemsets are called frequent itemsets. The size of an itemset represents the number of items in that set.

Second step of generation of association rules is straight forward.



III. RELATED WORK  Several algorithms are devised for finding frequent itemsets.

Apriori is the foremost and popular algorithm for finding frequent itemsets [3]. The Apriori is a level wise search algorithm for mining frequent itemsets for Boolean association rules. Apriori uses the property stating that for a k itemset to be frequent , all its k-1 itemsets have to be frequent.

The drawback of  Apriori is that of repeated database scanning and high computational cost.

Another approach of discovering frequent itemsets is the FP- growth (Frequent Pattern growth) algorithm [4]. This algorithm uses compact data structure called FP-Tree. FP- growth algorithm requires only two scans of database. First scan get all frequent 1-itemset and the next scan of database constructs the tree structure. Mining takes place directly in the tree structure. The shortcoming of the algorithm is the generation of thousands of FP tree. This memory based data structure consumes lot of space and time and this becomes a serious bottleneck for cases with large databases. Several methods do single scan of databases for finding the itemsets [7]. The TIMV algorithm [8] uses three dimensional itemset matrix vectors. Unlike Apriori, this algorithm needs one pass to scan the database and gains all frequent itemsets without generating candidate itemsets. The Diffset algorithm [9]  uses tree data structure and mines the frequent itemset by traversing the search tree thus saving a lot of I/O.

In this paper, we propose  a new algorithm named ILLT ? Limited Level Tree algorithm  that uses candidates but it has an advantage of  single database scan and finding the frequent itemsets  quickly for any given support threshold.

The remainder of the paper is organized as follows:  The proposed algorithm ILLT is described in section 2.

Experimental results are discussed in section 3.  Conclusion is presented in section 4.



IV.  THE  ILLT ALGORITHM  The main objective of developing this Indexed Limited Level Tree algorithm is to reduce the repeated database scans and to reduce the cost of computation required for generating     frequent itemsets. Proposed ILLT algorithm is a three level tree structure algorithm composed of two steps. First step is construction of ILLTree structures. Second step is mining the tree structures for finding frequent itemsets. Frequent itemsets for any given support levels can be discovered quickly from the ILLTree structures. The mining process might take in some cases less than one full scan of the data structure for discovering frequent itemsets.



V. CONSTRUCTING ILLTREE STRUCTURES  First step of ILLT algorithm is construction of tree data structures. The levels of the tree are limited to three with an index node so it is named as Index Limited Level Tree (ILLT).

The compact trees constructed in the first step is done  by doing only one scan of given transactional database. From the resultant ILLTree it is easy to find frequent itemsets for different support levels. Scanning the database again is not needed at any stage. The tree structures store the contents of the transactions in their nodes.

ILLT algorithm scans the database first and generates candidate itemsets for every transaction in the database. These generated candidate itemsets are of different lengths. An unique tree is constructed for each k-length itemsets. Level 1 of the trees is the header node. This header node with the label H indicates which k- itemset that tree stores. If the label of the header node is 3, then this tree stores all 3-itemsets. The header node has n children at level two. n is the total number of items that occur in the transactions. Each node in the level two indicates an individual item. Third level of the tree stores the candidate itemsets as its nodes. An index is associated with each tree. The Indexed Limited Level Tree structure with three levels is shown in the figure 1.

Fig. 1: ILLTree structure  When candidate itemsets are generated, an unique identification number is assigned to each of them. This candidate itemset with its identification number is stored in the index first. Then this itemset is stored in the third level of the tree in the following syntax.

<Node Id number><Number of occurrence>  Then a new candidate itemsets has to be inserted in the tree, it is first checked with the index. If it already exists in the index, only the occurrence number is incremented in the respective nodes. If it does not exist, then a new identification number is assigned and the itemset is stored in the tree. Depending on the length of the candidate itemset the appropriate tree is  chosen for insertion.  For illustration we use the example in table 1.

TID Items  T1 ABC T2 AB  Table 1  T1 and T2 are Transaction Ids. Transaction T1contains 3 items and T2 contains 2 items.

The candidate itemsets generated for the transactions in the table are: T1: {a}{b}{c}{ab}{ac}{bc}{abc} T2: {a} {b} {ab} Candidate itemsets of transaction T1 are 1-Itemsets : {a}, {b}, {c} 2-Itemsets : {ab}, {ac}, {bc} 3-Itemsets : {abc}  Fig 2:  Tree structures for T1  The respective tree structures after the insertion of candidate itemsets of transaction T1 is shown in figure 2.

Candidate itemsets for transaction T2 is as follows: 1-Itemsets : {a}, {b} 2-Itemsets : {AB} The resultant 1-item and 2-item tree structures after inserting the candidate itemsets of given two transactions is in figure 3.

