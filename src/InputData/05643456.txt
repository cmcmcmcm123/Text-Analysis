An Efficient Model for Information Gain of Sequential Pattern from Web Logs

Abstract Data mining is the task of discovering interesting patterns from large amounts of data. There are many data mining tasks, such as classification, clustering, association rule mining, and sequential pattern mining. Many frequent sequential traversal pattern mining algorithms have been developed which mine the set of frequent subsequences traversal pattern satisfying a minimum support constraint in a session database. However, previous frequent sequential traversal pattern mining algorithms give equal  weightage to sequential traversal patterns while the pages in sequential traversal patterns have different importance and have different weightage. Another main problem in most of the frequent sequential traversal pattern mining algorithms is that they produce a large number of sequential traversal patterns when a minimum support is lowered and they do not provide alternative ways to adjust the number of sequential traversal patterns other than increasing the minimum support. In this paper, we propose a frequent sequential traversal pattern mining with weights  constraint. Our main approach is to add the weight constraints into the sequential traversal pattern while maintaining the downward closure property. A weight range is defined to maintain the downward closure property and pages are given different weights and traversal sequences assign a minimum and maximum weight.

In scanning a session database, a maximum and minimum weight in the session database is used to prune infrequent sequential traversal subsequence by doing downward closure property can be  maintained. Our method produces a few but important sequential traversal patterns in session databases with a low minimum support, by adjusting a weight range of pages and sequence.

Keywords- Sequential traversal Pattern Mining; Periodic  Pattern; Weight constraint; Web usage mining; Data mining.



I. INTRODUCTION  Sequences are an important kind of data which occur  frequently in many fields such as medical, business,  financial, customer behavior, educations, security, and other  applications. In these applications, the analysis of the data  needs to be carried out in different ways to satisfy different  application requirements, and it needs to be carried out in an  efficient manner.

It is obvious that time stamp is an important attribute of  each dataset, and it can give us more accurate and useful  information and rules. A database consists of sequences of  values or events that change with time are called a time series database. This type of database is widely used to store  historical data in a diversity of areas. One of the data mining  techniques which have been designed for mining time series  data is sequential pattern mining.

Sequential pattern mining is trying to find the  relationships between occurrences of sequential events for  looking for any specific order of the occurrences. In the  other words, sequential pattern mining is aiming at finding  the frequently occurred sequences to describe the data or  predict future data or mining periodical patterns.

To gain a better understanding of sequential pattern  a shopping store database, we can find frequent sequential  bought the TV typically bought the DVD player and then  conceivable that achieving this pattern has great impact to  better advertisement and better management of shopping  store.

Interestingness measures play an important role in data  mining methods, regardless of the kind of patterns being  mined. These measures are intended for selecting and  ranking patterns according to their potential interest to the user. Choosing interestingness parameters that reflect real  human interest remains an open issue.

Sequential pattern mining methods often use the support,  which is the criterion to evaluate frequency but this  parameter is not efficient to discover some patterns.

Regardless of a great diversity of models for sequential  pattern mining, from one perspective, the problem of mining  sequential pattern can be partitioned into three categories:  periodic patterns, statistically patterns, and approximate  patterns. Due to the huge increase in data volume and also  quite large search space, efficient solutions for finding patterns in sequence data are nowadays very important. For  this reason, using some pruning technique is necessary to  optimize the algorithms. They aim to improve performance  and reduce response time to find patterns in sequence data.

To overcome problems of Apriori based sequential  pattern mining algorithms, prefix projected sequential  pattern growth based approaches have been developed.

Sequential pattern growth methods mine the complete set of  frequent patterns using a divide and conquer method to  reduce the search space without generating all the candidates. There are many limitations exist in the previous  sequential traversal pattern mining algorithms. Some are  given below.

First, in the real world, some traversal sequences  are more important and others are less important. However,  previous sequential traversal pattern mining approaches do  not consider this characteristic of real datasets. In other  words, all pages and traversal sequences are treated  uniformly.

Second, most sequential traversal pattern mining  algorithms use a support constraint to prune the  combinatorial search space. This strategy provides for basic pruning. However, support based pruning is not enough  when considering the characteristics of real datasets. In  previous mining approaches, after mining datasets to obtain  the sequential traversal patterns, there is no way to adjust  the number of sequential patterns through user feedback  without changing the minimum support. Sequential pattern  mining algorithms such as have better performance when a  minimum support is high, the database is sparse and the  length of the maximum sequential pattern is short.

Meanwhile, the main problem with these algorithms is that  they can still generate an exponentially large number of sequential patterns and the runtime increases dramatically  when a minimum support is lowered. Although closed  sequential pattern mining approaches have been used, many  sequential patterns are still generated in large dense  databases.

We propose an efficient method for sequential  traversal pattern mining with weight constraint to tackle  these problems of previous traversal pattern mining. Our  main goal in this framework is to add weight constraints  into the traversal pattern algorithm while keeping the  downward closure property. In our approach, a weight range  is defined, pages are given different weights to reflect characteristics of the real dataset, and the weights of  sequences are calculated. The weight range is used to  generate a reasonable number of frequent sequential  traversal patterns even in a dense database with a low  minimum support. Additionally, both the weight and  support of each page are considered separately for pruning  the search space. An extensive performance study shows  that the number of sequential traversal patterns can be easily  adjusted by setting a weight range and the runtime is  efficient.

The main contributions of this paper are: 1) Introduction of the concept of frequent sequential traversal patterns with  weight constraint, 2) Classification and incorporation of two  key features, a weight and a support, 3) Description of  periodic patterns, 4) Dynamic Significant Patterns, 5)  Analysis and performance evaluation; frequent traversal  pattern mining by using a weight constraint, and  experimental study to compare the performance of our  algorithm with a recently developed algorithm, WSpan.



II. PROPOSED WORK  This In this section, we suggest an efficient sequential traversal pattern mining algorithm in which the main  approach is to apply weight constraints into the frequent  sequential traversal tree while maintaining the downward  closure property. We discuss our algorithm in detail and  show actual examples for sequential traversal pattern mining  with weight constraint.

Definition 2.1 Weight Range  A weight of a web page is a non-negative real number  that shows the importance of each web page. The weight of  each web page is assigned to reflect the importance of each  web page in the session database.

Definition 2.2 Traversal sequence with weight  We can use the term, traversal sequence with weight to  represent a set of sequential traversal patterns with weight.

Definition 2.3 Average Weight of traversal  We can use the term; average weight of subsequence is  the sum of weight all pages in traversal divided by total  number of pages in sequence  Definition 2.4 Minimum and Maximum weight of  subsequence  Here we define the maximum and minimum  weight of traversal is average weight. If the weight of  sequence come under the maximum and minimum weight  range than given sequence is frequent otherwise infrequent.

A. Sequential traversal pattern with weight constraint In this paper, pages of traversals are assigned with  weights to show their importance. For example, when users traverse web site, they may have different interest in each  page, and therefore stay for different times. Web pages can  be assigned with a weight standing for the user stay time,  frequency of pages, content of pages and type of web site.

This paper generalizes the mining problem to the case where  pages of traversals are given such weights showing their  importance. The weights are taken into account in the  measurement of support, the ratio of traversals which  contains a candidate pattern. If a page of traversal has a  removed from session of user and treated as an outlier, and  can not consider for the support. For example, when users visit web site, they may traverse through a page very fast to  another page, or do another work for a long time during web  site visit. This type of page visit is not useful and consider  as an outlier because the page is not attentively read by the  user.

Table 1. A sequence database as a running example.

Sid Traversal  Sequence  Weight  S1 P2 P1 P3 P4 P1 P5  0.2, 0.3, 0.12, 0.34, 0.6, 0.3  S2 P1 P2 P4 P3 P4 P2  0.12, 0.5, 0.91, 0.12, 0.4,0.26  S3 P1 P2 P1 P3P6 P7  0.6,0.2,0.32,0.56,0.45,0.7  S4 P2 P3 P6 P5 P1 P4  0.5,0.56,0.32,0.23,0.7,0.54  S.No. Page Support Weight Range  1 P1 4 0.12  0.56  2 P2 4 0.45  0.67  3 P3 4 0.23 - 0.67  4 P4 3 0.12 -  0.45  5 P5 2 0.34  0.67  6 P6 2 0.24  0.8  7 P7 0 0.12  0.56  In this section, we propose the concept of sequential  traversal patterns with weight constraint, and show their  importance.

Example: In session S1 the weight of P2 is 0.2 and the  support is 4. The weight range for P2 is from 0.45 to 0.67.

So, when we construct the frequent sequential traversal  pattern tree P2 is eliminated from session.

B.  Frequent Sequential Traversal Pattern Tree with  weight constraint In this section, a data structure called FSTP-tree is  constructed. FSTP-Tree is a data structure, which must  satisfy the following conditions. Firstly, it consists one root  root, and a frequent-page head table. Secondly, every page  in the page prefix subtree contains three fields: the name of  the page, the support of the page, and a link to the next same  page. Thirdly, every page in the frequent-page table  contains three fields: the name of the page, the weight range  and a link to the first node in the tree which denotes this  page. The following algorithm to build the FSTP-tree:  Algorithm 1 (FSTP-tree Building: Building a FSTP-tree  of the SDB) Input: A session database SDB, weights of pages and a  minimum support  Output: corresponding FSTP-tree  Method:  1. Scan the whole SDB and find frequent pages from  SDB based on support and weight range assign to the page.

Here we add only those pages that come under the weight  range and contribute to the support and those not come in  given range consider as outlier and not contribute to support.

2. Create the root of the FSTP-tree, and  label it NULL.

3. Scan the whole SDB for the second time. For each  session in the SDB, we only preserve the pages which are  frequent and have a weight in given weight range, and hold  the traversal sequences of pages. The different branches of same prefix can be merged.

C. FSTPMW Algorithm The divide-and-conquer strategy is used for finding  frequent sequential traversal patterns.

To handle the ordered problem, the FSTPMW uses a  merging method. Each frequent ordered pattern whose first  page is P1 must be contained in one or more session. The  merging process in fact is rebuilding a smaller FSTP-tree.

This time, the relative sessions all contains P1 as the first  web page.

The complete algorithm given as:  Algorithm-2 (FSTPMW: Mining frequent sequential  traversal pattern)  Input: FSTP-tree  Output: frequent sequential traversal pattern  Method: call FSTPMW ( Weight range for each page,  support, Minimum & Maximum  Weight Range)  Procedure FSTPMW (FSTPtreeRootNode node,String  prefix )  { for each node x in the corresponding     page head table  do  if x.support  less than minimum support  then  calculate the average weight of prefix  if minimum weight<=average weight<=maximum  weight  {  output prefix;  }  return;  else if i.subs.count == 0 then prefix = prefix + i.content;  calculate the average weight of prefix  if  minimum weight<=average weight<=maximum  weight  {  output prefix;  }  return;  else  call CombineTree(i);  for each node j in i.subs do  call FSTPMW (j, prefix+i); end for  end if  end for  }

III. PERIODIC PATTERNS  This model of pattern is quite rigid and it fails to find patterns whose occurrences are asynchronous. Periodicity detection on time series database is an important data mining  mentioned above, this model is often too restrictive since we may fail to detect some interesting pattern if some of its occurrences are misaligned due to inserted noise events. A pattern can be partially filled to enable a more flexible model. For instance, pattern length three (I  ,*,*) is a partial  pattern showing that the first symbol must be I . The system  behavior may change over time and some patterns may not be present all the time.

Two parameters, namely min-rep and max-dist, are used to specify the minimum number of occurrences that is required within each subsequences and the maximum disturbance between any two successive subsequences. The rationale behind this is that a pattern needs to repeat itself at least a certain number of times to demonstrate its significance and periodicity.

Couple of algorithms in this area focused on patterns for some pre-specified period length and several models can discover all periodic patterns regardless of the period length.

Notice that period usually is apart of what we would like to mine from data. Let us look at an example to explain some definitions.

Fig. 1 Example of symbol sequence  Figure 1 shows matches of partial pattern (I ,*,*) that is  a 1-pattern of period 3. In this Figure, P ,P  2 10 are  ten matches of pattern (I ,*,*) and S  ,S  , and S  are three  segments which each one forms a list of N consecutive  matches of (I ,*,*). For example, segment S  is consist of 5  successive matches of this pattern. S  and S  are disjoint  segments and S  and S  are overlapped segments. In many  applications, overlapped segments often are not considered.

If the value of min-rep is set to 3, then S and S  qualify  as valid segments and S  is not a valid segment. Two or  more than two contiguous and disjoint segments can  construct a valid subsequence provided that distance  between any two successive valid segments does not exceed  the parameter max-dist. For example, if the value of min-rep and max-dist are set to 2 and 3 respectively, both S  and S   recognized as valid subsequence whose overall number of  repetition is 5.

Given a sequence S, the parameters min-rep and max- dist and the maximum period length L  max , in three phases  we can discover the valid subsequences that have the most  repetitions for each valid pattern whose period length does  not exceed L max  . When parameters are not set properly,  noise may be qualified as a pattern. Though, parameter max- dist is employed to recognize the noises between segments of perfect repetition of a pattern. The following three phases  outline algorithm for mining periodic patterns in brief .

The first phase: For each symbol I, the distance between any two occurrences of I are examined and then for each period l, the set of symbols whose number of times are at least min-rep are sent to the next phase. Since there are a huge number of candidates, a pruning method is needed to  reduce it.

The second phase: In this phase, the single patterns (1-  pattern) are generated. For each period l and each symbol I a  symbol * is (l-1).

The third phase: After discovering the single patterns in  previous phase, i-patterns are generated from the set of valid (i-1)-patterns and then these patterns are validated. In this  phase, we can apply some heuristics. For example, it is  obvious that if a pattern is valid, then all of its  generalizations are valid. Pattern (I ,I  ,*) is a generalization  of pattern (I ,I  ,I  ).



IV. DYNAMIC SIGNIFICANT PATTERNS  The support and confidence are the most popular measures for sequential patterns. The support evaluates frequencies of the patterns and the confidence evaluates frequencies of patterns in the case that sub-patterns are given. These parameters are meaningful and important for some applications. However, in other applications, the number of occurrences (support) may not always represent the significance of a pattern. Sometimes, a large number of occurrences of an expected frequent pattern may not be as interesting as few occurrences of an expected rare pattern.

This pattern called surprising pattern instead of frequent pattern. The information gain metric which is widely used in the information theory field, may be useful to evaluate the degree of surprise of the pattern. Target is finding set of patterns that have information gain higher than minimum information gain threshold. Experiments show that the support threshold has to be set very low to discover a small number of patterns with high information gain.

Note that surprising patterns are anti-monotonic. It means advantage of standard pruning techniques such as Apriori property can not be used. For example, the pattern (I  ,I  ) may  have enough information gain while neither (I ,*) nor (*,I  )  does.

Given a pattern P=(I  ,I  2 l ) and an information gain  threshold min-gain, the goal is to discover all patterns whose information gain in the sequence S exceed the min-gain     value. Similar to other parameters in data mining algorithms, the appropriate value of the min-gain is application dependent and may be defined by a domain expert. There are some heuristics and methods that user can set the value of this threshold.

Information gain of pattern P is defined as follows: Info-gain(P)=Info(P)*Support(P)   (1)  Info(P)=Info(I )+ Info(I  2 l )  (2)  Info(Ik)= - log|I| prob(I  k )                 (3)  where prob(I k ) is probability that symbol I  k occurs and |I| is  number of events in S.

For example, the sequence in Figure 1 contains 4  different events I , I  , I  , and I  . Their probabilities and  information gains are shown in Table 1.

Table 3: Probability of occurrence and information gain  Event Probability Information Information gain  I  10/20=0.50  -log (.50)=0.50  0.50*10=5.0  I  4/20=0.20  -log (.20)=1.16  1.16*4=4.64  I  3/20=0.15  -log (.15)=1.37  1.37*3=4.11  I  3/20=0.15  -log (.15)=1.37  1.37*3=4.11  The main strategy to tackle the problem of mining statistically significant patterns is a recursive method which at the ith level of recursion, the patterns with i events are examined.

In some applications, users may want to find the k most surprising patterns. On the other words, users may want to discover top k patterns that their information gain is greater than a threshold. However, the major limitation of information gain value is that it does not recognize location of the occurrences of the patterns.

and S  in Figure 2.

The pattern (I ,I  ) has the same information gain in the two  sequences, it scatter in S  but repeats consecutive in S . As a  result, it is beneficial if a parameter to evaluate this situation can be specified.

Fig. 2 Two examples of symbol sequence.



V.  ANALYSIS AND PERFORMANCE EVALUATION  In this section, we present our performance study over  various datasets. We report our experimental results on the  performance of FSTPMW in comparison with a recently  developed algorithm; WSpan, which is the fastest algorithm  for mining sequential patterns. The main purpose of this  experiment is to demonstrate how effectively the sequential traversal patterns with weight constraint can be generated by  incorporating a weight page, weight of sequence with a  support. First, we show how the number of sequential  traversal patterns can be adjusted through user assign  weights, the efficiency in terms of runtime of the FSTPMW  algorithm, and the quality of sequential traversal patterns.

Second, we show that FSTPMW has good scalability against the number of sequence transactions in the datasets.

All the experiments are performed on a 1.4GHz Celeron  CPU with 512 megabytes main memory, running on Dot  Net 2008. In our experiments, a random generation function  was used to generate weights for each page.

5.1 Environmental results. Comparison of  FSTPMW and WSpan In this performance test, we focused on the efficiency of  using a weight range. Our experiment shows that in most  cases, FSTPMW outperforms WSpan. First, we evaluate the  performance on the kosarak dataset.

Figure 3. Scalability with number of frequent sequential traversal patterns  Figure 4. Runtime  5.2 Further Extension FSTPMW basically focuses on sequential pattern mining  with weight constraint uses a weight range to adjust the  number of sequential traversal patterns. Frequent sequential  traversal pattern mining can be extended by considering  levels of support and/or weight of sequential traversal  patterns. There are many areas in which items have different  importance and patterns with a similar level of support  and/or weight are more meaningful. For example, the     concept of strong support and/or weight affinity can be  applied in DNA analysis. We can give importance to  specific DNA patterns and find interesting DNA patterns.

Our algorithm can be extended by considering the levels of  support and/or weight of sequential traversal patterns. By  not only giving a balance between the two measures of support and/or weight, but also considering both support  and/or weight affinity between items within patterns, more  valuable sequential traversal patterns can be generated.



VI.   CONCLUSION  In this work, we provide a brief overview of models of  sequential patterns. Many studies exist on mining sequential  frequent patterns. One of the main limitations of the  traditional approach for mining sequential traversal patterns  is that all items are treated uniformly, while each page of  web site has different importance. Moreover, previous  sequential traversal pattern mining generates a very large  number of subsequence as the minimum support becomes  lower. In this paper, we developed FSTPMW which focused  on frequent sequential traversal pattern mining with weight  constraint. A weight range is used to adjust the number of sequential patterns. The extensive performance analysis  shows that FSTPMW is efficient and scalable in mining  sequential traversal patterns.

This models fall into two classes are called periodic  pattern and dynamic significant pattern. Periodicity can be  full periodicity or partial periodicity. In former, every time  point contributes to the cyclic behavior of a time series. In  contrast, in partial periodicity, some time points contribute  to the cyclic behavior of a time series. This model of pattern  is so rigid. In many applications, the occurrences of symbols  in a sequence may follow a skewed distribution. Using the  information gain, as a new metric, help us to discover surprising patterns. In fact, this is still an active research  area with many unsolved challenges. Much more remains to  be discovered in this young research field, regarding general  concepts, techniques, and applications.



VII.   REFERENCES  [1]  Dong G., and Pei J., Sequence Data Mining , Springer, 2007.

[2]  Agrawal R., and Srikant R., "Fast Algorithms for Mining  Association Rules", 20 th  Int. Conf. Very Large Data Bases,  VLDB, Morgan Kaufmann, 1994, 1994, pp. 487-499.

[3]  th  Int. Conf. on Data Engineering, IEEE Computer Society Press, Taiwan, 1995, pp. 3-14.

[4]  Wang W., and Yang J., Mining Sequential Patterns from Large Data Sets , Springer, 2005.

[5]  Zhao Q., and Bhowmick S. S., Sequential Pattern Mining: A Survey , Technical Report, CAIS, Nanyang Technological University, No. 2003118, Singapore, 2003.

[6]  Transaction on Knowledge and Data Engineering, 15(3), 2003, pp. 613-628.

[7] th  ACM Int. Conf. on Knowledge Discover and Data Mining (KDD), 2001, pp. 395-400.

[8]  Han J., and Kamber M., Data Mining Concepts and  Techniques , Morgan Kanufmann, 2003.

[9]  of the 2002 ACM SIGMOD Int. Conf. on Management of data, ACM Press,2002, pp. 406-417.

[10] M. Garofalakis, R. Rastogi, and K. Shim, "SPIRIT: Sequential pattern mining with regular expression constraints,   " VLDB'99, 1999.

[11] J. Pei, J. Han, J. Wang, H. Pinto, Q. Chen, U. Dayal, M. C.

Hsu, "Mining Sequential Patterns by Pattern-Growth: The and Data Engineering, Oct, 2004.

[12] M. Seno and G. Karypis, "SLPMiner: An Algorithm for Finding Frequent Sequential Patterns Using Length- Decreasing Support Constraints," ICDM'02, 2002.

[13] J. Pei, J. Han, and W. Wang, "Mining Sequential Patterns  with Constraints in Large Databases," ACM CIKf,  Nov.

2002.

[14] J. Wang, and J. Han, "BIDE: Efficient Mining of Frequent Closed Sequences, ICDE'04, 2004.

[15] X. Yan, J. Han, R. Afshar, "CloSpan: Mining Closed Sequential Patterns in Large Datasets, " SDM'03, 2003.

[16] M. Zaki, "SPADE: An efficient algorithm for mining frequent sequences. Machine Learning, " 2001.

[17] Proc. Of the  , Sep. 2006, pp.

512-517.

[18] Itemset Mining with a Weight Range and a Minimum  Mining, Apr. 2005, pp. 636- 640.

[19]  Pattern Mining with Length-Decreasing Support Proc. Of the 9th Pacific-Asia Conf. on  Knowledge Discovery and Data Mining (PAKDD`05), May 2005, pp. 555-567.

[20] U. Y Knowledge Based Systems, vol. 20,  Feb. 2007, pp. 86-97.

