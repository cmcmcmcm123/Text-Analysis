Cloud based Big Data Analytics for Smart Future Cities

Abstract?ICT is becoming increasingly pervasive to urban environments and providing the necessary basis for sustainability and resilience of the smart future cities. Often ICT tools for a smart city deal with different application domains e.g. land use, transport, energy, and rarely provide an integrated information perspective to deal with sustainability and socioeconomic growth of the city. Smart cities can benefit from such information using Big, and often real-time cross-thematic, data collection, pro- cessing, integration and sharing through inter-operable services deployed in a Cloud environment. However, such information utilisation requires appropriate software tools, services and tech- nologies to collect, store, analyse and visualise large amounts of data from the city environment, citizens and various departments and agencies at city scale. This paper presents a theoretical perspective on the smart cities focused Big data processing and analysis by proposing a Cloud-based analysis service that can be further developed to generate information intelligence and support decision-making in smart future cities context.



I. INTRODUCTION  With the rapid increase in the presence of Internet of Things (IoT) and future internet [1][2] technologies in the smart cities context [3][4][5], a large amount of data (a.k.a.

Big data) is generated, which needs to be properly managed and analysed for various applications using a structured and integrated ICT approach. The structured approach can be based on a generic process identifying the necessary steps to be followed by using different techniques, tools and services.

These steps may consist of collection, storage, harmonisation, processing, visualisation, analysis and generation of smart city application specific information and knowledge for decision making using Cloud-based storage and analysis services.

Today, approximately 75% of the European population lives in urban areas and the urbanisation of the European popu- lation is expected to increase over 80% by 2020 [6]. A contin- uous increase in urban population strains the limited resources of a city, affects its resilience to the increasing demands on resources and urban governance faces ever increasing chal- lenges. Furthermore, sustainable urban development, economic growth and management of natural resources such as energy and water require better planning and collaborative decision making at the local level. In this regard, the innovation in ICT can provide integrated information intelligence for better urban management and governance, sustainable socioeconomic growth and policy development using participatory processes.

In order to mitigate the above challenges, a shift from classical models of top-down governance to new bottom-up approach using ICT support is needed to capture multi-dimensional expert opinions. Such an ICT driven urban management can  be considered as a step towards transforming cities into smart cities, which are defined as [3]:  . . . a city which invests in ICT enhanced governance and participatory processes to define appropriate public service and transportation investments, that can ensure sustainable socio-economic development, enhanced quality-of-life and intelligent management of natural resources.

.

ICT brings a significant change in smart cities? governance, particularly in terms of improved communication and infor- mation services, as well as offering the potential to provide citizens with the necessary information to better manage and utilise their surroundings and city resources. Similarly, these innovative tools provide the urban planners with the necessary intelligence for decision making needed to actively manage the urban environment. However, the realisation of the requisite knowledge and tools depends on the availability of the underlying data and facilities to process such data. Ap- propriate mechanisms are needed to manage data acquisition using different methods such as remote sensing, RFIDs, sensor networks, smart phones, city databases, satellite imagery, open data from governments initiatives [7]. Furthermore, processing and integration of cross-disciplinary data is needed to get knowledge and intelligence for the sustainability, resilience and governance of a city. This would also provide the nec- essary context-aware information services for general public such as public transport services, air quality of surrounding environment, etc. In addition, citizens can also participate in information collection such as pertaining to traffic gridlock de- tection (i.e. via crowd sourcing), building or household energy usage and environmental sensing related to bio-diversity and green infrastructures. Such public participation empowers the general public and raises awareness about their environment and health, which can result in behavioural changes for green and sustainable healthy city-wide initiatives.

Smart cities [4] use a variety of ICT solutions to deal with real life urban challenges. Some of these challenges include environmental sustainability, socioeconomic innovation, partic- ipatory governance, better public services, planning and collab- orative decision-making. In addition to creating a sustainable futuristic smart infrastructure, overcoming these challenges can empower the citizens in terms of having a personal stake in the well-being and betterment of their civic life. Consequently, city administrations can provide better urban governance and man- agement by applying these ICT solutions. Such ICT enabled   DOI 10.1109/UCC.2013.77    DOI 10.1109/UCC.2013.77    DOI 10.1109/UCC.2013.77     solutions thus enable efficient transport planning, better water management, improved waste management, new constructions and structural methods for health of buildings and effective environment and risk management policies for the citizens.

Moreover, other important aspects of the urban life such as public security, air quality and pollution, public health, urban sprawl and bio-diversity loss and energy efficiency can also benefit from these ICT solutions.

ICT as prime enabler for smart cities transforms application specific data into a useful information and knowledge. From the ICT perspective, the possibility of realisation of smart cities is being enabled by smarter hardware (smart phones, sensor nets, smart household appliances, etc.), which can organise in an ?Internet of Things? (IoT) and thus become a major source of user and environment specific data. With the passage of time, the volume of data generated from these IoTs is bound to increase exponentially and classified as Big data [8]. In addition, cities already possess land use, transport, census and environmental monitoring data which is collected from various local, often not interconnected, sources and used by application specific systems but is rarely used as collective source of information (i.e. system of systems [9]) for urban governance and planning decisions. Many local governments are making such data available for public use as ?open data? [7]. Man- aging such large amount of data and analysing for various applications e.g. future city models, visualisation, simulations, provision of quality public services and information to citizens and decision making becomes challenging without applying appropriate tools and techniques.

Smart Governance  Smart PeopleSmart Mobility  Smart Economy Smart  Environment  Data acquisition and storage, Information processing  and decision making  Informed People & Public  participation  City Management  &  Economic development  Transport and  CO2 Emission  Energy Efficiency  Public Health  Security & Emergency  services  Key: Some Possible City Applications  Main Pillars of a Smart City  Cloud infrastructure and application services  Information Flow  OTHERS e.g.

Waste & water management  Fig. 1. Cross-thematic data management and analysis for variety of smart city applications in Cloud environment  In the above context, recent emergence of Cloud computing promises solutions to such challenges by facilitating Big data storage and delivering the capacity to process, visualise and analyse city data. Such an infrastructure level solution can also facilitate the decision makers in meeting the QoS requirements by providing an integrated information processing infrastruc- ture for variety of smart cities applications to support decision making and urban governance.

Figure 1 depicts our view of the main thematic pillars of smart cities: smart people, smart economy, smart environment, smart governance and smart mobility which contribute towards the sustainability of resources and resilience against increasing urban demands. The main motive towards developing such a view is to consider a holistic approach for smart cities by providing data acquisition, integration, processing and analysis mechanisms to synthesize the needed information that can help in enhancing resilience and sustainability of a city. Managing data for these thematic domains in a Cloud environment pro- vides the opportunity to integrate data acquired from various sources and process it in acceptable time-frames. However, it is not straightforward to adopt Cloud computing to deal with smart city applications due to a number of challenges and requirements [10]. Our aim here is to discuss a theoretical perspective on how these challenges can be addressed in part by using ICT tools and software services to intelligently analyse and manage the complex Big data of smart cities, and by incorporating a suitable Cloud architecture such as the one proposed by [4], [11], [12].

The remainder of this paper is structured as: Section II provides a simple use case of smart cities identifying needs of information processing and knowledge generation. A service architecture and design for analytical processing of Big data for smart cities in Cloud environment is presented in Section

III. In Section IV, we conclude our discussion and present future research directions.



II. AN EXAMPLE USE CASE: SMART TOWN CENTRE  Consider the use case of a city that decides to transform its urban environment by interrelating peoples, processes, places and technologies. There can be number of different scenarios in this context e.g. related to urban management, water management, waste management, public administration, urban planning, policy development, citizens engagement, en- vironmental sustainability, business development and economy, energy efficiency, transport management, public security and health. Naphade et al. [9] highlight the need of innovation in planning, management and operation to transform a smart city. They argued for a ?system of systems? based approach using a unified information model that makes it possible to acquire a complete picture of urban complexity and processes.

They also present several smart cities application examples and opportunities of using innovative ICT solutions and as- sociated development challenges. Similarly, Libelium [13] lists 50 sensors-based applications for a smarter world which contribute towards development of a smart future city. We will build upon such use cases and briefly present one hypothetical smart future city use case.

In most urban settings, the town centre can be considered as the core of major socio-economic activities including tourism, social, business, shopping, work, travelling hubs (bus or train stations), education (colleges/universities) and often has resi- dential places as well. Typically, a number of people commute to the town centre at different times on weekdays (mostly for work) and over weekends (shopping, work, leisure etc.) and act as a stimulus to the socioeconomic development. These activities also create an environmental footprint that requires enhanced information intelligence to manage and mitigate any negative effects on these town centres. For such an urban     setting to be transformed into a smart town centre, there is a core requirement of pervasive, interconnected communica- tion infrastructure and access to contextual information of its citizens and physical spaces by data sensing, processing and generating useful information for different stakeholders for consumption and decision making.

Amongst many other technologies, environmental sensors and smart phones are major source of Big data points in a city environment as these technologies assist in determining presence and location of the objects and, in case of smart phones, provide a means of information dissemination and consumption as well. In order to utilise sensor based in- formation in a more effective way, additional digital data including that of city maps, road networks, pedestrian/cycling tracks, cadastre, buildings, populations census, utility services, digital elevation model, etc. are often needed from various city databases to process and utilise the needed information.

For instance, a common scenario can be locating empty parking spaces during peak hours using smart phones. For example, Libelium smart parking sensors for parking man- agement system (http://www.libelium.com/smart parking/) can provide real time information to motorists in town centres, thus saving fuel costs and reduced CO2 emissions. Another scenario can be based on a smart phone application with an interactive and navigable map of the town centre that allows end users (e.g. citizens or tourists) to find the nearest attraction, bank or pharmacy etc. Such a smart phone application can also support a feedback mechanism allowing end users to leave comments/annotations (e.g. complaint, fault reporting, experience details, appreciation, etc.) by clicking on a specific point of a map (or auto-detected current location using GPS), which can be dealt by city government staff. A new scenario relies on the information about number of vehicles available on specific roads of town centre which can be detected by specific counting sensors and/or vehicle fitted with GPS devices. This information helps in route optimisation by providing a traffic congestion map in real-time to the citizens who are planning to visit/leave town centre and assist their decision making towards their mode of transport (private, public) and route planning. In an alternative scenario, a similar kind of information can be collected by processing mobile phone activity data available to mobile service providers to determine sojourn population dis- tribution and mobility patterns [14], which can help transport agencies to tune the frequency of public transport dynamically on specific routes of the town centre. City councils can also use this information for public consultation by visualising overall socio-economic and environmental impact using web and/or smart phone platforms and engage the public on the development of new policies e.g. regarding restricted traffic zones, congestion charges, etc. and collaborative decision making.

All the above scenarios indicate that there are numer- ous possibilities for the development of smart solutions for the smart town centre use case. The Cloud-based Big data collection, processing and visualisation play a major role in dealing with the scalability issues of data, processing power and increasing number of users i.e. new scenarios, novel use cases, size and population of the city, etc., which can ultimately contribute towards better management, decision making and governance. In the following section, we propose an architec- ture for Cloud-based Big data analytics focused towards the  smart city use cases.



III. DEVELOPING AN ANALYTICAL PROCESSING SERVICE  This section discusses two elements pertinent to the devel- opment of a generic Cloud service for smart city related Big data analysis: i) design of the Cloud service, and ii) reusability of existing tools and techniques. Such a Cloud-based analysis service can be exploited as Analytics as a Service model.

A. Architectural Design of the Cloud Based Big Data Analysis  Our guiding design principle for the Cloud-based analysis service is to reuse existing, well-tested tools and techniques.

Therefore, we use some architectural concepts from our pre- vious work on Cloud architecture for information intelligence in urban systems [11], [4],  Data?and? Metadata?(RDF?  Storage)  Data?Acquisition,?Analysis?and?Filtering?Layer  Resource?data?mapping?and?linking?Layer  Interactive?Explorer?Layer  Data?Source? Classification CAData?Cleansing  Intelligent?Engine  Linked?Data  Data?Browser  Fig. 2. Proposed Architectural Design  The system architecture, as shown in Figure 2, is divided into three tiers to enable the development of a unified knowl- edge base. Each layer represents the potential functionality that we need to meet our objectives. The first requirement in the bottom-up approach of our design is data collection, however it is likely that collected data will be in a number of different formats due to heterogeneous data sources. Data from heterogeneous sources can be exposed through unified service interfaces if its meta-data is known and processed. The lowest layer in our architecture deals with this requirement.

The lowest layer in the architecture consists of distributed and heterogeneous repositories that are subscribed to the system. There are two ways data can be retrieved from these repositories. First, if APIs and services have been implemented by these data providers, then data access and retrieval process becomes simple because either an API or a web service can be invoked to retrieve the meta-data and populate the meta-data repository e.g. Open Geospatial Consortium (OGC) compliant web services. Alternatively, if an API or web service has not been provided by a data provider, suitable extractors can be implemented to extract meta-data from these distributed repositories to access the databases when this is needed. Apart from these data repositories, a major source of data will be ?connected things? (or sensor networks) that will sense city environment in real-time and provide large data volumes, which would also need to be analysed, filtered and processed into meaningful information. In this respect, Nathalie et al.

[12] introduce the concept of ?Cloud of things? by combining sensor networks in a Cloud environment. They abstract the heterogeneity of variety of sensors using semantics and OGC standards such as Sensor Web Enablement (SWE), Sensor Observation Service (SOS), SensorML etc. and provide useful insights to integrate sensor data in a smart city context.

Once the meta-data of heterogeneous data sources has been populated into meta-data stores, mappings are established between the resources, links are generated and the data is made semantically relevant and browse-able. The data is then mapped using standardised resource description semantics, e.g.

via an RDF store which has all the necessary links established between artefacts and resources. In case of linked services, higher level services and mashups can be composed to browse and make use of this data for interesting scenarios. The smart links layer finds new scenarios and supports workflows to develop relations that were not possible in the isolated data repositories. In the case of linked data, databases can be browsed to serve queries and find events of interest that were not possible without the availability of linked data.

An intelligent engine (top layer) will process the data returned from Open APIs available in the linked data and ser- vices layers. The engine unifies the data that is available in the linked data and services stores and helps users in submitting queries, algorithms and workflows to find information from the repositories. The analysis engine will process the data that is retrieved through the respective Open API implementations once these are invoked by the Explorer. Users, or third-party services, will be able to apply stochastic rules and criteria to generate non-obvious relations and associations based on the content of the linked databases.

The third layer in the architecture is an interactive Explorer.

The Explorer will provide a scalable and semantics-aware browsing platform to the meta-data and distributed databases.

This provides the interactivity and interfaces that users need to browse the information based on their topics of interest, submit queries and get access to unified resources. User can refine their queries after interpreting the results so that query and analysis algorithm evolution and execution become an interactive process. The Explorer will also interact with the intelligent engine to support users in their stochastic analysis and data mining operations to derive and produce new links and relations.

The system architecture is also based on the following design principles:  ? System scalability: The information linking, browsing, and analytics processes will be scalable. The aim is to use technologies such as Hadoop MapReduce to scale the analytics engine. Machine learning algorithms will be transformed as MapReduce scripts to parallelize the analysis and search processes. Similarly, stochastic aspects will be converted into MapReduce scripts to scale and optimize the processing activity. The system will be capable of both batch and stream mode of data processing to cater for real-time data streams being made available by environment sensor networks and other data services [15]  ? Low latency: The architecture will support the low latency and better quality of service goals to give users  a great browsing and analysis experience. To enable this, in-memory storage and analytics approaches will be exploited. A high level in-memory storage and Cloud-based processing cluster will be created that will exploit the low latency resources in clustered memories to cut down latencies, provide quick results and increase user experience on a distributed system of heterogeneous repositories. From system hardware point of view, GPU based scheduling, resource allo- cation and optimisation approaches will be used to optimise the data interrogation, stochastic processing and browsing operations. Overall aim here is not to rely on a particular hardware and to make the system hardware independent.

? Open system principle: The architecture will exploit open APIs and standards-based technologies. First of all, this will avoid lock-ins. The use of open standards will make the system open so that new tools and technologies which have better functionality and performance can be integrated on demand provided they are standards compliant. Secondly, the system can be extended to link and integrate new databases. The use of open standards will encourage data providers and user communities to join the system resulting in an ecosystem of repositories and planners, leading to unprecedented discoveries and interesting scenarios.

? Data acquisition and management: The system will implement two data acquisition mechanisms depend- ing on whether both an open data schema and its associated API are available from the data provider or not. If both data schema and API are accessible, deterministic queries can be made to the provider for data acquisition purposes. In addition to this, a stochastic engine will also play an important role in extracting data from sources by helping the users to find data sets that may add value to the analysis process. This may lead planners (or end users) to come up with ad-hoc or stochastic queries that are sent to the data sources for a batch like data querying process to assist planners in their quest for knowledge production.

? Processing, Analysis and Use: The system will pro- cess raw data to establish both casual associations and semantic links amongst multiple data sources.

Analyses will be performed both in batch mode and based on interactive input. The latter will be accessed through the Explorer which will be implemented as an open, publicly-available web tool. The batch mode will be realised by implementing stochastic operations on a Hadoop-based analytic platform. A number of data mining and machine learning algorithms will be experimented to produce the stochastic functionality in order to find events of interests to planners.

B. Existing Tools and techniques  There exists several tools and approaches for large scale data management [16], [17], [18], [19] and analytics [20], [21] in Cloud environment [22], [23], [24], [25], [26] and number of issues in this domain have been identified [27], [28]. Below we     represent some well-known tools and techniques which provide necessary foundation for the above architecture.

? System and Database Management ? OpenStack (http://www.openstack.org) will be  used to create a scalable and standards com- pliant cloud infrastructure. This will lead to a standard and scalable open source Cloud operating system enabling the system to create and offer Cloud computing services running on standard hardware.

? Apache Cassandra (NoSQL Database) will be used as a datastore to elastically organise linked meta-data in the system. Linear scal- ability and proven fault-tolerance on Cloud infrastructure makes Cassandra a viable plat- form for organising critical data. Cassandra?s data model offers column oriented schema and powerful built-in caching that will help planners (end users) in getting the quality of service in exploiting the data in the system.

? Web Resources Extraction ? Apache Solr (http://lucene.apache.org/solr)  will be used for searching the databases.

Solr is a standalone enterprise search server with a REST-like API. The operations such as full-text search, faceted search, near real- time indexing, dynamic clustering, database integration, rich document handling, and geo-spatial search can be supported through Apache Solr.

? Configurable browsers Lynx (http://lynx.isc.

org) or w3m (w3m.sourceforge.net) can be used to support the stochastic search engine of the system  ? REST base web service interfaces will be provided to access the meta-data, applications (interactive and batch) as well as the source repositories.

? Data Analysis Tools ? RapidMiner: Open source data mining toolkit  supporting both analytics and visualisation and R, which is a functional language adopted by the statistics research community, will be exploited for analysis. To scale the analyses process, Hadoop MapReduce (http://hadoop.

apache.org) will be integrated with R and RapidMiner to interrogate and mine the data at scale.

? Data and Meta-data Formats: Existing metadata for- mats (such as the European Data Model, Talis Aspire, the Open Library and DBLP as Linked Data) will be used to describe and store meta-data extracted from different sources. Similar to Ontologies, common meta-data format will be defined using eXtensible Markup Language (XML) conforming to the Re- source Description Framework (RDF) specification.

The extensible nature of mark-up language allows new vocabularies to be added as newly discovered asso- ciations emerge. SPARQL, an RDF query language,  will be used to retrieve and manipulate data stored in Resource Description Framework format.

? Processing Objects: REST, XML and JSON will form the foundation of the access and interac- tion APIs. API?s will return data in the follow- ing formats: i) Extensible Markup Language (XML), and ii) JavaScript Object Notation (JSON). XML and JSON representations of Open API?s will be exploited to make available the data, meta- data as well the tools for interrogating and vi- sualising the data. Open API?s initiatives such as mingle (https://mingle.io), Bloomberg?s open mar- ket data initiative (http://www.openbloomberg.com/ 2013/02/06/open-api-blpapi-v3-6-x-released), and the Guardian Open Platform (http://www.theguardian.

com/open-platform) will be evaluated for reuse.



IV. DISCUSSION AND CONCLUSION  Smart cities provide an opportunity to connect people and places using innovative technologies that helps in better city planning and management. At the core of smart cities is the collection, management, analysis and visualisation of huge amount of data that is generated every minute in an urban environment due to socioeconomic or other activities.

Smart cities data can be collected directly from variety of sensors, smart phones, citizens and integrated (or linked) with city data repositories to perform analytical reasoning and generate required information for decision-making for better urban governance. However, this requires carefully prepared uniform and integrated information model of cross thematic data in a Cloud environment that will provide the benefit of developing variety of information services for different city applications. Cloud computing provides a great opportunity to manage, analyse and process the Big data generated by cities but needs new tools and services to process and analyse city data effectively. Our future research work is to develop a prototype in order to identify technical implications and limitations and suggest viable solutions.

