Proceeding ofNLP-KE'O5

Abstract- Incrementally updating association rules based on two or more classes of frequent item sets may reduce the costs of scanning the original database remarkably. However, it was considered as a method of saving time with more storage spaces.

It is put forward in this paper that all frequent item sets of several minimal supports can be stored in a table with a little additional storage, and a representation model is given. Based on this model, the paper systematically discusses the problem of incrementally updating based on discovered association rules of several minimal supports. Theoretical analysis shows that the approach makes full use of the previous results and reduces the complexity of incremental updating algorithms.



I. INTRODUCTION  Mining association rules is a very important issue in knowledge discovery in databases (KDD) proposed originally by Agrawal [1, 2], which mines potentially useful association rules from transaction database.

Apriori, the classical algorithm proposed by Agrawal, must scan the transaction database for many times. Due to the transaction database is usually very huge, D. W. Cheung et al.

proposed the incrementally updating algorithm to reduce the times of scanning the database [3]. Hereafter, many researchers have studied and extended the incrementally updating algorithms [4-9]. It is widely accepted that incrementally updating based on multiple previously mined results can dramatically reduce the times of scanning the original transaction database. However, it is also regarded as a method of saving time by increasing storage spaces [9].

We suggest in the paper that, a little additional storage can  store frequent item sets of several minimal supports, and present a representation model. Based on this, we systematically study the problem of incrementally updating association rules according to several previously mined results.

Theoretical analysis and experimental results indicate that the method presented in this paper utility the previous results to a great extent.

The paper is organized as follows. In Section 2, we briefly introduce some concepts and notations of association rules mining. Section 3 presents the frequent item sets representation model of several minimal supports. Section 4 studies the incrementally updating algorithms based on several previous mining results. The time and space efficiency of the  algorithms are analysed in section 5. The conclusions are drawn in section 6.



II. NOTATIONS OF ASSOCIATION RULES MINING  Let I={ il , i2,9.. .9,m } denote the set of all of the items. An item set is a non-empty subset of 1. DB is a transaction database of I. A transaction, T, is a subset of I. Association rule is an implication of the form X => Y, where X c I, Yc , and Xr Y = (DP.

Support number of item set X is the length of the set  {T[ X c T T c DB }, denoted by X.count. The support degree of item set X is denoted by support(X)= X.count/IDBI, where IDBI denotes the number of the transactions in the database.

The support degree of item X U Y is called as the support  degree of association rule X => Y . The confidence degree of association rule X => Y is conf(X > Y )=support(X U Y )/support(X).

To mine the potentially useful association rules, two  important thresholds are given, minimal support degree (denoted by s) and minimal confidence degree (denoted by c).

X is called as frequent item set if and only if support(X) . s.

The key issue in association rules mining is to find all frequent item sets in the transaction database efficiently.

Frequent item sets relate to transaction database (DB) and minimal support (s). In this paper, we use L(s DB) to denote the set of all the frequent item sets of DB with the minimal support s, i.e. L(s,DB)={ X XC I and support(X)>s}. Let

X.countDB be the support number of item set X in DB. A frequent item set with k items is called as frequent k-item.

Lemma 1 if s<s', then L(S DB) C L(S,DB).

Proof: Vc E L(S DB) ]3 c c I and support(X) s' >s, i.e.

cE L(S,DB).



III. REPRESENTATION MODEL FOR FREQUENT ITEM SETS  The data mining behaviour usually can be modelled as follows: (1) based on the unchanged database, adjust the  0-7803-9361-9/05/$20.00 C2005 IEEE     minimal support several times to find the useful association rules; (2) updating the database; (3) repeat (1) and (2) as required.

A. An example  The test data is the mushroom database provided by UCl (ftp.ics.uci.edu/pub/machine-learning-databases/mushroom/).

There 8124 records, 23 kinds of attributes (items), and 2-12 values for each item. For clarity of description, the items (attributes) are denotes by 11, 12, ... , 123. For example, II denotes the decision attribute, 12 denotes 'cap-shape', 17 denotes 'gill-attachment', 18 denotes 'gill-spacing', 19 denotes 'gill-size', 118 denotes 'veil-color' 119 denotes 'ring-number' and 120 denotes 'ring-type'. And let DB denote the database of all 8124 records.

Example 1. Given the minimal support s=0.7, there are 31  frequent item sets in DB, and the frequent-4 item sets are listed in table I (the number is 5).

TABLE I FREQUENT 4-ITEM SETS OF DB WITH MINIMAL SUPPORT S=0.7  No 18 19 118 119 120 Count  1 f c p - o 6272  2 f c - w o 6272  3 f c p w - 6602  4 - c p w o 6272  5 f - p w o 7288  Where '-' denotes the item is not belong to the set, and all the unlisted items are assigned '-'  When the minimal support s is set as 0.8, there are 23 frequent item sets in DB, and the frequent-4 item sets are listed in table II (the number is 2).

TABLE II FREQUENT 4-ITEM SETS OF DB WITH MINIMAL SUPPORT s=0.8  No 18 19 118 119 120 Count  I f c p w - 6602  2 f - p w o 7288  It is obvious that L(O.8,DB) C L(O.7,DB) according Lemma 1, i.e. all the rows in table 2 will certainly be find in table 1. So we needn't spent storage spaces for L(O. DB)I this may save storage spaces of 23 item sets (records).

To represent frequent item sets of a database with several  minimal supports, the key issue is how to identify to which minimal support does a certain frequent item set belong.

B. Representation modelforfrequent item sets  The goal is represent n classes of frequent item sets, i.e.

L(s DB) (1 < i < n) with minimal storage spaces.

Without loss of generality, let Si < Si+5 .

The following result is directly deduced according to  lemma I1, i.e. 5n(s,DB) - L(s,,-,DB) c *-- - L(s,J)B) as shown in Fig. 1.

Fig. 1. Relations among several classes of frequent item sets  Let C(S ) = L(.in,DB)(sj+I,DB),I < i < n (s., DB),I n  then  n  L(vD)=UC(Sj).

J='  Obviously, { C(sj) ji <j . n} is an equivalence partition of L(S DB). Specifically, { C(sj) 11 <j < n} is a equivalence partition of L(s ,DB)' C(Sj ) (I <j < n) is an equivalence class.

Given a frequent item set, X, let X.Stag denote the tag of X, indicating to which equivalence class does X belong,.

XE C(sk) k=X.Stag.

This can be implemented as follows. Let LargeItem be the  table of all records in L(s DB) and let 'Stag' be a collum of Largeltem.

So, all the information in table 1 and 2 can be represented in table III.

For convenience, all the minimal supports, si (1 < i < n), are stored in table MS, MS has two collums, 'Stag' and 'Support', where 'Stag' denotes the index of minimal supports, and 'Support' denotes the corresponding minimal support, under the condition of s, < SiA .

Obviously, the equivalence class C(sj) can be get using following SQL sentence: select * from LargeItem where Stag=j.

It is easy to get L(s DB) via the following SQL statement: select * from Largeltem where Stag>j.

TABLE III  FREQUENT 4-ITEM SETS OF L(O.7,DB) L(O.8,DB) No 18 19 118 119 120 Count Stag  1 f c p - o 6272 1  2 f c - w o 6272 1  3 f c p w - 6602 2 4 - c p w o 6272 1  5 f - p w o 7288 2  The efficiency of this model will be examined in section 5.1 from a theoretical and experimental point of view.



IV. INCREMENTALLY UPDATING ASSOCIATION RULES BASED ON MULITPLE MINING TRANSACTIONS  Definition 1 The problem of incrementally updating association rules based on multiple mining transactions is, computing L(s',DB,) based on { L(S,D,1B) I < i < n}, where ( s' . si ) and/or ( DB' = DB -db+ db' ), db c DB, DBn db'=(.

The interesting feature of definition I is that the incrementally updating is based on several previously mined results (i.e. frequent item sets of several minimal supports).

This problem of incrementally updating can be divided into two classes according to whether the transaction database changes or not. The first class is that the transaction database does not change, and the minimal support changes; the second class is that transaction database changes.

A. Adjusting the minimal support Given the transaction database DB does not change and the  minimal support changes. The problem given by definition I is that, given { L(si DB) I < i < n}, try L(S,DB)  The problem can be divided into 3 cases according s: Case 1: s>sn.

Case 2: s<si .

Case 3: s <s< S  In Case 1, all the useful information are stored in L(S DB) it need not access DB using the 'algorithm 1' proposed by Feng et al. [4]. To fit in with the representation model presented in this paper, we implemented the algorithm with SQL sentence as follows:  Algorithm 1 Incremental update association rules (Case 1)  Input: L(S DB), s (s> S )  Output: L(s,DB)

I. insert into MS values(n+?,s); 2. update LargeItem set Stag=n+l where  Stag=n and count>=s*IDBI For Case 2, it is unavoidable to scan the transaction  database DB. We employ the algorithm DCIUA [6] to deal with this case.

The algorithm 2 is based on DCIUA. It adds some steps to fit in with our representation model.

Algorithm2 Incremental update association rules (Case 2)  Input: L( l,DB)I s (s< S1) Output: L(S,DB) 1. Update MS set Stag=Stag+l; 2. Insert into MS values(l,s); 3. mIL(S,DB) 4. update LargeItem set Stag=Stag+1 5. For each c computed by DCIUA do 6. begin 7. Insert into LargeItem values(m+ I,c,count, 1) 8. m=m+ 1 9. end  For case 3, find j (1 < j<n), such that s1<s< sj+1 . The general method is updating from L usino 'alaorithm 1'.(Si,DB) t: 11  The time complexity is ?(1 L(s ,DB) |) . However, when  L(sj,DB) and L(sj+ ,DB) are known, for L(sj,, DB) C L(S,DB) CL(s ,DB)' so only the frequent item sets in L(s DB) -L(sj ,DB) (i.e. C(sj)) have to be examined. This procedure is shown in Algorithm 3. The time complexity is 0( C(Sj1) I)  Algorithm3 Incremental update association rules (Case 3)  Input: L(S ,DB) I L(Sj+i,DB) X S (sjS< Sj+1 Output: L(S DB) 1. Update MS set Stag=Stag+l where Stag>j; 2. Insert into MS values(j+l,s) 3. update LargeItem set Stag=j+l where Stag=j and count>=s*IDBI  Note that the step 3 of Algorithm3 scans the records in C(sj).

B. Update the transaction database  Theory 1 (the condition of accessing the original database)     If s-s?>.sxl dbi lIDBI +(l -s)xl db' I/I DBJ, then c X L(SnDB) => C 0 L(s,DB-db+db') Proof:  C so50 c.countftB < s x |DB|  and c.countf(,(0, c.count,lb, <Idb'I c.countDBdb+dh c.countDB - c.countdb +  c.count.fi. < s " x 1DB1+1 db' 1, and s-s" .sx dbI1/DB +(I -s)x db'I/IDBj  C.countfDIdb+db < sx(IDBI-ldbl+IdbIj) i.e.

c X L(SDs-dh+db)d  This results in the follow inference.

Inference 1. If s-s" > sx db /DBI +(1-s) x db' /1DB , incrementally updating L( 5,DB) to  L(s,DB-db+db') needn't scan DB.

Theory I and inference 1 suggest that it is possible to obtain  frequent item sets of changed database, under certain conditions, without scanning the original transaction database.

When database updates, the following algorithm,  BatchUpdate, updates the current frequent item sets of various minimal supports to new frequent item sets of changed database without scanning the original database.

Algorithm BatchUpdate. Incremental update association rules (transaction database updates)  Input: Lf, DB) db, db , sI ; where sl-s.'>s.x Idb /I DBI +(1-si)x Idb'I/IDBI (l<i<n) Output: L(si DB-dh+dbO) 1. for (i=n; i>=1; i--) 2. begin 3. s11=(s,xIDBI+Idb'1)/(IDBI-ldbI+ldb'l) 4. Update MS set Support= s, ' where Stag=i; 5. for each c E C(s,) 6. begin 7. new_count-c.countDB - ccountd + C.ccountdb.

8. if(new count>=s,'x (IDB I- I db I + I db'l) 9. then c.count= new_count  10. else if (i>1) then C(sl)=C(si,I) u {c} 11. else delete cfrom C(S) 12. end{for}  13. end{for} Some comments on BatchUpdate: The algorithm scans  C(s,n), C(sn-) ,..., C(sl) in tum. For each frequent item set c in C(s1), step 7 compute c.countfd and c.countfl,( (scanning dataset db and db'), if the condition of step 8 suffices, update the support number, otherwise, c does not belong to frequent item set under the condition of (se', DB-  db+ db'), and it is put into C(QSl ) for further usage.

Note that the 'delete' process in step 11 can be run only if  i=1. And only if this is the case, the process of incrementally updating will lose information. As we will see in section 5, BatchUpdate only lose a little information.



V. SPACE AND TIME EFFICIENCY ANALYSIS  A. Space efficiency analysis  Let mi, denotes the number of frequent item sets in L(s DB)' i.e. mn H L( ,DL)  In the representation model presented in section 3.2, n classes of frequent item sets, L(sDB) (I < i < n), are represented using only ml records. Suppose the average storage space of frequent item set is t bytes. The additional storage spaces contain two components: (1) 4 byte for each record of L(sVDB), i.e. 4 m,, (2) 12*n bytes for table MS. The total additional storage space is (4 ml +12n) bytes. The total storage space is (t* ml +4 ml +12n) bytes. For 12n<< t* ml +4 ml , the storage space does almost not increase with n.

n  However, the usually method cost about E (mi x t) bytes i=l  of storage spaces.

For example, if the minimal supports are (0.30, 0.32, 0.34,  0.36, 0.38, 0.40}, compute L(O3,DB) with Apriori algorithm, then incrementally compute L(O.32,DB)7 L(O.34,DB) L(O 36,DA)7 L(038DB) L(O.4DB) with algorithm presented in this paper.

The data of table 4 and 5 are obtained with SQL.

Take the 5h row as an example. There are 7955 frequent item sets of minimal supports, {0.30, 0.32, 0.34, 0.36, 0.38}, where 2735 records belong to 0.30. The usual method need 246605 bytes for 7955 items sets; and our method only need 95785 bytes.

TABLE IV  STORAGE SPACE EFFICIENCY ANALYSIS  n n Minimal Z(n,) ml (m i x t) Cs C6supports  1=1 i=I {1,2} 4686 2735 145266 95749 10964 (1,2,3} 6081 2735 188511 95761 10976  {1,2,3,4} 7168 2735 222208 95773 10988 { 1,2,3,4,5} 7955 2735 246605 95785 11000 {1,2,3,4,5,6} 8520 2735 264120 95797 11012  C5= t* ml +4 ml +12*n, C6=4 ml +12*n, t-=31  B. Time efficiency analysis For Case 3, the time complexity of algorithm 3 is  TABLE V TIME COMPLEXITIES OF ALGORITHM3 AND ALGORITHM I  j 1 2 3 4 5 6  SX 0.3 0.32 0.34 0.36 0.38 0.4  IL(S.IDB) 2735 1951 1395 1087 787 565  C(Sj ) I 784 556 308 300 222 565 C(s1) -L(SjDB) 0.287 0.285 0.221 0.276 0.282 1  0(1 C(sj) 1). However, the previous method, i.e. 'algorithm 1' in reference 4, costs about ?(| L(s ,DB) j) .

Table V shows the time complexities of the two algorithms.

The time complexity of algorithm BatchUpdate is  0(1 L(s, DB) x(I db + db'j)).

For example, given a set of minimal supports, (0.30, 0.32,  0.34, 0.36, 0.38, 0.40), the mining results of original database DB are shown in table 5. Let db be the data set of the last 160 records of DB, and the database DB is updated to DB-db (i.e.

delete the last 160 records).

According to the condition of theory 1, the new series of minimal supports are si ' (1 < i < n), where s.' > s. *8124/(8124-160), i.e. si '=(0.3061, 0.3265, 0.3469, 0.3673, 0.3877, 0.4081).

The algorithm BactchUpdate is implemented with C++  Builder and Interbase6.5, it spent 82s to compute all the new  frequent item sets in a Personal Computer with P4-1.8G CPU and 256M memory. The number of frequent items sets of each minimal support are 2727, 1943, 1389, 1081, 781 and 561 respectively. Compared with the 3rd row in table 5, only 8 frequent item sets of L(s I)B) have been thrown away. There are 2727 frequent item sets updated from L(0 3j)R) to L(0.3061,DB-db) -

IV. CONCLUSION  In this paper, an efficient representation model for frequent item sets of several minimal supports was presented. It needs only a little additional storage spaces.

Based on this, it studied the problem of updating association rules based on several previously mined results, and presented two algorithms: Algorithm3 and BatchUpdate.

Theoretical and experimental results show that our method decreases the scan times of original database with the costs of a little additional storage spaces.

