An Integrated Framework for Disaster Event Analysis in Big Data Environments

Abstract?Today world has witnessed the catastrophic consequences of natural and man-made disasters are demanding the urgent need for more research to advance fundamental knowledge and innovation for disaster prevention, mitigation and management. At the same time, the world is in the age of the Big Data revolution which holds the potential to mitigate the effects of disaster events by enabling access to critical real time information. Thus, in this paper an integrated framework for analyzing disaster events by using the Big Data analytics is proposed.  The proposed framework shall address three key components to perform data organization, data integration and analysis, information presentation to users by utilizing Big Data with respect to disaster events. In doing so, the paper shall create a disaster domain-specific search engine using co-occurring theory and Markov chain concepts for preparing impacts of disaster attacks to make the society better aware of the situations. Specifically, stochastic clustering with constraints is used to automatically extract disaster events by defining the set of structural attributes. Some illustrative simulations are shown by using Big Data sources for the Great East Japan earthquake, tsunami and nuclear disaster events of 2011.

Keywords-Big Data analytics; disaster events; co-occurring theory; Markov chain appraoch

I.  INTRODUCTION Natural or man-made disasters have caused a huge impact  in the world`s economic and social systems which result in death or injury to humans, and damage or loss of properties such as building, communication systems, natural resources etc. Natural disasters come without warning taking lives of tens, hundreds and thousands of people. In such cases, the use of timely, accurate and effective disaster information in disaster management and preparation scenarios has been extensively discussed in literature [1-3]. Generally, the data resources include news/articles/blogs from web, social networks platforms such as Twitter, Facebook, Flickr and multimedia data like images and videos. The amount of data being gathered and stored is growing at a phenomenal rate in volume, velocity, and variety which can be referred to as Big Data. Since the combined characteristics of those data are based on (i) data producer and consumer concepts, (ii) time and space sensitivity of the exchanged information, (iii) the level of reliabilities of the information sources, (iv) unstructured, and (v) various formats, it is challenging as well as creating opportunities for extracting insight information about the disaster events through the Big Data analytics [4-6].

In this context, studying human and event behaviors become an important factor of Big Data environments. In addition, the timely prediction of weather patterns and likelihood of hazard occurrences are also key interests of Big Data analytics. Big Data can also provide more real-time feedback information than ever before.

On the other hand, there are more traffic flows in communication high ways through social network platforms such as Twitter, Facebook and etc. during the time of disasters.

These communications are mainly about information seeking, family and friends contacts in disaster zone. In such environments, Big Data can play a major role for seeking the insight information. Thus the aim of the paper is to explore the possibilities for the use of Big Data in the analyzing human behavior involved events in case of natural disasters and to propose an integrated framework for organizing insight information and data exchange between the participants in such events. The proposed method is based on the combination of Big Data concept and an emerging network science which is rooted in mathematics. Through the plotting of data on a network map, critical nodes known as hubs, can be identified for further study. Understanding a hub and its importance within a network provides information about the strength of the network, its interconnectedness, and the function of the network itself. In addition, the identification of less significant nodes and their quantity provides information on the scope of the network and its structural stability. Observing the nature of hubs and nodes in a network allows for an overall understanding of its function is illustrated in Fig. 1.

The remaining parts of the paper are section wise organized. First some related research works are described in section 2. Section presents the proposed integrated framework for analyzing disaster events by using Big Data analytics approach. Some simulation results are shown in section 3 to confirm the effectiveness of the proposed method. Conclusions are drawn in section 4.



II. SOME RELATED RESEARCH WORKS In the existing literature, many research works  concerning with simulation models for disaster response but only a few works in Big Data aspects. For example, according to [7], it has noticed that the tweets data about food price in Indonesia and the official statistics are very much related in similar patterns as seen in Fig. 2. This shows the important of Big Data analytics.

DOI 10.1109/IIH-MSP.2013.72    DOI 10.1109/IIH-MSP.2013.72     Earthquake  Victim 1 Rescue 1 Rescue 2  Volunteer 1  Mr. A  Town center  Mr. B  News station  Victim 2  Reporter  Mr. CMinister office  Disaster response  Disaster event   Figure 1.  Network science example on disaster event analysis.

Tw ee  ts ab  ou t t  he p  ric e  of ri  ce   Fo od  P ric  e In  fla tio  n   Figure 2.  UN Global Pulse?s project on food security trend graph.

Generally, disaster event analysis requires methodologies for aggregation of the disaster-related data. Toward such a demand, the concept of Disaster Management Data space is established based on data acquisition, organization, and representation [8]. Another effort to investigate disaster event behavior is ontology-based approach [9] and knowledge-based approach by using social network platforms [10]. On the other hand, a large number of decision support systems have been developed for various types of disasters based on different models and decision support needs. A web-based decision support system for the response to strong earth-quakes is developed [11]. The system was focused on damage assessment and identification of effective response measures. An agent-based system for knowledge management and planning is developed for suggesting plans in emergency and disaster scenarios. Similar decision support systems have also been developed for hurricane emergencies [12, 13], and rescue operations [14]. However most of existing disaster event analysis systems failed since the data in disaster management application domains are  collected and stored in various media types (text, image, video, graphics, etc.), formats, and structures from multiple information sources in Big Data environments. Many of these data are streaming data and collected in real-time, which may have temporal and spatial characteristics. These data may have different levels of completeness and confidence, and may be inconsistent. There is also information shift problem in these applications. That is, the information/knowledge may be constantly changed, outdated, and incomplete. Moreover the data come from heterogeneous sources, having a mix of unstructured and structured types, of different temporal and spatial characteristics, with various sources of uncertainty. To our best knowledge, there are no existing methodologies and/or algorithms that can properly address the current issues of disaster related event satisfactorily. Developing novel techniques for managing and analyzing data that are a mix of unstructured and structured types, of different temporal and spatial characteristics, with various sources of uncertainty, is a challenging task. In order to address the current issues of disaster related events, an integrated approach is proposed in this paper.



III. PROPOSED INTEGRATED FRAMEWORK To be able use the massive volume of unstructured Big  Data for disaster event analysis the proposed framework shall bring some order of the Big Data as shown in Fig. 3.

The framework is composed of three conceptual cubes namely; (i) structure-metric- time cube, (ii) domain-attribute- response cube, (iii) hub-node-analysis cube.

In the framework, the first tube is made up of three functional dimensions in which the structure dimension is to extract information about entities such as persons, organizations, places, etc. and events natural disasters, meetings, crowd behaviors etc. so that the structure of events can be further analyzed. The time dimension is to detect what actual calendar time the information is referred to when an event is described. For example, ?9:37 A.M, September 11, 2001?, ?3 P.M, March 11, 2011?. The function of metric dimension is for deciding the importance of received information. The metrics are numeric attributes of entities and events. For computational purpose, this cube will be represented by the random variable )(MSt  where S stands for structure at time t with reference to metric M.

When the structure, time and events are known, the data will be further organized into the second tube of specific domain, attributes, and response (action). In the second tube, the domain dimension shall address the type of disaster such as man-made or natural. Whether it is large or small since the scale will influence on the modeling techniques. For example, a terrorist attack may require methods for modeling the impact of explosion and suspicious people or objects behaviors. However, a tsunami and earthquake will require capabilities to model stranded victims and estimating social outcomes. The second dimension is organizing the interest of attributes. This dimension aims to minimize the impact of disaster event in the domain dimension. This will include living creature mainly human population, the impact of disaster on the infrastructure resources.

The World Disaster Events Big Data  Structure-metric-time cube  Domain-attribute-response cube  Hub-node-analysis cube  A victim is rescued from the sea Figure 3.  The overview of the proposed system.

The dimension of the controlling agents and their actions on the disaster events is also an important dimension in the second tube. It is necessary to model to understand the situations and scenarios. They themselves can become the disaster affected attributes. Since these three dimensions are equally important for disaster event analysis in Big Data aspect, three different random variables are used for representation of the cube. In particular, it will be represented by tD  for domain, tA  for attribute of interest and tR for types of response actions to be taken at time t.

The last tube of hub-node-analysis will perform the process of clustering the nodes or entities of interest defined in the previous two tubes. These clusters will be termed as hubs which will be focused for further analysis to obtain the insight situations of the disaster events. This can be described by a random variable ),,( ANHOt  representing the outcome result of analysis over corresponding hubs and nodes involved.

Therefore, the proposed framework will lead to the study of 5-tuples )),,(,,,),(( ANHORADMS ttttt . For simplicity, denote the process by  ),,,,()),,(,,,),(( ttttttttttt ORADSANHORADMSZ == , (1)  forming a Markov chain with transition probabilities for vector type states to described as  ),()|( 1 KJpKZJZp tt === ? ,  where, J and K are 5-tuples with scalar values. The corresponding transition matrix is given by  )].,([ KJpP =           (2)  Then, the time dependent probability for )( JZp tt = satisfies the Chapman-Kolmogorov equation of Markov chain as shown in (3).

?,2,1for ,01 === ? tpPpPp t  tt .        (3)  By arranging all possible combinations of 5-tuple process, and labeling as N,,2,1 ?  where N is the number of combinations, then (3) can be expressed as:  ),|()|( 1  ikppijp t N  k ikt ?  = ?=      (4)  Nji ,,2,1,for ?= , where, ikp  is one-step transition probability going from state i to state k.

Suppose that the initial state 0Z is random with distribution, )()( 00 iZpip ==  for all state i. Then by using (4), and law of total probability, we obtain  .)|()()( 0?== i  tt ijpipjZp        (5)  By using these probabilities, we can obtain the trends and behaviors of the associated disaster events.

Thus solving (3), recursively, one can obtain the information about the current situation for the disaster event.



IV. SIMULATION RESULTS In this section, some simulations of the proposed method  will be performed by using Japan earthquake and Tsunami events. An hour after the earth quake hit Japan on March 11, 2011, the Big Data tracks 1200 tweets per minute. It also found that nine out of 10 tweets are trending topics -such as #pray for japan, #tsunami and #japan - were directly related to the earthquake and tsunami. The corresponding state variables are shown in Table I.

)1(tS  causes )2(tS , meanwhile )2(tS  causes tD , and tD causes )3(),2(),1( ttt AAA . In order to investigate the trend patterns of the tsunami events, all possible combinations of 5-tuples defined in section 3 are formed as follows. In this scenario, there are 12 possible combinations all together.

They are described as follows.

)),(),(,),((,, tttttkji OkRjADiSE =  as shown in (1) for 2,1=i , 3,2,1=j , 2,1=k  which makes 2x3x2 = 12 events.

The corresponding transition probabilities are generated by using exponential random numbers and normalizing procedures. Then, resulting matrix P is given as shown in Table II.

By using (5), the time dependent solution for each event is obtained and the trend graph is plotted as shown in Fig. 4.

The graph shows the trends for a summary data from a group of subjects. The horizontal line represents the time points.

The vertical line represents the likelihood patterns of matching of event and corresponding response such as recuse or behavior information. The event of ?a family on the floating? and response type ?recuse? are more matched than other combination. The same is true for the event of     ?crowd stranded and ?behavior analyzed and recuse?. In particular, the top line shows the behavior of the combined event E2,3,2 which reads from table 1 as tsunami )2(tS , standard crowd forming a queue )3(tA  and actions taken by rescue workers )2(tR . Similarly, the second top line shows the matching pattern for the event of combination of (tsunami, a family floating and rescue). But, the second bottom line shows the matching patterns of (earthquake, family floating and crowd behavior analysis) are not much directly related. The same is true for the last bottom line in the graph.  Since these findings are matched with what we expect in real world, more insight information to be extracted in our future work.

TABLE I.  DISASTER SCENARIO DESCRIPTIONS  Types of variables at time t  Descriptions of variables  Structure 1: St (1) 2011, March 11, 3 pm Japan East Coast Earthquake 8.9 m hits, (Breaking News and Twitter)  Structure 2: St (2) 2011, March 11, 4 pm Japan East Coast Tsunami came in, (Breaking News, Twitter)  Domain: Dt Buildings and humans are swept away, (YouTube Video)  Attribute 1: At (1) A family on the roof of a building was detected, (YouTube Video)  Attribute 2: At (2) A crowd is stranded in a building and a queue of one group is detected in a door  Attribute 3: At (3) A chariot in the other group is detected Response 1: Rt (1) A crowd behavior is analyzed Response 2: Rt (2) Action evacuate by rescue workers Analysis 2: Ot  Insight information  TABLE II.  FIRST ORDER MARKOV CHAIN  0.01 0.08 0.11 0.11 0.13 0.1 0.03 0.04 0.15 0.01 0.13 0.11 0.11 0.01 0.13 0.14 0.1 0.12 0.07 0.01 0.15 0.06 0.03 0.07 0.03 0.08 0.09 0.1 0.11 0.1 0.04 0.11 0.06 0.09 0.06 0.11 0.08 0.14 0.02 0 0.14 0 0.07 0.13 0.15 0 0.13 0.13 0.08 0.12 0.1 0.02 0.08 0.14 0.14 0.13 0.1 0.07 0.04 0 0.17 0.08 0.14 0.03 0.05 0.07 0.17 0.11 0.01 0.1 0 0.07 0.09 0.16 0.05 0.16 0.02 0.04 0.01 0.12 0.14 0.08 0.01 0.15 0.14 0.01 0.04 0.1 0.08 0.04 0.04 0.14 0.08 0.1 0.08 0.14 0.14 0.06 0.02 0.13 0.1 0.05 0.1 0.11 0.19 0.01 0.01 0.08 0.1 0.12 0.02 0.08 0.08 0 0.09 0.07 0.13 0.13 0.13 0.04  0.11 0.01 0.12 0.12 0 0.11 0.1 0.09 0.09 0.12 0.04 0.1 0.13 0.08 0.12 0.1 0.08 0.04 0.08 0.04 0.02 0.04 0.18 0.09             1 2 3 4 5 6 7 8 9 10 11 12     1E1,1,1  E2,3,2  E1,1,2 E2,1,2  time  ev en  ts   Figure 4.  Event time series graph.



V. CONCLUSION In this paper, an integrated framework for disaster event  analysis in the Big Data environments has been presented.

The system had developed some useful insight information prediction scheme based on multidimensional Markov chain modeling and time dependent data models. This approach is tightly integrated into highly Big Data analytics system including social network platforms. In future works, context- based Big Data analysis will be addressed to improve the current disaster event analysis methods for faster and reliable insight information.

