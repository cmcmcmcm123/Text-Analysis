Mining Multi-Class datasets using Genetic Relation Algorithm for Rule Reduction

Abstract? This paper describes the use of a new evolutionary method named Genetic Relation Algorithm (GRA) for reducing the number of class association rules extracted by other methods such as Apriori, Genetic Network Programming(GNP) , etc. The purpose is to generate a small number of class association rules in order to delete irrelevant and redundant rules. A reduced rule set has advantages as it provides only useful rules and makes its analysis more efficient. Our approach is based on evaluating the distances between rules for evolving GRA and also evaluating the distances between the data in the test set and the rules for classification. Two matching criteria are presented: complete match and partial match. The classification accuracy obtained by our method is better compared to other reported results in multi-class datasets showing an impressive reduction rate.



I. INTRODUCTION  Data Mining is a technique employed to extract non-trivial information from large datasets. Its interest is growing in the research community. Association rule mining is one of the interesting research topics in data mining and several methods and techniques have been developed during the last decade. However, most of the methods for extracting association rules generate so many rules. Therefore, the problem of selecting the most interesting and useful rules is a research field that has not been completely solved because of the algorithmic complexity to prune a large number of rules.

This paper proposes the use of a new evolutionary algo- rithm named Genetic Relation Algorithm (GRA) in order to find and select only the most relevant and important association rules among a big set of them avoiding the redundant and uninteresting rules. In this paper, the large rule set is generated using the conventional GNP-based mining method [1] [2]. Our approach is based on the evaluation of the distances between rules in every generation during the evolutionary process. Two methods for evaluating the distance are presented: complete match and partial match.

The results are evaluated by comparing the classification accuracy of the reduced set of rules, the complete set of rules and other conventional methods. Furthermore, it is found from simulations that the proposed method not only reduces the number of rules from a large set of rules, but also improves the performance in terms of the classification accuracy.

Authors are with the Graduate School of Information, Production and Systems, Waseda University, Hibikino 2-7, Wakamatsu-ku, Kitakyushu, Fukuoka 808-0135, Japan. (phone: +81 93 692-5261; fax: +81 93 692-5261; email: {egonzale, karla taboada}@asagi.waseda.jp, {k.shimada, mabu}@aoni.waseda.jp, hirasawa@waseda.jp ).



II. RELATED WORK  There have been several attempts for rule reduction such as removing redundant rules using the concepts of closed item sets [3] [4] and representative rules [5], summarization of association rules [6] and a modified Apriori-like[7] method and visualization techniques. However, all of them show at most the comparative classification accuracy as the complete rule set.

Zaki et al. [4] present a framework based on FCI (Frequent Close Itemset) that reduces number of redundant rules. The authors used FCI to form a set of rules and inferred all other association rules from that set. Since FCI is used for choosing a set of rules based on the confidence values, the number of rules grows as the number of FCI increases.

Therefore, it becomes difficult for end-users to infer other rules when there is a large number of FCI. Additionally, since this approach uses FCI, it may prune some important rules without considering the confidence and support values of those rules.

Liu et al [6] proposed an algorithm known as multilevel organization and summarization of discovered rules. In this algorithm, rules are summarized in a hierarchical order, so that end users can browse all the rules at different levels in details. However, this algorithm only summarizes the rules and redundant rules may still exist in the final model.

Similar to all of the above mentioned redundant rule reduction algorithms, the main objective of this paper is to eliminate redundant and uninteresting association rules.

However, our proposed method have two distinct features that distinguish it from all other existing algorithms.

? It uses an evolutionary algorithm named Genetic Re- lation Algorithm (GRA) which encodes the association rules in its nodes and genetic operations are carried out as the conventional evolutionary methods.

? It is not based on any bias assumptions. In addition, our method evaluates each rule with a set of rules based on their distances in order to find redundant association rules. Hence it eliminates redundant association rules without losing any important knowledge from the re- sultant rule set.



III. GENETIC RELATION ALGORITHM  In this section, the outline of Genetic Relation Algorithm (GRA) is described. GRA is one of the evolutionary methods for determining the best relations between events. The basic structure of GRA is shown in Fig. 1. GRA is composed     of nodes and their directed or indirected branches. Nodes represent events and branches represent the relations between nodes. The genotype expression of GRA node is shown in Fig. 2.

Fig. 1: Structure of Genetic Relation Algorithm (In case of directed branches).

Fig. 2: Genotype expression of Genetic Relation Algorithm.

Fig. 2 describes the gene of node i, then, the set of these genes represents the genotype of GRA individuals. IDi is an identification number, for example, IDi = 1 means node i has the directed branches to other nodes, while IDi = 2 means node i has the indirected branches to the nodes. Fi denote the function of the node i. Ci1, Ci2, . . . , Cik denote the nodes which are connected from node i, firstly, secondly, . . . , and Si1, Si2, . . . , Sik denote the strength from node i to node Ci1, Ci2, . . . , Cik or the strength between node i and node Ci1, Ci2, . . . , Cik depending on the arguments of node i. All individuals in a population have the same number of nodes. The following genetic operators are used in GRA.

Crossover operator affects two parent individuals. All the connections or contents of the selected nodes in two parents are swapped each other by crossover rate of Pc. Mutation operator affects one individual. The connections or contents of each node are changed randomly by mutation rate of Pm.

GRA can be evolved in order to optimize the fitness function defined by the strength Sij , in other words, the events and their relations can be evolved by using the strength Sij . The point of GRA is that all the connections between nodes do not have to be defined, but the connection itself could be evolved.

There are two kinds of GRA: GRA with directed branches and GRA with indirected branches.

A. GRA with directed branches  In GRA with directed branches, the event is represented by the node, while the relation between two events is represented by directed branches with their strength. Fig. 3 is an example of GRA with directed branches. Node i has strength Sij to node j and node j has strength Sji to node i. The strength between all nodes does not have to be defined.

Fig. 3: Genetic Relation Algorithm with directed branches.

B. GRA with indirected branches  In the GRA with indirected branches, the event is also rep- resented by the node, while the relation between two events is represented by indirected branches with their strength. Fig. 4 is an example of GRA with indirected branches. The relation between node i and node j has a strength of Sij = Sji in GRA with indirected branches.

Fig. 4: Genetic Relation Algorithm with indirected branches.



IV. GENETIC RELATION ALGORITHM AND ASSOCIATION RULES  A. Association rules and their properties  In this section, the definition and properties of association rules are briefly reviewed. The association rule mining is  3250 2009 IEEE Congress on Evolutionary Computation (CEC 2009)    stated as follows: [8] Let I = {A1, A2, . . . , Al} be a set of attributes, also called items, over the binary domain {0, 1}.

Let G be a set of transactions, where each transaction T is a set of attributes such that T ? I . Associated with each transaction is a unique identifier whose set is called TID.

A transaction T contains X , a set of some attributes in I , if X ? T . An association rule is an implication of the form of X ? Y , where X ? I , Y ? I , and X ? Y = ?. X is called antecedent and Y is called consequent of the rule.

In general, a set of attributes is called an itemset or pattern.

More concisely, an itemset is a non-empty subset of I .

Each itemset has an associated measure of statistical significance called support. If the fraction of transactions containing X in G equals t, then support(X) = t. The rule X ? Y has a measure of its strength called confidence defined as the ratio of support(X ? Y )/support(X). This measure indicates the relative frequency of the rule, that is, the frequency with which the consequent is fulfilled when the antecedent is also fulfilled .

A class association rule is defined to be an implication with a class being its consequent  B. GRA for association rules with non-fixed consequent  For association rules with non-fixed consequent, GRA with directed branches are used. Fig. 5 shows an example of GRA for association rules with non-fixed consequent. In Fig. 5, the antecedent and the consequent of each rule are represented as nodes in GRA. The confidence of each rule is used as the strength, for example. The genotype of the GRA in the example of Fig. 5 is described in Table I  Fig. 5: Genetic Relation Algorithm for association rules with non-fixed consequent.

TABLE I: Genotype of GRA for association rules with non- fixed consequent  NodeID NodeFunction C1 C2 S1 S2 1 A 2 3 0.9 0.3 2 BC 3 - 0.8 - 3 K 2 4 0.7 0.4 4 M 1 - 0.6 -  C. GRA for association rules with fixed consequent  Association rules with fixed consequent are mainly used for classification. GRA with indirected branches are used for association rules with fixed consequent. Fig. 6 shows an example of GRA for association rules with fixed consequent.

In Fig. 6, the antecedent of each rule is represented as the node in GRA. The distance between the nodes is used as the strength. The genotype of the GRA in the example of Fig. 6 is described in Table II  TABLE II: Genotype of GRA for association rules with fixed consequent  NodeID NodeFunction C1 C2 C3 S1 S2 S3 1 AB 2 3 4 1.5 1.8 2.5 2 ABC 1 3 4 1.5 2.6 3.2 3 B 1 2 4 1.8 2.6 2.7 4 SK 1 2 3 2.5 3.2 2.7  Fig. 6: Genetic Relation Algorithm for association rules with fixed consequent.

D. Distance between rules  The distance between the rules in the same class is defined in this sub-section in order to realize GRA with fixed consequent supposing we are dealing with the classification problems.

Two types of distances are presented: complete match and partial match.

1) Distance using complete match: The distance between rule i and rule j denoted by D(i, j) is defined as follows:  D(i, j) = support(i) + support(j)? 2[support(i, j)], (1) where,  support(i) is the support of rule i, support(j) is the support of rule j, and support(i, j) is the support of rule i and rule j.

The distance expresses the ratio of the number of records with the same class in the database, where the matching between rule i and the data and the matching between rule j and the data do not coincide.

2009 IEEE Congress on Evolutionary Computation (CEC 2009) 3251    As an example, consider Table III and the following rule i and rule j.

TABLE III: Example of record data  TID A B C D E F Class 1 1 1 0 1 1 0 c 2 1 1 1 1 1 1 c 3 1 0 0 0 1 1 c 4 0 0 1 1 0 1 c 5 1 1 0 0 1 1 c  rule i: ABE ? c rule j: CDF ? c The distance D(i, j) between rule i and rule j is calculated  as follows. The support of rule i is 3/5, that is, tuple 1, 2 and 5 match rule i. The support of rule j is 2/5, that is, tuple 2 and 4 match rule j. The support of both rules is 1/5, that is, tuple 2 matches rule i and rule j. Therefore the distance is calculated as:  D(i, j) = (3/5) + (2/5) ? 2(1/5) = 3/5 2) Distance using partial match: The distance between  rule i and rule j using partial match is realized considering the partial match between rules and data and it is defined as follows:  D(i, j) = ?  d?D|D(d, i) ? D(d, j)| |D| , (2)  (0 ? D(i, j) ? 1.0)  where, D(d, i) = 1 ? rdiri , rdi is the number of attributes in the antecedent of rule i which match data d, ri is the number of attributes in the antecedent of rules i and D is the set of data.

The definition of the partial match includes the definition of the complete match as a special case.

E. Fitness of GRA  The fitness function of each GRA individual is defined as follows:  Fitness = |R|  ?  i?R  |R(i)|  ?  j?R(i) D(i, j), (3)  where, D(i, j) is the distance between rule i and rule j described  in Section IV-D. R is the set of suffixes of rules in GRA and R(i) is the set of suffixes of rules whose distance is defined between node i in GRA.

The fitness function evaluates the GRA individuals so that the distances between rules are maximized. It is our interest to find class association rules far away each other as much as possible, because that means the rules are not similar.

Therefore, the fitness function eliminates the rules near each other, as they are redundant or irrelevant.

F. Genetic Operators  In order to find really important class association rules, the function of the nodes in GRA should be changed. It is possible to realize the above effectively by GRA genetic operations, because mutation and crossover will change the connections or contents of the nodes. Three kinds of genetic operators are used: crossover, mutation-1 (change the connection of nodes) and mutation-2 (change the function of nodes).

In each generation, all of the individuals in the population are ranked by their fitnesses and the best individual is preserved for the next generation. Then, tournament selection of individuals is carried out for reproduction for the next gen- eration. Finally, the individuals are generated by crossover and mutation. These operators are executed for the gene of the nodes of GRA.

This procedure is demonstrated using 240 individuals at each generation. 80 individuals are selected from the popula- tion by tournament selection and their genes are exchanged by crossover. Then, 80 individuals are also selected from the population and their genes are changed by mutation-1.

Finally, 79 individuals are also selected from the population and their genes are changed by mutation-2. Therefore, the 239 new individuals generated by crossover, mutation-1 and mutation-2 and one elite individual form the next population.

? Selection. Elite selection is used in order to preserve the best individual in the current generation for the next generation.

? Crossover: Uniform crossover is used. Two parent in- dividuals are selected by tournament selection twice for reproduction. Nodes are selected as the crossover nodes with the probability of Pc. Two parents exchange the gene of the corresponding crossover nodes. The new individuals generated are the new ones in the next population.

? Mutation-1: Mutation-1 operator affects one individual.

One parent individual is selected by tournament selec- tion for reproduction. The connection of the nodes is changed randomly by mutation rate of Pm1. The parent individual in mutation-1 reproduces a new offspring and it becomes the new one for the next generation.

? Mutation-2: Mutation-2 operator also affects one indi- vidual. One parent individual is selected by tournament selection for reproduction. This operator changes the functions of the nodes by mutation rate Pm2. New offspring is reproduced from the parent individual by mutation-2 and becomes the new one for the next generation.

G. Flowchart of GRA  Fig.7 shows the flowchart of GRA. The initialization of GRA is carried out using the class association rules generated by GNP and stored in the pool. That is, for the first GRA population, each individual is generated assigning the antecedent of a certain class association rule selected  3252 2009 IEEE Congress on Evolutionary Computation (CEC 2009)    randomly to one of the nodes of GRA randomly. It is ensured that all nodes within one individual are different.

The evaluation of the individuals is carried out according to their fitness values. Then, reproduction of the individuals is carried out using the selection and genetic operations in order to generate a population for the next generation. This process is repeated until the last generation.

Fig. 7: Flowchart of Genetic Relation Algorithm.

H. Classification using the rules obtained by GRA  In our proposed method, i.e, the classification by selecting a small number of really important class association rules using GRA, is evaluated in terms of classification accuracy.

Two classification methodologies are described, using complete match and partial match.

1) Classifier using complete match: This classification methodology is proposed in [1][2], and described as follows:  1) RZ : Calculate the set of suffixes of rules in class Z, (Z = 0, 1, 2 . . . K).

2) scoreZ(d): Compute the number of rules in class Z in the classifier whose antecedent matches data d comple- tely.

3) mZ(d) = 1 ? scoreZ(d)|RZ | : Predict in such a way that data d belong to the class having the lowest mZ(d).

2) Classifier using partial match: The classification is done by comparing the average distances from the test data to the rules of each class as shown in Fig. 8. This is an extension of the complete match method.

The classifier is described as follows:  1) RZ : Calculate the set of suffixes of rules in class Z, (Z = 0, 1, 2 . . . K).

2) mZ(d): Compute the average distance between data d  and the rules in class Z.

mZ(d) =  |RZ | ?  i?RZ DZ(d, i), (4)  where, DZ(d, i) is the distance between data d and rule i in class Z, which is calculated by the following:  DZ(d, i) = 1 ? rdi(Z) ri(Z)  , (5)  where, rdi(Z) is the number of attributes in the antecedent of rule i in class Z which match data d ri(Z) is the number of attributes in the antecedent of rule i in class Z.

3) Predict in such a way that data d belongs to the class having the lowest mZ(d). That is, data d belongs to the closest class.

Fig. 8: Classification of data d

V. EXPERIMENTAL RESULTS  Two datasets from UCI ML Repository [9] were taken to conduct the experiments. Lymphography and Vehicle datasets. Lymphography is a medical dataset that contains the information about primary tumor. It contains 18 attributes, 148 records and 4 classes. Vehicle dataset is an image dataset that contains the information about the features of the silhouette of different types of cars. The purpose is to classify a given silhouette as one of four types of vehicles. This database contains 846 records, 18 attributes and 4 classes.

The original datasets are discretized using a supervised discretization method and the WEKA software [10]. Accord- ing to this procedure:  1. Replace missing values with the most frequent values (or means) for nominal (or numeric) attributes, respec- tively  2. Discretize continuous attributes into nominal ones using  2009 IEEE Congress on Evolutionary Computation (CEC 2009) 3253    the Fayyad and Irani?s entropy based MDL method [11], and finally  3. Convert the nominal values into binary values.

Once the dataset is discretized, 10-fold cross validation is performed and the results are given as an average.

The training set and test set are generated randomly from the dataset. Using the training set, the conventional GNP based mining method [1][2] is applied to obtain a pool of a large number of class association rules for each class Z.

Table IV shows the parameters for the conventional GNP mining method.

TABLE IV: Parameters for Genetic Network Programming.

Parameter V alue  Number of GNP individuals 120 Number of generations 100  Number of Judgment nodes 95 Number of Processing nodes 10  ?2 min 6.63 supmin 0.01  Then, GRA is applied to reduce the number of association rules for each class using different reduction rates (ex. 1%, 5%, 10%, etc.). For example, the reduction rate of 5% means that only 5% of the total number of rules generated by GNP are selected by GRA. Table V shows the parameters for the evolution of GRA.

TABLE V: Parameters for Genetic Relation Algorithm.

Parameter V alue  Number of GRA individuals 240 Number of generations 100  Number of nodes in each individual variable Crossover probability 0.1 Mutation-1 probability 0.01 Mutation-2 probability 0.01  Finally, the classification accuracy is evaluated and com- pared with other methods using the test set and.

All algorithms were coded in Java language. Experiments were performed on a 600MHz Pentium PC with 512M main memory, running Microsoft Windows XP.

In this paper, the complete match and partial match are compared and evaluated in terms of the prediction accuracy.

Fig. 9 and Fig. 10 show the accuracy of the complete match compared with the accuracy of the partial match with different reduction rates for the Lymphography and Vehicle datasets, respectively.

For instance, the reduction rate of 10% means that only 10% of the total number of rules generated by GNP are selected by GRA.

It is shown from Fig. 9 and Fig. 10 that when the reduction rate is small, GRA is able to get comparable accuracy to the large set of rules, that is, 100% of the rules, especially in the partial match, furthermore, it is shown that the accuracy does not change drastically compared to the accuracy of the large set of rules.

Fig. 9: Accuracy of dataset Lymphography  Fig. 10: Accuracy of dataset Vehicle  Table VI shows the accuracy comparison among the large set of rules (100 %), the reduced set of rules by GRA and several conventional methods. GRA in Table VI means the average prediction accuracy calculated using the rules reduced to 1%, 5%, 10% and 20% from all the rules obtained by GNP when complete match and partial match are used.

The results for C4.5.[12] Ripper[13], CBA[14], CMAR[15] and CPAR are taken from the paper of [16]. The first column of Table VI shows the names of the datasets, the second and third columns show the number of attributes before and after the discretization process, respectively. The fourth column shows the number of records in the datasets.

The rest of the columns shows the accuracy comparisons among several methods. The accuracy of GNP in seventh and eighth columns of Table VI is obtained considering the complete large set of association rules stored in the pool and using the classifier of the complete match and partial match, respectively. The other methods use a relatively small number of rules. The results show that the proposed method using GRA outperforms the conventional ones and is comparable with the GNP based mining method in terms of accuracy.

3254 2009 IEEE Congress on Evolutionary Computation (CEC 2009)    TABLE VI: Comparison of classification accuracy with other methods  Dataset Attr.

before discret  Attr.

after discret  No.

Recs  GRA GNP C4.5 CBA CMAR Ripper CPAR  CM PM CM PM  Lymph 19 55 148 85.60% 84.57% 85.76% 83.68% 73.50% 77.80% 83.10% 79.00% 82.30% Vehicle 19 109 846 70.02% 75.14% 72.41% 75.65% 72.60% 68.70% 68.80% 62.70% 69.50%  GRA: Use the reduced set of rules GNP: Use the large set of rules PM: Partial Match CM: Complete Match

VI. CONCLUSIONS AND FUTURE WORK  This paper proposes a novel approach to reduce a large number of association rules using an evolutionary computa- tion method named GRA. The main features of our proposed method are as follows:  ? GRA could be usefully applied to reduce a large set of class association rules and to improve the classification accuracy.

? Our method could be integrated to other conventional association rule mining methods, since the input could be any large set of rules.

? The classification accuracy is improved especially when the partial match is used in the classifier.

For future work, we plan to extend this method to eliminate redundant rules in general association rules, that is, the association rules with non-fixed consequent (multiple items), using the GRA with directed branches.

