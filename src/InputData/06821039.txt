Differentially Private Two-Dimension Sparse Data  Publication under Consistency

Abstract?Recently, differential privacy data publication has  become an extremely important research topic in data security field. However, most of the differential privacy algorithms do not take sparse data publishing into consideration. The aim of this study is to present an effective differential privacy algorithm for two-dimensional sparse data publication, so as to boost the accuracy of range queries of the released data. The proposed approach in this paper includes two steps: 1) getting the sampling set of the original two-dimensional sparse dataset by adopting filter sampling algorithm; 2) building an incomplete quadtree based on the sampling dataset and adjusting the tree nodes? noise values under consistency. Experimental analysis is designed by comparing the proposed algorithm and the traditional algorithms on the accuracy of range queries in the released data.

Experimental results show that the proposed algorithm is effective and feasible.

Keywords?differential privacy; sparse data publication; filter sampling; consistency

I. INTRODUCTION With the rapid development of information technology,  various organizations can gather vast amount of personal information easily, such as hospitals, online social networks, etc. Analysis on such data may find valuable information, while endanger the privacy of the individuals who contribute to the data. Privacy preserving becomes an increasingly serious issue. The purpose of  privacy protection research is to provide adequate privacy guarantees and enhance the utility of the released data.

Traditionally, there are three famous privacy preserving models, including k-anonymity[1], l-diversity[2] and t- closeness[3]. Though these models can preserve privacy in some situations, they are vulnerable to suffer attacks by the adversary who has specific background knowledge[4]. To overcome these shortages, Dwork proposed a new privacy model called  Differential Privacy[5], which can protect against the adversary with arbitrary auxiliary information. Differential privacy has emerged as a strong and widely accepted privacy model. The privacy safety of differential privacy is guaranteed by injecting a small random noise into query answer.

In general, the data owner could offer only a limited magnitude of quite accurate answers with differential privacy model. Every query needs a low privacy budget, when the numbers of queries grow, the privacy budget is exhausted. The  non-interactive mechanism publishes a ?sanitized? version of the collected data, so it can solve the problem of query numbers.

In this paper, we study two-dimensional sparse datasets of non-interactive mechanism of differential privacy. Such as the geo-spatial data, this type of data is very sparse and important.

This paper aims to balance the requirements of utility and achieve sufficient privacy guarantees. First, we adopt a filter algorithm to get a sampling dataset, in order to compress the dataset. Second, we build an incomplete quadtree over the sampling dataset. It is no longer to divide the area that if no node in the sampling dataset. After injecting noise data to the tree nodes, we exploit unbiased estimation algorithm to adjust the inconsistency of parent and children nodes.



II. RELATED WORK Differential privacy is achieved by adding noise to the real  results and returned to the user, the noise is based on a random variable with a zero mean, like Laplace mechanisms[6], Geometric mechanism[7], etc.

In this section, we present a brief summary of the data publication of differential privacy. Dwork[5] raised the basic method by adding a random noise data to every data, while with wide range of query will cause the noise accumulation.

Xiao[8] proposed an algorithm using wavelet transforms called Privelet. Privelet first conducts a wavelet tree on the original data and then adds polylogarithmic noise to the tree nodes.

Xu[9] generated two methods, NoiseFirst and StructureFirst.

Ace[10] developed two algorithms based on Fourier transform, and the other two methods similar to[9]. Hay[11] pointed out consistency constraints, as a post-processing technique, is able to boost the accuracy of histogram queries. Xiao[12] first generated a synthetic histogram by adding noise to each cell histogram, and then build a kd-tree based space partitioning strategy for releasing a v-optimal histogram. Graham[13] studied spatial data, and proposed structure a quadtree or a kd- tree over the input data, after adding noise to the tree, return the result by arithmetic method.

Sparse data is one of the real data. It has characteristic of sparse, so this type of data needs more strict privacy protection and higher requirements of utility. In this case, Graham[14] proposed a framework to summary the sparse data. This   DOI 10.1109/CLOUDCOM-ASIA.2013.55    DOI 10.1109/CLOUDCOM-ASIA.2013.55     framework reduces the output size without computing the huge contingency table.

From these above works, we studied that partition and summary both can compress the size of the data, ultimately achieve the purpose of reducing noise added. In our work, we combine these two methods to achieve data protection and enhance practicality.



III. PRELIMINARIES  A. Differential Privacy Definition 1 ( ? -Differential Privacy[5-6]). A randomized  algorithm   satisfied  ? -Differential Privacy, for all datasets 1D and 2D differing only in one tuple( denoted 1 2| | 1D D? = ),  and any subset of outputs ( )H Range K? :  1 2Pr[ ( ) ] exp( ) Pr[ ( ) ]K D H K D H?= ? ? = Differential privacy guarantees that no one tuple can  significantly affect the result. The noise added is a function of the privacy parameter-?  , and a property of the queries called sensitivity.

Definition 2 (sensitivity[6]). Let F be a set of functions, such function f F? , ( )f D is a query over dataset D , the output of ( )f D is a real number. The sensitivity of f ,denoted ( )S F ,is the maximum change in f when any  single tuple  of D changes:  1 2 1 2 1 2, :| | 1  ( ) max | ( ) ( ) | D D D D  S F f D f D ? =  = ?  An ? -Differential Privacy mechanism for answering query is adding a random noise, the noise is relate to ? and  ( )S F .Usually, the following mechanisms have be used to achieve differential privacy.

1) Laplace mechanisms[6]:The noise is drawn from the Laplace distribution with parameter( ( ) /S F? ?= ), the Laplace distribution function:   1Pr( ) exp( | | / )  x x ?  ? = ?  2)  Geometric mechanism[7]:When ( )f D is integer- valued, the noise can be drawn from the geometric distribution:  | | 1Pr[ ]  xX x ? ? ?  ?= = +    where / ( )S Fe ?? ?= , x?? .? - Geometric mechanism is the discrete of Laplace mechanism.

B. Problem Defined  A table has attributes 1,... kA A . It can be represented by a one-dimensional contingency table, denoted M .Let n be the number of non-zero entries in M . The size of the contingency  table is computed over attributes, then | |i im A= ? .In Fig. 1, 3n = and 3 2 6m = ? = . We define the density of M to  be /n m? = . Hence, applying differential privacy will generates an output which is about 1 / ? times lager than the data size. When the ? is very small, this makes time and space consuming.

(a)Original table                  (b) Contingency table with noise column  Fig. 1.  Table M? is the noisy version of M. The density of  is / 3 / 6n m? = = .

Definition 3 (Consistency constraints[11]). For a set of queries as { }1 2, ... kq q q , 2k ? . ( )Area q means the query area of q , then ( ) ( )i jArea q Area q ?=? ,1 i j k? ? ? . Another  query Q be  ( ) ( ) k  i i  Area Q Area q =  = ? , so  k  i i  Q q =  =? . After  inject noise to the results, lead to ~ ~   k  i i  Q q =  ?? . Adjust the values  make  k  i i  Q q ? ?  =  =? fits consistency condition.

C. Query Model We study 2-dimensional data, and propose to build an  incomplete quadtree depend on the sampling dataset. Fig. 2(a)  shows the quadtree after consistency adjust,  iN ?  represents  adjusted noise. So 12 6 7 8 94 2 2N N N N N ? ? ? ? ?  + = + + + + + . Give a query Q , shows by Fig. 2(b).The original answer is 4. Using  the incomplete quadtree, the query overlaps 124 N ?  +  and 10N ?  .

So estimation answer of Q ?  is 12 104 / 2N N ? ?  + + .

(a) Incomplete quadtree  tid Educ Status  1 HS S  2 HS S  3 BS M  4 PhD M  cid (Educ,Status) cnt ncnt  1 (HS,S) 2 4  2 (HS,M) 0 2  3 (BS,S) 0 -1  4 (BS,M) 1 -2  5 (PhD,S) 0 1  6 (PhD,M) 1 3       (b) Query estimation  Fig. 2.  Example: incomplete quadtree and query estimation

IV. THE F-BCQT ALGORITHM In this section, we will give the description of the F-BCQT  Algorithm. The algorithm consists of two parts. First, through Filter Algorithm to get the sampling dataset. Second, build the incomplete quadtree depend on the sampling dataset. If without the first step, the incomplete quadtree will expose all true location of the original dataset.

A. Filter Algorithm Contingency table contains a large portion of zero entries.

If n is the number of non-zero in M and m is the domain size, then n m? . M  can be stored as a list of non-zero entries. For example, in Fig.1(b),  M  consists of rows 1, 4 and 6. For 2-dimension data, we use ( , )M i j  to show the position of entry, i represents the row number, j represents the column number.

Let be the cut-off value( 1? ? ). If an item for 2-dimension data of ( , )i j has value ?? ?+ |)(),(| GeojiM ( ( )Geo ? denote Geometric noise), then we include ( , )M i j to 'M , else we drop it. We call this a two-side filter.

After a two-side filter step, we choose some random zero entries to 'M , in order to perturb the M . We draw the number of entries  k  that pass the filter from the distribution  ( , )Bin m n p?? , then the k  entries join to 'M .We get the final sampling dataset 'M .

Algorithm 1. Filter Algorithm Input: M ( original dataset) Output: 'M (sampling dataset) 1 For every non-zero entry ( , )M i j , add geometric noise  with parameter ? . If ?? ?+ |)(),(| GeojiM ,add ( , )M i j to 'M  2 For zero entries, compute a numeric k from the binomial  distribution ( , )Bin m n p?? , where  p ?  ? ?  ?+ ?  3 Random select k  locations ( , )i j from M , such ( , ) 0M i j = . Add the k entries to 'M .

PROOF. We focus on the distribution of entries which are zero in M .If they have added ( )Geo ?  noise, the probability that it passes the filter is:  Pr[| ( , ) ( ) | ] Pr[| ( ) | ]M i j Geo Geo? ? ? ?+ ? = ?  | |  | | 0  1 12 1 1  x x  x x  ?  ?  ? ?? ? ? ? ?? ?  ? ?= = + +? ?  1 1 22 1 1 1  p ?  ? ?  ? ?? ? ? ?  ?= = + ? +  ?  B. F-BCQT Algorithm The F-BCQT algorithm compresses the data, and then  adjust the noise between tree nodes, to meet the definition 3.

We call algorithm 3 to adjust inconsistencies between father and son nodes. Let x be a father node, the son of x  represent by ( )son x .

Algorithm 2. F-BCQT Algorithm(Filter-Build Consistency Quadtree)  Input: M , 'M ,? ,? Output: Consistency Quadtree 1 Make the 2-dimension sparse data satisfy 2 2d d? ,  d +?? . The rest default 0.

2 Recursive decomposition of the region until the area is  no point in 'M , every tree node is real value.

3 Every quadtree node add a ( ( ) / )Lap S F ?  noise.

4 Bottom-up to call Algorithm 3 (BLUE) to adjust the  value of the tree node.

5 ( )xMax ?? > , return to step 4.

We use an algorithm 3 to adjust the value of nodes.

~ ( )h x  denotes the has add a ( )Lap ?  noise after step 3 of F-BCQT.

Adjusted value expressed by ( )h x ?  . ( )son x  means the son number of  x . The algorithm is described as following.

Algorithm 3. BLUE(Best Linear Unbiased Estimator)  Input: x (the node of the tree), ~ ( )h x ,  ~  ( ) ( )  i son root h i  ?   Output: ( )h x ?  , ( ) ( )  i son root h i ?  ?   1 x is a leaf node, return ~ ( )h x .

2 ( )k son x=   ~ ~  ( )  ( ) ( )  i son x  x  h x h i  k ?  ? ? =  +  ?      ~  ( ) ( ) xh x h x ?  = ? ?  5 For each ( )i son x? , ~  ( ) ( ) xh i h i ?  = + ?  PROOF. BLUE(Best Linear Unbiased Estimator)could adjust the value of minimum variance. The node root  has sons. Need to meet the least-square formula as follows.

2 2~ ~   ( )  min ( ) ( )  . ( ) ( ) i son root  h root h root h h  s t h root h i  ? ?  ? ?  ?  ? ?? + ?? ? ? ?  = ? (1)  The above constraints into least squares formula can get the following formula.

2 2~ ~  ( ) ( ) ( ) ( ) ( ) ( ) ( )  i son root i son root f h h i h root h i h i  ? ? ?  ? ?  ? ?? ? ? ?= ? + ?? ?? ? ? ?? ? ? ?? ?? ? ? ?  Get the partial derivatives by ( )h i ?  , then equals to 0.

~ ~  ( )  2( ( ) ( )) 2( ( ) ( )) 0 ( ) x son root f h x h root h i h i  h i  ? ?  ? ?  ? = ? + ? = ?  ?  ~ ~  ( ) ( ) ( ) ( ) ( )  i son root h i h i h root h i ? ?  ?  ? = ? ?  ? all of the partial derivatives of  ( )i son x?  .

~ ~  ( ) ( ) ( )  ~ ~  ( )  ( )  ~ ~  ~ ( )  ( ) ( ) ( ) ( )  ( ) ( ) ( ) ( )  ( 1)  ( ) ( ) ( )  ( 1)  i son root i son root i son root  i son root  i son root  i son root  h i h i k h root k h i  k h root h i h root h i  k  h root h i h root  k  ? ?  ? ? ?  ? ? ?  ?  ?  ? = ?  + = =  +  ? = ?  +  ? ? ?  ? ?  ?   Then,  ~ ~  ( )  ( ) ( )  i son root  h root h i  k ?  ? ? =  +  ?

V. EXPERIMENTS This section experimentally compares the effectiveness of  the proposed solution F-BCQT satisfies consistency constraints with Boost[11] and the adjust algorithm BLUE. These three methods all base on four partition. All methods are implemented in C++ and tested on an AMD Athlon(tm)II X4 645 Processor ,3.10Hz CPU with 4GB RAM running Linux.

We extract 50 fixed size of range-query to average the value from each algorithm runs, every algorithm is executed 50 times. It means the fixed size of range-query have made 2500 times average operation.

For a set of queries 1 2{ , ,..., }mQ q q q= , iq  denotes real  result of query , iq ?  denotes the adjusted result . We use the following error equation to compare the data accuracy.

( ) m  i i i  q q error  m  ?  =  ? = ?  Two datasets(both real dataset and synthetic) with different characteristics are used in our experiment. The population distribution of USA is a real dataset that available at http://www.census.gov/. The other data generated by the random function, its discreteness has more representatives.

Table 1 shows the dataset statistic information.

TABLE I.  DATASET  STATISTIC  Dataset Table More Detail  Size of 2-dimension /n m? = ? USA 1024*2048 0.041 1&0.1  Synthetic 1024*1024 0.051 1&0.1  We accomplish the experiments with above two sets. The experiments use the privacy parameter ?  with value of 1 and 0.1. We set some different size of queries. In the below Figures, range size with one-dimension fixed, the other dimension gradually increase.

Fig. 3. The population distribution of USA with 1? =  For the sake of observing, we draw the figures by the X axis representing the size of the rectangle query ( *i x ), we have choose two value of i (200 and 800), x values as shown in figures. Y axis representing log10 (error).We can learn from Fig.3 that Boost method is not suitable for sparse data. The BLUE algorithm improves the accuracy of the data greatly.

While based on the context of sparse data, F-BCQT algorithm works better than only used BLUE algorithm.  Besides, compare Fig.3(a) with Fig.3(b), the error of the three algorithms all get increase when the range size of query get larger. Therefore, larger  range lead to more noise accumulated.

Fig. 4. The population distribution of USA with 0.1? =  Fig.4 shows the error of privacy parameter 0.1? = . The error is larger than Fig.3. Differential privacy is achieved by adding noise.  The added noise affect the utility of publishing data. So the ? more smaller,  the  greater the noise. The experimental results proved the theory.

Fig. 5. The synthetic dataset with 1? =    Fig. 6. The synthetic dataset with 0.1? =  The result of synthetic dataset is similar  to USA population.

Although the size of synthetic data is only half of the real data, the error is not half. Construction of incomplete quadtree depends on data. Discrete data will lead quadtree node add more noise. The synthetic data is more discrete, The results are also verified this.

In summary, our experiments demonstrate that F-BCQT algorithm has a better data utility on sparse data than Boost-4 and BLUE-4, which is consistent as our theory.



VI. CONCLUSIONS Differential privacy is a robust privacy protection  mechanism that can against the attack of background knowledge. We have propose a general framework of a two- step process the 2-dimension sparse data. First, by a filter algorithm to get the sample dataset, the purpose is to disrupt the original location of non-zero data. Second, we construct the incomplete quadtree depend on the sampling dataset. The data has compressed after this step. Then, we use unbiased estimation algorithm to adjust the tree nodes to satisfy the consistency constraints. Verified by experiment, we have improve the utility of sparse data. In order to reduce the noise added to sparse data, how to compress the sparse data is the future work.

