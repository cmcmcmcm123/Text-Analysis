Weaknesses Of DAGs For Imprecise General  Causal Representations

Abstract? Causal reasoning occupies a central position in hu- man reasoning. In order to algorithmically consider causal relations, the relations must be placed into a representation that supports manipulation. The most widespread causal rep- resentation is directed acyclic graphs (DAGs). However, DAGs are severely limited in what portion of the every day world they can represent. Both possible causal relationships and shifts in grain size are overly limited. Commonsense reasoning recognizes causal granularization. Sometimes, the details un- derlying an event can be known to a fine level of detail, some- times not; causal representations must accommodate shifts in grain size. Every day reasoning approaches are used that do not require complete knowledge. An algorithmic way of han- dling and representing causal imprecision is needed.

Keywords-causality; representation; common sense reason- ing; DAGs; complexes; imprecision

I. INTRODUCTION Causal reasoning occupies a central position in human  reasoning. It has a core position in human decision-making.

For thousands of years, philosophers, mathematicians, computer scientists, cognitive scientists, psychologists, economists, and others have formally explored causation.

Whether causality can be precisely defined or can be recognized at all has long been the subject of speculation. At the same time, people operate on the commonsense belief that causality exists.

Of particular interest to this paper are areas where the analysis is observational (non-experimental). The analytic world is not subject to experimentation. Data mining is of interest; one product of data mining is association rules.

Customers who buy strawberries  also tend to buy whipped cream with {confidence = 0.8}  in {support = 0.15} Customers who  buy beer and sausage also tend to buy hamburger  with {confidence = 0.7} in {support = 0.2}  Figure 1. Association rules.

At first glance, association rules seem to imply a causal or cause-effect relationship. That is:  A customer?s purchase of both sausage and beer causes the customer to also buy hamburger.

But, all that is discovered is a degree of joint occurrence.

The nature of the relationship is not understood. It is not known whether an item or set of items causes another item or set of items; or the converse, or some other phenomenon causes them to occur together.

Purely accidental relationships do not have the same decision value, as do causal relationships. For example,  IF it is true that buying strawberries somehow causes someone to buy whipped cream, ? THEN: A merchant might profitably put strawberries  on sale ? AND at the same time: Increase the price of whipped  cream to compensate for strawberries sale price On the other hand, knowing that  Bread and milk are often purchased together.

may not be useful information as the purchase of one does not normally influence the purchase of the other; both may often be independently purchased on the same store visit.

Consequently, when typically developed, association rules do not necessarily describe causality. The confidence measure is simply an estimate of conditional probability.

Support indicates how often the joint occurrence happens (the joint probability over the entire data set). The joint occurrence count is symmetric; that is, it does not matter what we count first.  The strength of any causal dependency may be very different from that of a paired association value.  In all cases  confidence ? causal dependence All that can be said is that associations describe the strength of joint co-occurrences.

Association rules can be used as an aid in retail mar- keting. However, na?ve use of association rules may lead to errors. Errors might occur; either if causality is recognized where there is no causality; or if the direction of the causal relationship is wrong [1] [2]. For example, if  A study of our customers shows that 94% are sick.

? Is it the following rule?

Our customers are sick, so they buy from us.

? Or, is it the following complementary rule?

If people use our products, they are likely to become sick.

From a decision making view, it is not enough to know that People both buy our products and are sick.

what is needed is knowledge of what causes what; if at all.

People do things in the world by exploiting commonsense perceptions of cause and effect. Manipulating perceptions has been explored [3]. The interest here is how perceptions affect commonsense causal reasoning, granu- larity, and precision.

To precisely reason about causality, complete knowledge of all of the relevant events and circumstances would be needed. In commonsense, every day reasoning, approaches are used that do not require complete knowledge. Often, approaches follow a satisficing [4] paradigm.

Commonsense understanding of the world tells us that we have to deal with imprecision, uncertainty and imperfect knowledge. A way of handling imprecision is needed to computationally handle causality. A difficulty is striking a good balance between precise formalism and commonsense imprecise reality.



II. COMPLEXES In many ways, causality is granular. This is true for  commonsense reasoning as well as for more formal approaches. Commonsense perception of causality is often large grained while the underlying causal structures may be more precisely described in a more fine-grained manner. A comprehensive causal representation structure should be able to accommodate changes in grain size.

In applying commonsense causal reasoning, it may be recognized that a complex collection of causal elements can result in a particular effect, even if the precise elements of the complex are unknown. It may not be known what events are in the complex; or, what constraints and laws the com- plex is subject to. Sometimes, the details underlying an event are known to a fine level of detail, sometimes not.

Events are rarely known to the finest possible grain size.

When events happen, there are usually other related events. The entire collection of events can be called a com- plex. A ?mechanism? [5] or a ?causal complex? [6] [7] is a collection of events whose occurrence or non-occurrence results in a consequent event happening.

Each complex, taken as a whole, can be considered to be a granule if the grain size is increased. Larger complexes can be decomposed into smaller complexes; going from large grained to small grained. For example, when describ- ing starting an automobile, A large-grained to small-grained, nested causal view could start with  When an automobile?s ignition switch is turned on, this causes the engine to start.

But, it would not happen if a large system of other nested conditions were not in place.

There has to be available fuel. The battery has to be good. The switch has to be connected to the battery so electricity can flow through it. The wiring has to connect the switch to the starter and ignition system (spark plugs, etc.). The engine has to be in good working or- der; and so forth.

Turning the ignition switch on is one action in a complex of conditions required to start the engine. The largest grained view is: turning on the switch is the sole causal element; the complex of other elements represents the finer grains. These elements in turn could be broken down into still finer grains; for example, ?available fuel? could be broken down into:  fuel in tank, working fuel pump, intact fuel lines, etc.

Sometimes, it is enough to know what happens at a large grained level; at other times it is necessary to know the fined grained result. For example, if  Bill believes that turning the ignition key of his automo- bile causes the automobile to start.

It is enough if Bill engages an automobile mechanic when his automo- bile does not start when he turns the key on.

As the automobile mechanic knows a finer grained view of an automobile?s causal complex than does Robin.

Nested granularity may be applied to causal complexes.

A complex may be several larger grained elements. In turn, each of the larger grained elements may be a complex of more fine-grained elements. In turn, these elements may be made up still finer grained elements. In general, people are more successful in applying commonsense reasoning to a few large grain sized events than the many fine-grained elements that might make up a complex.



III. PRECISELY DEFINING CAUSAL RELATIONSHIPS Coming to a precise description of what is meant by cau-  sality is difficult. There are multiple and sometimes con- flicting definitions.  Zadeh [8] suggested that a precise, for- mal definition may not be possible. To this, Pearl [9] sug- gested: ?For me, the adequacy of a definition lies not in abstract argumentation but in whether the definition leads to useful ways of solving concrete problems.?  Regardless, we do have a commonsense belief that there are causal relation- ships. Satisfactorily and explicitly specifying them may sometimes be difficult. This paper is not dependent on precise notation; it approaches the issues from a common- sense view and occasionally comments on more formal notations.

A common, simplistic conception [10] is that causality depends on one-way, time ordering. In contrast, Simon [11] [12] provides an analysis of causality that does not rely on time order. For a more extensive definition of various aspects of causality definition, see Mazlack [13].

Perhaps, complete knowledge of all possible situational factors might lead to a crisp description of whether an effect will occur. However, it is unlikely that the identity all possi- ble elements can or may come to be known. It is also un- likely that it may be possible to fully know the certainty all of the elements involved. Consequently, the extent or actu- ality of missing elements may not be known. Additionally, some well described physics as well as neuro-biological events appear to be truly random [14]; and some mathemati- cal descriptions randomly uncertain. Consequently, there is no way of avoiding causal imprecision.

Friedman [15] argues that any cause that we isolate is never the whole cause and that every direct cause itself has its own direct causes, so that networks of causation spread    synchronically across the economy and diachronically back into the mists of time. If this is true, granules must neces- sarily be imprecise as separation through truncation from a network would be implicitly required by any representation.

A. Positive Causation Commonsense understanding of causation focuses on  positive causation. Causal relationships exist in the com- monsense world; for example,  When a glass is pushed off a table and breaks on the floor  it might be said that Being pushed from the table caused the glass to break.

Although, Being pushed from a table is not a certain cause of breakage; sometimes the glass bounces and no break- age occurs; or, someone catches the glass before it hits the floor.

Counterfactually and more weakly, usually Not falling to the floor prevents breakage.

A counter factual statement is weaker as other factors can come into play; for example, sometimes  A glass breaks when an errant object hits it, even though it does not fall from the table.

Positive causal relationships can be described as: if ? then ? (or, ? ? ?). For example:  When an automobile driver fails to stop at a red light and there is an accident it can be said that the failure to stop was the accident?s cause.

However, negating the causal factor does not mean that the effect does not happen, sometimes effects can be overdeter- mined. For example:  An automobile that did not fail to stop at a red light can still be involved in an accident; another car can still hit it for a number of reasons, such as the other car?s brakes failing.

B. Negation Simple negation does not work; both because an effect  can be overdetermined and because negative statement is weaker than positive statements as the negative statements can become overextended. It cannot be said that ?? ? ??, for example:  Failing to stop at a red light is not a certain cause of no accident occurring; sometimes no accident at all occurs.

Instead of being concerned with all of the fined grained detail, a better approach may be to use larger grains to sof- ten the need for preciseness.

Negation or counterfactuals in causal reasoning has a place; although it may result in reasoning errors. One reason is that effects can be overdetermined; that is: more than one item can cause an effect. If so, eliminating one cause does not necessarily eliminate the effect. For example, the rule:  If a person drinks wine, they may become inebriated.

cannot be simply negated to  If a person does not drink wine, they will not become inebriated.

In this case: A person may also drink beer or whiskey to excess and become inebriated.

Figure 2. Overdetermined effect (inebriation)  Events that do not happen can similarly be overdetermined.

From a commonsense reasoning view, it is more likely that things do not happen than they do. For example, Ortiz [16] states that it is not true that  Closing the barn door caused the horse not to escape.

because the horse might not have attempted to escape even if the door was open. Therefore, a false counterfactual is:  If he had not closed the barn door, the horse would have escaped.

Similarly, for example, the rule If a person smokes, they will get cancer.

cannot be simply negated to If a person does not smoke, they will not get cancer.

Again, effects can be overdetermined. In this case, People who do not smoke may still get cancer from other causes.

Negative causal relationships are less sure; but often stated; for example, it is often said that:  Not walking under a ladder prevents bad luck.

Or, usually (but not always),  Stopping for a red light avoids an accident.

Other ideas that are sometimes involved in causal rea-  soning are causal uncorrelatedness [17] where if two vari- ables have no common cause they are causally uncorrelated.

Similarly, Dawid [18] speaks in terms of unresponsiveness and insensitivity. If ? is unresponsive to ? if whatever the value of ? might be set to, the value of ? will be unchanged.

In parallel, if ? is insensitive to ? if whatever the value ? may be set, the uncertainty about ? will be unaffected.

Some describe events in terms of enablement and use counterfactual implication whose negation is implicit; for example [16]:  Not picking up the ticket enabled him to miss the train.

Along the same vein, Shoham [19] [20] distinguishes be-  tween causing, enabling, and preventing. The enabling fac- tor is often considered to be a causal factor. Shoham distin- guished between background (enabling) conditions and foreground conditions. The background (enabling) condi- tions are inferred by default. For example [20]:  ?If information is present that the key was turned and nothing is mentioned about the stated about the state of the battery, then it is inferred that the motor will start, because the battery is assumed, by default to be alive.?  Given this distinction, causing is taken to refer to the fore- ground conditions where enabling and preventing refer to the background conditions (in this example, turning the key causes the motor to start, the live battery enables it, the dead battery prevents it).? C. Inherently Uncertain Recognition    Recognizing many things with absolute certainty is problematic. As this is the case, our causal understanding is based on a foundation of inherent uncertainty and incom- pleteness. Consequently, causal reasoning models must accommodate inherent ambiguity. For a more detailed dis- cussion of inherently uncertain recognition, see [21].



IV. CAUSALITY RECOGNITION & REPRESENTATION Various causality descriptions and discovery tools have  been suggested. It may eventually turn out that different subject domains may need different methodologies.

Hobbs [6] uses first order logic to describe causal com- plexes. Pearl [22] develops probabilistic causal networks of directed graphs (DAGs). The causal complexes explicitly considered by Hobbs and Pearl have a required structure that may be overly restrictive for commonsense causal un- derstanding, namely: ? If all of the events in the causal complex appropriately  happen, then the effect will occur ? There is nothing in the causal complex that is irrelevant to the effect  These requirements are probably too precise and extensive to be realized in a commonsense world. Sometimes, only some of the events need to happen. For example,  Someone may be able to save more money: ? If their taxes are lowered or ? If they earn more money.

Either even may lead to greater savings. However, Neither may result in increased savings if they also have to pay a large divorce settlement.

So, if all of the events happen, the effect may happen. If some of the events happen, the effect may happen. In the commonsense world, we rarely know whether all of the events are in a complex are necessary. For example,  A man may want to attract the attention of a woman. He may do a large number of things (e.g., hair, clothes, learn to dance, etc.). If he does attract the woman, he may never know which things were relevant and which were not

V. DIRECTED GRAPHS AND CAUSALITY Different aspects of causality have been examined. The  idea of ?positive? causation (? ? ?) is at the core of com- monsense causal reasoning. Often a positive causal relation- ship is represented as a network of nodes and branches [21].

!"   Figure 3. Diagram indicating that a is causally dependent on b.

Various graph based Bayesian based methods have been suggested to describe causality. Probably the best known is the class of methods based on Directed Acyclic Graphs (DAGs). The most fully developed approach is Pearl [22].

Silverstein [23] [24] followed a similar approach.

Pearl [25] and Spirtes [26] claim that it is possible to in- fer causal relationships between two variables from associa- tions found in observational (nonexperimental) data without substantial domain knowledge. Spirtes claims that directed acyclic graphs could be used if (a) the sample size is large and (b) the distribution of random values is faithful to the  causal graph. Robins [27] argues that their argument is incorrect. Lastly, Scheines [28] claims that only in some situations will it be possible to determine causality. Their discussion is tangential to the focus of this paper; going deeply into their discussion is outside this paper?s scope.

This paper focuses on the inadequacies of DAGs.

From the commonsense causal reasoning view, the vari- ous directed graph methods have similar liabilities, specifi- cally: A. Liability: Cyclic needs that cannot be represented in a  DAG.

Causal relationships are not cyclic in a DAG, either directly or indirectly (through another attribute).

This is at variance with our commonsense understanding of the world. Within cyclic dependencies, there are variants.

Liability: Representing cycles with time lag: feedback There are many commonsense examples where cycles are needed.

Figure 4. Positive feedback cycle: Robin tells Kim that I love you. Then,  Kim tells Robin I love you. Then, Robin tells Robin I love you more than before. Then, Kim ? and so forth and so on. The cy- clic reinforcement could be substantial.

In some cases, some cycles can be reasonably collapsed, some cannot be. In the following example, perhaps the right hand cycle can be collapsed without a loss of significant meaning. The problem with collapsing a feedback cycle is the loss of knowledge that a process is going on; also, iden- tifying stable values may be difficult.

Figure 5. Cyclic relationship that can be collapsed if process knowledge  loss is acceptable.

Figure 6. Cyclic relationship that cannot be collapsed  Liability: Representing: concurrent cycles. A form of a cycle is concurrent joint mutual dependency with no time lag. Mutual dependencies are possible; i.e., ? ? ? as well as    ? ? ?. It seems to be possible that they do so with different strengths with equal strengths being a special case. The dependencies can be described as shown in the following figure where Si,j represents the strength of the causal de- pendency from i to j .

!

!," S  S ",!

"    Figure 7. Cyclic relationship: Mutual dependency.

There are two variations: differing causal strengths for the same activity; and, different causal strengths for symmetric activities occurring at different times.

Different causal strengths for the same activity, simultane- ously occurring  Some argue that causality should be completely asym- metric and if it appears that items have mutual influences it is because there is another cause that causes both. A prob- lem with this is that it can lead to eventual regression to a first cause. Whether this is true or not, it is not useful for commonsense representation. In contrast, Simon [5] and Shoham [20] identify cases where causality is simultaneous.

It is also our commonsense experience. For example, in the preceding figure, ? could be short men and ? could be tall women. If S?,? meant the strength of desire for a social meeting that was caused in short men by the sight of tall women, it might be that S?,? > S?,? .

Different causal strengths for symmetric activities, occur- ring at different sequential times  It would seem that if there were causal relationships in market basket data, there would often be imbalanced de- pendencies. For example, if  A customer first buys strawberries, there may be a rea- sonably good chance that they will then buy whipped cream.

Conversely, if They first buys whipped cream, the subsequent pur- chase of strawberries may be less likely.

B. Liability: Markov Stationary Condition holds: Probabili- ties are time independent This does not correspond to our commonsense world under- standing. If one event is dependent on two other events, if one causing event happens much earlier (or later) than the other causing event, there may well be a different result.

Figure 8. Case where differing times in causal events affects probability of  causal result.

C. Liability: The Markov Condition holds: Memoryless States  The Markov Condition is defined as: Let A be a node in a causal Bayesian network, and let B be any node that is not a descendant of A in the network. Then the Markov (Markoff) condition holds if A and B are independent, conditioned on the parents of A. The intuition of this condition is: If A and B are dependent, then B must either be (a possibly indirect) cause of A or (possibly indirectly) caused by A. In the sec- ond case, B is a descendant of A, while in the first B is an ancestor of A and has no effect on A once A?s immediate parents are fixed. This makes sense in the example in the following figure.

Figure 9. ?Memoryless? Markov condition holds   However, not all of our commonsense perceptions of  causality work this way. Often, we believe that history mat- ters as in the example shown in the following figure.

Figure 10. Causality where memory play a part.

D. Liability: Discrete or continuous data must be reduced to Boolean values This is an early technique that was and is used in data  mining when analyzing market basket data. However, it is essentially flawed. Quantities do matter; some data co-oc- currences are conditioned on there being a sufficiency of a co-occurring attribute. Also, some relationships may be non-linear based on quantity [2].

E. Liability: There can be no missing data  This is at variance with day-to-day experience. There is almost always missing data of some sort. Data collection is rarely fully representative and complete. Incremental data is often acquired that is at variance with previously acquired data. What is needed is a methodology that is not brittle in the face of incompleteness.



VI. CONCLUSIONS Causal reasoning occupies a central position in human    reasoning.

In many ways, causality is granular. Commonsense rea- soning recognizes granularization and that objects may be made up out of granules. Knowledge of at least some causal effects is imprecise. Perhaps, complete knowledge of all possible factors might lead to a crisp description of whether an effect will occur. However, it is unlikely that all possible factors can be known. Commonsense understanding of the world deals with imprecision, uncertainty and imperfect knowledge. Even if the precise elements of the complex are unknown, people recognize that a complex collection of ele- ments can cause a particular effect. They may not know what events are in the complex; or, what constraints and laws the complex is subject to. Sometimes, the details un- derlying an event can be known to a fine level of detail, sometimes not. A causal model must accommodate shifts in grain size as well as imprecision and incompleteness.

There are several needs of a causal model. Some are: ? Represent imprecision: DAGs OK ? Accommodate changes in grain size: DAGs not OK as not  all cycles can be collapsed ? Describe complexes: DAGs OK ? Avoid over determination and over extension: Graphs in  general, including DAGs, not OK ? Support cyclic models of all kinds: DAGs not OK as can-  not represent any kind of cycles ? Be time varying: DAGs not OK ? Not be restricted by Markov conditions: DAGs not OK,  they must meet Markov conditions ? Handle incompleteness: DAGs, not OK; other models  such as fuzzy model OK  In order to algorithmically consider causal relations, the elements must be placed into a representation that supports manipulation. The most widespread causal representation is directed acyclic graphs (DAGs). However, DAGs are se- verely limited in what portion of the common sense world they can represent.

