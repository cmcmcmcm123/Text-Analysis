An Association Rule Mining Approach for Intelligent Tutoring System

Abstract?Intelligent tutoring system (ITS) creates a new teaching mode, but most ITS are merely e-learning platforms that provide course study, without considering learning processes of learners, which can't effectively help learners to consolidate and review the unmastered knowledge points. Data mining techniques can extract the potential, valuable pattern or regulation from a great quantity of data. An intelligent tutoring system has been designed based on data mining technology that could return the learners feedback about knowledge points. In order to quickly find all frequent patterns, i.e., knowledge points, an improved algorithm for mining association rules based on FP-growth is presented.

Experimental results show that the improved algorithm can provide effective decision support, and help learners to improve their learning efficiency.

Keywords-data mining; intelligent tutoring system; association rule; frequent itemset

I. INTRODUCTION  In the popularization of Internet today, teaching aided systems about exercise and examination based on Web have been used widely. These systems' learners usually take out exercises from exercises database according to some principles, then be graded by normal answers, but it can't acquire the dynamic information at the time of exercising. In fact, analyzing corresponding information from practice process can make learners know the shortage of courses knowledge, and return to the learners some chapters that learners don't master well. Furthermore, the analysis results make teachers clear about the courses' difficulty and deficiency in teaching, and grasp teaching emphases and difficulties. In addition, the analysis results can measure and supervise quality of teaching, too. The above analysis technique can be implemented by data mining process.

Along with the advancement of education informatization, the data mining technology was applied in education environment [1]. It becomes an imperative and important research topic that discovering hidden and useful knowledge from such an extensive quantity of data to guide and develop education. Data mining provides key techniques to realize a new-style intelligent tutoring system (ITS) for us.

ITS is an integrated topic which involves artificial intelligence, computer science, cognitive science, pedagogic, psychics and behavioral science and so on. Ultimate purpose of ITS is guide and help learners using computer system, which gives computer system intelligent and makes computer system instead of teachers in a certain extent so that to achieve the best teaching effect.

Application of ITS has changed the traditional teaching pattern, which brings into the student's study enthusiasm and go-aheadism, improves teaching efficiency and help students to develop intelligence and ability.



II. RELATED WORKS  Research on data mining techniques applied in tutoring system had been existed many years. Ochi[2] presented a method of picking up and studying relative knowledge using data mining in 1998. Tiffany[3] proposed using data mining techniques discovered clusters of students with similar learning characteristics. The literature [4] explained an example that using data mining techniques mined the aggregated data in teaching, which guided the selection on tuition ways and evaluated students' study behaviors, etc. In literature [5], a method that learner's related information exerting data mining techniques acquired individuation instruction for learners was presented. Hamalainen et al. [6] designed a data mining system (DMS) to construct a model for individual learning in distance education. An intelligent tutoring system was established using data mining techniques based on BP-nerve network and clustering analysis [7]. Pan et al. [8] used association rules of data mining to build the reasonable evaluation index system and teaching index method based on data mining.

The data mining techniques being widely used in teaching system is association rules mining. Apriori algorithm [9] is the first and best-known for association rules mining. It is an iterative algorithm to calculate the specific length of item collection of given database to produce frequent item sets. It cut down candidate item sets using the character that all non empty subsets in frequent item sets are frequent too. Focus on improving Apriori algorithm was to control the sizes of candidate item sets or to reduce the times of scanning database or sizes. Aiming to improvement of Apriori algorithm, AprioriTid algorithm [10] was proposed that it only scanned transaction database once and initialized a transaction sets. Mannila et al. proposed a Sampling algorithm [11] that tried to use less scanning times or scan less transaction records to achieve performance of ascension.

Relative to Apriori algorithm, Jiawei Han et al. [12] presented a FP-growth (frequent pattern growth) algorithm based on FP-tree that it didn't produce candidate item sets. FP-growth uses an extended prefix-tree (FP-tree) structure to store the database in the form of compressed.

In the proposed intelligent tutoring system, most were a platform about course learning or teaching management.

This paper will merge data mining techniques with traditional computer aided system, and design a novel     intelligent tutoring system based on data mining-ITSDM; In order to find quickly all frequent patterns and perfect tutoring system intelligently, as well as this system with the characteristics of field, we improve the association rule discovery algorithm based on FP-growth (IARAFP), and apply it to our ITSDM.



III. IMPROVED ASSOCIATION RULES DISCOVERY ALGORITHM  A. Association Rules  To find the inherent correlation of data is helpful for manager to make correct and reasonable decision.

Association rules model belongs to description model, and the algorithm to find association rules belongs to unsupervised learning methods.

Association rule reflects the relative degree among data sets. Given { , , ,..., }2 3 n1I = i i i i is an itemset, let  1 2 3 n{t , t , i ,..., t }D =  be a set of transaction called database.

Each transaction T  in D (T D? ) contains a subset of the items, and it has a unique identifier TID. An association rule is an implication formula such as A B? , and A I,B I,A B? ? ? = ? . The name A is the condition of  rule, i.e. antecedent, and B is the result of rule, i.e.

consequent.

To select significant rules from the set of all possible rules, two significant definitions were set up.

Support Degree, the rule A B?  to D , namely support(A B)? , is defined as the proportion of transactions in the data set D  which contain both A and B.

Confidence Degree, the rule A B?  to D , namely confidence(A B)? , is defined as the following equation: /confidence(A B) support(A B) support(A)? = ? .

Both support degree and confidence degree have minimum thresholds. Association rules are required to satisfy a user-specified minimum support and a user- specified minimum confidence as well.

B. Improved association rules algorithm based on FP- growth: IARAFP  In the known association rules mining algorithms, Apriori algorithm generated large numbers of candidate item sets and scanned databases many times, wasting storage space and time. Though FP-growth algorithm scanned databases only two times, generated FP-tree left a great deal of non frequent pattern, and storage space was wasted seriously too. So, we improve FP-growth algorithm, when it creates FP-tree and sorts the items without in term of support degree in L1, and needs not creating condition FP-tree in the pattern mining, which shortens the runtime.

In addition, because of the algorithm is applied to teaching system and each student is almost impossible same, we put the FP-tree store in a document, later, this FP-tree can be merged into other FP-tree when the data can be used directly. Therefore, the size of FP-trees is more important. In our system, through ameliorating FP-growth algorithm, that  generated FP-trees only include all frequent patterns, and enables the storage space condense.

Assuming p,q  are two nodes in a FP-tree, the path from  root to p is 1 2 kp , p ,..., p< > , and from root to q is  1 2 mq ,q ,...,q< > .

Definition 1 Uniform Path If there exists same nodes in two paths which represent  as 1 2 kp , p ,..., p< >  and 1 2 mq ,q ,...,q< > , we call the list composed of these same nodes as nodes p and q's uniform path.

Definition 2 Common Path If there exits 21 1 2 h hp q , p q ,..., p q= = = in two paths  which represent 1 2 kp , p ,..., p< >  and 1 2 mq ,q ,...,q< > ,  ,h k h m< < , we call the path 1 2 hp , p ,..., p< > composed of these same nodes as p and q's common path.

In order to facilitate the data mining, it needs to clean and pretreatment of operation before mining of data. The aim is to get clear suitable itemsets for mining. The data in itemsets are ranked in the order, while the items in the transaction D are on the dictionary in order.

Input data: Transaction databases D ; The minimum support threshold: min_sup.

Output data: Complete set L  of frequent patterns.

There are three backbone steps.

Step 1: Constructing FP-trees  Figure 1.  FP-tree before pruning  ? Scan database D , and collect frequent items into collection F and items' support degree;  ? Create an item head-table M, and put items of F into M. Set a pointer plink representing the locality of each item and initialize them with ? ;  In a head table, the first column represents identifier of an item; the second is the number of an item. Others represent k nodes to which plink will point. In the  beginning, plink  points the first node.

For example, as the FP-tree showed in Fig 1, its head  table is expressed as following: plink  I D a  b  c  d  e  coun t      plink  d:  c:  c:0  roo  a:  b:  b:  c:  e:  e:  c:  d:  e:  d:     ID Count d1 d2 ... dk a 6 b 7 ...

? Create a root node of FP-tree, as well as the roots of  sub-trees according to the order of item-head table below root node;  ? Set some variables as the emergence times of each item, named as count and initialize them with 0;  ? Set a market bit for each node, initialize them with 0; ? Scan database D ; ? set a pointer qq, qq  plink? ;  ? for each transaction I in D {  qq  first  item in I? ; add 1 to the variable count of the corresponding sub- tree below root node; for (pp second  item in I; pp <> null; pp next  item)? ?  { if a son node of qq  and p  are same  add 1 to the variable count of son node; else  create a son node pp ; qq pp? ;  } }  ? Finally, delete those nodes which their counters are zero under root node, and link all plink .

The result of constructing FP-tree is like as  Fig.1.

Step 2: Pruning FP-tree There are a large number of non frequent patterns in FP-  trees generated from step 1. Purpose of pruning FP-tree is deleting those non frequent patterns to make FP-tree only preserving frequent patterns.

The process is  as following: pointer W points to the last line in head-table; for (Q W; Q is not empty; Q Q - 1)? ?  { check each node id  linking to pointer Q. plink; if i i d .support degree < min_supp and d .market bit = 0  {  ;ip d=                //name id  as  p ; search the path Z =< root, ..., p > from root to node p;  search and store the paths{ }1 2 kz ,z ,..., z  from root to others nodes plink linked;  repeat { if node g ' path among { }1 2 kz ,z ,..., z have uniform  path with Z g.support degree = g.support degree+1 ;  if g.support degree < min_supp  .  0g market bit = ; else  .  1g market bit = ;  if two paths in { }1 2 jz ,z ,...,z share a common path  insert a node g into the common path; .  1g market bit = ;  g.support degree = g.support degree 1? ; delete node p from FP-tree;  until  (all nodes satisfied with market bit=1 or support degree>min_sup, and linked with plink);  } }  }  Figure 2.  FP-tree after pruning  After pruning, the FP-tree is like as Fig.2.

Step 3: Mining Frequent Patterns After pruning, FP-tree only contains frequent pattern.

The goal of mining is to finding all frequent rules in FP-tree.

The mining algorithm is described as following:  L? ? ;   // L represents the set of rule pointer W  points to the last line in head-table; for (Q W; Q is not empty; Q Q - 1)? ?  {  for each node id  linking to pointer Q. plink  search and store the paths 1 2, , ,...,i md v v v< > from id to the sub-node of root;    //every node is a item form many combinations like as  1 2 1 2 2 3 1 2, , , ,..., , , , , , ..., , , ,...,i i i i i md v d v d v v d v v d v v v< > < > < > < > < > ;  each combination constructs a rule rl ;  i id .counter d .support degree? ;  L rl L? ? ; if there is a rule rl  in L  di.support degree+ rl.support degree- > rl.support degree ; } Comparing with FP-growth algorithm, our algorithm has  the following traits. First, the itemsets are not ranked in terms of the size of support degree but the order of alphabets.

So, the rank can be accomplished at the time of data collection before data mining, and short the time of creating FP-trees. Secondly, the FP-tree only contains frequent patterns after pattern trees pruning, which condenses data furthest and reduces the storage space maximum. At the last, in the process of pattern discovery, it doesn't need considering whether or not the pattern is frequent and it need not to create condition FP-trees, which makes the process more simple and convenient, and lessen the mining time.

I D a  b  c  d  e  coun t      plink  c:2  b:3  b:4  d:2  root  a:6  c:2  c:2  e:2     C. Application and Argumentation  of IARAFP in Intelligent Tutoring System  An intelligent tutoring system based on association rules (ITSAR) is designed as Fig.3. ITSAR includes four subsystems or modules: an interface module, an expert module, a student module, and a teacher module. It provides a test and studying platform that learners could examine themselves by doing the test questions, and gain the feedback results of grade and evaluation that can guide learners to review weak knowledge points. There are many databases stored relative itemsets in each module.

Figure 3.  An intelligent tutoring system based on association rules Before association rules mining, preprocessing should be  done. First, the test questions are decomposed into many knowledge points be looked as items according to Chinese word segmentation dictionary algorithm [13]. Then, some  fields can be represented by code name respectively in order to mine expediently and take off useless fields. After preprocessing, each record has an itemset, the data in temset are ranked by alphabets. Association rules mining are executed on itemsets.

We implement IARAFP at the environment of Delphi 7.0 and Access 2003 of DBMS. In our experiments, we select a course-data structure as test object. The database gathered 382 knowledge points and 1469 unique test questions and 196 students. Through a round test, the number of records is 32 what the grade is excellent. Assuming min-supp is 2%, as well as known antecedent and consequent, then running the IARAFP algorithm, we get Table 1.

From Table 1, we can deduce the association degree between the right knowledge points (listed in antecedent) and the excellent grade (listed in consequent). Through setting dissimilar antecedents, consequents and minimum support degree, different mining outcomes can be gained. And from those outcomes, the relations between teachers and student's grade, students' study habit and grades and so on can be analyzed.

Rules on mining can be made process on different granularity, such as class, specialty and teacher and things.

According to the association at different granularity, we can judge the sorts of results, for example, a class of learning, a teacher's teaching, and then curricular difficulties could be found which can advise proposals to students and teachers.

Fig.4 is a learner exercise's feedback interface in our system, as feedback results, the learner gains proposals of further learning  TABLE I. ASSOCIATION RULES OF  GRADE=?EXCELLENT?  sequence number  antecedent ( Knowledge points of answer is  right) consequent support confidence  1 circular linked lists \stack \ character string \binary tree storage \preorder traversal of binary tree \postorder traversal of binary tree\undirected graph \graph adjacency lists storage \depth-first traversal graph \minimum spanning tree \sequential search \selection sort \ bubble sorting  grade=?Excellent? 3.57% 87.50%  2 circular linked lists \stack \ character string \binary tree storage \preorder traversal of binary tree \postorder traversal of binary tree \undirected graph \graph adjacency lists storage \depth-first traversal of graph \minimum spanning tree \sequential search \selection sort \quick sort  grade= ?Excellent?  3.06% 66.67%  3 circular linked lists \stack \ character string \binary tree storage \preorder traversal of binary tree \postorder traversal of binary tree \undirected graph \graph adjacency lists storage \depth-first traversal of graph \minimum spanning tree \Sequential Search \binary search  grade= ?Excellent?  2.55% 35.71%  4 stack \ character string \binary tree storage \preorder traversal of binary tree \postorder traversal of binary tree \undirected graph \graph adjacency lists storage \depth-first traversal of graph \minimum spanning tree \sequential search \selection sort  grade= ?Excellent?  2.55% 29.41%  5 binary tree storage \preorder traversal of binary tree \inorder traversal of binary tree \undirected graph \graph adjacency lists storage \depth-first traversal of graph \minimum spanning tree \sequential search \selection sort  grade= ?Excellent?  2.55% 20.83%  6 binary tree storage \inorder traversal of binary tree \undirected graph \graph adjacency lists storage \depth-first traversal of graph \minimum spanning tree \sequential search \selection sort  grade= ?Excellent?  2.04% 12.90%  .

Figure 4.  A feedback interface of exercise  The results of experiments show that our algorithm can be applied to ITS and manifest its accuracy and robustness while mine association rules among the data in the ITS.



IV. CONCLUSION  ITS based on data mining can guide students autonomic learning, and help students discover weakness in knowledge structures, so that it can advance students' comprehensive use of intellectual ability to solve problems. A large number of data in the system will also help students learning some common problems, even the personalized, so as to improve teaching effect. This paper proposed an improved association rules mining algorithm based on FP-growth ?IARAFP which applied to our designed ITSDM. The results of practical application proved that IARAFP can accelerate the speed of discovering frequent patterns and enable learners quickly find unmastered knowledge. Further, the system can help learners to consolidate and review, and effectively improve the teachers' teaching level, at the same time, enhance the teaching quality monitoring.

