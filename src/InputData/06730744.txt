Towards Machine Learning-Based Auto-tuning of MapReduce

Abstract?MapReduce, which is the de facto programming model for large-scale distributed data processing, and its most popular implementation Hadoop have enjoyed widespread adop- tion in industry during the past few years. Unfortunately, from a performance point of view getting the most out of Hadoop is still a big challenge due to the large number of configuration parameters. Currently these parameters are tuned manually by trial and error, which is ineffective due to the large parameter space and the complex interactions among the parameters.

Even worse, the parameters have to be re-tuned for different MapReduce applications and clusters. To make the parameter tuning process more effective, in this paper we explore machine learning-based performance models that we use to auto-tune the configuration parameters. To this end, we first evaluate several machine learning models with diverse MapReduce applications and cluster configurations, and we show that support vector regression model (SVR) has good accuracy and is also compu- tationally efficient. We further assess our auto-tuning approach, which uses the SVR performance model, against the Starfish auto- tuner, which uses a cost-based performance model. Our findings reveal that our auto-tuning approach can provide comparable or in some cases better performance improvements than Starfish with a smaller number of parameters. Finally, we propose and discuss a complete and practical end-to-end auto-tuning flow that combines our machine learning-based performance models with smart search algorithms for the effective training of the models and the effective exploration of the parameter space.



I. INTRODUCTION  The low cost of data acquisition and storage has enabled industry to store massive amounts of data with the hope of driving their innovation. MapReduce, the programming model of the data center, and Hadoop, the most popular open source MapReduce implementation, have taken a huge step towards solving the problem of processing these big data in a scalable and fault-tolerant way, and made it possible to process tens of petabytes of data daily [1]?[3]. However, performance- wise getting the most out of Hadoop is non-trivial; as of Hadoop 0.20.2 there are around 190+ configuration parameters and 10+ of these parameters have impact on the application performance [1].

On the one hand the large parameter space enables a wide range of opportunities for significant performance im- provement by careful parameter tuning (Section III), but on the other hand the large parameter space and the complex interactions among the parameters make manual tuning time consuming and difficult. Therefore, the research community has recently started exploring auto-tuning Hadoop configura- tion parameters [4]. Auto-tuning involves two phases: model  building and parameter optimization (Section VI). In the first phase, the auto-tuner establishes a performance model to predict the performance of an application given a parameter configuration. Then, using this performance model in the parameter optimization phase, the auto-tuner searches for the optimal parameter values. Therefore, the performance model is of crucial importance to the auto-tuner, and the quality of the auto-tuner depends strictly on the quality of the performance model. In this paper, we explore the feasibility of machine learning-based performance models as we move towards a new framework for the auto-tuning of Hadoop MapReduce.

Cost-based (analytical) performance modeling is a well- known approach that has proven itself useful in diverse com- puter systems, but it suffers from several drawbacks when modeling MapReduce applications. First, cost-based modeling is a white box approach where a deep knowledge about a sys- tem?s internals is required, and since the system comprising the software stack (operating system, the Java R? virtual machine, Hadoop, and the workloads) and the hardware stack are very complex, it becomes very difficult to capture this complexity with cost-based models. Second, Hadoop has several extension points where users can plug in their own policies, such as scheduling and block placement policies, making it necessary for the performance model to support these different policies.

Finally, although cost-based models may be effective, due to the high coupling of the model to the system internals a change in the system, such as the hardware technologies or the Hadoop framework itself, triggers a change in the model. We are motivated by these drawbacks to explore machine learning- based performance models, which are black box models, since building cost-based models for a complex system such as Hadoop with good accuracy while being flexible and robust is challenging.

Compared with the white box approach, black box models have two main advantages. First, black box models and the recommendations of an auto-tuner using these models are based on observations of the actual system performance for a particular workload and cluster. Second, they are usually simpler to build than white box models as there is no need for detailed information about a system?s internals. One of the interesting research questions that motivated our work is: Can we build an effective auto-tuner even if we treat the underlying system as a black box? As we demonstrate in Section V, the answer is yes; our machine learning-based approach results in comparable and in some scenarios even better performance than a cost-based approach.

2013 IEEE 21st International Symposium on Modelling, Analysis & Simulation of Computer and Telecommunication Systems  DOI 10.1109/MASCOTS.2013.9     Parameter Description Default Rules of Thumb SNB Cluster ZT Cluster  io.sort.mb (map output sort buffer) The amount of memory used while sorting files during the map phase  100 200 400  mapred.tasktracker.map.tasks.maximum (map slots) The maximum number of map tasks to run simul- taneously by a task tracker  2 7 31  mapred.tasktracker.reduce.tasks.maximum (reduce slots) The maximum number of reduce tasks to run simultaneously by a task tracker  2 2 2  mapred.reduce.tasks (reduce tasks) The number of reduce tasks to run for a job 1 15 15  Job input size The size of the input dataset N/A N/A N/A  TABLE I. FIVE PARAMETERS THAT WE HAVE USED IN OUR PERFORMANCE MODELS. THE FIRST FOUR PARAMETERS ARE HADOOP CONFIGURATION PARAMETERS SO THEY HAVE DEFAULT VALUES AND RULE OF THUMB SETTINGS FOR THE TWO CLUSTERS WE HAVE USED IN OUR EXPERIMENTS: THE SNB  AND ZT CLUSTERS (SECTION IV-B), AND THE LAST PARAMETER IS THE SIZE OF THE JOB INPUT DATASET.

Unlike the cost-based approach, our approach relies on training data to learn the performance model, which makes our approach more robust and flexible. The training data have to be collected separately for every application and cluster, and as expected, the data collection process may take more time than profiling the workload once, which is a common method used by cost-based approaches [4]. However, in a real deployment we expect the training to be done once, because in practice applications rarely change, instead their input datasets change [5], and our performance models can easily capture the changes to the input dataset as the input size is one of our model parameters. Moreover, training data collection time can be further reduced by using the logs of the completed jobs as Hadoop daemons already generate a large amount of logging information. Our contributions are threefold:  ? We develop several machine learning-based perfor- mance models of two Hadoop benchmarks (wordcount and sort) using data collected from two different cluster configurations, and we assess these models in terms of accuracy, computational performance, and their sensitivity to training data size (Section IV).

? We perform an extensive evaluation of the support vector regression model (SVR), which has both good accuracy and computational performance, by compar- ing it against the cost-based model of the Starfish auto-tuner, the rules of thumb settings, which are industry recommended parameter settings, and the default Hadoop parameter settings. Our results reveal that the SVR model is able to achieve comparable and in some cases even better performance improvements than the cost-based model (Section V).

? We propose a machine learning-based auto-tuning approach that uses smart search algorithms for both training the performance models and exploring the parameter space (Section VI).



II. MAPREDUCE AND HADOOP  MapReduce is a programming model used for process- ing large amounts of data on commodity clusters. The user specifies a map function that processes a key-value pair to produce a list of intermediate key-value pairs, and a reduce function to aggregate the output of the map function. Hadoop is a framework that implements the MapReduce programming model, and simplifies cluster programming by taking care of automatic parallelization, load balancing, and fault-tolerance.

A typical Hadoop cluster runs over the Hadoop Distributed File System (HDFS) and has a single job tracker (master) that is responsible for managing the task trackers (slaves) that run on each of the nodes in the cluster.

When a user submits a job consisting of map and reduce functions, Hadoop first splits the input data that resides in the HDFS into splits. Then, Hadoop divides the job into several tasks depending on the size of the input data. For every split, Hadoop runs a separate map task, which produces a list of key-value pairs. Hadoop then partitions the map output based on the keys, and runs a reduce task for each key writing the final output to the HDFS.

Hadoop gives users enough flexibility to change its behav- ior by exposing a large number of configuration parameters (tuning knobs). While some of these parameters, such as the number of map and reduce slots, have impact at the machine level some parameters, such as the number of reduce tasks, have impact at the cluster level. Similarly, parameters may impact different resources in the system; while the size of the map output sort buffer impacts mainly the memory and disk I/O performance, the number of reduce tasks parameter impacts mainly the network and disk I/O performance.

In this work to model the performance of MapReduce applications we have used the five parameters shown in Table I.

The first four parameters are Hadoop parameters and the last one is the size of the job input dataset. For the Hadoop parameters, the default column shows the default settings of Hadoop, and the rules of thumb column shows the values that the industry recommends [6], [7]; note the different rule of thumb settings for our SNB and ZT clusters (Section IV-B).

Our motivation for using these parameters is threefold. First, these parameters have impact on different resources and the impact of this parameter set covers all the available resources in a cluster. Second, these parameters have impact at different levels (machine-level or cluster-level). Finally, based on our domain expertise we expect these parameters to have sig- nificant impact on the performance. However, selecting the parameters to use in a machine learning-based performance model is a non-trivial research problem in its own, which is known as the feature selection problem. Therefore, we have used our domain expertise to select these parameters, and we have left the feature selection problem as an important future work.



III. THE NEED FOR AUTO-TUNING  In this section we make the case for why auto-tuning is the right approach to tuning Hadoop parameters. First, through experiments in our 8-node SandyBridge (SNB) cluster (see Section IV-B) we show that there is significant performance improvement opportunity even by tuning a small number of parameters. Second, we explain why manually tuning a complex system, such as Hadoop, is not feasible.

100 150 200 250 300 350 400  J o  b C  o m  p le  ti o  n T  im e  [ s ]  io.sort.mb [MB]           16 32 64 128  J o  b C  o m  p le  ti o  n T  im e  [ s ]  Number of Reduce Tasks  1 2 3 4 5 6 7 8 9       J o b C  o m  p le  ti o n T  im e [ s ]  Nu mb  er of  M ap  S lot  s  Number of Reduce Slots   Fig. 1. Performance of the sort benchmark with 80GB input on our 8-node SNB cluster (see Section IV-B) with different parameter settings for the size of the map output sort buffer (left), the number of reduce tasks (middle), and the number of map and reduce slots (right).

Configuration 1  (100MB,4,1,32)  Configuration 2  (100MB,5,2,24)  J o  b C  o m  p le  ti o n  T im  e [  s ]  Fig. 2. Performance obtained by tuning several Hadoop parameters at once for the sort benchmark with 120GB input on our 8-node SNB cluster (see Section IV-B) for two configurations (map output sort buffer, map slots, reduce slots, reduce tasks).

Figure 1 shows the performance of different parameter con- figurations comprising different values for the map output sort buffer parameter (left), the reduce tasks parameter (middle), and the map and reduce slots parameters (right) for the sort benchmark with 80GB input on our 8-node SNB cluster (see Section IV-B). The performance difference between the best and the worst configuration is 16% for the map output sort buffer parameter, 35% for the reduce tasks parameter, and 42% for the map and reduce slots parameters. Our results show that even by only tuning a single parameter in isolation it is possible to obtain up to around 40% improvement in performance.

Figure 2 shows the result when we tune several Hadoop parameters at once for the sort benchmark with 120GB input on our 8-node SNB cluster. For Configuration 1, we set the map output sort buffer size to 100MB, the number of map slots to 4, the number of reduce slots to 1, and the number of reduce tasks to 32. For Configuration 2, we set the map output sort buffer size to 100MB, the number of map slots to 5, the number of reduce slots to 2, and the number of reduce tasks to 24. Our results show that by tuning only a small number of parameters together we can achieve roughly a factor of two performance improvement.

Although there is a vast performance improvement op- portunity with careful parameter tuning as we have shown above, manual tuning is not feasible for two reasons. First, it is very difficult to understand the complex interactions among the parameters and reason about their performance impact as the impact of a parameter depends on several factors such as the workload characteristics, the input dataset, the cluster configuration, and even on the values of other parameters [4].

Second, the parameter search space is huge; even if we assume that the parameters take values from different sets of the same size, say 20, for 10 parameters the size of the search space  will be 2010, and it is simply impossible to manually explore this search space. Even if we explore a small subset of the search space, which may yield sub-optimal performance in the end, manual tuning will still be inefficient, since the user has to run a large number of trials to carefully search for the performance sweet spots. For example, when tuning the number of reduce slots the user has to address the trade-off between resource utilization and resource contention; while large values can cause resource contention low values may leave resources underutilized.



IV. MODELING THE PERFORMANCE OF MAPREDUCE APPLICATIONS  In this section we study several machine learning algo- rithms for modeling the performance of MapReduce applica- tions as performance modeling is the key component in an auto-tuning system. We evaluate our models in terms of their accuracy, computational performance, and their sensitivity to various variables such as the training data size, the application characteristics, and the cluster configuration.

A. Machine Learning-based Performance Models  We have explored various machine learning models to use in a practical auto-tuner, such as the one we propose in Section VI. Our models have five inputs (Table I) and one output, which is the job completion time. Although multiple linear regression is also considered as a machine learning model [8], when presenting the results we refer to it as a ?traditional statistical model? to discriminate it from the other more complex machine learning models we have explored. We briefly describe our models in turn.

Simple Multiple Linear Regression (MLR): We have used the simplest form of multiple linear regression for mod- eling the job completion time. This model does not have any parameter interactions and higher order terms.

Multiple Linear Regression with Parameter Interac- tions (MLR-I): With this model the completion time is modeled as  yi = ?1xi1 + ?2xi2 + ...+ ?kxik + k?  p,r=1?p ?=r  ?prxipxir + ei  where ?prxipxir terms represent the parameter interactions.

As we don?t know which parameters have interactions among them, we have performed an exhaustive search over all possible pairwise interactions to identify the interactions that yield the best performing model.

Multiple Linear Regression with Quadratic Effects (MLR-Q): With this model the completion time is modeled as       0  200  400  600  800  1000  C P  U /D  is k U  ti liz  a ti o  n [  % ]  Time Since Experiment Start  CPU Util.

Disk Util.

(a) Sort CPU/Disk Util.

0  200  400  600  800  1000  N e  tw o  rk U  ti liz  a ti o  n [  % ]  Time Since Experiment Start  (b) Sort Network Util.

0  100  200  300  400  C P  U /D  is k U  ti liz  a ti o  n [  % ]  Time Since Experiment Start  CPU Util.

Disk Util.

(c) Wordcount CPU/Disk Util.

0  100  200  300  400  N e  tw o  rk U  ti liz  a ti o  n [  % ]  Time Since Experiment Start  (d) Wordcount Network Util.

Fig. 3. CPU, disk, and network utilization when running the sort (a and b) and the wordcount (c and d) benchmarks on the SNB cluster.

0  100  200  300  400  500  600  700  C P  U /D  is k U  ti liz  a ti o  n [  % ]  Time Since Experiment Start  CPU Util.

Disk Util.

(a) Sort CPU/Disk Util.

0  200  400  600  800  N e  tw o  rk U  ti liz  a ti o  n [  % ]  Time Since Experiment Start  (b) Sort Network Util.

0  100  200  300  400  C P  U /D  is k U  ti liz  a ti o  n [  % ]  Time Since Experiment Start  CPU Util.

Disk Util.

(c) Wordcount CPU/Disk Util.

0  100  200  300  400  N e  tw o  rk U  ti liz  a ti o  n [  % ]  Time Since Experiment Start  (d) Wordcount Network Util.

Fig. 4. CPU, disk, and network utilization when running the sort (a and b) and the wordcount (c and d) benchmarks on the ZT cluster.

yi = ?1xi1+?2xi2+ ...+?kxik+?k+1xi 1+ ...+?2kxi  k+ei  where the xi2k terms represent the quadratic effects of each input parameter.

Multiple Linear Regression with Parameter Interac- tions and Quadratic Effects (MLR-IQ): Finally, we have also explored a regression model that captures both parameter interactions and quadratic effects.

Artificial Neural Networks (ANN): ANNs are one of the powerful learning models for general nonlinear regression between multiple input and output variables. ANNs have several desirable properties for performance modeling that motivated us to assess ANNs for auto-tuning purposes. First, ANNs are learning models that adjust their internal state to the data without any assumptions about the data. Second, ANNs can represent any function to arbitrary precision making them universal function approximators [9]. Third, ANNs can capture complex relationships between the input and output variables, such as nonlinearity and parameter interactions, making them suitable for practical performance modeling. Finally, ANNs have been shown to be useful for performance modeling in several previous studies (Section VII).

Model Trees (M5Tree): Model trees are an important class of machine learning algorithms for constructing tree models from data. In particular, we have used the M5? model tree algorithm provided by the Weka toolkit [8].

Support Vector Regression (SVR): Support Vector Ma- chines (SVM) are a set of machine learning algorithms used for classification and regression. In the context of regression SVMs are called Support Vector Regression (SVR). Two unique features of SVR have motivated us to explore it for performance modeling. First, SVR is considered as a powerful learning algorithm that has good generalization capabilities and has less risk of overfitting than the other approaches. Second, unlike ANNs, SVR is faster to train (see Section IV-E), and there is no local minima problem during the training phase as SVR transforms the regression problem into a convex optimization problem where all local minima are guaranteed  to be global minimums.

B. Experimental Setup  Workloads: We have used the wordcount and the sort benchmarks from the HiBench benchmark suite [10]. Our motivation for using these benchmarks is threefold. First, these workloads are simple, and hence, easy to reason about. Second, these benchmarks are representative of real MapReduce appli- cations as the computation performed by these benchmarks are common use cases of MapReduce, namely extracting a small amount of data from a large dataset and transforming data from one representation to another, respectively. Second, these two benchmarks have different characteristics in terms of resource requirements; wordcount is a CPU bound benchmark while the sort benchmark is mostly I/O bound as shown in Figure 3.

Clusters: We have assessed our models using data col- lected from two different clusters: SandyBridge (SNB) cluster and ZT cluster. The SNB cluster comprises eight machines connected through a 1 Gbps Ethernet switch, and each machine has a four-core Intel R? Core  TM i7-2600 processor running at  3.4 GHz, has 16GB main memory and three rotational drives that serve the HDFS data. The ZT cluster has more resources than the SNB cluster; it comprises eight machines connected through a 10 Gbps Ethernet switch, and each machine has a sixteen-core Intel R? Xeon R? E5-2670 processor running at 2.6 GHz, has 64GB main memory and three rotational drives that serve the HDFS data. In our experiments we have used Hadoop 0.20.2 and the master node running the job tracker and the name node were also responsible for running application tasks.

Finally, to give an idea about the workload characteristics and our cluster configurations, we present the resource utiliza- tions when running the sort and wordcount benchmarks with 80GB input in Figures 3 and 4. While the sort benchmark is mostly network I/O bound on the SNB cluster, it achieves a speedup of around 35% on the ZT cluster where the network is no longer a bottleneck. Similarly, on the SNB cluster the wordcount benchmark is CPU bound, but on the ZT cluster     ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ?    ? ?  ?? ??  ? ??  ? ? ??  ? ? ??  ?? ? ??  ?? ?  ??? ????? ????! ?????! ?"" ?#$??? %&?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  '??? '?*+?? ???+??  (a) Sort benchmark on SNB cluster ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ?    ? ?  ?? ??  ? ??  ? ? ??  ? ? ??  ?? ? ??  ?? ?  ??? ????? ????! ?????! ?"" ?#$??? %&?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ?  '??? '?*+?? ???+??  (b) Sort benchmark on ZT cluster  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ?  ?    ? ?  ?? ??  ? ??  ? ? ??  ? ? ??  ?? ? ??  ?? ?  ??? ????? ????! ?????! ?"" ?#$??? %&?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? '??? '?*+?? ???+??  (c) Wordcount benchmark on SNB cluster  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ?  ?    ? ?  ?? ??  ? ??  ? ? ??  ? ? ??  ?? ? ??  ?? ?  ??? ????? ????! ?????! ?"" ?#$??? %&?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? ?  ? '??? '?*+?? ???+??  (d) Wordcount benchmark on ZT cluster  Fig. 5. The distributions of the absolute percentage error for the sort and wordcount benchmarks on the SNB (a,c) and ZT clusters (b,d).

the CPU is not a bottleneck anymore. We also observe that the resources on the ZT cluster are utilized less than the SNB cluster as the ZT cluster has more resources.

C. Methodology  Data Collection: To train our models we have collected data from real sort and wordcount executions on the SNB and ZT clusters. During training an important question to address is which parameter values should we explore while collecting the training data. Since our parameter space is huge we have used a sparse sampling approach. In particular, we have collected data both with exhaustive search over different small subsets of the parameter space (exploring a specific range of parameter values) and with random explorations, where we have picked parameter values uniformly random from different range of values. The former approach is guided by our domain knowledge when choosing the specific parameter ranges while the latter approach provides us unbiased observations from the real performance surface of the application. We expect that these two approaches together provide more insights into the real performance surface than the individual approaches.

During data collection the clusters were dedicated to our workloads. For each benchmark and each cluster we have explored the same parameter values to collect the training data, and to capture the performance variability we have executed the benchmarks three times for every parameter configuration resulting in around 400 training points for each benchmark.

Training and Testing: After we have collected the raw data we have split the dataset randomly into an 80% training set and a 20% test set. We have trained the models with the training set, and we have evaluated their accuracy with the test set. We have performed this train-test cycle five times with different random splits, and then we report the average performance metrics. To build our models we have used both the Weka toolkit [8] and the R statistical software environment [11].

Model Tuning: Our models have various parameters, such as the number of hidden layers in the ANN and the maximum tree depth of the M5Tree. As these parameters depend on the nature of the data there is no simple way to determine the best parameter values. Therefore, we have used five-fold cross- validation and exhaustive search to find the best parameter values for our models. In particular, we have used a subset of one of the training sets as the validation set, and we have performed exhaustive search using cross-validation to identify the model parameters that yield the minimum error.

Metrics: We have assessed both the computational perfor- mance and the accuracy of our models as both are important when using the models for auto-tuning. To characterize the computational performance we have evaluated the time it takes to build the model and the time it takes to make a single prediction using the model. To characterize the accuracy we have used the absolute percentage error, the R2 statistic, and the root mean squared error (RMSE) statistic.

The absolute percentage error for the ith prediction is defined as |Pi?Oi  Oi | ? 100 where Pi is the ith predicted value  and Oi is the ith observation in the test set. We also present the mean absolute percentage error (MAPE), which is the mean of the absolute percentage error values computed over all the data points in the test set. The smaller the absolute percentage error the better; in particular a zero absolute percentage error denotes a perfect prediction. The R2 is defined as R2 = 1?SSerr  SStot where  SSerr is the residual sum of squares and SStot is the total sum of squares. SSerr is defined as SSerr =  ?  i  (Pi ? Oi) 2, and  SStot is defined as SStot = ?  i  (Oi?O?) 2, where O? is the mean  of the observed values in the test set. R2 simply shows the predictive power of a model. Models with R2 values close to 1 are considered as better models in terms of predictive power.

Finally, the RMSE statistic is defined as the square root of the  mean squared error, which is defined as  ?  i  |Pi?Oi|  N , where N  is the number of data points in the test set. A smaller RMSE value denotes a more accurate model.

D. Model Accuracy  In this section we explore the accuracy of our models using the data collected from two benchmarks on two different clusters.

1) Sort Benchmark: Table II shows the basic statistics for the absolute percentage error for all the models for the sort benchmark, and Figure 5 (a) and (b) present the corresponding box plots that show the distributions of the absolute percentage error. In the box plots presented in this section, the outliers are defined as points with values either less than Q1-1.5IQR or greater than Q3+1.5IQR, where Q1 and Q3 are the first and third quartiles, and IQR is the interquartile range (Q3-Q1).

As the multiple linear regression (MLR) model gets more complex, from MLR to MLR-IQ, the model gets more accu- rate; the mean model error decreases from 17% to 14% for the SNB cluster, and from 23% to 18% for the ZT cluster.

Similarly, the median and the max errors also decrease as the     SNB Cluster ZT Cluster Model  min Q1 median mean Q3 max IQR min Q1 median mean Q3 max IQR  MLR 0 7 15 17 23 68 16 0 8 18 23 33 117 25 MLR-I 0 6 14 16 22 69 16 0 8 17 22 31 129 23 MLR-Q 0 6 11 15 22 66 16 0 7 16 19 27 92 20 MLR-IQ 0 6 11 14 20 67 14 0 7 15 18 25 87 18  ANN 0 4 10 12 17 61 13 0 4 10 12 17 61 13 M5Tree 0 5 10 12 17 65 12 0 5 10 14 19 71 14  SVR 0 2 4 8 10 73 8 0 3 6 10 13 64 10  TABLE II. BASIC STATISTICS FOR THE ABSOLUTE PERCENTAGE ERROR [%] FOR THE SORT BENCHMARK ON THE SNB AND THE ZT CLUSTERS. THE BEST PERFORMING MODEL IS DEPICTED WITH LIGHT GRAY. Q1, Q3, AND IQR DENOTE THE FIRST QUARTILE, THE THIRD QUARTILE, AND THE  INTERQUARTILE RANGE, RESPECTIVELY.

SNB Cluster ZT Cluster Model R2 RMSE R2 RMSE  mean median mean median mean median mean median  MLR 0.79 0.8 179.23 160.69 0.76 0.73 199.75 213.65 MLR-I 0.81 0.81 170.8 155.9 0.79 0.8 184.38 190.91 MLR-Q 0.82 0.84 165.38 154.64 0.82 0.82 173.66 176.45 MLR-IQ 0.84 0.85 157.08 145.67 0.85 0.87 156.03 160.66  ANN 0.87 0.89 135.71 134.71 0.93 0.94 108.78 106.84 M5Tree 0.83 0.81 159.81 164.2 0.92 0.93 114.62 104.74  SVR 0.89 0.92 125.47 122.2 0.95 0.96 87.51 88.87  TABLE III. THE R2 AND RMSE STATISTICS FOR THE SORT BENCHMARK ON THE SNB AND THE ZT CLUSTERS. THE BEST PERFORMING MODEL IS DEPICTED WITH LIGHT GRAY.

complexity of the MLR model increases. This result confirms the presence of both nonlinearity and second order effects in the actual performance surface, and further confirms that these effects are captured by the complex MLR models. In general, all machine learning models (ANN, M5Tree and SVR) have better accuracy and lower variability (IQR) than the traditional statistical models (MLR models). ANN and M5Tree models have similar accuracy for both SNB and ZT clusters with a MAPE of around 12% while SVR has a MAPE of 8% for the SNB cluster and 10% for the ZT cluster. Moreover, SVR has a significantly better median error than the other models with a median error of 4% and 6% for the SNB and the ZT cluster, respectively.

For the SNB cluster the minimum and the maximum errors of different models are similar while this is not the case for the ZT cluster; the same modeling techniques can behave differently when trained with data collected from different clusters. Therefore, it is important to assess machine learning models with data from significantly different clusters.

In particular, the maximum error of the traditional statistical models increase significantly with the data collected from the ZT cluster whereas the maximum errors obtained with the machine learning models increase only slightly, which shows their robustness. Similarly, for the ZT cluster the MLR models have higher variability (with an IQR of up to 25%) than the machine learning models (with an IQR of 10% to 13%), but in contrast this difference is less pronounced for the SNB cluster.

An important error statistic is the third quartile (Q3) of the error distribution, which constitutes the bulk (75%) of the test data. Our results reveal that at the third quartile machine learn- ing models have smaller errors than the traditional statistical models on both clusters (Table II). In particular, for the SNB cluster 75% of the test data have an error of 20%-23% for the MLR models and an error of 10%-17% for the machine learning models. Similarly, for the ZT cluster 75% of the test data have an error of 25%-33% for the MLR models while for  the machine learning models the error is 13%-17%.

Finally, Table III presents the R2 and RMSE statistics for the sort benchmark on the two clusters. Similarly to the error statistics presented in Table II, machine learning models have higher R2 values and lower RMSE values confirming their bet- ter predictive capabilities than the MLR models. Considering the results in Table II and Table III we conclude that, overall, machine learning models perform better than the traditional statistical models, and in particular, SVR has the best performance among the models we have explored for the sort benchmark.

2) Wordcount Benchmark: Table IV presents the basic statistics for the absolute percentage error for all the models for the wordcount benchmark, and Figure 5 (c) and (d) present the corresponding absolute percentage error distributions. Sim- ilarly to the results for the sort benchmark, as the complexity of the MLR model increases the mean/median error decreases from 15%/13% to 12%/9% for the SNB cluster, and from 26%/20% to 12%/9% for the ZT cluster. The decreasing error trends confirms that complex MLR models can capture the nonlinearity and second order effects in the performance surface also for the wordcount benchmark. In general, SVR and ANN have better performance than the other models with a median error of 1% and 6% for the SNB cluster, and 5% and 8% for the ZT cluster, respectively. A particularly interesting result is that the M5Tree model performs worse than the other machine learning models with a similar performance as the MLR-IQ model. This result suggests that the workload characteristics definitely have an impact on the performance of different modeling techniques, since for the sort benchmark, M5Tree model has a similar performance as the other machine learning models. Therefore, it is important to assess the models with data collected from workloads with different characteris- tics.

When we look at the error IQRs, traditional statistical mod- els tend to have a higher variability (IQR) than the machine     SNB Cluster ZT Cluster Model  min Q1 median mean Q3 max IQR min Q1 median mean Q3 max IQR  MLR 0 7 13 15 21 94 14 0 9 20 26 32 181 23 MLR-I 0 6 12 14 18 187 12 0 9 17 22 27 208 18 MLR-Q 0 5 10 13 18 94 13 0 7 14 19 27 169 20 MLR-IQ 0 4 9 12 16 133 12 0 4 9 12 16 133 12  ANN 0 2 6 8 12 92 10 0 4 8 10 13 71 9 M5Tree 0 3 9 12 17 124 14 0 4 9 11 16 72 15  SVR 0 0 1 4 2 91 2 0 1 5 9 12 70 11  TABLE IV. BASIC STATISTICS FOR THE ABSOLUTE PERCENTAGE ERROR [%] FOR THE WORDCOUNT BENCHMARK ON THE SNB AND THE ZT CLUSTERS. THE BEST PERFORMING MODEL IS DEPICTED WITH LIGHT GRAY. Q1, Q3, AND IQR DENOTE THE FIRST QUARTILE, THE THIRD QUARTILE, AND  THE INTERQUARTILE RANGE, RESPECTIVELY.

SNB Cluster ZT Cluster Model R2 RMSE R2 RMSE  mean median mean median mean median mean median  MLR 0.45 0.51 241.98 193.85 0.45 0.47 234.24 246.8 MLR-I 0.45 0.48 242.13 194.29 0.53 0.54 215.02 230.04 MLR-Q 0.6 0.72 206.78 142.16 0.67 0.75 174.57 193.76 MLR-IQ 0.59 0.74 209.38 134.38 0.69 0.76 169.93 193.85  ANN 0.73 0.88 162.83 80.36 0.87 0.95 96.77 76.71 M5Tree 0.48 0.5 233.9 192.1 0.83 0.91 115.23 110.67  SVR 0.76 0.95 147.8 56.35 0.81 0.83 131.66 137.92  TABLE V. THE R2 AND RMSE STATISTICS FOR THE WORDCOUNT BENCHMARK ON THE SNB AND THE ZT CLUSTERS. THE BEST PERFORMING MODELS ARE DEPICTED WITH LIGHT GRAY.

learning models. For the SNB cluster the best performing machine learning model, SVR, has an IQR of 2%, but in contrast the best performing MLR model, MLR-IQ, has an IQR of 12%. Likewise, for the ZT cluster, the best performing machine learning model, ANN, has an IQR of 9% while the best performing MLR model, MLR-IQ, has an IQR of 12%.

Since 50% of the predictions have an error in the range Q1 to Q3 (the IQR), a smaller IQR for the machine learning models confirms their better robustness than the traditional models.

Similarly to the results of the sort benchmark, machine learning models also tend to have smaller errors at the third quartiles for the wordcount benchmark (Table IV). For the traditional statistical models, 75% of the predictions have an error in the range 16%-21% for the SNB cluster and 16%- 32% for the ZT cluster. On the other hand, for the machine learning models 75% of the predictions have an error in the range 2%-12% for the SNB cluster and 12%-16% for the ZT cluster. We conclude that machine learning models have better accuracy than the traditional statistical models for the 75% of the predictions, which constitute the bulk of the test data.

Finally, Table V shows the R2 and RMSE statistics for wordcount. Similarly to the error statistics presented in Ta- ble IV and similarly to the results for sort (Table III), machine learning models have higher R2 values and lower RMSE values confirming their better predictive capabilities than the traditional models. In particular, SVR performs the best for the SNB cluster while ANN is the best modeling approach for the ZT cluster. This result is particularly interesting as it demon- strates the impact of the workload and cluster characteristics on the predictive power of the models. When we consider the results for sort and wordcount together, overall, machine learning models have better predictive capabilities than the traditional models. In particular, SVR is the best performing model except for the dataset collected from the ZT cluster using the wordcount benchmark, for which ANN performs slightly better.

E. Computational Performance of the Models  In an auto-tuner, the computational performance of the models also matters. To this end, in this section we assess the time to train our models and the time it takes to make a single prediction with each model. We perform the measurements on a machine that has a dual-core Intel R? Core  TM i5-2540M  processor running at 2.60 GHz and 4GB main memory, and we report the average of ten measurements. We present the computational performance of the models only for the SNB cluster using the sort benchmark as the results are similar for the other datasets.

Figure 6 (top) shows the time to train the models, which is measured using the whole dataset; the final models that will be used in the auto-tuner will also be trained using the whole dataset. As the multiple linear regression models get more complex, from MLR to MLR-IQ, the training time increases by 2.08x, from 2.5ms to 5.2ms.

Machine learning models have significantly longer training times than multiple linear regression models with ANN having the longest training time (?29s), SVR having a training time of ?1s, and M5Tree having the shortest training time (?100ms).

Overall, we find that all traditional statistical models are relatively lightweight to train. Among the machine learning models, ANN takes the longest time to train as we train the ANN for 100,000 epochs, and for each epoch the network weights are updated using gradient descent, which is a com- putationally intensive operation. Finally, as shown with the vertical lines in Figure 6 all models have little variability in their training times.

Figure 6 (bottom) shows the time to make a single pre- diction using the models. Similarly to the results for the training time, as the multiple linear regression models get more complex, the time to make a single prediction increases by 2x, from 2.5ms to 5ms. On the other hand, although machine learning models take significantly longer time to train they           MLR MLR-I MLR-Q MLR-IQ ANN M5Tree SVR  T ra  in in  g T  im e  [ m  s ]    MLR MLR-I MLR-Q MLR-IQ ANN M5Tree SVR  P re  d ic  ti o  n T  im e  [ m  s ]  Fig. 6. Time to train the models (top) and to make a single prediction (bottom) for all models. Please note that the vertical axis has a logarithmic scale for the top graph.

are relatively lightweight when making predictions with a prediction time of less than a millisecond for all the machine learning models.

F. Model Sensitivity to Training Data Size  In this section we explore the sensitivity of the models to the size of the training data. To this end, we have trained the models using only a fraction of the data, that is 25%, 50%, 75%, and 100% of the data. For each fraction we have applied the same modeling method described in Section IV-C. Figure 7 presents the results for the sort and wordcount benchmarks on the SNB cluster. The results are similar for the datasets collected from the ZT cluster. Among the multiple linear regression models, we only present the sensitivity of the MLR- IQ model as it performs the best.

For sort, as the training set size increases MAPE decreases for all the models, by 3% for MLR-IQ, 2% for ANN, 1% for M5Tree, and 7% for SVR. Similarly, for wordcount as the size of the training set increases MAPE decreases by 26% for MLR-IQ, 14% for ANN, 16% for M5Tree, and 6% for SVR.

Based on these results we conclude that our models can benefit from additional data; if we further increase our training set size we expect the accuracy of our models to increase.



V. MACHINE LEARNING-BASED VS. COST-BASED MODELS  In this section, we compare our SVR model against the cost-based model of the Starfish auto-tuner [4] to assess how much performance improvement we can get with each ap- proach. We have performed the experiments in our SNB cluster using two different datasets (80GB and 240GB). Therefore, for each dataset we have a different SVR performance model as the job input size is one of the model parameters. To find the completion time with our approach, first we have identified the best configuration by performing exhaustive search over the performance surface generated by our model, then we have measured the completion time with this configuration. We have compared the completion time of our approach against the completion time achieved with the configuration recommended by Starfish.

25 % 50 % 75 % 100 %  M A  P E  [ %  ]  Fraction of data used  MLR-IQ ANN  M5Tree SVR    25 % 50 % 75 % 100 %  M A  P E  [ %  ]  Fraction of data used  MLR-IQ ANN  M5Tree SVR  Fig. 7. Accuracy of the models for various training data sizes for the sort (top) and wordcount (bottom) benchmarks on the SNB cluster.

An important difference between Starfish?s cost-model and our model is that the cost-based model uses fourteen Hadoop parameters while our model uses five parameters, which gives the cost-based model more flexibility when exploring the available headroom for performance improvement as it has more knobs to tune. Consequently, the absolute completion time numbers are not directly comparable, and for a fair comparison we have normalized the completion time with respect to the completion time obtained with the rules of thumb settings. In addition, we have also compared our approach against the default parameter settings; we refer to Table I for our model parameters, and their default and rules of thumb values.

Figure 8 shows the results of our comparison. For the sort benchmark, our SVR model has improved the performance more than Starfish for the 80GB input. While Starfish has improved the performance by 13% over rules of thumb, our SVR model has provided a 39% improvement. For the 240GB input, both models perform similarly and improve the performance around 40%. Similarly, for the wordcount benchmark, both models have relatively similar performance improvements with Starfish being slightly better (?5%). Since our model has a smaller number of inputs than the cost- based model, we expect that increasing the number of model inputs will provide more flexibility for parameter tuning and help further improve the performance. As expected, for both benchmarks the default settings perform significantly worse than both approaches as default settings do not involve any tuning at all. Our results reveal that compared with the cost- based model our SVR model achieves comparable or in some cases even better performance improvements.

One limitation of our approach may be the time it takes to collect the training data. However, in a real deployment we expect the training to be done once per application on a particular cluster?in practice applications rarely change, but rather their inputs change, and this is easily captured by our models as job input size is one of our model parameters.

Moreover, the training time can be further reduced by using the logs of the completed jobs in a Hadoop cluster.

0.5   1.5   Default Rules of  Thumb  SVR Starfish  N o rm  a liz  e d J  o b  C o m  p le  ti o n T  im e   (a) Sort with 80GB input  0.5   1.5   Default Rules of  Thumb  SVR Starfish  N o rm  a liz  e d J  o b  C o m  p le  ti o n T  im e   (b) Sort with 240GB input  0.5   1.5   Default Rules of  Thumb  SVR Starfish  N o rm  a liz  e d J  o b  C o m  p le  ti o n T  im e  (c) Wordcount with 80GB input  0.5   1.5   Default Rules of  Thumb  SVR Starfish  N o rm  a liz  e d J  o b  C o m  p le  ti o n T  im e  (d) Wordcount with 240GB input Fig. 8. The normalized job completion times with respect to the rules of thumb settings for the sort (a and b) and wordcount benchmarks (c and d). For figures a and b, the numbers on the Default bar show the normalized completion time with the default settings.

Benchmarks  Use smart sampling  to collect training data  Determine model  parameters  Train the machine  learning model  Evaluate  accuracy  Generate  parameter space  Use smart search to explore the parameter space for the optimal  parameter values  Run the job with optimal  parameter values  Model Building Parameter Optimization  Performance  Model  N o  t A  c c u  ra te  E n  o u  g h  Fig. 9. A practical end-to-end machine learning-based auto-tuning flow.



VI. TOWARDS A PRACTICAL MACHINE LEARNING-BASED AUTO-TUNER  A practical auto-tuner has to implement the model building and parameter optimization phases shown in Figure 9. So in ad- dition to the performance model several additional components are required to implement this end-to-end auto-tuning flow. In this section, we propose a practical auto-tuning approach that realizes this flow using machine learning-based performance models and smart search techniques, which are used both in the model building phase for training the models and in the parameter optimization phase for exploring the parameter space.

Our machine learning-based auto-tuning approach learns the underlying performance model from the training data collected from benchmark executions, and thus, is flexible and robust when dealing with different applications and clusters.

One of the major challenges with our approach is to train a relatively accurate performance model quickly. Random sampling, which is a simple approach to collect unbiased observations from the performance surface of an application, has been used to collect training datasets in previous stud- ies [12], [13]. However, based on our experience random sampling may require a large number of samples to build an accurate model, and since the overall tuning time is an important consideration in an auto-tuner a long training time can reduce its effectiveness.

To address the above challenge, we propose using smart sampling techniques during the model building phase to reduce  the model training time. With smart sampling we employ a direct search algorithm rather than random sampling. The direct search method focuses on regions of interest (e.g., a region with good performance) and searches towards such regions for finding the parameter configuration that yields the best performance. Unlike random sampling, this method can reduce the number of samples required to accurately represent the features of the performance surface in those regions. As our results have already shown that the performance surfaces of MapReduce applications are usually nonlinear and multimodal, we apply a global search algorithm, such as a genetic algorithm or recursive random sampling, to avoid being trapped in a local minimum. The smart search algorithm collects training samples and trains the performance model using these samples as it searches through the actual performance surface of the application (Figure 9). Then, the auto-tuner evaluates the accuracy of the performance model and stops the sampling process if the model is accurate enough (e.g., 90%). Otherwise, sampling continues until either the search algorithm converges, reaches the search budget or the model is accurate enough.

After building a reasonably accurate performance model, the auto-tuner proceeds to the parameter optimization phase. In this phase, the auto-tuner generates a parameter search space and explores it using smart search techniques, and it uses the performance model to find the parameter configuration that has the best predicted performance. When the search algorithm finds the best parameter configuration it terminates, and finally the auto-tuner starts the job with the best configuration.



VII. RELATED WORK  Closest to our work are the previous research efforts on ma- chine learning-based performance modeling and performance auto-tuning, which we describe in turn.

Machine Learning-Based Performance Modeling Ma- chine learning has been successfully used to model the per- formance of diverse applications. ANNs and multiple linear regression have been shown to be effective for modeling the performance of parallel applications [14]. Similarly, ANNs and M5? model trees have been used to model the performance of virtualized systems [15] and utility computing systems [16], respectively. ANNs, support vector machines, and decision trees have also been used for optimizing the performance of data center applications [17]. Our work contributes to this body of work by applying machine learning to model the performance of an interesting class of applications, namely MapReduce applications, with the goal of performance auto- tuning.

Performance Auto-tuning Previous studies have used different approaches to performance auto-tuning. Cost-based approaches have been successfully used in query optimization in traditional database systems [18]. With this approach, the cost model is the most important component of the optimizer as the accuracy of a cost model directly impacts the resulting performance. Empirical auto-tuning, which is based on an empirical search of the best parameter configuration, has been used in systems such as Atlas [19] and PHiPAC [20].

However, one major drawback of this approach is the long search time for large search spaces, which is usually the case in practice. To auto-tune the performance of MapRe- duce applications, Babu [21] proposes a competition-based approach where two copies of the same task are started with different parameter configurations and the best configuration is identified empirically. Similarly, Kambatla et al. [22] propose a history-based approach where the system keeps a history of job executions, and similar jobs are executed with the same optimal configuration. Finally, machine learning-based approaches have also been used successfully for auto-tuning the performance of parallel applications [14] and data center applications [17].

Closest to our work is the Starfish auto-tuner [4], which relies on a cost-based performance model. However, building a cost model that is accurate, robust, and flexible at the same time is challenging for a complex system such as Hadoop. Although cost-based models provide deep insights into a system?s internals, one of their main limitations is their flexibility; a change in the scheduling policies, the Hadoop framework internals, or the cluster requires the cost models to be rebuilt. However, our approach does not have this limitation, because addressing such a change with our approach only requires the models to be retrained, and model retraining is easier than building a new cost-model. Moreover, Starfish only models the performance impact of job-level parameters (mostly memory-related), and it does not model various important cluster-level parameters, such as the number of map and reduce slots. Finally, our findings show that a machine learning-based approach yields comparable and in some cases better perfor- mance improvements than Starfish?s cost-based approach.



VIII. CONCLUSION AND FUTURE WORK  In this paper we have explored various machine learning- based performance models for auto-tuning Hadoop MapRe- duce. We have shown that support vector regression model (SVR) has good accuracy and computational performance across diverse workloads and clusters. We have then compared our auto-tuning approach, which uses the SVR performance model, against the Starfish auto-tuner, which uses a cost-based model. Our findings reveal that the SVR model is able to achieve comparable and in some cases even better performance than Starfish by considering less parameters. Unlike the cost- based approach, our approach is more robust and flexible as it is easier to adapt to changes; our models learn the performance surface of the applications rather then being hardwired as is the case for the cost-based models. Our results demonstrate that it is possible to build an effective auto-tuner with a black box approach, that is, by only using observations from the system and without getting exposed to its internals. Finally, we have also proposed a practical end-to-end auto-tuning flow by combining our models with smart search algorithms.

