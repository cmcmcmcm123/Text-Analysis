

AN INVESTIGATION OF NEURAL NETWORKS

I. System Description  Richard J. McDuff?

Patrick K. Simpson?

David Gunning$  FOR F-16 FAULT DIAGNOSIS:  We will report results of our ongoing research exploring the use of artificial neural networks (ANNs) for F16 flight line diagnostics. ANN?S are based upon the methods of in- formation processing that might be used in neural circuitry rather than those of a conventional computer. A significant aspect of neural networks is their ability to develop associ- ations simply from examples. ANN?S hold the promise of solving difficult logistics problems such as: multiple fault diagnosis, prognostication, changing configurations and en- vironments, and inaccurate diagnosis attributable to incom- plete and/or flawed rules. We tested three representative ANN?S to see which type worked best for our problem.

We chose back propagation (BPN) and counterpropaga- tion (CPN) because they are considered to be two of the more promising pattern matching paradigms. The binary adaptive resonance theory I (ART1) was picked because it leams faster than CPN or BPN and has on-line adaption (i.e. does not have to be totally retrained every time a new pattern is discovered). On-line adaption is a powerful at- tribute, allowing new associations to be immediately incor- porated into the knowledge base on the flight line or wher- ever needed. This paper explains the advantages and drawbacks to each network tested and describes how we trained them using historical flight line data. Of the three ANN?S examined ART1 proved to be the most appropriate and was able to produce multiple symptom to multiple fault diagnoses.

1. INTRODUCTION  There are several problems that plague existing  military diagnostic systems. Multiple fault diagnostics - one symptom leads to several faults, many symptoms lead  to one fault, or many symptoms lead to many faults - is currently being performed with systems that are brittle and slow. Because of the need for time-critical flight-line re- sponse, available symptom data is either misinterpreted or  unused - often leading to the incorrect removal of a sys- tem?s component. Every new weapon system must devel- op its own diagnostic system, resulting in slowly devel- oped and costly systems. Lastly, when a weapon system goes through a configuration change, a costly process of di-  351 2; ., />0?0-035i 1. 1 .- :  ~~~~ ~~- -_ ~ ~  agnostic system development for the new configuration be- comes necessary to keep the diagnostic system up to date.

We are examining the use of neural networks [ l ] as a potential method of solving these maintenance and di- agnostics problems. We have approached diagnostics from a pattern matching perspective in that we have con- structed an input pattern from symptoms and matched that symptom pattern to an appropriate output pattern that cor- responds to the fault that occurred. An operational sketch of this approach is shown in Figure 1.

INPUT PATTERN (SYMPTOM) I 1 1 1 1  I  t r t t t  OUTPUT CLASS (FAULT) FIGURE 1: An illustration of the neural network approach to diagnostics. Input pattem!

(symptoms) are passed to a two-layer feedback neural network that determines whick class the input belongs within. Once the input class is determined the outputs (faults) as.

saciated with that class are displayed. The most sophisticated neural network pattar classifiers (Adaptive Resonance Theory networks) will automatically add new classe!

when they are needed.

After an extensive comparative analysis of several key neural network paradigms, we have developed a neu- ral network-based diagnostics systeh that addresses each of the previously stated problems. This system is tar- geted for eventual integration with the Air Force Human Resources Lab?s Model-based Diagnostic Aiding System (MDAS). These preliminary results hold the potential promise for a generic weapon system diagnostic tool for any arbitrary weapon platform produced by any branch of the service (i.e. MlA1, F-16, ATF, ATA, SSN-21, etc.).

Our efforts sought to answer eight key questions: (1) How should the mining data for the networks be  prepared?

(2) What is the most accurate way of representing the  data?

(3) Which neural networks are most appropriate for  (4) What is the proper hardware to use?

( 5 )  How well did the chosen network perform?

(6) How can we maximize the speed of this network?

(7) What is the optimal user interface design?

(8) How can we provide multiple fault output probabili- ties that elnulate an MDAS probability table out-  these problems?

and  put?

2. DATA ACOUISITION. PREPARATION, AND REPRESENTATION  2.1 DATA ACQUISITION  The database used for training the neural networks is contained in the F-16 Tactical Interim CAMS And RE- MIS Reporting System (TICARRS) [2]. This database was acquired from the initial flight-line debriefing and the corrective actions taken. Each database entry contains in- formation for each discrepancy (symptom-fault pair). The TICARRS database was transformed into a neural net- work training set that consisted of binary-valued symp- tom-diagnosis pairs.

The TICARRS database we received was not com- plete and contained many incorrectly entered discrepan- cies. In addition, many database entries did not contain a sufficient symptom description, often omitting important in- formation such as the state of the plane at fault time and any intermediate tests that were conducted that led to a successful diagnosis. Because of this poor set of data, it became imperative that the neural network was able to learn and classify symptoms with inherently noisy and missing information.

2.2 DATA PREPARATION  Although the TICARRS database has problems, it is the only source of actual F-16 symptom-diagnosis data (and a good representation of what can be expected from any modem weapon system). A large portion of the time spent on this project was dedicated to data preparation.

We created a neural network training set by filtering  through the TICARRS database and correcting or discard- ing unsuitable entries.

From the TICARRS database we chose three key fields to represent the symptoms:  (1) MFL - Maintenance Fault List codes; (2) FRC -Fault Reporting Codes; and  (3) WD - When Discovered codes.

A combination of these three fields is used as the input (symptoms) for the neural network. The MFL code is the only symptom acquired directly from the plane. The FRC code, when recorded out to the sixth digit, can represent a specific pilot complaint and is, therefore, useful symptom information. Sometimes, however, the FRC code is derived from the MFL code and is therefore redundant. The WD code is not a "formal" symptom, but is associated with the problem being diagnosed, therefore it is used. The remain- ing fault information, such as the air force base, the aircraft serial number, etc. was not used because of the data anal- ysis time constraints, although, in a fielded system it might be beneficial.

Also, from the TICARRS database we chose two key fields to represent the fault that occurred:  (1) WUC -Work Unit Code; and  (2) AT - Action Taken (AT) code.

A four digit WUC specifies which Line Replaceable Unit (LRU) was involved, and a five digit WUC indicates which Shop Replaceable Unit (SRU) was involved. The AT code signifies what type of action was taken on the unit repre- sented by the WUC. The narratives in both the discrepan- cy (symptom) and action taken (fault) portions of each re- port sometimes contain useful information but, since these are not formally or consistently encoded, they are not used. A complete description of the symptom and fault codes found in the TICARRS database is found in Table 1.

We acquired six months of fire control system data and prepared it for neural network training. From an initial set of 5,182 TICARRS entries, only 1,662 usable entries were found to be usable. We divided the usable discrepan-  cies (i.e. the historical data) into two groups: the training  set - a group of all but the last three weeks of database entries (1464 entries), and a test set - the last three weeks of database entries (198 entries). Although each of the database entries is usable, each entry is not necessari- ly accurate. In many instances the repair listed in the da- tabase was not what actually fixed the problem. Fortu-     MFL - u a r i a s  of ha leaas followed by he numbers. There are 24 possible thm letter combinmions used in our system and so the vecta has 24 d o f f  bits for them.

There PIC a maximum of 341 three Lgit numbers and so the vector has 341 d o f f  bits for each There are cosily a thwsand MFL codes.

Example M F L  FCR 003  FRC - consists of 8 digits of which we use only the middle 4. The middle four digits am- sist of 8 number pair and tbm two reparate digits. There are 100 possible two digit number wmbinmims for the pair and so the veaor has 100 possible odoff bits. There are 27 on/off bits e 4 1  fa the two separm leaa or m o  digits. Thae are over a thou- sand FRC coded p s i b l r  Emmwlr F E  9463AFM  WD - amsirta of 8 single digit which M cithcr be 8 lmcr or a number. There are 36 pos-  Example WD D  WUC - consists of a 5 or 6 digit number separated into a 2 digit number followed by 3 dig- iu which M eitha be 8 later or a number. The 2 digit number and the 3 single digits w e  each aorrd 81 is m the output vecta.

sible leaas or digits and so there arc 36 d o f f  bits for the WD.

ExamDlr W C  74AKB  AT - amsina of 8 single digit which M c i b  bc 8 letter or a number and was smed as  E m &  AT. R is in the output v e a a .

TABLE 1: DESCRIPTION OF TICARRS DATABASE ENTRIES  nately this was not a problem, our neural network ap- proach is able to handle such noise inherently.

2.3 DATA REPRESENTATION  2.3.1. Choosing a Representation Scheme  One of the primary difficulties with choosing a neu- ral network pattern recognition approach to diagnostics is data representation. Because neural networks expect fixed length patterns (i.e. vectors) to be presented during training and use, a considerable amount of careful thought and planning is required to develop input (symptom) and output (fault) representations.

Three representation schemes were examined for our data: (1) variable-unit representations, (2) intermedi- ate-unit representations, and (3) value-unit representa- tions [3]. The first scheme (variable-unit representation) represents each symptom, or action taken, by a single neu- ral network processing element (or vector component), whose value is the symptom code. Using this scheme a processing element (PE) in a neural network?s input layer represents all MFL numbers (lOOO+) and its value would represent the MFL?s ordinality. As an example, the MFL number 312 would be represented by a PE value of 312.

An advantage to this representation is that it eliminates the need for an extensive analysis of the data to find all possible inputs and outputs. This representation also re- quires a smaller input and output vector dimensionality which will speed up the compute time for each pattern pre- sentation. Conversely, such a representation creates a more difficult mapping because the low dimensional pat- tern space is often linearly inseparable. The more nonlin- ear the mapping, the more difficult it is to acquire an accu-  numbers and/or letten that are transfamed into a binuy repnrentation amenable to n w - ral networks. The resulting input represmution is a 555 element v h r  of binary values.

rate mapping. It is felt that this data representation would require a highly nonlinear mapping, leading to extensive training time. Hence, this method was not pursued any further.

The third representation scheme (value-unit repre- sentation) assigns every possible input or output a sepa- rate PE. This method would produce the least difficult map- ping because the high dimensional pattern space is the closest to being linearly separable. This representation, however, would have unacceptably slow computation times because the vectors are so large. In addition, such an approach would require enumeration of all possible in- puts or outputs, a task beyond the scope of this effort. Be- cause of the computation and data analysis requirements of this approach, encoding it is infeasible for our purposes.

The second representation scheme (intermediate- unit representation) represents the symptoms and actions taken with an encoding somewhere between the first and third schemes. We chose this method for the input be- cause it represents a compromise between exhaustive da- ta analysis and extensive computation time. The mapping is assumed to be linearly inseparable, yet computationally achievable within the projects time constraints  2.3.2. Input and Output Representations  Figure 2 shows how we represented the symptom (input) as a 555-element binary-valued vector. Because the input representation is well understood and static, .the transformation from data base entry to binary vector was  the only preprocessing necessary.

The fault (output) representation was more diffi-  cult. Because both single and multiple faults can be asso- ciated with the same symptom (input), the output repre- sentation has to maintain a running set of statistics that describe the likelihood of each possible fault given a partic- ular input. In addition, the number of faults is not known apriori, hence it is necessary to develop a dynamic output representation that can grow with the number of faults be- ing encoded in the network. To handle each of these issue,    y1? y2? ..? Jk? r ..I) YP - OUTPUT PATTERN CLASSES  we encoded the output data in a dynamically sized 3 di- mensional array that tabulates all faults that occur. Fig- ure 3 illustrates what information is stored with each pat- tern class processing element h the network and Figure 4 shows the overall picture of the input and output represen- tation with the neural network.

Class k Statistics: T a l  number of murrencen of this class: 4 List of faults associated with this class:  {Fault name:  {Fault name: Number of occLencen:  Number of ohmences: x,,,  Fault ?k { ~ ~ ~ ~ ~ o c c m a n ~ s :  k Qnk  3. NEURAL NETWORK IMPLEMENTATION  3.1. WHICH NEURAL NETWORK IS BEST?

Choosing the proper neural network is essential to the success of this experiment. To determine which net- work is best suited to perform our pattern classification task requires a complete enumeration of the qualities de- sired in the overall system. These qualities include:  ability to immediately classify symptoms; ability to handle noisy and incomplete data; ability to not favor heavily occumng symptoms  ability to recognize novel symptoms; ability to immediately incorporate new symptoms;  ability to develop new symptom classes.

over rarely occurring symptoms;  and  Originally we had intended to use the backpropagation [4] network, but quickly realized that its inability to detect suf- ficiently novel symptoms and its inability to immediately incorporate new symptom information were too limiting for its use. Another neural paradigm that we considered was the Learning Vector Quantization network [5] and its counterpropagation extension [6] .  Although these net- works do provide an ability to determine the novelty of a symptom, they suffered from an inability to immediately in- corporate new symptoms and are not useful in this applica-  Figure 4: The overall view of the neural network representation scheme for diagnostics.

Ihe TICARRS data base envy is transformed into a 555-element input that represents ;hat symptom. During both leaming and operation the symptom is classified and each class has a set of dynamically changing statistics as well as a list of all the faults associ- ated with the class.

tion, What was needed was a network that would allow new patterns to be immediately incorporated (i.e. on-line learning) and could distinguish between novel and known patterns. The answer is the binary adaptive resonance theory network (ART1) [7].

3.2. BINARY ADAPTIVE RESONANCE THEORY (ART11  The binary adaptive resonance theory (ART1)  ANS - introduced by Carpenter and Grossberg [7] - is a two layer, nearest-neighbor classifier that stores an ar- bitrary number of binary spatial patterns Ak = (akl, ...,  a kn ), k = 1, 2, ..., m, using a fast-learning version of the competitive learning law. ARTl learns on-line, operates in discrete or continuous time, and has the topology shown in Figure 5, where the n FX PES correspond to Ak?s com-  ponents and the p Fy PES each represent a pattern class.

The connections from the FX PES to each Fy PES w.. 1J form  reference vectors. For example, the connections from the FX PES to the Fy PE b. J form the reference (weight) vec-  tor W. J = (wlj, w2j, ..., w nJ .) . The connections from the Fy  PES to the Fx PES form the pattern vectors. For example,  the pattem vector attached to the jfh Fy PE is V.  = (v. J 11? vj2, ..., Vjn>.

Although ARTl is principally a two layer architec- ture, it is also transparently framed within two sub- systems - the attentional subsystem and the orienting   -~    + +  'kl 'kn a  Figure 5: Topology of the binary adaptive resonance theory (ARTI) neural network.

There are inter-layer feedback connections (w.. and vji) between the FX and F y  PES that facilitaw a resonation upon proper match between e n d e d  patterns V.  = (vjl, v j ~ .__, Y -  ) and input pattems Ak = (akl, a@ __., ah). The FX PES accept inputs from the environment and the Fy PES each represent a pattern class. During operation the F y PES employ an invisible on-center/off-surmund competition that is used U) choose the proper class for the presenred input. These lateral interactions are shown in the figure as shaded selfexciting (+) and neighbor-inhibiting (-) connections to emphasize this point. To keep the presentation uncluttered. all connections are not shown -there is ac- tually a connection from each FX PE to each Fy PE and vice-versa, a shaded negative lateral connection from each Fu PE to every other Fy PE, and a shaded positive recur- rent connection from every Fy PE to itself.

subsystem. The attentional subsystem only allows the Fx PES to be engaged when an input pattern is present.

The orienting subsystem removes Fy PES from the set of  allowable winners when an insufficient memory-input  match occurs - an operation termed short-term memory (STM) reset. These subsystems are implemented as in- herent operations during pattern processing.

In essence, ARTl conducts a serial search through the encoded patterns associated with each class trying to find a sufficiently close match with the input pattern. If no class exists, a new class is made. The test for a sufficient match between the top-down feedback pattern and the bottom-up input pattern is called hypothesis testing. An operational overview is provided in Appendix One and the equations are provided in Appendix Two.

3.3. PROBABILITY POST-PROCESSING  By tracking the number of occurrences of each class in the ARTl network (see Figure 3) and by tracking the number of occurrences of each fault that occurred within each class we are able to provide a frequency-based prob- ability measure for each fault within a given class. In addi- tion, as the diagnostic system is used and the number of fault occurrences increases, the statistics become more re- liable.

As an example, assume that we are operating the  system and we have just classified a symptom as belong-  ing to class 123 - y123. The hypothetical statistics asso- ciated with ~ 1 2 3  are shown in Figure 6 .  This class has  only three faults associated with it: (1) FCC FAILED, (2) INS NEEDS SERVICE  r Y 1' Y t '  -., Y1*3' '"9 Y  OUTPUT PATTERN CLASSES  and (3) INS FAILED. The to ~  Class 123 Statlstics: ~ o t a l  uumher of occurrences of this class: 43  List of faults associated with this class: Fault {Fault: FCC FAILED  Fault {Fault: INS NEEDS SERVICE  Fault {Fault: INS FAILED  Number of occurrences: 17  Number of occurrences: 12  Number of occurrences: 35  Tigure 6: An example of how the output class statistics are used to provide probahilit) nformation concerning which fault is associated with each symptom. The statistics show hat this class has occurred 43 times. Of the 43 occurrences of this class, 17 times fault I ,ccurred, 12 times fault 2 occurred and 35 times fault 3 occurred. Using this information he probabilities of each fault being associated with the given symptom are 39.5%. 28.6% md 81.4%. respectively  number of times that this class has occurred is 43. Each of the three faults occurred 17, 12, and 35 times respec- tively. To calculate the probability of each fault simply requires dividing the number of occurrences for each indi- vidual fault by the total number of occurrences of the class. For example, the probability that fault 1 is associ- ated with the symptom is 17/43 = 0.395, or 39.5%.

4. CONCLUSION  We have developed an extension of ARTl that is used to implement an on-line learning multiple-fault di- agnostic system that improves its performance with use. ARTl was found to be the most appropriate neural network for this application because it is able to quickly incorporate new pattems, it can inherently handle noisy and missing data, and it provides immediate responses.

Also, with the addition of the output pattern statistics,  we can overcome database ambiguities - a very difficult problem in classical AI systems.

ARTl is targeted for eventual use in diagnostic systems such as the Air Force Human Resources Lab's Model-based Diagnostic Aiding System (MDAS). The potential for this system is not strictly limited to this system. Because of the flexibility in construction and use, this system is easily applied to any weapon plat- form (as a generic diagnostic engine). When addressing the issue of flexibility, it is important to remember that neural networks can easily fuze data from several sen-  sors - an ominous task for most diagnostic systems.

Information fusion comes easily because the network learns to map input vectors to pattern classes irrespec- tive of the actual information contained within the input data. As an example, acoustic stress information and in- frared images could be combined as inputs to a heli-rotor diagnostics system.

In this paper we have described the system that has been implemented to perform fault diagnosis of F-16 fighters on the flight line. In part I1 of this paper [8] we will discuss the results of our simulation experiments with actual TICARRS data and we will outline some areas of fu- ture exploration.

