Multi-Query Unification for Generating Efficient Big Data Processing Components from a DFD

Abstract?This paper proposes multi-query unification, a technique for generating unified components from a DFD aimed at reducing the total cost of data transmission between components that are deployed to a computing fabric that includes processing nodes and interconnection services. The method focuses on generating components of the two primary data processing methodologies: cumulative data processing (CDP) and data stream processing (DSP). The method utilizes multi-query unification and generates a unified query by applying two methods depending on the order sensitivity of processes in a DFD.

Nesting unification composes a unified query by embedding  the query of a process into the query of the next process as a subquery. Clause assembly unification composes a query using templates for each clause of the original query. For clause assembly is applicable only to processes that is executable simultaneously, we define the criteria called order sensitivity for applying clause assembly and propose two-stage unification in which nesting unification is always applied after clause assembly.

The performance evaluation based on a virtual DFD shows  that applying two-stage unification reduces the execution time of components by 60 percent in DSP; however, execution time is reduced by only 10 percent in CDP. On the other hand, nesting unification alone reduces the execution time by 30 percent.

Based on those results, we conclude that clause assembly should be applied to DSP using Esper but should not be applied to CDP using Hive.

Keywords-multi-query unification; order sensitivity; big data; component; DFD; platform as a service;

I. INTRODUCTION  Big data processing technologies, such as MapReduce [1] and complex event processing (CEP), enable efficient pro- cessing of massive event data produced by mobile devices, sensors, web services, various ICT systems, and so on. A consolidated development environment to support the use of these technologies is important to extract new and different value from unutilized stored data or data that may be used in the near future.

Two primary data processing methodologies can be ap-  plied to massive event data: cumulative data processing (CDP) and data stream processing (DSP). These method- ologies are differentiated based on the type of data. The former is a data-intensive batch-style process and is often applied to statistical analysis of past data. The latter is real- time processing that continuously processes event data in order of arrival and is often applied to event detection to provide real-time services.

Similar to business intelligence tools or ?extract, trans- form, load? tools, an intuitive data-flow diagram (DFD) is used to define how data is processed and the order of execution in the processing medhodologies. Several existing development environments for big data processing also adopt DFD or other domain specific language (DSL). For exam- ple, [2], [3] adopt DSLs to define MapReduce processes, and [4]?[6] adopt DFD and DSLs to define continuous queries for CEP. However, these development environments only support one of the processing methodologies. Multiple development environments are necessary to execute real- service development procedures to analyze massive event data and to apply the results of the analysis to the service.

Madras [7] provides integrative support for utilizing both CDP and DSP. Madras transforms a DFD into components that have different query processing implementations for deployment to a cloud and provides a computing fabric that includes CDP and DSP nodes and interconnection services.

In Madras deployment, each implementation should be able to use a different query language and therefore should be deployed to different types of processing nodes. In such an environment, components communicate with each other to deliver event data using an interconnection service. Using this type of environment to process massive event data is problematic due to the large size of the data being transmitted between components.

To address this data overhead problem, we propose a technique that unifies multiple queries of processes to reduce the number of components generated from a DFD. We call this technique ?multi-query unification.? This technique generates a single query from queries that can be processed simultaneously and also embeds a process query into the next process as a subquery to retain the correct processing order.

The remainder of this paper is organized as follows.

Section II presents an overview of Madras as an example of a target development environment. Section III describes three unification methods of multi-query unification. Section IV describes criteria for applying unification method. We evaluate and discuss the reduction of execution time by multi-query unification in Section V. Section VI summarizes related work and our conclusions are presented in Section VII.

DOI 10.1109/CLOUD.2013.99

II. MADRAS: TARGET DEVELOPMENT ENVIRONMENT EXAMPLE  Madras is a platform as a service that is capable to process massive event data produced by point-of-sales sys- tems, electronic ticket systems, etc. to provide integrative support for data analysis, service provision and evaluation.

We assume that the end user of Madras is an analyst who has extensive data analysis experience but does not know which technology to use to process data most efficiently or how to implement the selected technology. Madras provides a method to define a data processing procedure using a DFD that does not depend on any particular technology.

Consequently, the end user can execute data analysis and develop a real-time service without actually implementing specific technologies, such as CEP and MapReduce.

Figure 1 shows the Madras architecture. In Figure 1, Web  Browser denotes the web browser on a client PC. The DFD Editor works in the Web Browser and is employed by the end user to define a DFD. We assume that Web Node, Control Node, and the other nodes that execute processing engines illustrated in Figure 1 are deployed to a public or private cloud. The Resource Service stores the DFD defined by the end user in the Resource Repository for version control. The Deploy Service generates components from the DFD, stores them in the Component Repository for version control, and transfers them to the Control Node for execution. According to the component description, the Control Node deploys nodes for processing engines and provides message queue services, such as the Java Message Service.

Each component has an implementation and interfaces  to transmit data between components using a specified method in accordance with the component assembly model of Service Component Architecture (SCA)1. Madras adopts Apache Tuscany2 as the runtime engine for components, Apache Hive3 as the CDP engine, and Esper4 as the DSP engine. Madras is also empowered by Eclipse Modeling Framework (EMF)5 to create and manipulate the DFD model described below.

A. DFD model In Madras, data analysis and service development proce-  dures are consistently defined by the same style of DFD.

The benefit of this methodology is that it facilitates the application of information, such as a rule, model, or method, revealed by the data analysis to service development. Gen- erally, the application of such information is a challenging problem because there are gaps between data analysis and service development that vary depending on the characteris- tics of the data and the process. In data analysis, a number of past event data that have been stored for a long time are processed using batch-style processing technology, whereas  1http://www.oasis-opencsa.org/sca 2http://tuscany.apache.org/ 3http://hive.apache.org/ 4http://www.espertech.com/ 5http://www.eclipse.org/modeling/emf/  ??? ????	??   ?????  ???  ?????  ??? ????   ???	???  ??	????  ??????  ??	????  ???????  ?	?   ??????????  ???????????  ??	??????????	?????  ????  ????  ????  ????? ? ??????	?????  ?? ???!

????  ??????????  ??	????	??  ??	????  ???!???? ???"?????  ??????? ??????  ?	????????	??????  ?????	???	????  ??		?????	?????????  ?????? ??	??	??????  Figure 1. Madras architecture.

in service development, fresh event data uses real-time pro- cessing technology. Therefore, the development environment should bridge the gaps between data analysis and service development.

The definition of the Madras DFD model is similar to the  general DFD definition [8] in that it consists of dependencies between data and processes. However, differing from the general DFD definition, the data source, data sink, and temporal data store are not differentiated in the Madras DFD model. They are simply treated as indistinct data. That is, let DFD be a directed bipartite graph (DN,PN,E) comprising two disjoint sets DN and PN , and a set E such that every directed edge e ? E connects from a data node d ? DN to a process node p ? PN , or vice versa. In this paper, we assume that the DFD model in the proposed method is the same as the Madras DFD model.

We define data analysis and service development proce-  dures by combining the following types of processes: data filtering with a condition, numerical calculation, an analyti- cal method, data cleansing, service provision processes, and so on.

In the Madras DFD model, a process has implementation  parameters, and data has a schema that is comprised of a list of fields (i.e., name and type) and the type of data storage used. Moreover, both process and data are assigned their available processing behaviors (i.e., CDP, DSP, both or other).

The DFD defined by the end user is serialized to the  XML Metadata Interchange (XMI)6 format by using EMF and is transferred to the Resource Service and stored in the Resource Repository.

B. Generating components from the DFD The Deploy Service generates component source code in  SCA format from the DFD in XMI format in response to re-  6http://www.omg.org/spec/XMI/     quests from the DFD Editor. To generate component source code, the Deploy Service uses template engine combining templates and process properties.

There are two types of templates: query and compo-  nent. A query process is implemented using a specific query template and the generalized component template to process the specific query language associated with the query. The non-query process (i.e., analytical method) has an implementation-specific component template. The Deploy Service generates components by the following procedure.

First, the Deploy Service generates a query that corresponds to the process using its query template to apply process properties to the parameter. Then, if the process has a query, the generated query is applied to the generalized component template parameter, and the component source code is generated. If the process does not have a query, process properties are applied to the implementation-specific component template parameter, and the component source code is generated.

A message queue service and file delivery are considered  the most general and versatile methods for transmitting data between components.



III. OVERVIEW OF MULTI-QUERY UNIFICATION Multi-query unification is a technique that unifies queries  of processes to reduce the number of components generated by the generalized component template previously described.

In this section, we describe three unification methods that consitutes multi-query unification. In this paper, to simplify the expressions of the methods, we assume query languages that have similar syntax to Structured Query Language (SQL).

A. Clause assembly unification Clause assembly unification is a method that composes a  unified query by dividing the original SQL-like queries into several clauses, such as SELECT. To unify process queries with the next process, the clause assembly method generates clauses of process query using templates and then composes clauses as the unified query using string operations, such as concatenation and replacement, for each clause. To execute the method, clause templates, rather than query templates, must be prepared for each clause.

Figure 2 shows an example of clause assembly unifica-  tion. In the example shown in Figure 2, queries can only be unified by concatenating the SELECT clause of the second process, the FROM clause of the first process, and the WHERE clause that concatenates the conditions of both processes using the AND operator.

B. Nesting unification Nesting unification is a method that composes a unified  query by embedding a process query into the query of the next process as a subquery.

The procedures for embedding the subquery vary depend-  ing on the processing engines. Figure 3 shows an example of nesting unification. As shown in Figure 3, in Hive, queries  ???????   ??????  ???????????????????????????????????????????????????????????????? ??	?   ????	???  ???????  ????? ?????? ??????????????????????????????????????????????????  ???????  ??????? ??	?  ?????????????????????????????????????????????????????? ??	?   ????	???  ???????  ??????  ?????????	????????	?  ?? !!?"#?$???  ?%??$????"#?&! !!

??????????????  ?????????????????  ?????????	????????	?  ???	?????????  ?	?????? ?  ?? !!?"#?$???  ?%??$????"#?&! !!

Figure 2. Clause assembly unification.

?????? ??																	?????  ?????? ??																	?????  ?????	??  ???????  ?????	??  ????	???????  ??????? ?????????? ??????  ??????? ?????????? ??????  ??????????????????????? ?????? 	?????????? ?? ?????????????????????   ?????????? ??????  ???	? !???  "#????	"#??														?????? ??																?????																				$  ?????? ??																?????																				$  ?%?	?&?  Figure 3. Nesting unification.

can be unified by replacing the expression of the FROM clause of the next process with the query of the first process in parentheses. On the other hand, in Esper, queries can be unified by the following procedure. INSERT INTO clause is placed at the beginning of the query of the first process.

This query will be treated as an internal stream with a new name. Then, the FROM clause of the next process is replaced by the name of the internal stream.

C. Two-stage unification Two-stage unification is a combined method that applies  clause assembly first and then nesting. Clause assembly cannot unify several query types that typically occur in a DFD. On the other hand, nesting can unify any type of query in a DFD and can be applied after clause assembly.

Two-stage unification is applicable to the same cover-  age of query types as nesting. However, queries unified by the two-stage unification have different characteristics from those unified by nesting unification; there are fewer nested queries in a two-stage unification, and each subquery     Table I CLASSIFICATION OF OPERATORS.

Type order-sensitive SQL Example Description ? No SELECT a, b, c FROM A Retrieves tuples having the specific subset of fields in schema ? No SELECT * FROM A WHERE 10<a AND a<20 Retrieves the specific subset of tuples X Partially No SELECT a, b, a+2*b AS c FROM A Calculates a value of a new field from existing fields ? Yes SELECT COUNT(*) FROM A Calculates a tuple from multiple tuples M Yes SELECT * FROM A JOIN B ON A.a=B.a Uses multiple inputs such as ??, ? and ?  generated by the two-stage unification is more complex than those generated by nesting unification.

In the next section, we describe the types of queries that  cannot be unified by clause assembly.



IV. CRITERIA FOR APPLYING UNIFICATION METHOD If we apply clause assembly, to ensure that the unified  query causes the same result as the original queries be- ing processed sequentially, we have to classify processes depending on whether or not queries can be processed simultaneously.

SQL implements a close approximation of relational al-  gebra and provides the calculus for a table declared by a relational model. Hive and Esper have DSLs with SQL-like syntax to describe a query: HiveQL and Event Processing Language (EPL). Therefore, along with SQL, we can clas- sify operations in the DSLs, such as EPL and HiveQL, using relational algebra operators.

A. Preparation Table I shows the classification of operations using SQL  queries. Relational algebra has several basic operators (e.g., Projection (?), Selection (?) and Natural Join (??)) and several applied operators (e.g., Rename (?), Equijoin (?) and Cartesian Product (?)). The proposed method treats opera- tors with multiple inputs, such as ??, ?,?, and other Join-like operations, as a simple Multiple Input (M). Moreover, the method treats ? as a part of Extension (X ) that calculates a value of a new field from existing fields. The Aggregation (?) operator calculates a tuple from multiple tuples.

We assume a DFD (DN,PN,E) with data d ? DN has  a schema Sd with a set of fields {F 1d , ? ? ? , Fnd }, where n is the number of fields of schema Sd, F id is the i-th field of data d, and every process p ? PN has a query qp and a set of property names PRp.

For a process p, let pbp denote a set of available processing  behaviors of p, query qp denote a set of m operators {op1, ? ? ? , opm}(opi ? OP = {?, ?,X , ?,M}, qp ? 2OP).

The query operation op[qp] denotes op1 ? op2 ? ? ? ? ? opm where op1 ? op2 signifies that op1 and op2 are operated simultaneously, whereas op1(op2(?)) signifies that op1 is operated after the completion of op2. Let p(pr) denote the property pr value where pr ? PRp and op[qp](d) denote the data derived from input data d processed by query qp.

For a DFD instance (DN,PN,E) where ? DN = {d1, d2, d3}, ? PN = {p1, p2},  ? E = {(d1, p1), (p1, d2), (d2, p2), (p2, d3)}, d2 is derived from op[qp1 ](d1) and d3 is derived from op[qp2 ](d2) or op[qp2 ](op[qp1 ](d1)).

Let data d be a set of tuples {t1, ? ? ? , tn} where tj ? d  is the j-th tuple of data d, and let tj(F id) denote the value of the field F id of the j-th tuple of data d. The tuple tj is also a map denoted by tj : {F 1d , ? ? ? , Fnd } ? D1d ? ? ? ? ?Dnd where Did is a domain of the field F id. For a tuple t ? d, let t[?] denote a tuple having fields either selected from the original schema or derived from arbitrary expressions.

The operators can be defined as follows: ? ?F1,???,Fk(d) := {t[F1, ? ? ? , Fk]|t ? d}, ? ?F1,???,Fk,C(d) := {t|t ? d ? C(F1, ? ? ? , Fk)}, ? XF1,???,Fk,f (d) := {t[F 1d , ? ? ? , Fnd , f(F1, ? ? ? , Fk)]|t ?  d}, ? ?F1,???,Fk,g(d) := {t[F1, ? ? ? , Fk, g(d)]|t ? d ? g(d) has a value correspondent to F1, ? ? ? , Fk},  ? MC(d1, d2) := a set of tuples having fields selected from d1 and d2 and combined under the condition of C,  where {F1, ? ? ? , Fk} ? {F 1d , ? ? ? , Fnd }.

B. Order sensitivity The most important characteristic among operators for  clause assembly is the relationship that is executable simul- taneously, i.e., order sensitivity. We define order sensitivity as follows.

Definition 1 (Order Sensitivity): for two operators  op1, op2 ? OP, op1 ?= op2, the relationship is order- sensitive if and only if the relationship does not satisfy both associative law and commutative law. That is,  op1(op2(d)) ?= op1 ? op2(d)), (1) op1(op2(d)) ?= op2(op1(d)). (2)  Clause assembly is applicable to operators if and only if their relationship is NOT order-sensitive. For the relationship not to be order-sensitive, satisfying associative law must be a necessary condition, and satisfying commutative law must be a sufficient condition. In the context of multi-query unification, satisfying associative law between operators means that the operators are executable simultaneously, and satisfying commutative law between operators means that the operators are executable simultaneously and in inverse order.

The operators ? and ? are NOT order-sensitive because  they satisfy the following associative law:     ?F1,???,Fn(?G1,???,Gm(d)) = ?F1,???,Fn(d), (3)  where {F1, ? ? ? , Fn} ? {G1, ? ? ? , Gm}, and ?C1(?C2(d)) = ?C1?C2(d), (4)  ?F1,???,Fn(?C(d)) = ?F1,???,Fn ? ?C(d)). (5) Operators ? and ? also satisfy the following commutative  law:  ?C1(?C2(d)) = ?C2(?C1(d)), (6)  ?F1,???,Fn(?C(d)) = ?C(?F1,???,Fn(d)). (7)  The operator XF1,???,Fk,f generates tuples having a sub- set of fields F1, ? ? ? , Fk and a new field derived from f(F1, ? ? ? , Fk) (denoted as F+). The relationship involving XF1,???,Fk,f is partially order-sensitive. This characteristic is described as follows.

Theorem 1 (Order sensitivity regarding X ): let opPC ?OP denote an operation that consumes fields in C of the  input data and produces new fields in P . The relationship between XF1,???,Fk,f and opPC is NOT order-sensitive if and only if F+ /? C and {F1, ? ? ? , Fk} ? P = ?.

Proof:We assume an operator opPC for the next operator of XF1,???,Fk,f where F+ ? C and P is an arbitrary set. The operator opPC cannot execute before XF1,???,Fk,f because F+ is not generated before XF1,???,Fk,f is executed. Moreover, these operators are not executable simultaneously because the value of f(F1, ? ? ? , Fk) cannot be calculated and denoted as F+ before the next operator is executed, and opF cannot use the value of f(F1, ? ? ? , Fk).

Then, assuming an operator opPC for the previous operator  of XF1,???,Fk,f where {F1, ? ? ? , Fk} ? P ?= ? and C is an arbitrary set, these two operators are not executable simultaneously and in inverse order because field F ? P does not exist when XF1,???,Fk,f requires F .

For ?F1,???,Fk,g and MC , the relationship involving one of them is order-sensitive and can be described as follows.

Theorem 2 (Order sensitivity regarding ?): the relation-  ship involving ?F1,???,Fk,g is order-sensitive.

Proof: We assume an arbitrary operator op ? OP for  the next operator of ?F1,???,Fk,g . Then,  op(?F1,???,Fk,g(d)) ?= op ? ?F1,???,Fk,g(d), (8) op(?F1,???,Fk,g(d)) ?= ?F1,???,Fk,g(op(d)), (9)  because, in both equations, the left side applies op to aggregated data derived from ?F1,???,Fk,g and the right side applies op to the original data.

We assume an arbitrary operator op ? OP for the  previous operator of ?F1,???,Fk,g . Then,  ?F1,???,Fk,g(op(d)) ?= op ? ?F1,???,Fk,g(d), (10) because any calculation in op and g(d) are accurately not executable simultaneously.

Algorithm 1 Check if processes can be unified.

1: function ISORDERINSENSITIVE(p, pnext) 2: if (qp ? qpnext) ? {?,M} ?= ? then 3: return false 4: else if X ? q then 5: properties? {p(pr)|pr ? PRp} 6: if properties ? PRpnext ?= ? then 7: return false 8: end if 9: end if 10: return true 11: end function 12: 13: function ISUNIFIABLE(p, pnext) 14: if |{e|e ? E ? p is head of e}| = 1 then 15: return false ? p has multiple outputs.

16: else if pbp ? pbpnext ?= ? then 17: return false ? There is no common pb.

18: end if 19: return true 20: end function  Theorem 3 (Order sensitivity regardingM): the relationship involvingMC is order-sensitive.

Proof: We assume an arbitrary operator op ? OP for the next operator of MC where input data are d1 and d2.

Then,  op(MC(d1, d2)) ?= op ?MC(d1, d2), (11)  op(MC(d1, d2)) ?=MC(op(d1), op(d2)), (12)  because, in both equations, the left side applies op to combined d1 and d2 data, whereas the right side applies op to d1 and d2 data separately.

We assume arbitrary operators op1, op2 ? OP for the  previous operators ofMC(d1, d2) where op1 is applied only to d1, and op2 is applied only to d2. Then,  MC(op1(d1), op2(d2)) ?= op1 ? op2 ?MC(d1, d2), (13)  MC(op1(d1), op2(d2)) ?= op1 ? op2(MC(d1, d2)), (14)  because, in both equations, the left side applies op1 only to d1 and applies op2 only to d2, whereas the right side applies both op1 and op2 to the combined d1 and d2 data.

We can find a comprehensive rule of order sensitivity from the above. This rule is defined as follows.

Definition 2 (Comprehensive order sensitivity rule):  only the relationship among ?, ? and X is NOT order- sensitive. The exception is XF1,???,Fk,f , where the field F+ derived from f(F1, ? ? ? , Fk) is used by the next operator.

????????	 ????????  ????????   ???	???  ????????  ??????? ??	? ???????????????	????? ?????????????  ??	??????????????? ????? ????!????  ????"#$%%?&%$%% ?????'?????????????'? ??	(???)*?  Figure 4. DFD of a virtual case for a coupon service using event data from an electronic ticket system.

C. Essentially inapplicable cases Multi-query unification is essentially inapplicable to the  processes described below.

? Processes having multiple outputs cannot be unified with the next processes because multiple queries that are processed concurrently cannot be described as a unified query. We can detect processes that have mul- tiple outputs by counting the number of directed edges where the process is the head.

? Processes NOT having common processing behavior cannot be unified because the DSL syntax is different in each processing engine, and the syntax is incompatible.

D. Implementation of unification In accordance with the criteria described above, we need  to confirm if a process can be unified. This confirmation function is performed using Algorithm 1. Let pnext be the next process of an arbitrary process p in a DFD. For two processes p and pnext, clause assembly is applicable if and only if both ISORDERINSENSITIVE(p, pnext) and ISUNIFIABLE(p, pnext) are true, and nesting is applicable if and only if ISUNIFIABLE(p, pnext) is true.

We can specify the type of operator executing a number  of string retrievals from their clause templates. Multi-query unification can easily be implemented using a number of string operations to schemata, process properties and clause templates descriptors.



V. EXPERIMENTAL RESULTS We performed an experiment to confirm the reduction of  data transmission execution time by applying the multi-query unification described in Section III using a virtual DFD.

We used Madras to create a virtual case for a coupon  service using event data from an electronic ticket system.

Table II shows the schema of ?Ticket Event? that is the event data processed by the DFD. Table III shows the EPL queries of the processes in the DFD. Except for the last ?Send Coupon? process, the DFD processes of the virtual case shown in Figure 4 could be transformed into both CDP and DSP components. The ?Send Coupon? process is a core coupon service that sends a coupon to the email address correspondent to the user ID in the event data selected by  Table II SCHEMA OF Ticket Event.

field type description userid String User?s ID station String Station?s ID evtype Integer Type of the event date Long Date in milliseconds gender Integer Male=1, Female=2  previous processes and is implemented as a web application that is neither CDP nor DSP. In the experiment, we set all the processes either CDP or DSP and prepared nine data sets with up to 1,000,000 events for CDP and five data sets with up to 50,000 events for DSP.

To exclude the component initialization time, we defined  the measurement of the execution time as follows. The execution time for CDP was defined as the time between the arrival time of the first event in the first process and the arrival time of the last event in the last process. The execution time for DSP was defined as the time between the first events arrival and the last event of the last process, ?Send Coupon? storing all of the input event data into the first queue, ?Ticket Event.? In the experiment, we used Apache Velocity7 to generate  the queries and components from the DFD and created the necessary clause and component templates in advance.

The only goal of the experiment was to evaluate how  multi-query unification reduced execution time. We used a PC (Intel Core i5 2.67GHz with 4GB memory) with per- formance capability sufficient to execute the experiment. In this paper, we do not assess the length of the execution time relative to the performance of the experimental environment.

A. Overall reduction effect of multi-query unification We measured the execution time before and after applying  two-stage unification. We conducted three execution time measurements using the same data set and calculated the average execution time.

Figure 5 shows the execution time measurements. Figure  5(a) shows the times for CDP using Hive, and Figure 5(b) shows the execution times for DSP using Esper. Table V  7http://velocity.apache.org/     Table III EPL QUERIES OF THE PROCESSES IN THE DFD.

process query Pick Users Getting Off At The Station  q1(?) = select * from TicketEvent where station = "1" Convert Date-time For- mat  q2(?) = select *, (Math.floor(date / 3600000) % 24) * 3600000 as time from TicketEvent2  Pick Males q3(?) = select * from TicketEvent3 where gender = 1 Pick 18:00-20:00 q4(?) = select * from TicketEvent4 where 72000000 > time and time > 64800000 Select User ID q5(?) = select userid from TicketEvent5  Table IV EPL QUERIES UNIFIED BY EACH UNIFICATION METHOD.

method query Two-stage q4 ? q5(q1 ? q2 ? q3(?)) = insert into TicketEvent4 select *, (Math.floor(date / 3600000) % 24)  * 3600000 as time from TicketEvent where station = "1" and gender = 1; select userid from TicketEvent4 where 72000000 > time and time >  Nesting q5(q4(q3(q2(q1(?))))) = insert into TicketEvent2 select * from TicketEvent where station = "1"; insert into TicketEvent3 select *, (Math.floor(date / 3600000) % 24) * 3600000 as time from TicketEvent2; insert into TicketEvent4 select * from TicketEvent3 where gender = 1; insert into TicketEvent5 select * from TicketEvent4 where 72000000 > time and time > 64800000; select userid from TicketEvent5  shows the average quotients of reduction of execution time for each data set.

Table IV shows the EPL query unified by two-stage unifi-  cation. In two-stage unification, clause assembly generated two unified queries. The first included ?Pick Users Getting Off At The Station,? ?Convert Date-time Format,? and ?Pick Male.? The second included ?Pick 18:00-20:00? and ?Select User ID.? Then, nesting unification generated a unified query that embedded the first clause-assembled unified query into the second clause-assembled unified query.

We found that applying two-stage unification reduced the  execution time by 60 percent for DSP but only reduced CDP by 10 percent.

B. Change of reduction effect with and without application of clause assembly We measured the execution time solely for nesting  unification to evaluate the effect of clause assembly by comparing the results from nesting unification with two- stage unification. Consistent with the conditions given in the previous section, let the execution time be the average of three measurements using the same data set. We also measured the execution time without multi-query unification because the contents of the data set were different from the data set measured in the previous section.

Figure 6 shows the execution time measurements. Figure  6(a) shows the times for CDP using Hive, and Figure 6(b) shows the execution times for DSP using Esper. Table V shows the average quotients of reduction of execution time for each data set.

Table IV shows the EPL query unified by nesting unifica- tion. Nesting unification generated a unified query involving all processes between ?Pick Users Getting Off At The Station? and ?Select User ID.? The unified query had four- stage nesting.

We found that applying nesting unification alone reduced  the execution time by 30 percent for CDP and 35 percent for DSP.

C. Discussion  In CDP using Hive, data transmission was performed by file delivery on the HDFS. Multistage Map and Reduce processing in Hive was produced from a HiveQL query [2]. Temporary data was generated between each processing stage. We believe that the execution time reduction effect with multi-query unification in CDP was generally smaller than in DSP because the number of file deliveries did not decrease regardless of whether or not multi-query unification was applied. However, the execution time reduction when only nesting unification was applied was higher than when two-stage unification was applied. We consider this was be- cause query optimization of Hive results in a more efficient multistage nesting query than the complex query generated by clause assembly.

For DSP using Esper, data transmissions between com-  ponents were implemented using a message queue service.

Regardless of whether or not clause assembly was applied, the DFD shown in Figure 4 was eventually transformed into a unified component involving all processes for ?Pick     %  &%%  +%%  ,%%  #%%  "%%%  "&%%  % &%%-%%% +%%-%%% ,%%-%%% #%%-%%% "-%%%-%%%  ?? ?? ?? ?  ? ???  ?? ? ?  ??	????? ??  ???)	????( ?.???????  (a) CDP using Hive.

%  &%  +%  ,%  #%  "%%  "&%  % "%-%%% &%-%%% /%-%%% +%-%%% 0%-%%% ,%-%%%  ?? ?? ?? ?  ? ???  ?? ? ?  ??	????? ??  ???)	????( ?.???????  (b) DSP using Esper.

Figure 5. Execution time of the components applying two-stage unification.

%  &%%  +%%  ,%%  #%%  "%%%  "&%%  % &%%-%%% +%%-%%% ,%%-%%% #%%-%%% "-%%%-%%%  ?? ?? ?? ?  ? ???  ? ??  ??	????? ??  ???)	????( ????	?  (a) CDP using Hive.

%  &%  +%  ,%  #%  "%%  "&%  % "%-%%% &%-%%% /%-%%% +%-%%% 0%-%%% ,%-%%%  ?? ?? ?? ?  ? ???  ? ??  ??	????? ??  ???)	????( ????	?  (b) DSP using Esper.

Figure 6. Execution time of the components applying nesting unification.

Users Getting Off At The Station? and ?Select User ID.? The number of message queues decreased from six to two.

Because the quotient of execution time reduction for DSP is high, we consider that reducing the number of message queues had a positive effect on execution time.

When applying nesting to DSP using Esper, event data  was temporarily stored in PC memory, creating an internal stream by positioning INSERT INTO clause at the begin- ning of the query. We believe that clause assembly had a positive effect on execution time reduction in DSP because the number of data transmissions in memory was increased.

In light of the above results, the effect of clause assembly  differs between CDP and DSP. Consequently, it is reasonable to conclude that nesting unification should be applied to CDP and two-stage unification should be applied to DSP.



VI. RELATED WORK Query optimization [9] is a technique that optimizes  a query execution plan on a processing engine, such as a database management system. Multi-query optimization [10], [11] is a technique that optimizes execution plans for multiple queries arriving at a processing engine si- multaneously. Multi-query unification is a technique that unifies sequentially-processed queries to generate unified  Table V QUOTIENT OF THE REDUCTION OF EXECUTION TIME.

CDP DSP Two-stage 0.108 0.600 Nesting 0.299 0.345  components. Multi-query unification works outside a pro- cessing engine, whereas query optimization works within a processing engine. Therefore, we can use multi-query unification in combination with query optimization or multi- query optimization.

There are several query transformation methods that work  outside a processing engine. Yang et al. [12] proposed a query transformation method that defines multiple queries in relation to members that transform themselves to enable calculation from pre-calculated relationships. Ahmed et al.

[13] proposed a method that extracts subqueries to reduce processing engine execution time. However, unlike multi- query unification, these methods do not reduce the number of generated components.

Several methods to facilitate the creation and execution  of queries in a development environment have also been     reported. Peterson et al. [14] proposed a method that facili- tates the creation of a query by providing an editor that can combine templates for each clause of a query. Ahmed et al.

[15] proposed a method that reuses the processing results of part of a query by dividing the query into several blocks.

There are various commercial products for CEP development environments that adopt DFDs to create queries. Products such as StreamBase [6], Sybase [5], and Oracle CEP [4] can create queries using primitive operations, such as Pro- jection, Selection and Join in a DFD. Moreover, Oracle CEP provides an editor that enables the creation of an application by composing queries during editing. However, in these environments, components are created for each query, and consequently significant data transmission overhead persists.

None of these products provides a solution for this problem.



VII. CONCLUSIONS This paper proposed multi-query unification, a technique  for generating unified components from a DFD aimed at reducing the total cost of data transmission between compo- nents. We described three unifiation methods that constitute multi-query unification.

Nesting unification composes a unified query by embed-  ding the query of a process into the query of the next process as a subquery. Clause assembly unification composes a query using templates for each clause of the original query.

For clause assembly is applicable only to processes that is executable simultaneously, we defined the criteria called order sensitivity for applying clause assembly and proposed two-stage unification in which nesting unification is always applied after clause assembly.

In this paper, we assumed query languages that have  similar syntax to Structured Query Language (SQL) to discribe the methods. However, we consider that multi- query unification is applicable to various query languages that implement a close approximation of relational algebra even without SQL-like syntax. Moreover, we believe that generalization of component unification from multi-query unification is even possible by clarifying order sensitivity between processes that utilize various technologies such as NoSQL and other unstructured databases.

The performance evaluation based on a virtual DFD shows  that applying two-stage unification reduces the execution time of components by 60 percent in DSP; however, exe- cution time is reduced by only 10 percent in CDP. On the other hand, nesting unification alone reduces the execution time by 30 percent. Based on those results, we conclude that clause assembly should be applied to DSP using Esper but should not be applied to CDP using Hive.

In two-stage unification, clause assembly can reduce the  number of nesting operations. Deciding whether or not it is appropriate to use clause assembly must take processing engines into consideration because processing engines treat subqueries differently. We believe that, when using Hive, this issue arises because of incompatibility between clause assembly and query optimization; however, we do not con- firm or verify this assumption in this paper. Therefore, future  work will attempt to verify this assumption and improve the proposed method to achieve higher query optimization compatibility.

