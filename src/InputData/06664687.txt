Connected Components for a Fast and Robust 2D Lidar Data Segmentation

Abstract?The paper presents a novel segmentation ap- proach applied to a two-dimensional point-cloud extracted by a LIDAR device. The most common approaches perform well in outdoor environments where usually furniture and other objects are rather big and are composed of smooth surfaces.

However, these methods fail to segment uneven, rough surfaces.

In this paper we propose a novel range data segmentation algorithm that is based on the popular one-pass version of the Connected Components algorithm. Our algorithm outper- forms most commonly used approaches, while keeping the low computational complexity. The algorithm is used as a part of control and perception system in our unmanned ground vehicle where real-time response time is required. We presented experimental results obtained indoors and outdoors. The latter experiment was conducted in the real test field while the vehicle was autonomously driven.

Keywords- 2D Lidar Segmentation; Connected Component; Intelligent Vehicles; Point-cloud analysis; Unmanned Ground Vehicle;

I. INTRODUCTION  In the past decade or so the rapid growth of robotics and particularly increasing popularity of autonomous vehicles opened up new areas of applications of LIght Detecting And Ranging (LIDAR) devices. LIDAR is a remote sensing tech- nology that allows measuring distances by emitting a laser beam and analyzing light reflected by the object. LIDAR technology is known to be accurate and the measurements can be obtained at a high frequency. These are the reasons why LIDAR technology is found to be useful in various robotics fields. Nevertheless, the field of unmanned ground vehicles (UGV) that is a sub-field of robotics brings its spe- cific requirements to range data analysis. These requirements include fast processing, accurate and reliable performance.

In this paper we focus on the segmentation task. LIDAR data segmentation is a necessary part in many tasks such as obstacle detection and object detection/recognition.

A number algorithms have been reported in the area of range data segmentation [1] [2] [3]. However, most of them focus on 3D data analysis. Nevertheless, some of the reported works employ 2D data segmentation for car detection and tracking. The authors of [4] implemented a general approach based on the idea that beams reflected from the same object have similar distances. We investigated  Figure 1: This image illustrates a single layer LIDAR. In this image, each point p(i)l is defined by the distance to the device ?(i) and an angle ?(i).

this approach by calculating distances between consecutive points. This approach generates artifacts that make this technique unacceptable in some UGV applications.

The contribution of this paper consists proposing a sim- ple yet fast and accurate segmentation algorithm. We also overviewing the most common approaches for 2D data seg- mentation and compare them with the proposed algorithm.

The remainder of this paper is organized as follows: Section II gives an introduction to the problem and discusses the most common approaches and their limitations. Section III describes the proposed algorithm and its implementation.

Section IV presents the experimental results and comparison analysis. In section V we give concluding remarks and briefly describe future directions of our work.



II. LITERATURE OVERVIEW  Before we proceed with the description of the proposed algorithm it is important to review the functional principles of the sensor and show some of the issues of commonly used segmentation approaches.

The LIDAR device consists of a laser and a mirror or a set or mirrors that are constantly rotating within the device.

The mirror reflects the laser beam and then the sensor measures how far photons have travelled round-trip. The device returns an array of distances ?(i) from the laser to the  2013 7th Asia Modelling Symposium  DOI 10.1109/AMS.2013.31   2013 7th Asia Modelling Symposium  DOI 10.1109/AMS.2013.31   2013 7th Asia Modelling Symposium  DOI 10.1109/AMS.2013.31   2013 7th Asia Modelling Symposium  DOI 10.1109/AMS.2013.31     object that reflected the beam. The array index corresponds to the angle of the mirror that varies in the range of [??, ?].

The range of angles is divide into intervals of ??. A general representation of one of these devices in shown in fig. 1.

Due to the nature of these devices, the absolute value of the differences of consecutive ? distances |?d?(p(i)l , p(i+1)l )| between a LIDAR point p(i)l with a distance ?  (i) for an angle ?(i) and the consecutive point p(i+1)l with a distance ?  (i+1)  for an angle ?(i+1) = ?(i) +?? should be close to 0 for all the points that lie on the same object [4].

If the absolute value of the difference of the distances between two consecutive laser points is less than some certain threshold ?dth, these two points are assigned to the same object. Otherwise, the point is associated with a new object.

We have implemented and experimented with the above- described approach. Figure 2 shows the differences of distances calculated for consecutive points. The blue line represents the differences for the ? distances between two conductive points in polar coordinates (i.e ?(i) and ?(i+1)).

The back line shows the differences of the Euclidian dis- tances from one point p(i)C to next one p  (i+1) C . The points first  were converted from polar coordinate system to Cartesian coordinates The green line shows the differences of the Euclidian distances of one point p(i)C to its nearest neighbor in the Cartesian plane. Lastly, the red line shows the ? values of each laser beam. These values have been normalized in order to fit them in the same graph. Hence, in this graph we can see a high response of the differences of the distances every time there is a gab between objects. in ? (red line).

As it can be seen from the figure 5a the segmentation based on comparing the differences in ? can fail to seg- ment any object with an uneven surface. For example this approach will fail to segment a fence made of bars. The bars will reflect some of the beams while other beams will penetrate through the fence making each bar labeled separately as a different object.

The solution that could resolve this problem consists is applying clustering algorithms. However, to apply clustering algorithms we have to know the number of clusters in advance. K-means clustering algorithm is an example of such algorithm. In reality the number of cluster is not given.

Nevertheless there are clustering algorithms that do not require knowing the number of clusters in advance. One of them is Fast-RNN [5]. Unfortunately, Fast-RNN has a complexity of O(n2). Moreover, as it is seen in figure 6a Fast-RNN does not provide good clustering.



III. PROPOSED MODEL  One of the most essential algorithms in pattern recognition and image processing is the Connected Components (CC) algorithm [6]. The purpose of the CC algorithm is to transform the input binary image, into a symbolic image  0 200 400 600 800 1000 1200  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  Lidar points     drho rho NN distance Next distance  Figure 2: This graph shows the responses of the differences of the distances to consecutive points. The blue line represent the difference operator applied directly to the ??s values from the laser. The green line shows the difference of the Euclid- ian distances from a point p(i)C to its nearest neighbor. The black line shows the difference of the Euclidian distances from the point p(i)C to the point p  (i+1) C . Lastly the red line  shows the ? values from the laser.

Figure 3: The left part of the figure shows an example of a binary image. The right side shows a result of the labeling process using CC.

where each connected component will have a unique label (see figure 3).

We extend the CC algorithm from labeling binary images to segmentation of 2D LIDAR data by firstly preprocessing LIDAR data. The data returned by LIDAR is represented as an array of k 2D points. The index of the array corresponds to the angle ?i and the value is the distance to the object along the beam emitted in the direction of the angle ?i.

Before applying the CC algorithm, the points should be converted to Cartesian coordinate system. Then points are projected onto occupancy grid. This grid is treated as a binary image and used for labeling. The whole process is summarized as follows:  1) Convert all the input points pl (originally in polar coordinates) to points pC in Cartesian coordinates.

2) Discretize the obtained Cartesian values     Figure 4: The diagram shows the segmentation flow of the range data obtained by the LIDAR. Polar Array contains the raw data obtained by the laser and is shown in red. Cartesian Point List is a linked list that is a structure that holds all the unlabeled points in Cartesian coordinates. Map is a m ? n occupancy grid which is used as an input data for connected component analysis. Finally, Label Array is an array which contains the labels of the input point-cloud.

3) Project all the 2D points onto an occupancy grid.

4) Find connected component over the grid.

5) Return labels.

The following formula is used to convert the raw data represented in polar coordinates, to a Cartesian coordinate system:  p(i)c = ? (i)[cos(?(i)) sin(?(i))]T . (1)  The dimensions (m and n) of the grid are calculated as follows:  m = range max  s , (2)  n = 2 range max  s . (3)  Where s is a scale factor that defines the size of each bin of the map. Therefore, we get a grid of m ? n bins. Thus, each bin can be thought as a portion of a real word with a constant size that can have 0 or k points of the scan. By putting all together, the grid is treated as a binary image, where we can consider each bin as a pixel that can have two values, 0 or 1 depending if it has points inside or not.

During the labeling process a bin can have one of two states, activated and deactivated depending on whether that bin has been considered for labeling or not. The process of filling up of the occupancy grid given by  x = x(i)  s + lx, (4)  y = y(i)  s 2d+ ly. (5)  Algorithm 1 Proposed Labeling Algorithm.

1: procedure CCLABELING(map, unlabelDataList) 2: labelsV ector ? zeros(length(unlabelDataList)) 3: currLabel? 0 4: while length(unlabelDataList) > 0 do 5: point? unlabelData.first() 6: unlabelData.pop front() 7: point2LabelList ADD point 8: repeat 9: point2Label? point2LabelList.first()  10: point2LabelList.pop front() 11: nh? getNeighbourhood(point2Label) 12: deactivateBins(map, point2Label) 13: deactivateBins(map, nh) 14: point2LabelList ADD nh 15: labelsV ector ? labelPoint(point2Label) 16: until length(point2LabelList) = 0 17: currLabel? currLabel + 1 18: end while 19: return labelsV ector 20: end procedure  Where x(i) and y(i) are the x and y of the point p(i)C and lx and ly are the x and y coordinate where the LIDAR is placed on the map.

After we filled up the occupancy grid, we are able to apply CC to the obtained grid. There are several versions of the algorithm: one pass [7], two passes [8]. There are server ways to decrease the computational by using complex data structures such as binary trees (e.g. [9]). Such algorithms are able to can reach a constant execution time regardless of the number of pixels. However, for our specific model, we propose a new single pass version of this algorithm that     ?3 ?2 ?1 0 1 2 3         (a) This image show the result of a segmentation based on the most common approaches that rely on difference of ?.

?3 ?2 ?1 0 1 2 3         (b) This plot shows the results of the proposed algo- rithm.

Figure 5: This figure shows a comparison results between the approach based on the difference of the ? distances and the proposed algorithm of this paper based on Connected Components algorithm. In both images, the laser is located in the position (0, 0) which is represented by a triangle. As we can appreciate, (a) presents some artifacts like dividing some object that should not be divided, or by joining other that should be sparse. In contrast, we can see in (b) how our algorithm do not divide the object that are clearly just one object while it can separate in a better way those objects that are not connected.

?2 ?1.5 ?1 ?0.5 0 0.5 1 1.5 ?1        (a) This figure shows the results of a data segmentation done by the algorithm Fast-RNN.

?2 ?1.5 ?1 ?0.5 0 0.5 1 1.5 ?1        (b) This graph shows the results of the algorithm proposed in this paper.

Figure 6: This figure shows a comparison between the clustering algorithm Fast-RNN and our method. In both images, the laser is represented by a triangle which is located in the (0, 0) position. In the image (a) we can see how this algorithm has the problem that divides the long surfaces, like in the right wall, into different clusters while in (b) this the effect is not as pronounced.

can run with an O(n) complexity.

The pseudo-code of our Connected Components algorithm is give in 1. Due to the fact that we have a list of points, we can bypass the grid scanning and directly jump into labeling.

Hence, just taking the first point of our list of points or just by choosing one randomly we can start to label. By taking a bin that is activated and occupied, we assign the current label to all of the points that fall into that bin. Then, we deactivate it and begin to expand the labeling process to the neighbor bins in a 4-connected or 8-connected version.

When there are no activated bins left to expand, we will  increase the label, by choosing a point that has not being labeled yet, then the previous process in repeated until all the points are labeled.

Implementation Details  The above-descried algorithm runs in a linear time due to the fact that we know the locations of all the points in the grid from the beginning, so we achieved on average a rate of 238 segmentations per second. The figure 4 shows the data structures that we is used in the implementation. In order to make it fast and efficient in memory we are handling 4 data     (a) Obstacle avoidance. (b) Car detection. (c) Pedestrian detection.

?30 ?20 ?10 0 10 20 30 40 50 ?5           (d) Obstacle avoidance.

?60 ?50 ?40 ?30 ?20 ?10 0 10 20  ?5           (e) Car detection.

?25 ?20 ?15 ?10 ?5 0 5 10 15  ?10         (f) Pedestrian detection.

Figure 7: This image shows the results of the proposed algorithm in a real application for an autonomous vehicle. The first row shows the contextual information which is provided by a conventional camera, while the second row shows the segmentation results. In each graph of the second row, each group is represented by a color. The position of the lidar device is always placed at (0, 0) position and it is represented by a triangle.

structures at once. The first data structure is the raw input data from the LIDAR (represented by red the red color).

This array contains all the pl points from the LIDAR sorted from ?? to ?. This gives us a rigid data structure that will define the size of the output. The second data structure is a list that contains all the pC points. This structure is just a linked list that points into the occupancy grid. Each bin in the grid is a data structure that points to the elements pC , plus can hold two states, activated or deactivated. These two states allow us to avoid the labeling the points that has been already labeled. Therefore, the relationship between pC and the map is bidirectional. In contrast, the relationship between pl and pC is in one direction as pl is not modified or accessed again.



IV. EXPERIMENTS  This section devoted to experimental analysis of the proposed algorithm. We analyze the quality of the pro- posed algorithm by comparing segmentation results with the above-described algorithms. The labeling obtained for the data extracted indoors and outdoors.

In both experimental setups we used a Sick lms511 pro device, that provides a maximum of 1141 points for a single scan and runs at 25Hz. The algorithm was running on the  Intel Core i7-3820 CPU at 3.60GHz.

A. Indoors experiments  The LIDAR device was placed on a table of our lab (see image 8) facing various obejcts. The scale factor s that we used in order to build up the occupancy grid is 10cm.

The segmentation performance for indoors environment is shown in the figure 5b. The point-cloud that is used for la- beling is exactly the same as the one shown in the figure 5a.

It is visually easy to see that our algorithm based on CC has a better capability to properly segment the data into different object that segments that belongs to different objects. On the other hand the other method does not separate well some clearly defined object. Comparing the segmentation results obtained by the proposed algorithm (figure 6b), against the results produced by Fast-RNN algorithm (figure 6a) it is easy to see how our algorithm preserves the same label even for long and thin objects simultaneously well separating objects that are not connected.

B. Outdoor Experiments  The purpose of developing our algorithm was to create a method that provides robust and fast laser data segmentation for an autonomous vehicle perception system. Therefore, in     (a) View from lidar. (b) Laboratory hardware setup.

Figure 8: This two images are shown for a better under- standing of the scans of our lab.

Figure 9: This graph shows a numerical comparison between the algorithm based on the ? differences (Diff), Fast-RNN and the proposed method (CC)) with respect a handmade ground truth. The first column (Lab1) corresponds with the scan displayed on 5, the second one (Lab2) corresponds with 6 and finally the third, fourth and fifth (Car1, Car2 and Car3), corresponds to 7 (d), (e) and (f) respectively.

this subsection we show some of the results obtained in the real outdoors environment.

We attached the LIDAR to the front bumper of our vehicle, placed in the middle of the bumper at 50cm above the ground. To provide contextual information for this exper- iment we synchronized LIDAR with a camera located inside of the vehicle. The scale factor s was fixed to 30cm. The figure 7 shows segmentation of the laser data into a number clusters. It can be see that most of the objects are correctly labeled. The segmentation time of one-scan takes on average about 0.0042 seconds; which is about 238 segmentations per second.

Finally, in order to show some numerical results (figure 9), on the performance of our algorithm, we measured the segmentation accuracy of each discussed algorithm by comparing them to hand-segmented maps. Our algorithm outperformed other algorithms in most of the tests except Car1. The reason why our algorithm underperformed is a large amount of noise on the right side of the scan that is labeled as many independent objects.



V. CONCLUSION  In this paper, we have presented a 2D point-cloud seg- mentation algorithm. We showed that algorithm outperforms the common 2D point-cloud segmentation approaches. We have compared the quality of segmentation and the compu- tational time of our algorithm and the other segmentation approaches, based on the range data obtained indoors and outdoors. Discretizing the space, mapping the point-cloud onto a grid and then applying an efficient data structure that is used in Connected Components analysis achieves such good performance.

We are planning to extend the proposed algorithm by creating a non-equal cell sized grid. The cell size should depend on the distance to the points. The points located closer to the sensor are more densely distributed. Moreover, there is more uncertainty for the points located farther away from the sensor. The larger cell size will take into account such uncertainty.

