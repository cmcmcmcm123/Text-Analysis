Suffix Tree Clustering with Named Entity  Recognition

Abstract?The news searching is challengeable in providing web users with clear and readable lists of news reports. This paper proposes the Suffix Tree Clustering with Named Entity Recognition (STC-NER). STC-NER is supposed to cluster news searching results returned by the search engine. STC-NER uses the snippets returned from the searching results and then derives patterned information by means of named entity recognition.

STC-NER makes a great contribute to the reduction of storage as well as the time complexity. Experiments show that STC-NER has a better performance in precision and efficiency than the traditional Suffix Tree Clustering (STC).

KeyWords?suffix Tree; clustering; news reports; named entity  recognition

I. INTRODUCTION  As is known to all that news reporting has become the main competition between web portals. Nowadays, the search engines also take part and break out a fierce competition. A survey [1] made by Nielsen/ NetRatings shows that news browsing and searching has become one of the important online activities. There are many commercial News search engines. Google News retrieves news information by more than 4,000 sources, organizes it in categories and automatically builds a Web page with the most important news for each category. Yahoo News runs an analogous service on more than 5,000 sources [2]. The advantages of online news searching are timeliness and richness. The disadvantage is that the search engine goes through all the web pages and returns reduplicative news reports, which in turn increases the burden on users.

News searching results need to be clustered before presented to the user. Clustering news reports searching results facilitates users browsing through search results more quickly and provides a better access to the information users are looking for.

Document clustering is a special data clustering technique that clusters a document collection into meaningful sub-collections. The documents in each sub-collection are highly related (in some sense) to each other and vastly different (in the same sense) to the documents placed in other sub-collections [ 3 ]. Document clustering has long been investigated as a post-retrieval document visualization technique [4]. Among them K-means [5] clustering algorithm based on Vector Space Model (VSM) [6] is a classic algorithm and it has a wide range of application in scientific fields, for example, digital image processing, data mining, medical researches. However, the K-means clustering algorithm has its limits in document clustering, because it treats documents as bags of words, ignoring word sequences in the documents, on which the meaning of natural languages strongly depends [7].

The biggest shortcoming of K-means clustering algorithm is that it needs a stop-condition, specifically, the value of K.

What?s more, K-means clustering algorithm has a restriction that each text be included in just one cluster, regardless of the possibility that one text may contain multiple subjects.

The Suffix Tree Clustering (STC) [8] algorithm proposed by Zamir and Etzioni gave a good solution on these issues.

There are two reasons why we study suffix tree model and STC. Firstly, this algorithm identifies sets of documents that share common phrases extracted from the snippets and treats a document as a set of words and is appropriate to Chinese document clustering. Secondly, one or several phrases are naturally selected to generate a topic summary to label the corresponding cluster during building the clusters [9].

STC is an incremental clustering algorithm and its time complexity is linear with regard to the document size [10]. A conventional STC algorithm construct a suffix tree model with documents and then clusters those documents by analyzing nodes in the model. We made some improvements to STC to   DOI 10.1109/CLOUDCOM-ASIA.2013.102    DOI 10.1109/CLOUDCOM-ASIA.2013.102         make it more suitable in clustering Chinese news searching results.

The unique feature of a news report is that it consists of certain elements, i.e. time, location, character and event. A method called Named Entity Recognition [11] can extract these elements in news reports. Named entities are phrases that contain the names of persons, organizations, locations, times and quantities [ 12 ]. The main task of Named Entity Recognition is to identify and classify Proper Nouns as well as meaningful phrases. In this paper we concentrate on four types of named entities: names of organizations, names of individuals, names of places, time expressions. By identifying these elements in each news report, we extract patterned information. These derived information then assemble a new document to replace the original one. This process is achieved by using a lexical tool for Chinese language named Natural Language Processing & Information Retrieval (NLPIR), which is also called Institute of Computing Technology, Chinese Lexical Analysis System 2013 (ICTCLAS2013)[13]. NLPIR is also an appropriate and necessary tool to implement word segmentation and POS tagging (part-of-speech tagging) [14].

The precision of word segmentation reaches as high as 97.58%; the recall rate of unknown words recognition exceeds 90% as well. NLPIR integrates word segmentation, POS tagging, which makes it a superior in terms of practicalness and precision.



II. SUFFIX TREE MODEL AND STC ALGORITHM  Zamir and Etzioni gave a good analysis on document clustering with STC algorithm. For example, the algorithm should take the document snippets instead of the whole documents as input, since the downloading of original documents is time-consuming; the clustering algorithm should be fast enough for online calculation; and the generated clusters should have readable descriptions for quick browsing by users, etc.[15] The conventional STC algorithm has five steps as following:  A. Preprocessing of documents The document snippets are retrieved from search engine  and make up the textual sources. Sentences are then identified and split into strings of words. During this process, stop words and symbols are removed.

B. Building a Suffix Tree Model Build a Suffix Tree Mode by inserting the strings  associated with each document into it. A suffix tree is a data structure that presents the suffixes of a given string in a way that allows for a particularly fast implementation of many important string operations. The suffix tree for a string S is a tree whose edges are labeled with strings, and such that each suffix of S corresponds to exactly one path from the tree's root to a leaf. It is thus a radix tree (more specifically, a Patriciatrie) for the suffixes of S [16].

Here is an example of construction of Suffix Tree Model with a set of documents: ?cat ate cheese?, ?mouse ate cheese too? and ?cat ate mouse too?.

Fig. 1 illustrates a Suffix Tree, which is constructed with these 3 documents.

Fig. 1.  Suffix Tree of three documents  The label below a leaf node shows where the substring comes from. The first number in the squared label is the index of documents. The second number in the label is the start point of the substring in its original string.

C. Merging base clusters Once the suffix tree has been built, each node on the suffix  tree that contains multiple documents can be considered a base cluster. To reduce the number of clusters, base clusters are merged according to the following steps.

Firstly, calculate the similarity value between two  base clusters according to a certain algorithm. Base clusters are merged if the similarity value is 1. Given two base clusters Bm and Bn, the number of documents each base cluster has are |Bm| and |Bn|, |Bm ??Bn| is the overlap of their documents set.

If: ??? ?? ???? ???? ? and ??? ?? ???? ???? ?  Then: set the similarity value of these two base  clusters????and ???to 1; Else: set the similarity value to 0;  Where ? is the threshold, which value is settled between 0 and 1. The conventional algorithm is: while two base clusters are merged, these two base clusters are connected logically.

These connected base clusters then form a base cluster graph, from which the final clustering result is derived. Fig. 2 illustrates a base cluster graph of these 3 documents, each node represent a base cluster in the suffix tree.

Fig. 2.  A base clusters graph  D. Acquiring clusters A cluster is defined as being a connected component in the  base cluster graph. Each cluster contains the all the documents of all its base clusters. It can be implied that a document may emerge in different clusters simultaneously, which is an instance of soft-clustering.

It is obviously that STC prefers to cluster text documents, other than numeric data. As the time complexity of this algorithm is linear with regard to the document size, the original document should be refined to reduce the complexity and time consummation of the clustering processing.



III. STC-NER  The distinctive methodology of the Suffix Tree Clustering with Named Entity Recognition (STC-NER) algorithm is that the input data of the algorithm is documents of name entities extracted from snippets of news searching results. This helps to simplify the documents. As the conventional method to construct a suffix tree with a document of m words takes ???? time, it is obviously that the size of document can affect the efficiency of STC algorithm on a large scale.

In this paper, we make some improvements on the procedures of preprocessing and merging base clusters. And due to the special feature of news reports, we add a procedure called named entities extraction after the word segmentation to refine the documents before clustering.

Here we also improve the suffix tree model to make it easier to build and operate during the clustering algorithm.

Fig. 3 shows the framework of STC-NER.

Fig. 3.  Framework of STC-NER  A. Preprocessing with Chinese documents The STC is proposed based on English web page. But the  STC-NER in this paper aims at clustering news reports written in Chinese. The English written language is composed of words between which there are nature segmentations such as space character. Thus it is not difficult for the computer to analyze, understand and manipulate English written language.

The Chinese written language, to the contrary, has no segmentation of any kind between words, which makes it hard for the computer recognition processing [17]. To the computer, Chinese written language is a string made up of Chinese characters and punctuations. Characters make up words, words make up phrases, phrases make up sentence, and then other language structures like paragraphs, chapters and sections. But not all the words are meaningful; these indistinctive words are called stop words, which are frequently occurring, insignificant words that appear in the documents. They are useless to index or use in search engines or other search indexes. Stopwords lists and stemming algorithms are two commonly used information retrieval techniques for preparing text document [9]. We hold a list of 842 stop words to filter out these meaningless words.

Expressing a document in a simple and accurate way is the purpose of preprocessing. Preprocessing includes automatic word segmentation, removing punctuations and stop words, POS tagging and key words extraction [18]. Due to the special characteristic of news reports, we deploy named entity extraction within the process of preprocessing, to reduce the size of documents.

1) Word segmentation Word segmentation is the first priority in preprocessing; it  splits a sentence written in Chinese into words or phrases by their meanings. After the word segmentation, stop words and symbols are removed and the left words are regarded as meaningful ones. In order to put these words into different categories (or Name Entities), POS tagging (part-of-speech tagging) [14] is also a necessity. We use the open source lexical tool NLPIR (or ICTCLAS2013) [1313] to implement word segmentation and POS tagging. The tags that we concern are: ?/t? for time, ?/ns? for China, ?/nsf? for foreign countries, ?/nr? for names of people, ?/nt? for names of organizations, ?/n? for nouns and ?/v? for verbs. Among them, words with tags of ?/t?, ?/ns?, ?/nsf?, ?/nr?, ?/nt? are extracted as named         entities, in other words, basic elements in news reports. Other words with tags of ?/n? and ?/v? are also extracted in sequences.

2) Named entities extraction In the field of news reporting, the basic elements are: time,  location, character and event, so it is very convenient for us to apply Name Entity Recognition to news reports. After the preprocessing tags words or phrases with their POS information, the Named Entity Recognition extracts elements according to the POS information.

Here we extract six kinds of information and put them into a structure:  struct NameEntity{ vector<WORD_CN> Time;// ?/t? tag for time vector<WORD_CN> Location;//?/ns? tag for China, ?/nsf?  for foreign countries vector<WORD_CN> Name;//?/nr? tag for names of  people, vector<WORD_CN> Organ;//?/nt? tag for names of  organizations vector<WORD_CN> Nouns;//?/n? tag for nouns vector<WORD_CN> Verbs;// ?/v? tag for verbs.

}; Where ?WORD_CN? is a customized structure that stands  for a Chinese word.

The pseudo-code for the implementation of the named entities extraction is shown in Algorithm 1.

Algorithm 1: Extract Entities 1: input <-- set of Chinese words with POS  tags 2: output <-- set of named entities 3: for each entity (time, location, name,  organization, nouns, verb){ 4:   for each word (text){ 5:     if word is an instance of entities 6:     then{ 7:       if this word is not involved 8:       then add this word to the set of  named entities 9:       else discard this word 10:     } 11:   } 12: }  All these extracted words or phrases are then transformed in sequence of time, location, name of people, name of organization and event, where the event is a string of nouns and verbs with a same word sequence as in the original document. These documents are the final input of SCT-NER algorithm in this paper.

Here is an example of how a snippet of news report is processed. The snippet is: ?  ? After the word segmentation, the sentence is cut into words and labeled with POS tag:?  /nt, /t, /t, /v, /ns, /ns, /v   3/m, /q, /n, /v, H7N9/n,  /n, /n, /m, /n, /vi?, note that stop words and punctuations are already removed. Then the named entities are extracted and transformed into a new sentence in sequence of time, location, name of people, name of organization and event. The result is: ?time{ }; location{  }; name of people{ }; name of organization{ }; event{  }?.

B. Improvements of Suffix Tree Model We can see from the Figure 1 that the suffix tree model  uses a path definition while constructing the tree. The contents of a substring are labeled on the path from root to the leaf, in other words, edges between nodes in the suffix tree model.

Each suffix of a string S corresponds to exactly on path from the tree?s root to a leaf. This may look good but it is hard to manipulate. In this paper, we put all these labels into the corresponding node. Each node is seen as a storage unit, together with all the necessary information like document index number, start point of substring, child node pointer and so on, which makes it easier to construct the tree model, traverse the tree and operate the node.

The structure of each node contains four main elements (see Fig. 4):   Fig. 4.  Node structure of suffix tree  ? Node label: it stores the content of a substring, in other words, the corresponding content of the string S.

? Document index label: this is an array of variable length. Each element in this array is the label of a document which contains substring of this node.

? Start point of substring: it is used to mark the start point of the substring in the string S. The substring is stored in the node label mentioned above. In order to find a substring more quickly, the start point of a substring is the start position in the original string before preprocessing.

? Child node pointer: this is an array of variable length. Each element in this array is a pointer that point to a node in the next tier. Note that each node itself is a pointer too.

Fig. 5 shows the improved suffix tree model with document ?ABDCABCD? based on the new node structure.

This model has the advantage over the conventional suffix tree clustering algorithm as following:    Fig. 5.  The structure of improved suffix tree model  ? Change node string from edge label to node storage.

We use node definition instead of path definition for flexibility in clustering operations. Besides, Each node contain all the information needed in the process of clustering, which facilitated for users to traverse the suffix tree.

? We transform the data structure of the suffix tree model into linked nodes. To traverse the whole suffix tree, we start from the root node, and look into every node that the child node pointer point to.

When build the suffix tree, we need not a fully depth traverse. If the node label in a node does not match the substring from the beginning, then all its sub nodes will not match too. This can save a lot of time and operation for traversing.

C. Merging base clusters Each node of the suffix tree represents a group of  documents and a phrase that is common to all of these documents. Therefore each node is a base cluster. Before merging two base clusters, we use the same method as defined in the Zamir and Etzioni paper and we found the threshold ? = 0.8 is appropriate to conduct the document clustering.



IV. EXPERIMENT EVALUATION  We implemented STC-NER algorithm in C++ on a Windows PC with a Core2 Duo 3.0GHz processor and 2GB memory.

A. Data sets Two groups of data sets are used to conduct the  experiments. One group is news reports with similar themes and the other is news reports within same time period. All these documents are snippets of news reports from news search engine like Baidu News and Google News and are  written in Chinese. We also merged the duplicated items. They are different in terms of documents sizes, cluster sizes, number of classes. The detail information of these textual resources is lists in the tables below:  TABLE I. DATA SETS OF NEWS REPORTS IN CHINESE WITH  SIMILAR THEMES  Data Set  Theme (Query)  Number of  Classes  Number of Documents Details of classes  A1   3 28     A2  2 25 3 16  4 9  A3    2 18    A4   2 18   TABLE II. DATA SETS OF NEWS REPORTS IN CHINESE WITHIN SAME TIME  PERIOD  Data Set  Time Period  Number of  Classes  Number of Documents Details of classes  B1 3.29~3.31 2 31  3 16  B2 3.29~3.31 3 39     B3 3.29~3.31 4 55     3 16  B. Evaluation of preprocessing We introduced the procedure of entities extraction by means of named entity recognition. The whole preprocessing steps including: word segmentation, stop words and symbols removal, entities extraction. We monitored the number of words as the input of constructing the suffix tree model. Fig. 6 shows a remarkable decline in the number of words in the Suffix Tree Model.

0.00  500.00  1000.00  1500.00  2000.00  2500.00  A1 A2 A3 A4 B1 B2 B3  N um  be r o  f w  or ds  Documents Sets  STC-NER  STC    Fig. 6.  The number of key words in the model of the STC-NER vs. the STC  The less the words there are in the suffix tree model, the faster the algorithm performs. We can see from the figure that the STC-NER reduces about 40% of total number of words in the suffix tree model.

C. Evaluation method of clustering algorithm To evaluate the effectiveness of the STC-NER algorithm,  we use F-measure value to the quality of the clustering result.

The F-measure is a harmonic combination of the precision and recall values used in information retrieval [19].It is commonly used in evaluating the effectiveness of clustering and classification algorithms.

F-measure evaluates the result of clustering with the idea of considering both the precision P(i , j) and recall R(i , j) of each cluster j for class i. The definition of precision and recall are:  P(i , j) = Nij / Ni  R(i , j) = Nij / Nj where Nij is the number of documents of class i that are  included in cluster j; Nj is the number of documents in cluster j; Ni is the number of documents in class i.

The definition of corresponding F-measure F(i , j) is:  ???? ?? ? ? ?? ? ???? ?? ? ???? ??? ????? ?? ? ???? ???? Then, the F-measure for the whole clustering result is  defined as:  ? ? ???? ? ??? !"? ?#$??%?? $    where n is the total number of documents in data set. In general, the larger the F-measure is, the better the clustering result is [20]. Fig. 7 shows the improvements in F-measure.

Fig. 7.  F-measures of STC-NER vs. STC

V. CONCLUSION  In this paper we propose a new text document clustering algorithm named STC-NER, which stands for Suffix Tree Clustering with Named Entity Recognition. This algorithm is supposed to cluster news reports written in Chinese returned from news search engine. Due to the characteristics of news reports, we import the method of entities extraction by means of named entity recognition into the document preprocessing.

This helps to reduce the high dimension of the documents by reducing the number of key words. After the preprocessing, number of nodes in the suffix tree model decreases, which makes the algorithm more effective.

As the STC algorithm was proposed for clustering English documents, we adapt Chinese words segmentation to make the algorithm suitable for Chinese documents as well. The Chinese words segmentation is accomplished with the open source tool NLPIR. In this way all documents written in Chinese are also treated as strings and they are appropriate for the STC algorithm.

We also proposed a new structure for the suffix tree model by moving labels of the string from edges to the nodes. Each node is a storage unit, together with all the necessary information like document index numbers, start point of substrings, child node pointer and so on. This facilitates the traversing and operation of the algorithm.

During the experiments, we found that the threshold 8.0=?  is appropriate to conduct the document  clustering. We used two groups of data sets to conduct the experiments. We can see from the results that our STC-NER algorithm gets better performance than conventional STC algorithm in both precision and efficiency when clustering news searching results returned by the search engines.

ACKNOWLEDGEMENT  This research was supported by National 863 Program (No. 2011AA01A204), P. R. China.

