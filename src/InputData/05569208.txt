

Abstract?This FDM algorithm is a fast algorithm of distributed mining of association rules. However, the algorithm is designed under the condition of non shared resource; therefore the cost of the algorithm is great. Moreover, the important information at every site is exposed to other sites that is opposite to the nowadays trend of attaching importance to privacy preserving increasingly. In order to improve FDM algorithm, a novel strategy is proposed: to compute the total support count with the method of privacy preserving, meanwhile to ensure the source of every local large item-set and local support count is covered, thus to preserve the privacy of the data distributed at sites. The efficiency and effectiveness of the proposed method have been validated by the experiments based upon some public data sets.

Keywords-distributed data mining; FDM; privacy preserving

I. INTRODUCTION Count Distribution (CD) and Data Distribution (DD)  algorithms have been developed by Agrawal [1] in 80?s of last century for effectively distributed mining of association rules and the communication complexity to compute global support count of a large item-set by means of these two algorithms is  which is relatively great. In 90? of last century, Fast Data Mining (FDM) algorithm has been developed by D.W.Cheung which is much improved comparing with CD algorithm. In FDM algorithm, local pruning is performed for every locally large item-set before locally large item-sets broadcasted to all sites, which makes unuseful locally large item-sets greatly decreased, spending of memory reduced and efficiency of algorithm increased accordingly. Moreover, communication complexity to compute global support count of a large item-set is cut down to ) through introducing into Hash function in [2].

)( 2nO  (nO  However, FDM algorithm was designed under the condition of non shared resource, namely the network framework of topology is formed between all sites in [3] and local large candidate item sets are broadcasted to all sites that results into the exposure of important information of every site in the distributed system and disbennifit to privacy preserving.

Therefore, it is indispensable to discuss how to make up this defect of FDM algorithm. An improved strategy is proposed here which computes global support count with the method of privacy preserving, and ensures the source of every locally large item-set and local support count is covered, thus preserves the privacy of the data distributed in all sites.



II. DESCRIPTION OF THE IMPROVED STRATEGY Nowadays with the increasing access to information in  electronic format or from web, as well as more and more tools for data mining coming into being, people appeal to privacy preserving urgently in [4]. Singularly high privacy preserving is required in some fields of data mining, especially in the field of finance, medical treatment etc. For instance, to analyze the incidence of a disease, it needs for several hospitals to integrate and analyze the information held by their own, but in practice, the hospitals are unwilling to share the information for the reason of protecting privacy of patients or for other reasons.

Thus, in some fields, privacy preserving becomes the important index to evaluate the system of distributed data mining. in [5] As far as the defect of FDM algorithm concerned, since it was designed under the condition of non shared resource, the topology of network causes one site to expose its own information to other sites. Accordingly, the stress of this paper would be put to adding the function of privacy preserving to classical FDM algorithm that may help prevent revealing important data and improve the performance of the algorithm.

Depending on partition of data, distributed mining of association rules can be classified into two types: horizontally partitioned and vertically partitioned. in [6-11] FDM algorithm is on the base of horizontally partitioned data and correspondingly the theory of privacy preserving in horizontally partitioned data mining is that ensure locally large item-sets are accessible to local sites but inaccessible to other sites. Hereby the motive of introducing privacy preserving in this paper, namely the problems needed to be solved is as follows.

1) Ensure the locally large item-set and local support count is covered to other sites.

2) Compute the global support count.

In the first place, secure set union is proposed to adopt. By means of encrypting, re-encrypting and permuting encrypted items at every site, the local large item-set and local support count could be transferred between sites and the tracing of source of original data could be prevented well.

Secondly, secure sum could be adopted to solve the second problem. In detail, a home site is proposed to set up, then it is proposed to compute a certain function from the home site to other sites with the privacy input into this function, return the ultimate function value to the home site, decrypt the returned  This work was sponsored by the Graduate Innovation Fund of Chongqing Jiaotong University, Chongqing, China.

function value at the home site according to the original privacy input, and obtain the secure sum finally, i.e. global support count.



III. TECHNIQUE OF PRIVACY PRESERVING FOR FDM ALGORITHM  On the one hand, in classical FDM algorithm, the locally large item-sets need to be broadcasted to other sites after the local pruning so that the global support count of these locally large item-sets could be computed. In order to ensure the information of local site such as locally large item-sets and local support count could not be aware to other sites, secure set union is suggested to introduce into the algorithm.

Secure set union is a method of privacy preserving in data mining, through which the information of local site such as rules, locally large item-sets etc. can be broadcasted in distribution system, but owners of broadcasted information can?t be exposed. Theoretically, secure set union executes its function basing on the thought of permuting encrypt item.

Figure 1 shows the principle to set up secure set union.

))(( 32 CEE ))(( 32 DEE                             )(1 CE  C D)(3 CE  )(3 DE  )))((( 132 CEEE                                                                   ))(( 13 CEE  Figure 1. Determining the union of the set of items  If given key 1,... nK K K , for any permutation , the following two equations hold:  ,i j  (1) 1 1 (... ( )...) (... ( )...)  i in j jnK K K K E E M E E M  2121 ,, MMMMM , given arbitrary kk 2 1, , s.t   1 11  ( (... ( )...) (... ( )...)) i in j jnr K K K K  P E E M E E M 2           (2)  By introducing the secure set union, each site encrypts the local data and transfers it to other sites, then each site re- encrypt data received from other sites. Accordingly to equation 1 and equation 2, duplicates in the original items will be duplicated in the encrypted items, and can be deleted. In addition, the decryption can occur in any order. Consequently,  by permuting the encrypted items, it is prevented that each site tracks the source item-sets.

Through this method of secure set union, each site could transfer the information of locally large item-sets and local support count etc., without revealing which information from which site. However during the course of data transfer, the number of locally large item-sets is revealed which exists in two sites. For example, if K site have a locally large item-set, it will be duplicated k times. Although the item-set itself is not revealed, the true secure computation could not reveal this information. In practice, allowing innocuous information leakage in an algorithm means lower cost than the algorithm with fully secure computation.

On the other hand, we would like to compute the global support counts and ensure the local supports of each site could not revealed to other sites as well. This can be easily fulfilled by the method of secure sum.

If given sites1, 2,...s , first a home site(site No.1) must to be determined; and site No.1 randomly produces a random R which ranges in [1  and will be added the local support count of site No.1, then transfers  , ]n  1 modR v n  to site  No.2; as R is a random ranging in , site No.2 could not obtain the real value of  after receiving the information of  [1, ]n  1v  1 modR v n ; similar mode to compute the function will be set up in remainder sites No. l  ( ) and now the  received function value in site No. l  is  ,  which will be added  (that is )  and transferred to site No. l ; ?; similarly the last site (site No. ) computes the function and returns the function value to site No.1 where decryption will be implemented according to the value of cryptically , global support count will be acquired and local support counts of other sites can?t be revealed. Figure 2 shows the principle to compute secure sum.

2... 1l s  mod  l  j j  V R v n  R  mod ( ) mod l  j j j  R v n v V n  s  R      19 !2R  17R   517                                                           0R Figure 2. The principle to compute secure sum  Theoretically, the method of secure sum will be confronted with problem if sites collude. For instance, site No. l 1  and  D  C  C  Site No.3  Site No.2 -5  Site No.1     site No.  could collude, then could confirm the real value of  by comparing the function values that they sent out and received. However one site could be threatened on privacy secure, unless all the other sites colluded. This makes it possible for secure sum to be used in our proposed strategy.

1l lv

IV. EXPERIMENT AND ANALYSIS Our proposed improved algorithm is test on some UCI  datasets. And the distributed system in the experiment is made of four personal computers which are deployed with the following hardware and software: CPU: Pentium(R) D CPU 2.80GHZ; Memory: 504MB; Operation System: Windows XP.

And Java was adopted as the programming language in the experiment.

The front 1400 records of dataset named Contraceptive Method Choice in UCI datasets are used in the experiment. We firs discretize an attribute named Wife's age, the original values of which are integers and range in [20, 50] (the values of other attributes are discretized originally and need not be discretized).

We suppose the data distributes symmetrically in each computer, namely the numbers of the data distributed in each site are approximately equal. Our scheme is described as: symmetrically distributing 1400 discretized records to each site, just 350 records per site. Table I describes some samples within records.

TABLE I. SOME SAMPLES0 WITHIN RECORDS  Code of  Attribute  No. of record  Name of  attribute  1 2 3 4 5  A Wife?s age 2 4 4 4 3  B Wife?s education 2 1 2 3 3  C Husband?s education 3 3 3 2 3  D Number of  children ever born  3 10 7 9 8  E Wife?s religion 1 1 1 1 1  F Wife?s now working? 1 1 1 1 1  G Husband?s occupation 2 3 3 3 3  H Standard of living index 3 4 4 3 2  I Mediaexposure 0 0 0 0 0  J Contraceptivemethod used 1 1 1 1 1  Among the above attributes, firstly, attribute A denotes wife?s age: 2 for 20~29 years old, 3 for 30~39 years old, 4 for 40~49 years old; secondly, attribute B denotes wife?s education level which ranges from low to high as: 1, 2, 3, 4; thirdly, attribute C denotes husband?s education level which ranges from low to high as: 1, 2, 3, 4; and attribute D is the statistic of number of children ever born; attribute E shows wife?s religion: 0 for non-Islam and 1 for Islam; attribute F figures whether wife is now working: 0 for working and 1 for not working; attribute G denotes husband?s occupation level which ranges from low to high as: 1, 2, 3, 4; in addition, attribute H depict standard of living index which ranges from low to high as: 1, 2, 3, 4; and attribute I shows media exposure: 0 for good and 1 for not good; last, attribute J shows way to contracept: 1 for never use, 2 for long-time use and 3 for short-time use.

Considering mobile agent is of self-determination, mobility and resource-saving, it well adapts to be introduced into distributed data mining. Accordingly, in our experiment, Aglets of IBM, an open source programming platform developed in Java language was used to create and dispatch mobile agents which can migrate from a start host to a destination host and execute tasks of data mining. We designed two kinds of agents in our experiment, AgentA and AgentB. AgentB is used to compute the global support counts and this kind of agent extends from Aglets class, takes its own algorithm of both privacy preserving and data mining. AgentA is used to compute the locally large item-set and similar with AgentA in framework except absence of algorithm of privacy preserving.

The framework of the AgentB class is as follows.

public class AgentB extends Aglet {  AgletID AgentBID;  URL currentHost;  // information of  datasource  String datasource;  //create a listener. MyListener is our original class which extends from MobilityListener class.

MyListener myListener=new MyListener();  public void onCreation() {  // initiate AgentB  }  public void AlgorithmB (){  // the algorithm of privacy preserving and data mining  }  public void run() {  // AgentB starts running from this  entry when migrating to destination host  }  public void handleMerssage(Message msg) {  // to handle message transfer     }  this.addMobilityListener(myListener);  public void onDisposing() {  // action when a AgentB is disposed  }  }  During the whole course of mining, the home site is in charge of creating, dispatching and retracting AgentA or AgentB to destination host. When task of the agent done, relevant agent will be disposed by home site.

A testing on effectiveness and efficiency of the proposed strategy was hold. Given min_sup=20%, min_conf=70%. We got average time of 10 times tested on experimented dataset respectively by classic algorithm and improved algorithm. And the experimental results are showed in Table II.

TABLE II. EXPERIMENTAL RESULTS ON EFFECTIVENESS TESTING  Table II shows a summary of computation results which verifies the effectiveness of the proposed strategy to improve FDM algorithm. For one thing, we have got the same large association rules by the improved algorithm as classical FDM algorithm. Furthermore, we have compared the efficiency of the improved algorithm to the classical one. Although the proposed strategy added algorithm of privacy preserving, the proposed strategy does cut short the computation time with home-site communication method replacing broadcast method.

Thirdly, through analysis, the communication complexity to compute global support count of a large item-set in proposed strategy is same as classical FDM algorithm, namely . Last but not least, the space efficiency of our proposed strategy is  lower than classical FMD algorithm because of additional space cost for algorithm of privacy preserving.

)(nO

V. CONCLUSION In this paper, we have discussed a strategy of privacy  preserving to improve FDM algorithm. To reduce time spent on communication and preserve privacy distributed in each site, computation method of privacy preserving has been adopted including secure set union and secure sun. Our test on UCI datasets proves that this method is rather suitable for practical fields particularly the field which needs severe privacy preserving in data mining.

