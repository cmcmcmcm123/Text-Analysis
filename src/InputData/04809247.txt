2009 IEEE International Advance Computing Conference (IACC 2009) Patiala, India, 6-7 March 2009

Abstract: - Association rules discovered by association includes a large number of transactions. Different from rule mining may contain some sensitive rules, which data modification, data reconstruction [7] is a new may cause potential threats towards privacy and promising method in dealing with the association rule security. In this paper, we address the problem of hiding problem. This approach is based on knowledge privacy preserving association rule mining by sanitization. Specifically, it hides the rules by sanitizing proposing a Knowledge Sanitization to prevent the itemset lattice called a knowledge base rather than disclosure of sensitive rules. We also present parallel sanitizing original dataset. Then a reconstruction approach to generate a non-sensitive and sensitive rule procedure reconstructs a new released dataset from the mining. Our proposed solution key issue is to provide a sanitized itemset lattice. In this way, data reconstruction high degree of parallelism for privacy to the data gives user a knowledge level window to control the owner. availability of rules handily and control the hiding  1. Introduction effects directly. Our approach is based on knowledge sanitization.

Association rule mining extracts novel, hidden and useful patterns from huge repositories of data. 2. Formulate the problem These patterns are useful for an effective analysis and decision making in corporation, marketing, business, Given a database D to be released with medical analysis, website linkages, financial minimum support threshold and minimum confidence transactions, health-care records and other applications. threshold, a set of rules R mined from D, and a set of The sharing of association rules can bring a lot of sensitive rules Rh C R to be hided, we need to advantages in industry, research and business construct a new data set D', such that the rules in Rh collaboration. At the same time, a huge repository of cannot be mined from D', while the rules in R-Rh can data contains private data and sensitive rules that must still be mined as many as possible.

be protected before sharing. On demand to various Two problems are addressed here: one is the mismatched requirements of data sharing, privacy protection of private data; another is the protection of preserving and knowledge discovery, privacy sensitive rules contained in the data. The former settles preserving data mining has become a research hotspot how to get normal mining results when private data in data mining. Simply, the association rule-hiding cannot be accessed accurately; the latter settles how to problem is to hide secret, sensitive association rules protect sensitive rules contained in the data from being contained in data from being discovered, while without discovered, while non-sensitive rules can still be mined losing non-sensitive at the same time. This problem normally.

motivated different authors [5, 6, 7] who proposed a number of algorithms to this problem. There have been 3. Proposed Framework two broad approaches: Data modification approaches and data reconstruction approaches. Data modification The framework is depicted in Figure 1. The [4] methods hide sensitive association rules by directly whole approach is divided into three phases: The first modifying original data. According to different phase is to use Fast Frequent Set Mining (FFSM) modification means, it can be further classified into the algorithm, to generate all frequent itemsets with their two subcategories: Data Distortion techniques and Data supports and support counts from original database D.

Blocking techniques. Data Distortion[3] is implemented This gives the set of association rules R. In the second by deleting or adding items to reduce the support or phase, we perform sanitization algorithm over R and get confidence of the sensitive rules, while data-blocking the sanitized frequent itemsets FFSM'. In the best case, is implemented by replacing certain items with a from FFSM', ensured from sanitization algorithm we question mark "?" to make the support and confidence get exactly the set of non-sensitive rules R-Rh, with no of the sensitive rules uncertain. As a traditional method, normal rules lost and no ghost rules generated. The data modification can operate simply. However, they third phase is to generate released database D' from suffer from the weakness of providing a way of fine- FFSM' by using inverse frequent set mining algorithm.

tuning the generation of the released database, which The fast frequent itemset mining algorithm and inverse makes that they cannot control the hiding effects frequent set mining algorithm are parallelized by using directly and clearly. Data sanitization can produce a lot Linux cluster environment.

Of I/O operations, especially when the original database  978-1T-4244-1888-6/08/f$25.OO Q 2008 IEEE 1538    D:-Original Data Base. 5. Parallel data mining in Linux Clusters FFSM: -Fast Frequent Set Mining algorithm.

R: -Set of Association rules (sensitive + Non sensitive). Challenging problems in engineering and Rh: - Set of Sensitive Association rules. information sciences typically require a lot computing FFSM':-Inverse Fast Frequent set Mining algorithm. power and Linux clusters are one of the solutions.

R-Rh:-only non sensitive rules. Linux clusters are less expensive and are scalable. Data D': -Reconstructed Data Base. mining applications require processing huge collections  of data and are computationally intensive. Hence these applications can be parallelized to reduce the time  r T |. a required to complete the calculations. A cluster of  _FFSM _ machines was built to use as a parallel processing D P_, R platform. Applications can be parallelized to reduce the  time required to complete the calculations. Parallelism can affect the execution time of data mining applications. Benefits of clusters are Lower cost, Scalability, Vendor independence, Adaptability, Reliability, Availability and Serviceability and Faster  Linux cluster nodes technology innovation.

Clusters are becoming increasingly popular as  computational resources both in research and Knowledge Sanitization commercial organizations. These organizations are  favoring clusters over single large servers for a wide variety of problems. Super computers being highly expensive and being less scalable. The increasing popularity of the Linux operating system is adding fuel  < FFSM ' 1 to this. Linux provides a very cost effective and open D'v R-Rh environment to build a cluster. The main motivation  factor is usually faster computation very simple idea that n computers operating simultaneously can achieve the result n times faster. Other motivation factors are: fault tolerance, larger amount ofmemory available, etc.

Linux cluster nodes U __rAppiator' PoullIle Prograrnmming Lib ra ry and Devekppreznt Tcls |  Fig. 1. Proposed Framework I_nernect NlsagIrg Protocol lntrcoonneck Hardiare (N5Cs, Swlteha and Cble|s)  4. Procedure Cluster Nodes  Begin Fig. 2. Layers in a typical Cluster Step 1: A cluster of n machines was built to use as a  parallel processing platform. 5.1 Fast Frequent set Mining algorithm Step 2: Use Fast Frequent set Mining algorithm to We introduce a new parallel algorithm PFPT  generate itemset with supports over original (Parallel Frequent Pattern Tree) for parallel mining of dataset D. (D 4 FFSM 4 R) frequent patterns, based on FP-growth mining[2], that  Step 3: Find all frequent itemsets from Database and uses only two full I/O scans of the database, eliminating generate corresponding association rules R. the need for generating the candidate items, and  Step 4: Identify sensitive frequent itemsets and select distributing the work fairly among processors. We have the hiding strategy. devised partitioning strategies at different stages of the  Step 5: Perform sanitization algorithm. mining process to achieve near optimal balancing Step 6: Next generate exactly the set of non-sensitive between processors. The PFPT approach we proposed  rules R-Rh from sanitization algorithm. consists of two main stages. Stage one is the (Sanitization i R-Rh) construction of the parallel frequent pattern trees (one  Step 7: Reconstructed database D' based on inverse for each processor) and stage two is the actual mining frequent set mining algorithm, of these data structures, much like the FP-growth  (R-Rh -)Inverse FFSM o D') algorithm.

End  2009 IEEE Inxternational Advanxce Computing Conference (IACC 2009) 1539    5.2 Knowledge Sanitization algorithm Each processor finds the local counts of each data item. Data item A, has 2 references, item 3 has  (1) Choosing hiding strategy: We would decrease three references say for example. The local counts of support of sensitive rule from current support, so that it each processor on each data item are shown in Table 3.

will not be mined from dataset with a minimal support threshold value. Counters (2) Configuring support values: We will find all the Item P P1 P2 subsets of sensitive rule. Then subtract their support, finding all supersets of sensitive rule, and then modify A 2 the support. After finding all subsets of superset B 3 3 2 excluding subsets of sensitive rule, their supports are C 1 0 0 modified accordingly. D 3 (3) After completion of Knowledge sanitization, use B 0 parallel frequent set mining algorithm to generate F 3 exactly the set of non-sensitive rules R-Rh.

G 2 3 1 5.2 Example H 0 1 1  K 0 0 1 Table 1 represents a transaction database D, having ()  nine transactions with 11 different items.

Tid Items Bought Table 3. Local Counts 1 A,B,C,D,E 2 F,B,D,E,G These local counts of each data item are 3 B,D,A,E,G summed which gives global count of each processor.

A,B,F,G,D Item A has a total of 7 references overall, which gives A,B,F,D,G,H the global count of it. We find Global count of all data  6 A,B,F,G,D items similarly. This is shown in Table 4  8 A,F,,A,DJ Proc. # Item Global counter 9 A,B,F,I,J A 7  Table 1. Original transaction database (D) D  In order to enumerate the frequent items E 3 efficiently, we divide the datasets among the available P1 F 6 processors. We consider three processor for example. G 6 Each processor is given an approximately equal number H 2 of transactions to read and analyze. In this original data K I base is horizontally partitioned into three parts and each P2 2 part is assigned to corresponding processors shown in 2 Table 2. So each processor is having three itemsets, Table 4. Global count which performs the given tasks similarly and parallely on pc clusters. Let us assume the Minimum Support threshold  value is 6. Items which are below the threshold value Tid Items Bought Processor are removed and which are equal to or above theNumber threshold value are retained. This levies A, B, D, F, and  tA.BC. E G to retain in the frequent items.

2 F,B,D,E,G PO  Item Global counter 4 A,B,F,G,D A 7 5 B,F,D,G,H P1 B 8 6 A,B,F,G,D D 7  7 AXBFJ GJQ,,,,Uf_'_1 A TN IDi F 6  Table 2. Divide the datasets Table 5. Frequent Items Frequent Item sets: FS  11540 2009 IEEE Internactionalz Advance Computing Conference (IACC 2009)    From Table 5 to find all possible Frequent Now after the sanitization, we have the Item sets (FS). frequent itemsets set FS' from which we get the set of  non sensitive association rules R-Rh shown in this Items Support Count Table 9.

7_  B 8 Rules Confidence % Support % D 7 B=> D 87 77 F 6 B=>F 75 66 G 6 B =>G 75 66 A,B 6 D=>G 75 66 B,D 7 Table 9. Association Rules: R-Rh B,F 6 B,G 6 Applying Inverse frequent set mining D,G 6 algorithm to find released database (D'), from this  database (D') we can not find sensitive rules shown in Table 6. Frequent Item sets: FS this Table 10.

From the frequent itemsets FS, we get six TID Items association rules shown in this table 7 1 B,D,F,G  2 G,F,D,B  Rules Confidence % Support 4 B,DG A=>B 75 66 5 F,D,B,G B=>D 87 77 6 F,D,B,G B=> F 75 66 7 G,B,D,F B =>G 75 66  Table 10. Released Database (D') LD=>G 75 66  5.4 Inverse frequent set mining algorithm Table 7. Association Rules: R  Use parallel Inverse frequent set mining algorithm Now let us suppose the first rule A=>B is a to reconstruct new database (D') from the sanitized  sensitive rule that needs hiding. So Applying frequent itemsets. First, we try to "guess" a FP-tree that Knowledge Sanitization algorithms to remove the satisfies the set of non-sensitive rules R-Rh. The whole A=>B rule we find the Frequent Itemsets (FS') shown process of the proposed method is the reverse process in this table 8. of the FP-tree-based frequent itemsets mining. If we  apply mining process on D', it generates the set of non- Rules Support Count sensitive rules R-Rh.

B 7 Inverse frequent set D 7 Mining algorithm FFSM F 6 G 6 BID 7 B,F 6    6. Experimental Results Experiments used 64 Linux cluster nodes of  Intel Pentium dual core with 2.80GHz and 2 GB of RAM (my institution laboratory environment) to conduct the experiments. The sizes of the input databases vary from 1 GB transactions to 50 GB. Each of these transactions has at least 2 items preceded by a unique transactional ID. The largest dataset is in the order of 512 bytes  Frequent Set Mining Result   * 2500  z 2000 w  z  D 1000U w x w 500  2 4 g 16 32 64  NO OF PROCESSORS  Fig. 4. Execution time  7. Conclusion  In this paper a Framework has been implemented for Fast and Scalable Privacy-Preserving Association Rule Mining. We have introduced an efficient parallel implementation of an FP-Tree-based association nule mining Algorithm on Linux clusters to achieve fast, scalability and preserve a high degree of accuracy in the mining results. Sanitization algorithm provides a high degree of privacy to the user. Our further research will focus on the optimal Knowledge Sanitization to improve degree of privacy.

8. References  [1] R. Agrawal, A. Evfimievski, and R. Srikant. Information sharing across private databases. In SIGMOD, 2003.

[2] J. Han, J. Pei, Y. Yin, and R. Mao. Mining frequent patterns without candidate generation: A frequent-pattern tree approach. Data Mining and Knowledge Discovery, 2003.

[3] Kargupta, H. Datta, S. Wang, Q. and Sivakumar K.: On the Privacy Preserving Properties of Random Data Perturbation on Data Mining (ICDM'03), Melbourne, Florida, USA, November 2003, pp. 99-106.

[4] Oliveira, S.R.M. and Zaiane, O.R. Protecting sensitive knowledge by data sanitization. In: Proc. of the 3rd IEEE Int'l Conf on Data Mining (ICDM'03). IEEE Computer Society, USA, 2003. 613-616.

[5] J. Vaidya and C. Clifton. Privacy preserving association rule mining in vertically partitioned data. In SIGKDD, 2002.

[6] Z.Wang, B. Liu,W.Wang, H. Zhou, and B. Shi. An effective approach for hiding sensitive knowledge in data publishing.

In WAIM, pages 146-157, 2006.

[7] Yuhong Guo, Reconstruction-Based Association Rule Hiding, Pzroceedings of SIGMOD2007 Ph.D. Workshop on Innovative Database Research 2007(IDAR2007), June 10, 2007, Beijing, China.

