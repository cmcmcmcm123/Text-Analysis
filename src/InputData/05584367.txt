?

Abstract?Data mining is a very active and rapidly growing research area in the field of computer science. Its goal is to obtain useful knowledge for users from a database. Association rule mining from a database is one of the most well-known data mining techniques. In general, a large number of if-then rules are extracted by specifying minimum support and confidence levels. They are, however, too complicated as knowledge for users to understand many rules at one time. Multiobjective genetic fuzzy rule selection from Pareto-optimal and near Pareto-optimal rules is a promising approach which can obtain an accurate and simple rule set by considering the accuracy maximization and the complexity minimization. In this paper, we propose two extensions of multiobjective genetic fuzzy rule selection for designing more accurate fuzzy rule-based classifiers. One extension is to add compatible rules with misclassified patterns into candidate rules for genetic fuzzy rule selection. The other is to tune membership functions after genetic fuzzy rule selection. We examine the effects of these extensions through computational experiments on imbalanced data sets.



I. INTRODUCTION SSOCIATION rule mining is one of the most well-known techniques in data mining. It finds all rules that satisfy  the given minimum confidence and minimum support levels.

A large number of rules are generated from a database. From the view point of human users, it must be very difficult to understand all the extracted rules at one time. That is, some pruning process is needed to choose a small number of interesting rules. A number of rule evaluation criteria which quantify the interestingness or goodness of a rule have been proposed. For example, gain, variance, chi-squared value, entropy gain, gini, laplace, lift, and conviction. It was shown in [1] that the best rule according to any of the above- mentioned criteria is included in the Pareto-optimal rules with respect to the maximization of confidence and support. In some recent studies [2], [3], association rule mining has been applied to the design of accurate fuzzy rule-based classifiers.

In [4], we proposed genetic fuzzy rule selection from the Pareto-optimal rules to obtain simpler but more accurate classifiers than classifiers with all Pareto-optimal rules.

Our genetic fuzzy rule selection is a simple two stage method for designing fuzzy classifiers [4]-[9]. In the first stage, a large number of short fuzzy rules are generated. The   Y. Nojima, Y. Kaisho, and H. Ishibuchi are with the Department of  Computer Science and Intelligent Systems, Osaka Prefecture University, Sakai, Osaka 599-8531, JAPAN. (phone: +81-72-254-9198; fax: +81-72- 254-9915; e-mail: nojima@cs.osakafu-u.ac.jp, kaisho@ci.cs.osakafu-u.ac.jp, hisaoi@cs.osakafu-u.ac.jp).

short rule means that the rule has a few antecedent conditions.

In [8], [9], Pareto-optimal and near Pareto-optimal rules are chosen among the generated rules based on the ?-dominance relation with respect to the confidence and support of each rule. The chosen rules are referred to as candidate rules. In the second stage, we apply a genetic algorithm to a combinatorial optimization of the candidate rules. We use two criteria: accuracy maximization and complexity minimization.

Although we successfully obtained simple and accurate classifiers by our method, the accuracy was not always high for some data sets, especially class imbalanced data sets.

In this paper, we propose two extensions of our genetic fuzzy rule selection for designing more accurate classifiers.

One extension is to add compatible rules with misclassified patterns into candidate rules for genetic fuzzy rule selection.

The other extension is to tune membership functions after genetic fuzzy rule selection. We examine the effects of the proposed extensions through computational experiments on imbalanced data sets.

This paper is organized as follows. In Section II, we briefly explain fuzzy if-then rules for pattern classification problems, and Pareto-optimal rules. We also explain genetic fuzzy rule selection for the design of fuzzy rule-based classifiers. In Section III, we propose the above-mentioned two extensions of genetic fuzzy rule selection. We examine the effects of the proposed extensions through computational experiments in Section IV. Finally, we conclude this paper in Section V.



II. ASSOCIATION RULE MINING AND GENETIC FUZZY RULE SELECTION FOR DESIGNING FUZZY CLASSIFIERS  A. Fuzzy If-then Rules Let us assume that we have m training (i.e., labeled)  patterns xp = (xp1, ?, xpn), p = 1, 2, ?, m from M classes in the n-dimensional continuous pattern space where xpi is the attribute value of the p-th training pattern for the i-th attribute (i = 1, 2, ..., n). For the simplicity of explanation, we assume that all the attribute values have already been normalized into real numbers in [0, 1].

For our n-dimensional pattern classification problem, we use fuzzy rules of the following type:  Rule Rq: If x1 is Aq1 and  ...  and xn is Aqn then Class Cq with CFq,   (1)  where Rq is a rule label, x = (x1, ?, xn) is an n-dimensional pattern vector, Aqi is an antecedent fuzzy set (i = 1, 2, ?, n), Cq is a class label, and CFq is a rule weight.

Accuracy Improvement of Genetic Fuzzy Rule Selection with Candidate Rule Addition and Membership Tuning  Yusuke Nojima, Member, IEEE, Yutaka Kaisho, and Hisao Ishibuchi, Senior Member, IEEE  A          We simultaneously use multiple fuzzy partitions with different granularities in fuzzy rule generation. We use four homogeneous fuzzy partitions in Fig. 1 (i.e., 14 triangular fuzzy sets). We also use a domain interval [0, 1] as an antecedent fuzzy set to represent a don?t care condition. That is, we use the 15 antecedent fuzzy sets in total.

0 1   M em  be rs  hi p  Input value 0 1   M em  be rs  hi p  Input value  0 1   M em  be rs  hi p  Input value 0 1   M em  be rs  hi p  Input value  S2 L2  S5 ML5SM5 L5M5S4 ML4SM4 L4  S3 L3L3   Fig. 1.  Four fuzzy partitions used in our computational experiments.

The consequent class Cq and the rule weight CFq of each fuzzy rule Rq can be specified in a heuristic manner by compatible training patterns with the antecedent part of Rq.

For details, see [10], [11].

Since we use the 15 antecedent fuzzy sets for each attribute of our n-dimensional pattern classification problem, the total number of possible fuzzy rules is 15n. For high-dimensional data sets, the total number of possible fuzzy rules becomes quite large. Moreover, it is very difficult to intuitively understand long fuzzy rules with many antecedent conditions.

Thus, we generate short fuzzy rules with only a small number of antecedent conditions. In this paper, we examine short fuzzy rules of length Lmax or less (e.g., Lmax = 3) in order to generate understandable fuzzy rules as candidates in fuzzy rule selection. It should be noted that the length of a fuzzy rule is defined by the number of its antecedent conditions excluding don?t care. This limitation on the rule length also leads to short computation time for rule generation. It is much faster than GA-based optimization and tuning processes.

Instead of specifying the maximum rule length, identifying the relevant variables for each data set may be a good alternative approach (e.g., [12]).

B. Pareto-optimal and Near Pareto-optimal Rules In the data mining field, two rule evaluation criteria called  confidence and support are frequently used to measure the goodness of rules. Confidence and support of rules for data with quantitative attributes are calculated by using fuzzy sets.

Let us assume that we have m training patterns xp. The confidence of the rule Rq for class h is defined as follows:  ?  ? ??  ?  ?  m  p p  h p  q  q  p q  hconf   Class  )(  )( )Class(  x  x A  A  x A  ?  ? ,      (2)  where )( pq xA? is the membership value of the pattern xp to the antecedent part Aq = (Aq1, ..., Aqn). It is calculated with the  product operator as:  )()()( 11 pnApAp xx qnqq ??? ??? ?xA ,      (3)  where )(? qiA?  is the membership value to the Aqi .

The confidence conf (Aq ? Class h) is the ratio of compatible patterns with both the antecedent part Aq and the consequent class h to compatible patterns with the antecedent part Aq. The confidence conf (Aq? Cq) measures the validity of the linguistic association rule Aq? Cq. The confidence can be viewed as the fuzzy conditional probability of class Cq.

In the same manner, support of the rule Rq for class h is defined as follows:  m hsupp  h p  q p  q?  ?? ?Class  )(  )Class( x x  A A?  .     (4)  The support supp(Aq? Class h) is the ratio of compatible patterns with both the antecedent part Aq and the consequent class h to the given m training patterns. The support supp(Aq? Cq) measures the covered rate of training patterns by the linguistic association rule Aq ? Cq. In the same manner, the coverage covr(Aq? Class h) is calculated as:  h  h p  q m hcovr p  q? ??  ?Class )(  )Class( x  A x A  ? ,     (5)  where mh is the number of patterns in the class h. In this paper, we use coverage instead of support. This is because the range of support values is often very different among the classes for imbalance data sets.

We generate all the possible rules of length Lmax or less. If the confidence and coverage of the generated rules are smaller than the minimum confidence and coverage levels, they are removed. Among the remaining rules, Pareto- optimal and near Pareto-optimal rules with respect to the maximization of confidence and coverage are extracted.

In order to handle not only Pareto-optimal rules but also near Pareto-optimal rules, ?-Pareto-optimal rules using a dominance margin ? are defined [8]. Fig. 2 shows (a) Pareto-optimal rules and (b) near Pareto-optimal rules in the confidence-coverage space. Each circle represents a rule. A red line in Fig. 2 (a) indicates a Pareto front.

Confidence  C ov  er ag  e  ?conf  ?covr  Confidence  C ov  er ag  e   (a) Pareto-optimal rules               (b) Near Pareto-optimal rules  Fig. 2.  Example of the distribution of Pareto-optimal and near Pareto-optimal rules with the dominance margin ?.

A rule Ri is said to be ?-dominated by another rule Rj when at least one of the following two conditions are satisfied:  covr(Ri) ? covr(Rj) + ?covr?? and  conf (Ri) ? conf (Rj) + ?conf, (6)  covr(Ri) ? covr(Rj) + ?covr?? and  conf (Ri) ? conf (Rj) + ?conf, (7)  where ?conf and ?covr are the ? margins for confidence and coverage, respectively. To adjust the ranges between confidence and coverage, ?covr is calculated as:  conf kk  kk covr RconfRconf  RcovrRcovr ??  )(min)(max )(min)(max  ? ?  ? .    (8)  When a rule Ri is not dominated by any other rules in the sense of ?-dominance in (6), (7), we refer the rule Ri as an ?-Pareto-optimal rule. We remove weak Pareto-optimal rules with the highest confidence (i.e., 1.00) and small coverage as in [8] because good results were obtained by removing them (i.e., to reduce the search space for rule selection).

C. Classifier Design by Genetic Fuzzy Rule Selection In order to obtain simple and accurate classifiers, we use  multiobjective genetic fuzzy rule selection. Let us assume that we have already extracted N rules by the association rule mining technique explained in the last section. Each binary string of length N is represented as NssssS ???? 321  where si = 1 and si = 0 mean that the i-th candidate rule is included in and excluded from the rule set S, respectively.

Since any subsets of the N rules are represented by binary strings, we can use almost all evolutionary multiobjective optimization algorithms. In this paper, we use the NSGA-II algorithm [13] because it is a well-known high-performance EMO algorithm. Let P be the current population in NSGA-II.

The outline of NSGA-II can be written as follows:  1: P = Initialize(P) 2: while a termination condition is not satisfied do 3:  P? = Selection(P) 4:  P?? = Genetic Operations(P?) 5:  P = Replace(P?P??) 6: end while 7: return non-dominated solutions (P)   First, an initial population is generated in Line 1. In Line 3, parent individuals (i.e., P?) are selected from the current population P. The standard binary tournament selection is usually used to choose a pair of parent individuals. In Line 4, an offspring population P?? is generated from the parent population P? by uniform crossover and biased mutation. The biased mutation changes 0 to 1 with a small probability and 1 to 0 with a large probability to decrease the number of 1?s in each offspring. In Line 5, the best individuals are chosen from the merged population (P ? P??) to construct the next population P. For details of NSGA-II, see [13].

We use the following two objectives to find an accurate and simple fuzzy classifier S:  f1(S): The arithmetic average of the classification rate for each class by S,  f2(S): The number of selected fuzzy rules in S.

Genetic rule selection is formulated as follows:  Maximize  f1(S)  and  minimize  f2(S).       (9)  We use a single winner-based (i.e., winner-take-all) classification method. A single winner rule is identified by using the product of the compatibility grade and the rule weight CF of each fuzzy rule. Each CF value is not changed during genetic rule selection.

Since we use the single winner-based classification method, some rules may be used for the classification of no training patterns. Whereas the existence of such an unnecessary rule in the rule set S has no effect on the first objective (i.e., the arithmetic average of the classification rate for each class), it deteriorates the second objective. Thus we remove all the unnecessary rules responsible for the classification of no training patterns before calculating the second objective.



III. TWO EXTENSIONS FOR ACCURACY IMPROVEMENT We propose two extensions of genetic fuzzy rule selection:  candidate rule addition and membership function tuning.

A. Candidate Rule Addition For class imbalanced data, the classification accuracy is  often very worse. The reason may be that the necessary rules for correctly classifying patterns of a minority class are not extracted as candidate rules for genetic fuzzy rule selection.

This means that there is no possibility to improve the accuracy for the minority class even if we found the optimal combination of candidate rules.

To handle this issue, we propose a candidate rule addition procedure which adds compatible rules with misclassified patterns into candidate rules. The procedure is as follows: Step 1: A number of rules are generated from numerical data  under the condition on the maximum rule length, the minimum confidence and coverage levels. Let us refer to the generated rules as R.

Step 2: ?-Pareto optimal rules are extracted from R. Let us refer to these rules as RPareto.

Step 3: Pre-classification of all the training patterns is performed by RPareto.

Step 4: Rules compatible with misclassified patterns are extracted from R\RPareto. A single rule is extracted for each misclassified pattern. Let us refer to the additional rules as Radd.

We use RPareto and Radd as candidate rules of our genetic fuzzy rule selection.

As a rule addition criterion, we examine the following two cases in this paper.

EC: For each misclassified pattern, we add a rule with the         same class as that of the pattern and with the highest compatibility grade to the pattern.

ECW: For each misclassified pattern, we add a rule with the same class as that of the pattern and with the highest product value of the compatibility grade and the rule weight.

B. Membership Function Tuning A number of membership function tuning techniques have  been already proposed in the literature [14]-[17]. In this paper, we employ genetic lateral tuning [14], [15] after genetic rule selection. We show the example of lateral tuning in Fig. 3.

The vertex of the membership function is originally on x = 1/3 in the unit space [0, 1] (i.e., it corresponds to SM4 in the fourth granularity in Fig. 1). The vertex of the membership function is laterally movable between 1/6 and 1/2 in genetic lateral tuning.

Genetic lateral tuning does not lose the structure of the linguistic labels initially defined because the prespecified shape of the membership functions is preserved and the vertexes of the adjoining membership functions are not overlapped, see more details in [14], [15].

0 1/2 11/31/6 Fig. 3.  The movable area of a membership function.

We apply a single-objective genetic algorithm with real coding to the genetic lateral tuning. We tune the set of 14 fuzzy sets for each attribute in the classifier obtained by genetic fuzzy rule selection. That is, each string length is 14? (the number of attributes).

The objective function in the genetic lateral tuning is the same as f1(S) of NSGA-II. Fig. 4 illustrates the genetic lateral tuning procedure. Each square plot represents a non- dominated classifier obtained by genetic rule selection. We perform the genetic lateral tuning for each non-dominated classifier obtained by genetic rule selection. Each circle represents a newly obtained classifier by the genetic lateral tuning from the classifier of the closed square. A closed circle means the best classifier among the new classifiers. After the genetic lateral tuning for all the non-dominated classifiers, we choose a classifier with the best training data accuracy.

An initial population is generated by uniformly distributed random values within each movable area. One individual has the same values as the original vertex position. Tournament selection, BLX-? crossover (? = 0.1) and uniform mutation are used as genetic operations in our experiments.

The CF value of each rule is specified as the original one and not changed by the genetic lateral tuning. The adaptation of the CF value during the genetic lateral tuning can be interesting alternative method.

Rule 1  Rule 2  Rule 3  Rule 4  Class 1  Class 2  Class 3  Er ro  r  Number of rules  Class 4   Fig. 4.  Illustration of genetic lateral tuning.



IV. COMPUTATIONAL EXPERIMENTS In our computational experiments, we used two-class data  sets shown in Table I. Some of the data sets are generated from original data sets with more than two classes available from UCI Machine Learning Repository. Table I shows the number of patterns, the number of attributes, and the imbalance ratio for each two-class data. ?bal1? was also examined, but we eliminated this data set because we could not generate any minority class rules under the condition of the maximum rule length specified in this experiment. The imbalance ratio is the number of patterns of a majority class divided by that of a minority class.

TABLE I  DATA SETS USED IN OUR COMPUTATIONAL EXPERIMENTS  Data set Number of patterns Number of attributes  Imbalance ratio  bal0 625 4 1.17 bal2 625 4 1.17  glass1 214 9 1.82 pima 768 8 1.87  glass0 214 9 2.06 newt2 215 5 2.31  haberman 306 3 2.78 newt1 215 5 5.14 newt0 215 5 6.17 glass5 214 9 6.40 glass2 214 9 11.6 glass3 214 9 15.5 glass4 214 9 22.8   For rule extraction, we specified the minimum confidence  and coverage levels as 0.60 and 0.01, respectively. We examined the effects of four specification of the dominance margin ?conf, ?conf = 0.00, 0.01, 0.05, 0.10. The ?covr was calculated by (8).

The settings of computational experiments are as follows.

[Genetic Fuzzy Rule Selection] Population size: 200, The number of generations: 1000,         Crossover probability: 0.9, Mutation probability: pm(0?1) = 1/N  and  pm(1?0) = 0.1.

(N: the number of candidate rules)  [Lateral Tuning] Population size: 100, The number of generations: 100, Crossover probability: 1.0, Mutation probability: 1/L (L: the length of a string).

We examined the following six approaches:  Pareto:  Genetic rule selection with ?-Pareto optimal rules.

EC:  Genetic rule selection with ?-Pareto optimal rules  and additional rules according to the membership degree.

ECW:  Genetic rule selection with ?-Pareto optimal rules and additional rules according to the product of the membership degree and the rule weight.

Pareto*:  Pareto with genetic lateral tuning.

EC*:  EC with genetic lateral tuning.

ECW*:  ECW with genetic lateral tuning.

We performed the three times of the ten-fold cross validation procedure (3?10CV). We chose the classifier with the best training accuracy after genetic fuzzy rule selection in the case of Pareto, EC, ECW, and after genetic lateral tuning in the case of Pareto*, EC*, ECW*.

A. Experimental Results with ??= 0.0 Table II shows the average training data accuracy over 30  runs for each data set and the average training data accuracy over all the data sets. Although the average training data accuracy over all the data sets may be unfair statistics, we use this value for rough comparison among six approaches. Bold face indicates the best value in each row.

From Table II, we can see a clear positive effect of  candidate rule addition comparing Pareto with EC and ECW.

We can also see further improvement by genetic lateral tuning. The best training data accuracy was improved from 82.58 to 89.91 on average.

According to the recommendation by Dem?ar [18], we performed the Freidman?s test [19] to test the null hypothesis that all the approaches work equivalently on average.

Regarding the training data accuracy in Table II, the Friedman?s test rejected the null hypothesis. Each average rank is shown in Table II. A smaller rank value is better.

TABLE II  TRAINING DATA ACCURACY OF THE OBTAINED CLASSIFIERS (??= 0.0) Pareto EC ECW Pareto* EC* ECW*  bal0 93.51 96.33 97.92 96.23 97.50 98.72 bal2 93.50 96.42 98.03 96.17 97.74 98.88  glass1 71.02 77.72 79.28 81.79 88.80 89.18 pima 76.00 79.35 80.69 78.96 81.04 82.29  glass0 66.52 69.91 69.84 76.05 74.77 74.36 newt2 95.79 97.78 97.95 99.82 99.75 99.86  haberman 60.67 63.85 63.80 69.88 73.34 72.62 newt1 94.82 97.69 97.75 97.68 99.32 99.36 newt0 98.66 98.85 98.85 99.80 99.75 99.76 glass5 95.24 97.78 97.94 97.14 98.05 98.05 glass2 55.56 56.45 56.45 56.11 58.42 58.55 glass3 89.04 91.54 95.41 93.32 95.42 97.75 glass4 83.18 94.88 94.80 93.62 99.51 99.51  Average 82.58 86.04 86.82 87.43 89.49 89.91 Ave. Rank 6.00 4.15 3.54 3.77 2.15 1.38   Since the Friedman?s test rejected the null hypothesis, we  also performed pair-wise comparisons like Nemenyi?s test [20], Holm?s test [21], Shaffer?s test [22], and Bergmann and Hommel procedure [23]. We used the open source code   TABLE III  ADJUSTED P-VALUES OBTAINED BY NEMENYI?S TEST, HOLM?S TEST, SHAFFER?S TEST, AND BERGMANN-HOMMEL PROCEDURE FOR THE TRAINING DATA ACCURACY OBTAINED IN OUR COMPUTATIONAL EXPERIMENTS  i Hypothesis Unadjusted p pNeme pHolm pShaf pBerg 1 Pareto vs. ECW* 3.2 x10-10 4.8 x10-9 4.8 x10-9 4.8 x10-9 4.8 x10-9 2 Pareto vs. EC* 1.6 x10-7 2.4 x10-6 2.2 x10-6 1.6 x10-6 1.6 x10-6 3 EC vs. ECW* 0.0002 0.0024 0.0021 0.0016 0.0016 4 Pareto vs. ECW 0.0008 0.0119 0.0095 0.0080 0.0056 5 Pareto* vs. ECW* 0.0012 0.0173 0.0127 0.0116 0.0081 6 Pareto vs. Pareto* 0.0024 0.0355 0.0237 0.0237 0.0142 7 ECW vs. ECW* 0.0033 0.0500 0.0300 0.0237 0.0142 8 EC vs. EC* 0.0064 0.0963 0.0514 0.0449 0.0385 9 Pareto vs. EC 0.0119 0.1781 0.0831 0.0831 0.0475 10 Pareto* vs. EC* 0.0277 0.4156 0.1663 0.1663 0.0831 11 ECW vs. EC* 0.0592 0.8876 0.2959 0.2367 0.1183 12 EC* vs. ECW* 0.2945 1.0000 1.0000 1.0000 1.0000 13 EC vs. ECW 0.4017 1.0000 1.0000 1.0000 1.0000 14 EC vs. Pareto* 0.6002 1.0000 1.0000 1.0000 1.0000 15 ECW vs. Pareto* 0.7532 1.0000 1.0000 1.0000 1.0000         developed by Garc?a and Herrera [24]. Table III shows the adjusted p-values of those statistical tests. The statistical results also show the effectiveness of the proposed candidate rule addition and genetic lateral tuning.

Table IV shows the average number of rules in the obtained classifiers. From Table IV, we can see that each classifier has a very small number of rules. There are three interesting observations. One is that the number of rules was increased when we compared Pareto with EC and ECW. This means that the necessary rules were successfully added to the candidate rule set and selected by genetic rule selection.

Another interesting observation is that the number of rules was reduced after genetic lateral tuning. This is a positive side effect of genetic lateral tuning. The other interesting observation is that the number of rules decreased as the imbalance rate became larger. We need further investigation in a future study.

TABLE IV  NUMBER OF FUZZY RULES IN THE OBTAINED CLASSIFIERS (??= 0.0) Pareto EC ECW Pareto* EC* ECW*  bal0 8.3 14.8 25.5 6.5 12.3 24.5 bal2 8.0 14.8 27.5 4.6 12.5 25.8  glass1 6.0 10.3 11.2 5.1 8.8 9.8 pima 7.7 12.5 15.4 7.1 11.4 13.9  glass0 3.0 2.8 2.8 2.9 2.6 2.4 newt2 5.3 6.8 6.6 4.6 5.2 5.4  haberman 7.3 8.4 8.1 6.6 7.5 7.2 newt1 3.9 4.4 4.5 3.4 4.2 4.5 newt0 3.8 3.8 3.8 2.4 2.1 2.2 glass5 3.6 4.6 5.3 2.7 4.5 5.0 glass2 3.6 3.5 3.5 2.7 2.9 2.9 glass3 3.2 4.1 5.1 3.1 3.8 4.8 glass4 3.7 4.6 4.3 2.7 3.6 3.0     TABLE V TEST DATA ACCURACY OF THE OBTAINED CLASSIFIERS (??= 0.0)  Pareto EC ECW Pareto* EC* ECW* bal0 88.35 91.51 89.22 92.26 92.68 89.79 bal2 91.58 92.43 91.07 94.07 93.03 91.68  glass1 63.97 68.35 67.65 72.19 76.62 74.45 pima 73.99 72.14 73.51 74.19 73.36 72.28  glass0 62.85 68.10 68.04 70.75 73.40 72.53 newt2 94.77 92.48 92.98 97.09 96.44 95.57  haberman 55.48 57.30 56.75 59.76 60.20 60.37 newt1 95.28 95.56 94.86 95.19 97.04 96.67 newt0 96.14 93.36 95.03 96.31 96.03 96.59 glass5 93.53 93.05 93.14 92.05 91.10 93.69 glass2 49.62 49.15 48.90 49.40 50.44 50.56 glass3 80.71 81.26 83.59 81.76 87.00 82.32 glass4 69.46 82.17 78.99 72.17 88.32 91.58  Average 78.13 79.76 79.52 80.55 82.74 82.16 Ave. Rank 4.54 4.31 4.62 3.00 2.23 2.31  Table V shows the average test data accuracy over 30 runs for each data set and the average test data accuracy over all the data sets as Table II. From Table V, it seems that there is a less effect of candidate rule addition comparing the training data accuracy in Table II. On the other hand, we can see that genetic lateral tuning can improve the generalization ability for the test data. We performed the statistical tests in the same manner as the training data accuracy. The Friedman?s test rejected the null hypothesis. Thus, we performed Nemenyi?s test, Holm?s test, Shaffer?s test, and Bergmann-Hommel procedure. Table VI shows the adjusted p-values of those statistical tests. There are clear statistically significant differences between Pareto and all the approaches with genetic lateral tuning. We can also see that the combinational use of candidate rule addition and genetic lateral tuning can improve the generalization ability on the test data very well (e.g., see the p-values of Pareto vs. ECW* and Pareto vs.

EC*).

B. Comparison among Several the Dominance Margins We examined the effects of the dominance margin. Figs. 5  and 6 show the overall training data accuracy and test data accuracy over all the data sets. While a larger ? value improved the training data accuracy thanks to a larger number of candidate rules, the test data accuracy was not improved by the larger ? value. Comparing the results in the same ?, we can see a clear improvement by genetic lateral tuning for both training and test data accuracy.

Pareto EC  ECW Pareto*  EC* ECW*  0.00 0.01  0.05 0.10      ?  A cc  ur ac  y [%  ]   Fig. 5.  Average training accuracy over all the data sets.

Pareto EC  ECW Pareto*  EC* ECW*  0.00 0.01  0.05 0.10      A cc  ur ac  y [%  ]  ?   Fig. 6.  Average test accuracy over all the data sets.

Figs. 7 and 8 show the average rank for the training data  accuracy and the test data accuracy. We can observe almost all of the same effects of candidate rule addition and lateral tuning as in the case of ? = 0.0.

Pareto EC  ECW Pareto*  EC* ECW*  0.00 0.01  0.05 0.10      A ve  ra ge  ra nk  ?   Fig. 7.  Average rank for the training data accuracy over all the data sets.

A smaller rank is better.

Pareto EC  ECW Pareto*  EC* ECW*  0.00 0.01  0.05 0.10      A ve  ra ge  ra nk  ?   Fig. 8.  Average rank for the test data accuracy over all the data sets.

A smaller rank is better.

C. Comparison between Low and High Imbalanced Data We divided the data sets used in our experiments into two  subsets: Low imbalance data sets (IR < 3.0) and high imbalanced data sets (IR > 3.0). Figs. 9 and 10 show the average rank for the test data accuracy over the low imbalanced data sets and the high imbalance data sets, respectively. We can see that the positive effect of genetic lateral tuning became weaker as ? became larger for the low imbalance data sets. On the other hand, the approaches with candidate rule addition and genetic lateral tuning (i.e., EC* and ECW*) kept good ranking in almost all cases. This observation may indicate that the proposed extensions are effective especially for the high imbalanced data sets.



V.   CONCLUSION In this paper, we proposed two extensions of our genetic  fuzzy rule selection for designing more accurate classifiers.

One extension is to add compatible rules with misclassified patterns into candidate rules for genetic fuzzy rule selection.

The other extension is to tune membership functions by genetic lateral tuning after genetic fuzzy rule selection.

Experimental results showed that the candidate rule addition can improve the training data accuracy. This is because the possibility that the misclassified training patterns are classified by additional rules becomes high. Experimental results also showed that the genetic lateral tuning can improve the test data accuracy as well as the training data accuracy, since fuzzy membership functions are properly adjusted according to the pattern distributions. The combination of the proposed two extensions would be the best choice.

As a future study, we will examine the effects of the proposed extensions using a large number of data sets  TABLE VI ADJUSTED P-VALUES OBTAINED BY NEMENYI?S TEST, HOLM?S TEST, SHAFFER?S TEST, AND BERGMANN-HOMMEL PROCEDURE FOR THE TEST DATA  ACCURACY OBTAINED IN OUR COMPUTATIONAL EXPERIMENTS i Hypothesis Unadjusted p pNeme pHolm pShaf pBerg 1 Pareto vs. ECW* 3.1 x10-10 4.8 x10-9 4.8 x10-9 4.8 x10-9 4.9 x10-9 2 Pareto vs. EC* 1.6 x10-7 2.4 x10-6 2.2 x10-6 1.6 x10-6 1.6 x10-6 3 EC vs. ECW* 1.6 x10-4 0.0024 0.0021 0.0016 0.0016 4 Pareto vs. ECW 8.0 x10-4 0.0119 0.0095 0.0080 0.0056 5 Pareto* vs. ECW* 0.0012 0.0173 0.0127 0.0116 0.0081 6 Pareto vs. Pareto* 0.0024 0.0355 0.0237 0.0237 0.0142 7 ECW vs. ECW* 0.0033 0.0500 0.0300 0.0237 0.0142 8 EC vs. EC* 0.0064 0.0963 0.0514 0.0449 0.0385 9 Pareto vs. EC 0.0119 0.1781 0.0831 0.0831 0.0475 10 Pareto* vs. EC* 0.0277 0.4156 0.1662 0.1662 0.0831 11 ECW vs. EC* 0.0592 0.8876 0.2959 0.2367 0.1183 12 EC* vs. ECW* 0.2945 1.0000 1.0000 1.0000 1.0000 13 EC vs. ECW 0.4017 1.0000 1.0000 1.0000 1.0000 14 EC vs. Pareto* 0.6002 1.0000 1.0000 1.0000 1.0000 15 ECW vs. Pareto* 0.7532 1.0000 1.0000 1.0000 1.0000         including data sets with more than two classes. We also have to compare the proposed method with other learning algorithms. There are still a lot of things we have to improve in the proposed extensions, especially the search space and genetic operations in the lateral tuning. The discussion on the tradeoff relation among accuracy, complexity, and interpretability is also another important future research issue.

Pareto EC  ECW Pareto*  EC* ECW*  0.00 0.01  0.05 0.10      A ve  ra ge  ra nk  ?   Fig. 9.  Average rank for the test data accuracy over low imbalanced data sets.

A smaller rank is better.

Pareto EC  ECW Pareto*  EC* ECW*  0.00 0.01  0.05 0.10      A ve  ra ge  ra nk  ?   Fig. 10.  Average rank for the test data accuracy over high imbalanced data  sets. A smaller rank is better.

